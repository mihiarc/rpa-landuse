{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RPA Land Use Analytics","text":"<p>Welcome to the RPA Land Use Analytics documentation! This AI-powered analytics tool enables natural language exploration of USDA Forest Service 2020 Resources Planning Act (RPA) Assessment land use projections.</p> <pre>\n    ____  ____  ___       __                   __   __  __         \n   / __ \\/ __ \\/   |     / /   ____ _____  ____/ /  / / / /_______  \n  / /_/ / /_/ / /| |    / /   / __ `/ __ \\/ __  /  / / / / ___/ _ \\ \n / _, _/ ____/ ___ |   / /___/ /_/ / / / / /_/ /  / /_/ (__  )  __/ \n/_/ |_/_/   /_/  |_|  /_____/\\__,_/_/ /_/\\__,_/   \\____/____/\\___/  \n                    ___                __      __  _          \n                   /   |  ____  ____ _/ /_  __/ /_(_)_________\n                  / /| | / __ \\/ __ `/ / / / / __/ / ___/ ___/\n                 / ___ |/ / / / /_/ / / /_/ / /_/ / /__(__  ) \n                /_/  |_/_/ /_/\\__,_/_/\\__, /\\__/_/\\___/____/  \n                                     /____/                    \n</pre>"},{"location":"#what-is-rpa-land-use-analytics","title":"\ud83c\udf32 What is RPA Land Use Analytics?","text":"<p>RPA Land Use Analytics transforms the USDA Forest Service's 2020 Resources Planning Act Assessment data into actionable insights through:</p> <ul> <li>Natural Language Queries - Ask questions in plain English about land use transitions</li> <li>20 Integrated Scenarios - Explore projections across climate and socioeconomic pathways</li> <li>County-Level Detail - Analyze 3,075 US counties from 2012-2070</li> <li>AI-Powered Analysis - Modern agents understand context and provide intelligent insights</li> </ul>"},{"location":"#key-features","title":"\ud83c\udfaf Key Features","text":""},{"location":"#advanced-natural-language-interface","title":"Advanced Natural Language Interface","text":"<p>Powered by LangGraph and Claude/GPT-4, ask complex questions and get meaningful answers:</p> <pre><code>You&gt; Which RPA scenarios show the most agricultural land loss by 2070?\n\nAgent&gt; I'll analyze agricultural land transitions across all 20 RPA scenarios...\n\n\ud83d\udcca Analysis Assumptions:\n- Scenarios: Comparing all 20 climate-socioeconomic combinations\n- Time Period: Full projection period 2012-2070\n- Geographic Scope: All US counties\n</code></pre>"},{"location":"#comprehensive-rpa-scenario-analysis","title":"Comprehensive RPA Scenario Analysis","text":"<ul> <li>4 Integrated Scenarios: LM, HL, HM, HH combining climate and socioeconomic pathways</li> <li>5 Climate Models: Wet, Hot, Dry, Least warm, Middle projections</li> <li>Private Land Focus: Based on econometric model calibrated to 2001-2012 observations</li> <li>Development Irreversibility: Once urban, always urban assumption</li> </ul>"},{"location":"#interactive-streamlit-dashboard","title":"Interactive Streamlit Dashboard","text":"<ul> <li>Modern web interface with natural language chat</li> <li>Pre-built visualizations for key insights</li> <li>SQL query interface for advanced users</li> <li>Data export in multiple formats</li> </ul>"},{"location":"#example-rpa-queries","title":"\ud83d\udcca Example RPA Queries","text":"<p>Explore the 2020 RPA Assessment data with queries like:</p> <p>RPA-Specific Natural Language Queries</p> <ul> <li>\"Compare forest loss between the sustainability (LM) and fossil-fueled (HH) scenarios\"</li> <li>\"Which climate model shows the most urban expansion - hot or dry?\"</li> <li>\"How does agricultural land change differ between RCP4.5 and RCP8.5?\"</li> <li>\"Show me land use transitions in the South region under high growth scenarios\"</li> <li>\"What's the impact of the 'wet' climate model on crop to pasture transitions?\"</li> </ul>"},{"location":"#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<pre><code>graph LR\n    A[RPA JSON Data&lt;br/&gt;20M+ lines] --&gt; B[DuckDB Converter&lt;br/&gt;Star Schema]\n    B --&gt; C[Analytics Database&lt;br/&gt;5.4M transitions]\n    C --&gt; D[LanduseAgent&lt;br/&gt;Natural Language]\n    D --&gt; E[Streamlit Dashboard&lt;br/&gt;Web Interface]\n    E --&gt; F[User Insights]\n    F --&gt; E</code></pre>"},{"location":"#quick-start","title":"\ud83d\udea6 Quick Start","text":"<p>Get started analyzing RPA land use projections:</p> <ol> <li> <p>Clone and install <pre><code>git clone https://github.com/mihiarc/langchain-landuse\ncd langchain-landuse\nuv sync\n</code></pre></p> </li> <li> <p>Run guided setup <pre><code>uv run python setup_agents.py\n</code></pre></p> </li> <li> <p>Launch the dashboard <pre><code>uv run streamlit run streamlit_app.py\n</code></pre></p> </li> <li> <p>Start exploring! <pre><code>\ud83d\udcac Try: \"How much forest is projected to be lost under the high warming scenarios?\"\n</code></pre></p> </li> </ol>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":""},{"location":"#rpa-assessment-background","title":"RPA Assessment Background","text":"<ul> <li>RPA Overview - Understanding the 2020 Assessment</li> <li>RPA Scenarios - Detailed scenario definitions</li> <li>Land Use Methodology - Econometric model details</li> <li>Climate Models - 5 climate model characteristics</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation - Set up the project</li> <li>Quick Start - Run your first RPA queries</li> <li>Configuration - Customize for your needs</li> </ul>"},{"location":"#natural-language-queries","title":"Natural Language Queries","text":"<ul> <li>Overview - How the AI understands RPA questions</li> <li>Basic Queries - Simple RPA query patterns</li> <li>Advanced Queries - Complex scenario comparisons</li> <li>Examples - Real RPA analysis examples</li> </ul>"},{"location":"#data-schemas","title":"Data &amp; Schemas","text":"<ul> <li>Data Sources - RPA Assessment data structure</li> <li>Database Schema - Star schema design</li> <li>Land Use Categories - Crop, Forest, Urban definitions</li> <li>Processing Pipeline - JSON to DuckDB transformation</li> </ul>"},{"location":"#api-reference","title":"API Reference","text":"<ul> <li>LanduseAgent Overview - Unified agent architecture and features</li> <li>Agent API Reference - Complete API documentation</li> <li>Natural Language Queries - Query processing capabilities</li> <li>Converters - Data transformation tools</li> <li>Tools - Available agent capabilities</li> </ul>"},{"location":"#rpa-scenarios-quick-reference","title":"\ud83c\udf1f RPA Scenarios Quick Reference","text":"Scenario Climate Socioeconomic Key Theme LM RCP4.5 (~2.5\u00b0C) SSP1 Sustainability focus, lower warming HL RCP8.5 (~4.5\u00b0C) SSP3 Regional rivalry, high warming HM RCP8.5 (~4.5\u00b0C) SSP2 Middle of the road, high warming HH RCP8.5 (~4.5\u00b0C) SSP5 Fossil-fueled growth, high warming"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>We welcome contributions! Check out our contributing guide and branding strategy.</p>"},{"location":"#data-attribution","title":"\ud83d\udcc4 Data Attribution","text":"<p>This project analyzes data from the USDA Forest Service 2020 Resources Planning Act Assessment.</p> RPA Land Use Analytics Transforming America's land use data into actionable insights \ud83c\udf32 Powered by USDA Forest Service RPA Assessment \ud83c\udf32"},{"location":"AGENT_CONSOLIDATION/","title":"Agent Consolidation Complete \ud83c\udf89","text":""},{"location":"AGENT_CONSOLIDATION/#overview","title":"Overview","text":"<p>The RPA Land Use Analytics agent architecture has been successfully consolidated from 10+ agent files into a single, unified <code>agent.py</code> module using LangGraph.</p>"},{"location":"AGENT_CONSOLIDATION/#what-changed","title":"What Changed","text":""},{"location":"AGENT_CONSOLIDATION/#before-10-files-3-different-agent-classes","title":"Before (10+ files, 3 different agent classes):","text":"<pre><code>src/landuse/agents/\n\u251c\u2500\u2500 base_agent.py (450+ lines)\n\u251c\u2500\u2500 landuse_natural_language_agent.py (400+ lines)\n\u251c\u2500\u2500 langgraph_agent.py (600+ lines)\n\u251c\u2500\u2500 langgraph_base_agent.py (500+ lines)\n\u251c\u2500\u2500 landuse_natural_language_agent_v2.py (250+ lines)\n\u251c\u2500\u2500 langgraph_map_agent_v2.py (200+ lines)\n\u251c\u2500\u2500 migration_wrappers.py (100+ lines)\n\u2514\u2500\u2500 (and 3 more similar files...)\n</code></pre>"},{"location":"AGENT_CONSOLIDATION/#after-1-file-1-class","title":"After (1 file, 1 class):","text":"<pre><code>src/landuse/agents/\n\u251c\u2500\u2500 agent.py (600 lines - unified implementation)\n\u251c\u2500\u2500 constants.py (unchanged - shared constants)\n\u251c\u2500\u2500 formatting.py (unchanged - output formatting)\n\u2514\u2500\u2500 __init__.py (simplified exports)\n</code></pre>"},{"location":"AGENT_CONSOLIDATION/#the-new-unified-agent","title":"The New Unified Agent","text":""},{"location":"AGENT_CONSOLIDATION/#single-class-landuseagent","title":"Single Class: <code>LanduseAgent</code>","text":"<pre><code>from landuse.agents import LanduseAgent\n\n# Basic agent\nagent = LanduseAgent()\n\n# Map-enabled agent\nagent = LanduseAgent(enable_maps=True)\n\n# Custom configuration\nagent = LanduseAgent(\n    model_name=\"gpt-4\",\n    temperature=0.1,\n    enable_memory=True,\n    enable_maps=True\n)\n</code></pre>"},{"location":"AGENT_CONSOLIDATION/#key-features","title":"Key Features","text":"<ol> <li>Unified Architecture: All functionality in one class</li> <li>LangGraph-Based: Modern graph-based control flow</li> <li>Configurable: Enable/disable features via parameters</li> <li>Clean API: No legacy code or compatibility layers</li> <li>Clean API: Simple, intuitive interface</li> </ol>"},{"location":"AGENT_CONSOLIDATION/#configuration-options","title":"Configuration Options","text":"<ul> <li><code>db_path</code>: Path to DuckDB database</li> <li><code>model_name</code>: LLM model (GPT-4, Claude, etc.)</li> <li><code>temperature</code>: LLM temperature (0.0-2.0)</li> <li><code>max_tokens</code>: Maximum response tokens</li> <li><code>enable_memory</code>: Enable conversation memory</li> <li><code>enable_maps</code>: Enable map generation capabilities</li> <li><code>verbose</code>: Enable verbose logging</li> </ul>"},{"location":"AGENT_CONSOLIDATION/#migration-guide","title":"Migration Guide","text":""},{"location":"AGENT_CONSOLIDATION/#for-users","title":"For Users","text":"<p>No changes required! Existing code continues to work:</p> <pre><code># All imports now use the unified agent\n\n# New code (recommended)\nfrom landuse.agents import LanduseAgent\nagent = LanduseAgent()\n</code></pre>"},{"location":"AGENT_CONSOLIDATION/#for-developers","title":"For Developers","text":"<ol> <li> <p>Import Changes:    <pre><code># Old\nfrom landuse.agents import LanduseAgent  # Single import for everything\n\n# New\nfrom landuse.agents import LanduseAgent\n</code></pre></p> </li> <li> <p>Map Agent:    <pre><code># Old\nfrom landuse.agents.langgraph_map_agent import LangGraphMapAgent\nagent = LangGraphMapAgent()\n\n# New\nfrom landuse.agents import LanduseAgent\nagent = LanduseAgent(enable_maps=True)\n</code></pre></p> </li> </ol>"},{"location":"AGENT_CONSOLIDATION/#benefits","title":"Benefits","text":"<ol> <li>Simplicity: One file to understand instead of 10+</li> <li>Maintainability: No more duplicate code across agents</li> <li>Consistency: All agents share the same architecture</li> <li>Performance: Reduced import overhead</li> <li>Extensibility: Easy to add new features to all agents</li> </ol>"},{"location":"AGENT_CONSOLIDATION/#technical-details","title":"Technical Details","text":""},{"location":"AGENT_CONSOLIDATION/#architecture","title":"Architecture","text":"<ul> <li>Built on LangGraph for graph-based control flow</li> <li>Uses <code>@tool</code> decorator for clean tool integration</li> <li>StateGraph manages conversation state</li> <li>Optional memory/checkpointing support</li> </ul>"},{"location":"AGENT_CONSOLIDATION/#tools","title":"Tools","text":"<p>All agents have access to: - <code>execute_landuse_query</code>: Run SQL queries - <code>get_schema_info</code>: Database schema information - <code>suggest_query_examples</code>: Example queries - <code>get_state_code</code>: State name to code mapping - <code>get_default_assumptions</code>: Default analysis assumptions - <code>create_choropleth_map</code>: Map generation (when enabled)</p>"},{"location":"AGENT_CONSOLIDATION/#testing","title":"Testing","text":"<p>All tests pass with the new consolidated agent: - \u2705 Basic agent functionality - \u2705 Map agent capabilities - \u2705 Backward compatibility - \u2705 All existing tests (89.75% coverage maintained)</p>"},{"location":"AGENT_CONSOLIDATION/#completion-status","title":"Completion Status","text":"<ol> <li>Phase 1 \u2705 Consolidate agents (COMPLETE)</li> <li>Phase 2 \u2705 Remove all legacy code (COMPLETE)</li> <li>Phase 3 \u2705 Update documentation (COMPLETE)</li> <li>Phase 4 \ud83d\udea7 Update Streamlit integration (IN PROGRESS)</li> </ol>"},{"location":"AGENT_CONSOLIDATION/#legacy-code-removed","title":"Legacy Code Removed","text":"<p>All legacy code has been successfully removed: - \u2705 Removed 8 deprecated agent files (3000+ lines) - \u2705 Removed compatibility module - \u2705 Removed migration scripts - \u2705 Removed migration documentation - \u2705 Updated all imports across codebase</p>"},{"location":"AGENT_CONSOLIDATION/#summary","title":"Summary","text":"<p>The agent consolidation successfully reduced code complexity from 10+ files and 3+ classes to a single, unified <code>LanduseAgent</code> class. All legacy code has been removed, making the codebase clean, simple, and easy to maintain.</p>"},{"location":"CLAUDE.local/","title":"Local Configuration","text":""},{"location":"CLAUDE.local/#best-practices","title":"Best Practices","text":"<ul> <li>Refer to the langchain documentation before every task.</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/","title":"GitHub Pages Documentation Setup","text":""},{"location":"GITHUB_PAGES_SETUP/#overview","title":"Overview","text":"<p>The RPA Land Use Analytics documentation is now configured for deployment to GitHub Pages using MkDocs with the Material theme.</p>"},{"location":"GITHUB_PAGES_SETUP/#configuration-updates","title":"Configuration Updates","text":""},{"location":"GITHUB_PAGES_SETUP/#1-mkdocs-configuration-mkdocsyml","title":"1. MkDocs Configuration (<code>mkdocs.yml</code>)","text":"<ul> <li>\u2705 Updated site name to \"RPA Land Use Analytics\"</li> <li>\u2705 Updated site description with RPA Assessment context</li> <li>\u2705 Changed repository URLs to mihiarc/langchain-landuse</li> <li>\u2705 Updated theme colors to forest green (#2E7D32)</li> <li>\u2705 Added RPA Assessment section to navigation</li> <li>\u2705 Updated copyright with RPA attribution</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#2-documentation-structure","title":"2. Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                    # Updated with RPA branding\n\u251c\u2500\u2500 rpa/                        # New RPA-specific section\n\u2502   \u251c\u2500\u2500 overview.md            # 2020 RPA Assessment overview\n\u2502   \u2514\u2500\u2500 climate-models.md      # 5 climate model details\n\u251c\u2500\u2500 RPA_SCENARIOS.md           # Detailed scenario documentation\n\u251c\u2500\u2500 LAND_USE_METHODOLOGY.md    # Econometric model methodology\n\u251c\u2500\u2500 api/\n\u2502   \u2514\u2500\u2500 langgraph-agent.md     # New LangGraph agent documentation\n\u2514\u2500\u2500 development/\n    \u2514\u2500\u2500 BRANDING_STRATEGY.md   # RPA branding guidelines\n</code></pre>"},{"location":"GITHUB_PAGES_SETUP/#3-github-actions-workflow","title":"3. GitHub Actions Workflow","text":"<p>Created <code>.github/workflows/deploy-docs.yml</code> for automatic deployment: - Triggers on push to main branch - Builds documentation with strict mode - Deploys to GitHub Pages</p>"},{"location":"GITHUB_PAGES_SETUP/#local-development","title":"Local Development","text":""},{"location":"GITHUB_PAGES_SETUP/#build-documentation","title":"Build Documentation","text":"<pre><code># Build the site\nuv run mkdocs build\n\n# Build with strict mode (catches all warnings)\nuv run mkdocs build --strict\n</code></pre>"},{"location":"GITHUB_PAGES_SETUP/#serve-locally","title":"Serve Locally","text":"<pre><code># Using mkdocs directly\nuv run mkdocs serve\n\n# Using the helper script\nuv run python scripts/serve_docs.py\n</code></pre> <p>Documentation will be available at http://localhost:8000</p>"},{"location":"GITHUB_PAGES_SETUP/#deployment","title":"Deployment","text":""},{"location":"GITHUB_PAGES_SETUP/#initial-setup-one-time","title":"Initial Setup (One-time)","text":"<ol> <li>Go to repository Settings \u2192 Pages</li> <li>Source: Deploy from a branch</li> <li>Branch: gh-pages / (root)</li> <li>Save the settings</li> </ol>"},{"location":"GITHUB_PAGES_SETUP/#automatic-deployment","title":"Automatic Deployment","text":"<p>Documentation automatically deploys when: - Documentation files are changed and pushed to main branch - The deploy-docs workflow is manually triggered - Uses <code>mkdocs gh-deploy</code> to build and push to gh-pages branch</p>"},{"location":"GITHUB_PAGES_SETUP/#manual-deployment","title":"Manual Deployment","text":"<pre><code># Using the helper script\nuv run python scripts/deploy_docs.py\n\n# Or using mkdocs directly\nuv run mkdocs gh-deploy --force\n</code></pre>"},{"location":"GITHUB_PAGES_SETUP/#key-updates-made","title":"Key Updates Made","text":""},{"location":"GITHUB_PAGES_SETUP/#content-updates","title":"Content Updates","text":"<ul> <li>Home page now features RPA branding and scenarios</li> <li>Quick start guide updated with RPA-specific examples</li> <li>Added comprehensive RPA Assessment documentation</li> <li>Created climate model reference guide</li> <li>Updated all examples to use RPA terminology</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#visual-updates","title":"Visual Updates","text":"<ul> <li>Forest green color scheme throughout</li> <li>RPA ASCII logo on home page</li> <li>Consistent branding across all pages</li> <li>USDA Forest Service attribution</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#technical-updates","title":"Technical Updates","text":"<ul> <li>Modern navigation with RPA sections</li> <li>Cross-referenced RPA documentation</li> <li>Updated API documentation for agents</li> <li>Fixed broken links and references</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#urls","title":"URLs","text":"<ul> <li>Live Documentation: https://mihiarc.github.io/langchain-landuse</li> <li>Repository: https://github.com/mihiarc/langchain-landuse</li> <li>RPA Assessment: https://www.fs.usda.gov/research/rpa</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#next-steps","title":"Next Steps","text":"<ol> <li>Enable GitHub Pages in repository settings</li> <li>Monitor first deployment via Actions tab</li> <li>Update README with documentation link</li> <li>Add documentation badge to repository</li> </ol>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/","title":"Knowledge Base Integration Guide","text":"<p>This guide explains how to use the vector store knowledge base feature to enhance the RPA Land Use Analytics agent with domain knowledge from markdown documentation.</p>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#overview","title":"Overview","text":"<p>The knowledge base integration allows the agent to search through RPA Assessment documentation using semantic search, combining structured data queries with contextual information from official documents.</p>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#features","title":"Features","text":"<ul> <li>Semantic Search: Uses OpenAI embeddings to find relevant documentation based on meaning</li> <li>Automatic Indexing: Processes markdown files and creates searchable chunks</li> <li>Persistent Storage: Uses Chroma vector database for efficient retrieval</li> <li>Seamless Integration: Works with the existing LangGraph agent architecture</li> <li>No Technical Debt: Implemented as a configurable feature in the existing agent</li> </ul>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#configuration","title":"Configuration","text":"<p>Enable the knowledge base by setting environment variables in your <code>.env</code> file:</p> <pre><code># Enable knowledge base feature\nLANDUSE_ENABLE_KNOWLEDGE_BASE=true\n\n# Optional: customize paths (defaults shown)\nLANDUSE_KNOWLEDGE_BASE_PATH=src/landuse/docs\nLANDUSE_CHROMA_PERSIST_DIR=data/chroma_db\n</code></pre>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#usage","title":"Usage","text":""},{"location":"KNOWLEDGE_BASE_INTEGRATION/#command-line","title":"Command Line","text":"<p>When the knowledge base is enabled, the agent automatically gains access to a documentation search tool:</p> <pre><code># Run the agent with knowledge base enabled\nLANDUSE_ENABLE_KNOWLEDGE_BASE=true uv run rpa-analytics\n\n# Or set it in your .env file and run normally\nuv run rpa-analytics\n</code></pre>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#python-api","title":"Python API","text":"<pre><code>from landuse.agents.landuse_agent import LanduseAgent\nfrom landuse.config.landuse_config import LanduseConfig\n\n# Create config with knowledge base enabled\nconfig = LanduseConfig(enable_knowledge_base=True)\n\n# Initialize agent\nwith LanduseAgent(config) as agent:\n    # Query combining documentation and data\n    response = agent.query(\n        \"What does the RPA Assessment say about forest loss? \"\n        \"Also show me actual data for forest transitions.\"\n    )\n    print(response)\n</code></pre>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#streamlit-app","title":"Streamlit App","text":"<p>The knowledge base is automatically available in the Streamlit app when enabled:</p> <pre><code>LANDUSE_ENABLE_KNOWLEDGE_BASE=true uv run streamlit run streamlit_app.py\n</code></pre>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#example-queries","title":"Example Queries","text":"<p>The knowledge base enables new types of queries that combine documentation context with data analysis:</p>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#documentation-only-queries","title":"Documentation-Only Queries","text":"<ul> <li>\"What are the key findings from the RPA Assessment about land development threats?\"</li> <li>\"What climate scenarios does the RPA Assessment use?\"</li> <li>\"Explain the wildland-urban interface according to the RPA documentation\"</li> </ul>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#combined-documentation-and-data-queries","title":"Combined Documentation and Data Queries","text":"<ul> <li>\"What does the RPA Assessment say about drought projections? Show me rangeland data for western states.\"</li> <li>\"According to the RPA documentation, which regions face the most forest loss? Show me the actual data.\"</li> <li>\"Explain the RPA's methodology for land use projections and show me an example from the database.\"</li> </ul>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#how-it-works","title":"How It Works","text":"<ol> <li>Document Loading: The <code>RPAKnowledgeBase</code> class loads markdown files from <code>src/landuse/docs/</code></li> <li>Text Splitting: Documents are split into chunks while preserving context</li> <li>Embedding Generation: Each chunk is converted to a vector embedding using OpenAI</li> <li>Vector Storage: Embeddings are stored in Chroma for fast similarity search</li> <li>Tool Integration: A retriever tool is added to the agent's toolset</li> <li>Query Processing: The agent can now search documentation when answering questions</li> </ol>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#architecture","title":"Architecture","text":"<pre><code>LanduseAgent\n\u251c\u2500\u2500 Standard Tools\n\u2502   \u251c\u2500\u2500 execute_landuse_query\n\u2502   \u251c\u2500\u2500 analyze_landuse_results\n\u2502   \u2514\u2500\u2500 explore_landuse_schema\n\u2514\u2500\u2500 Knowledge Base Tool (when enabled)\n    \u2514\u2500\u2500 search_rpa_documentation\n        \u2514\u2500\u2500 RPAKnowledgeBase\n            \u251c\u2500\u2500 Document Loader\n            \u251c\u2500\u2500 Text Splitter\n            \u251c\u2500\u2500 Embeddings (OpenAI)\n            \u2514\u2500\u2500 Vector Store (Chroma)\n</code></pre>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Initial Setup: First run will process all documents and create embeddings (one-time cost)</li> <li>Subsequent Runs: Vector store is persisted to disk for fast loading</li> <li>Query Performance: Semantic search typically returns results in &lt;1 second</li> <li>Storage: Vector database requires ~50-100MB depending on document volume</li> </ul>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#troubleshooting","title":"Troubleshooting","text":""},{"location":"KNOWLEDGE_BASE_INTEGRATION/#knowledge-base-not-loading","title":"Knowledge Base Not Loading","text":"<ul> <li>Check that <code>OPENAI_API_KEY</code> is set (required for embeddings)</li> <li>Verify markdown documents exist in <code>src/landuse/docs/</code></li> <li>Ensure write permissions for <code>data/chroma_db/</code> directory</li> </ul>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#slow-initial-loading","title":"Slow Initial Loading","text":"<ul> <li>First run processes all documents; subsequent runs load from disk</li> <li>Use <code>force_rebuild=True</code> to recreate the vector store if needed</li> </ul>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#search-not-finding-expected-results","title":"Search Not Finding Expected Results","text":"<ul> <li>The knowledge base uses semantic search, not keyword matching</li> <li>Try rephrasing queries to be more specific</li> <li>Check that relevant content exists in the markdown files</li> </ul>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#adding-new-documentation","title":"Adding New Documentation","text":"<p>To add new documentation to the knowledge base:</p> <ol> <li>Add markdown files to <code>src/landuse/docs/</code></li> <li>Delete the existing vector store: <code>rm -rf data/chroma_db/</code></li> <li>Run the agent - it will automatically rebuild the index</li> </ol>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#dependencies","title":"Dependencies","text":"<p>The knowledge base feature requires additional packages: - <code>chromadb</code>: Vector database for storing embeddings - <code>unstructured</code>: Document parsing and processing - <code>markdown</code>: Markdown file support</p> <p>These are installed automatically when you run <code>uv sync</code>.</p>"},{"location":"KNOWLEDGE_BASE_INTEGRATION/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements for the knowledge base:</p> <ol> <li>Multiple Document Sources: Support for PDFs, Word docs, etc.</li> <li>Dynamic Updates: Add new documents without rebuilding</li> <li>Query Optimization: Fine-tune retrieval parameters</li> <li>Caching: Cache frequently accessed documentation chunks</li> <li>Multi-Modal Search: Support for tables, charts, and images</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/","title":"RPA Land Use Change Methodology","text":""},{"location":"LAND_USE_METHODOLOGY/#overview","title":"Overview","text":"<p>The land use projections in the RPA Assessment database are based on a sophisticated econometric model that projects county-level land use transitions from 2020 to 2070. This document explains the methodology, key assumptions, and how to interpret the data.</p>"},{"location":"LAND_USE_METHODOLOGY/#model-characteristics","title":"Model Characteristics","text":""},{"location":"LAND_USE_METHODOLOGY/#core-features","title":"Core Features","text":"<ul> <li>Spatial Resolution: County-level (3,075 counties in conterminous U.S.)</li> <li>Temporal Coverage: 2020-2070 projections</li> <li>Land Ownership: Private land only</li> <li>Scenarios: 20 integrated climate-socioeconomic futures</li> <li>Policy Approach: Policy-neutral projections</li> </ul>"},{"location":"LAND_USE_METHODOLOGY/#key-assumptions","title":"Key Assumptions","text":"<ol> <li>Development is Irreversible: Once land converts to developed use, it doesn't revert</li> <li>Private Land Focus: All transitions occur on privately owned land</li> <li>Historical Basis: Model calibrated on observed transitions from 2001-2012</li> <li>Policy Neutral: No assumptions about future conservation policies</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#land-use-classes","title":"Land Use Classes","text":"<p>The model tracks five major land use categories:</p> Code Land Use Category Description cr Crop Agriculture Agricultural cropland ps Pasture Agriculture Livestock grazing land fr Forest Natural Forested areas ur Urban Developed Built/developed areas rg Rangeland Natural Natural grasslands"},{"location":"LAND_USE_METHODOLOGY/#historical-context","title":"Historical Context","text":""},{"location":"LAND_USE_METHODOLOGY/#development-trends","title":"Development Trends","text":"<p>The model was calibrated during a period of changing development patterns: - 1980s: ~1.2 million acres/year converted to developed - 1992-1997: Peak at ~2.0 million acres/year - After 2000: Declining rate (reflected in projections)</p>"},{"location":"LAND_USE_METHODOLOGY/#observed-transitions-2001-2012","title":"Observed Transitions (2001-2012)","text":"<ul> <li>Most active transitions between crop \u2194 pasture (agricultural rotation)</li> <li>Forest \u2192 Developed: Primary urbanization pathway</li> <li>Agricultural \u2192 Developed: Secondary urbanization pathway</li> </ul>"},{"location":"LAND_USE_METHODOLOGY/#projection-methodology","title":"Projection Methodology","text":""},{"location":"LAND_USE_METHODOLOGY/#model-structure","title":"Model Structure","text":"<ol> <li>Econometric Foundation: Based on empirical analysis of NRI data</li> <li>Climate Integration: Incorporates temperature and precipitation projections</li> <li>Socioeconomic Drivers: Population and GDP growth from SSPs</li> <li>Spatial Constraints: Respects county boundaries and land availability</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#scenario-integration","title":"Scenario Integration","text":"<p>Each of the 20 scenarios combines: - Climate Model (5 options): Hot, Wet, Dry, Least warm, Middle - RCP Pathway (2 options): RCP 4.5 or RCP 8.5 - SSP Pathway (4 options): SSP1, SSP2, SSP3, or SSP5</p>"},{"location":"LAND_USE_METHODOLOGY/#projection-process","title":"Projection Process","text":"<ol> <li>Calculate transition probabilities based on:</li> <li>Historical land use patterns</li> <li>Projected climate conditions</li> <li>Socioeconomic growth rates</li> <li> <p>Land quality factors</p> </li> <li> <p>Apply constraints:</p> </li> <li>Total county area must be conserved</li> <li>Development cannot revert</li> <li> <p>Transitions follow observed patterns</p> </li> <li> <p>Generate projections for six time periods:</p> </li> <li>2012-2020, 2020-2030, 2030-2040, 2040-2050, 2050-2070, 2070-2100</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#key-projections-2020-2070","title":"Key Projections (2020-2070)","text":""},{"location":"LAND_USE_METHODOLOGY/#national-level","title":"National Level","text":"<ul> <li>Developed Land: +41.3 to +57.0 million acres</li> <li>Forest Land: -7.6 to -15.0 million acres</li> <li>Agricultural Land: Variable by scenario</li> <li>Primary Conversion: ~46% of new developed land from forest</li> </ul>"},{"location":"LAND_USE_METHODOLOGY/#regional-patterns","title":"Regional Patterns","text":"<p>Highest Development Pressure: 1. South Region: 18.4-25.0 million acres 2. North Region: 10.6-14.0 million acres 3. Rocky Mountain: 6.4-8.9 million acres 4. Pacific Coast: 5.9-9.9 million acres</p> <p>Forest Loss Patterns: - Largest losses: South Region (4.6-9.2 million acres) - Moderate losses: Pacific Coast, North - Smallest losses: Rocky Mountain Region</p>"},{"location":"LAND_USE_METHODOLOGY/#scenario-effects","title":"Scenario Effects","text":""},{"location":"LAND_USE_METHODOLOGY/#climate-impact-rcp-45-vs-rcp-85","title":"Climate Impact (RCP 4.5 vs RCP 8.5)","text":"<p>Higher warming (RCP 8.5) results in: - 2.4% less developed land expansion - 1.2 million acres more forest retention - Climate stress reduces development attractiveness</p>"},{"location":"LAND_USE_METHODOLOGY/#socioeconomic-impact-low-vs-high-growth","title":"Socioeconomic Impact (Low vs High Growth)","text":"<p>Higher growth (SSP5 vs SSP3) results in: - 9.4% more developed land expansion - 3.5 million acres less forest - Economic pressure drives conversion</p>"},{"location":"LAND_USE_METHODOLOGY/#data-structure-in-database","title":"Data Structure in Database","text":""},{"location":"LAND_USE_METHODOLOGY/#fact-table-fact_landuse_transitions","title":"Fact Table: <code>fact_landuse_transitions</code>","text":"<p>Each record represents a land use transition for a specific: - County (geography_id) - Time period (time_id) - Scenario (scenario_id) - Transition type (from_landuse_id \u2192 to_landuse_id)</p>"},{"location":"LAND_USE_METHODOLOGY/#key-fields","title":"Key Fields","text":"<ul> <li>acres: Area undergoing this specific transition</li> <li>transition_type: 'change' (actual transition) or 'same' (no change)</li> </ul>"},{"location":"LAND_USE_METHODOLOGY/#aggregation-patterns","title":"Aggregation Patterns","text":"<p>Common aggregations in analysis: - By Scenario: Compare climate/socioeconomic pathways - By Time: Track temporal trends - By Geography: State or regional patterns - By Transition: Focus on specific conversions (e.g., forest loss)</p>"},{"location":"LAND_USE_METHODOLOGY/#important-considerations","title":"Important Considerations","text":""},{"location":"LAND_USE_METHODOLOGY/#when-analyzing-data","title":"When Analyzing Data","text":"<ol> <li>Default to Averages: When not comparing scenarios, average across all 20</li> <li>Focus on Changes: Use transition_type = 'change' for actual transitions</li> <li>Consider Scale: National patterns may differ from local trends</li> <li>Remember Constraints: Development is irreversible in projections</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#common-analysis-patterns","title":"Common Analysis Patterns","text":"<pre><code>-- Total agricultural loss (averaged across scenarios)\nSELECT AVG(acres) as avg_loss_per_scenario\nFROM fact_landuse_transitions\nWHERE from_landuse_id IN (SELECT landuse_id FROM dim_landuse WHERE landuse_category = 'Agriculture')\n  AND to_landuse_id NOT IN (SELECT landuse_id FROM dim_landuse WHERE landuse_category = 'Agriculture')\n  AND transition_type = 'change';\n\n-- Urbanization by source\nSELECT fl.landuse_name as source, SUM(acres) as total_converted\nFROM fact_landuse_transitions f\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE tl.landuse_code = 'ur' AND f.transition_type = 'change'\nGROUP BY fl.landuse_name;\n</code></pre>"},{"location":"LAND_USE_METHODOLOGY/#limitations","title":"Limitations","text":"<ol> <li>Private Land Only: Public lands assumed static</li> <li>Policy Neutral: Doesn't account for future conservation efforts</li> <li>County Level: Sub-county patterns not captured</li> <li>Historical Basis: Assumes past relationships continue</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#references","title":"References","text":"<ul> <li>Mihiar, C.J.; Lewis, D.J.; Coulston, J.W. 2023. Land use projections for the 2020 RPA Assessment. https://doi.org/10.2737/RDS-2023-0026</li> <li>Chapter 4: Land Resources. In: Future of America's Forest and Rangelands: Forest Service 2020 Resources Planning Act Assessment. Gen. Tech. Rep. WO-102.</li> </ul>"},{"location":"RPA_SCENARIOS/","title":"RPA Assessment Scenarios Reference Guide","text":""},{"location":"RPA_SCENARIOS/#overview","title":"Overview","text":"<p>The 2020 RPA Assessment uses four integrated scenarios to explore alternative futures and provide a framework for evaluating a plausible range of natural resource outcomes through 2070. These scenarios combine climate pathways (RCPs) with socioeconomic pathways (SSPs) to create comprehensive projections.</p>"},{"location":"RPA_SCENARIOS/#the-four-rpa-scenarios","title":"The Four RPA Scenarios","text":""},{"location":"RPA_SCENARIOS/#quick-reference-table","title":"Quick Reference Table","text":"Scenario Code Climate Socioeconomic Description Lower-Moderate LM RCP 4.5 SSP1 Lower warming, moderate U.S. growth, sustainable development High-Low HL RCP 8.5 SSP3 High warming, low U.S. growth, regional rivalry High-Moderate HM RCP 8.5 SSP2 High warming, moderate U.S. growth, middle of the road High-High HH RCP 8.5 SSP5 High warming, high U.S. growth, fossil-fueled development"},{"location":"RPA_SCENARIOS/#detailed-scenario-descriptions","title":"Detailed Scenario Descriptions","text":""},{"location":"RPA_SCENARIOS/#scenario-lm-lower-warming-moderate-us-growth-rcp-45-ssp1","title":"Scenario LM: Lower warming-moderate U.S. growth (RCP 4.5-SSP1)","text":"<ul> <li>Theme: \"Taking the Green Road\"</li> <li>Climate: Lower emissions with moderate warming (~2.5\u00b0C by 2100)</li> <li>Society: Strong international cooperation, sustainable practices</li> <li>U.S. Economy: 3.0X GDP growth by 2070</li> <li>U.S. Population: 1.5X growth to ~470 million by 2070</li> <li>Key Features: Environmental protection prioritized, renewable energy transition</li> </ul>"},{"location":"RPA_SCENARIOS/#scenario-hl-high-warming-low-us-growth-rcp-85-ssp3","title":"Scenario HL: High warming-low U.S. growth (RCP 8.5-SSP3)","text":"<ul> <li>Theme: \"A Rocky Road\"</li> <li>Climate: High emissions with significant warming (~4.5\u00b0C by 2100)</li> <li>Society: Nationalism, regional conflicts, security concerns</li> <li>U.S. Economy: 1.9X GDP growth by 2070 (slowest)</li> <li>U.S. Population: 1.0X (no net growth, ~330 million by 2070)</li> <li>Key Features: Trade barriers, resource competition, adaptation challenges</li> </ul>"},{"location":"RPA_SCENARIOS/#scenario-hm-high-warming-moderate-us-growth-rcp-85-ssp2","title":"Scenario HM: High warming-moderate U.S. growth (RCP 8.5-SSP2)","text":"<ul> <li>Theme: \"Middle of the Road\"</li> <li>Climate: High emissions with significant warming (~4.5\u00b0C by 2100)</li> <li>Society: Historical trends continue, slow progress</li> <li>U.S. Economy: 2.8X GDP growth by 2070</li> <li>U.S. Population: 1.4X growth to ~450 million by 2070</li> <li>Key Features: Uneven development, moderate challenges and progress</li> </ul>"},{"location":"RPA_SCENARIOS/#scenario-hh-high-warming-high-us-growth-rcp-85-ssp5","title":"Scenario HH: High warming-high U.S. growth (RCP 8.5-SSP5)","text":"<ul> <li>Theme: \"Taking the Highway\"</li> <li>Climate: High emissions with significant warming (~4.5\u00b0C by 2100)</li> <li>Society: Rapid development, technology-focused, fossil fuel reliant</li> <li>U.S. Economy: 4.7X GDP growth by 2070 (highest)</li> <li>U.S. Population: 1.9X growth to ~580 million by 2070</li> <li>Key Features: High consumption, technological solutions, urbanization</li> </ul>"},{"location":"RPA_SCENARIOS/#climate-models-used","title":"Climate Models Used","text":"<p>The RPA Assessment uses five climate models to capture different aspects of climate change:</p>"},{"location":"RPA_SCENARIOS/#the-five-core-climate-projections","title":"The Five Core Climate Projections","text":"Model Type Climate Model Institution Key Characteristic Least warm MRI-CGCM3 Meteorological Research Institute, Japan Lower bound of warming Hot HadGEM2-ES Met Office Hadley Centre, UK Upper bound of warming Dry IPSL-CM5A-MR Institut Pierre Simon Laplace, France Reduced precipitation Wet CNRM-CM5 National Centre of Meteorological Research, France Increased precipitation Middle NorESM1-M Norwegian Climate Center, Norway Central tendency"},{"location":"RPA_SCENARIOS/#understanding-rcps-and-ssps","title":"Understanding RCPs and SSPs","text":""},{"location":"RPA_SCENARIOS/#representative-concentration-pathways-rcps","title":"Representative Concentration Pathways (RCPs)","text":"<ul> <li>RCP 4.5: Medium forcing scenario with emissions peaking around 2040</li> <li>Assumes implementation of climate policies</li> <li>~2.5\u00b0C global warming by 2100</li> <li> <p>Used in scenario LM</p> </li> <li> <p>RCP 8.5: High forcing scenario with continued emissions growth</p> </li> <li>Assumes limited climate action</li> <li>~4.5\u00b0C global warming by 2100</li> <li>Used in scenarios HL, HM, and HH</li> </ul>"},{"location":"RPA_SCENARIOS/#shared-socioeconomic-pathways-ssps","title":"Shared Socioeconomic Pathways (SSPs)","text":"<ul> <li>SSP1 - Sustainability: Green growth, reduced inequality, international cooperation</li> <li>SSP2 - Middle of the Road: Historical trends continue, slow progress</li> <li>SSP3 - Regional Rivalry: Nationalism, security concerns, material-intensive consumption</li> <li>SSP5 - Fossil-fueled Development: Rapid growth, technological solutions, high energy use</li> </ul>"},{"location":"RPA_SCENARIOS/#land-use-implications-by-scenario","title":"Land Use Implications by Scenario","text":""},{"location":"RPA_SCENARIOS/#development-pressure","title":"Development Pressure","text":"<ul> <li>Highest: Scenario HH (high growth, urbanization)</li> <li>Moderate: Scenarios LM and HM (balanced growth)</li> <li>Lowest: Scenario HL (low growth, limited expansion)</li> </ul>"},{"location":"RPA_SCENARIOS/#agricultural-land-loss","title":"Agricultural Land Loss","text":"<ul> <li>Most Severe: Scenarios with high population/economic growth (HH)</li> <li>Moderate: Middle scenarios (LM, HM)</li> <li>Least Severe: Low growth scenario (HL)</li> </ul>"},{"location":"RPA_SCENARIOS/#forest-conservation","title":"Forest Conservation","text":"<ul> <li>Best Outcomes: Scenario LM (sustainability focus)</li> <li>Worst Outcomes: Scenario HH (development pressure)</li> <li>Variable: Scenarios HL and HM (depends on regional factors)</li> </ul>"},{"location":"RPA_SCENARIOS/#using-scenarios-in-analysis","title":"Using Scenarios in Analysis","text":""},{"location":"RPA_SCENARIOS/#time-horizons","title":"Time Horizons","text":"<ul> <li>Near-term (2020-2030): Limited divergence between scenarios</li> <li>Mid-term (2030-2050): Increasing differentiation</li> <li>Long-term (2050-2070): Maximum scenario divergence</li> </ul>"},{"location":"RPA_SCENARIOS/#best-practices","title":"Best Practices","text":"<ol> <li>Always specify the scenario when presenting results</li> <li>Compare across scenarios to show uncertainty range</li> <li>Use scenario names consistently (LM, HL, HM, HH)</li> <li>Include climate model when relevant (e.g., \"HH-Hot\" or \"LM-Wet\")</li> <li>Consider averaging across all scenarios for general trends</li> </ol>"},{"location":"RPA_SCENARIOS/#common-analysis-patterns","title":"Common Analysis Patterns","text":""},{"location":"RPA_SCENARIOS/#for-climate-impact-studies","title":"For Climate Impact Studies","text":"<ul> <li>Compare RCP 4.5 (scenario LM) vs RCP 8.5 (scenarios HL, HM, HH)</li> <li>Use all five climate models to capture precipitation uncertainty</li> </ul>"},{"location":"RPA_SCENARIOS/#for-socioeconomic-analysis","title":"For Socioeconomic Analysis","text":"<ul> <li>Compare high growth (HH) vs low growth (HL) scenarios</li> <li>Use middle scenarios (LM, HM) for moderate projections</li> </ul>"},{"location":"RPA_SCENARIOS/#for-integrated-assessment","title":"For Integrated Assessment","text":"<ul> <li>Present all four scenarios to show full uncertainty range</li> <li>Highlight scenario LM as \"best case\" and HL as \"challenging case\"</li> </ul>"},{"location":"RPA_SCENARIOS/#data-structure-in-database","title":"Data Structure in Database","text":"<p>In our DuckDB database, scenarios are structured as:</p> <pre><code>-- Scenario naming convention\n-- Format: {ClimateModel}_{RCP}_ssp{SSP}\n-- Example: CNRM_CM5_rcp45_ssp1 (Wet climate, lower warming, sustainability)\n\n-- The 20 scenarios in our database combine:\n-- 5 climate models \u00d7 2 RCPs \u00d7 variable SSPs = 20 total scenarios\n\n-- Scenario components:\n-- Climate models: CNRM_CM5, HadGEM2_ES365, IPSL_CM5A_MR, MRI_CGCM3, NorESM1_M\n-- RCPs: rcp45, rcp85\n-- SSPs: ssp1, ssp2, ssp3, ssp5\n</code></pre>"},{"location":"RPA_SCENARIOS/#references","title":"References","text":"<ul> <li>U.S. Department of Agriculture, Forest Service. 2023. Future Scenarios. Chapter 3 in: Future of America's Forest and Rangelands: Forest Service 2020 Resources Planning Act Assessment. Gen. Tech. Rep. WO-102. Washington, DC.</li> <li>O'Dea, C.B.; Langner, L.L.; Joyce, L.A.; Prestemon, J.P.; Wear, D.N. 2023. Future Scenarios. https://doi.org/10.2737/WO-GTR-102-Chap3</li> </ul>"},{"location":"SECURITY/","title":"Security Guide","text":"<p>This document outlines the security features and best practices implemented in the Langchain Landuse Analysis System.</p>"},{"location":"SECURITY/#overview","title":"Overview","text":"<p>The system implements multiple layers of security to protect against common vulnerabilities and ensure safe operation when processing natural language queries and database operations.</p>"},{"location":"SECURITY/#security-features","title":"Security Features","text":""},{"location":"SECURITY/#1-sql-injection-prevention","title":"1. SQL Injection Prevention","text":"<p>All user-generated queries are validated before execution:</p> <ul> <li>Query Validation: Only SELECT statements are allowed</li> <li>Keyword Blocking: Dangerous SQL keywords (DROP, DELETE, etc.) are blocked</li> <li>Comment Stripping: SQL comments are removed to prevent comment-based attacks</li> <li>Single Statement Enforcement: Multiple SQL statements are not allowed</li> </ul> <p>Example of blocked queries: <pre><code>-- These will be rejected:\nDROP TABLE dim_scenario;\nSELECT * FROM users; DELETE FROM users;\nSELECT * FROM users WHERE id = 1 OR '1'='1'--\n</code></pre></p>"},{"location":"SECURITY/#2-input-validation","title":"2. Input Validation","text":"<p>All user inputs are validated and sanitized:</p> <ul> <li>File Path Validation: Prevents directory traversal attacks</li> <li>Identifier Sanitization: Database identifiers are validated against safe patterns</li> <li>Parameter Validation: Query parameters are type-checked and range-validated</li> </ul>"},{"location":"SECURITY/#3-api-key-security","title":"3. API Key Security","text":"<p>API keys are handled securely throughout the system:</p> <ul> <li>Secure Storage: Keys stored in <code>.env</code> files (gitignored)</li> <li>Format Validation: Keys are validated against expected patterns</li> <li>Masking: Keys are masked in logs and UI output</li> <li>No Hardcoding: Code is scanned to prevent hardcoded secrets</li> </ul>"},{"location":"SECURITY/#4-rate-limiting","title":"4. Rate Limiting","text":"<p>Protection against API abuse:</p> <ul> <li>Default Limit: 60 queries per minute per user</li> <li>Configurable: Limits can be adjusted based on needs</li> <li>Graceful Handling: Clear error messages with retry information</li> </ul>"},{"location":"SECURITY/#5-database-security","title":"5. Database Security","text":"<p>Database access is restricted and monitored:</p> <ul> <li>Read-Only Access: Agents connect with read-only permissions</li> <li>Query Limits: Automatic LIMIT clauses prevent data exfiltration</li> <li>Connection Security: Connections are properly closed after use</li> </ul>"},{"location":"SECURITY/#6-logging-and-auditing","title":"6. Logging and Auditing","text":"<p>Comprehensive security logging:</p> <ul> <li>Query Logging: All queries are logged with status</li> <li>Access Logging: Resource access attempts are tracked</li> <li>Security Events: Failed validations and rate limits are logged</li> <li>No Sensitive Data: Logs exclude full API keys and query results</li> </ul>"},{"location":"SECURITY/#configuration","title":"Configuration","text":""},{"location":"SECURITY/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>config/.env</code> file with:</p> <pre><code># Required (at least one)\nOPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-ant-...\n\n# Security Settings\nDEFAULT_QUERY_LIMIT=1000    # Max rows returned\nLOG_LEVEL=INFO              # Logging verbosity\nENABLE_LOGGING=true         # Enable security logging\n</code></pre>"},{"location":"SECURITY/#file-permissions","title":"File Permissions","text":"<p>On Unix-like systems, ensure proper file permissions:</p> <pre><code>chmod 600 config/.env       # Only owner can read/write\nchmod 755 scripts/*.py      # Scripts are executable\n</code></pre>"},{"location":"SECURITY/#usage","title":"Usage","text":""},{"location":"SECURITY/#running-the-secure-agent","title":"Running the Secure Agent","text":"<pre><code># Run the secure setup wizard first\nuv run python setup_secure_agents.py\n\n# Then run the secure agent\nuv run python scripts/agents/secure_landuse_query_agent.py\n</code></pre>"},{"location":"SECURITY/#security-features-in-action","title":"Security Features in Action","text":"<p>When you run the secure agent, you'll see:</p> <ol> <li>API Key Validation: Keys are validated on startup</li> <li>Query Validation: Each query is checked before execution</li> <li>Rate Limiting: Prevents excessive API usage</li> <li>Audit Logging: All actions are logged</li> </ol>"},{"location":"SECURITY/#best-practices-for-users","title":"Best Practices for Users","text":"<ol> <li>Protect Your API Keys</li> <li>Never share your <code>.env</code> file</li> <li>Don't commit API keys to version control</li> <li> <p>Rotate keys regularly</p> </li> <li> <p>Use Appropriate Queries</p> </li> <li>Stick to analytical queries</li> <li>Avoid trying to modify data</li> <li> <p>Report any security issues</p> </li> <li> <p>Monitor Usage</p> </li> <li>Check logs regularly</li> <li>Watch for unusual patterns</li> <li>Stay within rate limits</li> </ol>"},{"location":"SECURITY/#security-architecture","title":"Security Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   User Input    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n    \u2502Validation\u2502  \u2190 Rate Limiting\n    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518     Input Sanitization\n         \u2502          SQL Validation\n    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n    \u2502  Agent  \u2502  \u2190 Secure Config\n    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518     API Key Validation\n         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n    \u2502 Database \u2502  \u2190 Read-Only Access\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     Query Limits\n</code></pre>"},{"location":"SECURITY/#logging","title":"Logging","text":"<p>Security logs are stored in <code>logs/security.log</code> and include:</p> <ul> <li>Query attempts (successful and blocked)</li> <li>Rate limit violations</li> <li>Invalid input attempts</li> <li>Configuration errors</li> </ul> <p>Example log entry: <pre><code>2024-01-15 10:23:45 - security - INFO - Query attempt - User: user123, Status: success, Error: None\n2024-01-15 10:24:12 - security - WARNING - Blocked query from user123: DROP TABLE...\n</code></pre></p>"},{"location":"SECURITY/#troubleshooting","title":"Troubleshooting","text":""},{"location":"SECURITY/#common-security-issues","title":"Common Security Issues","text":"<ol> <li>\"Invalid API key format\"</li> <li>Ensure your API key matches the expected pattern</li> <li>OpenAI: <code>sk-</code> followed by 48 characters</li> <li> <p>Anthropic: <code>sk-ant-</code> followed by 95 characters</p> </li> <li> <p>\"Rate limit exceeded\"</p> </li> <li>Wait for the specified retry time</li> <li> <p>Consider upgrading limits if needed frequently</p> </li> <li> <p>\"Query validation failed\"</p> </li> <li>Ensure you're only using SELECT statements</li> <li>Remove any data modification keywords</li> <li>Check for SQL injection patterns</li> </ol>"},{"location":"SECURITY/#getting-help","title":"Getting Help","text":"<p>If you encounter security issues:</p> <ol> <li>Check the security logs</li> <li>Review this documentation</li> <li>Report issues (without including sensitive data)</li> </ol>"},{"location":"SECURITY/#updates-and-maintenance","title":"Updates and Maintenance","text":"<p>Keep your security features up to date:</p> <pre><code># Update dependencies\nuv sync\n\n# Re-run security setup\nuv run python setup_secure_agents.py\n\n# Test security features\nuv run python scripts/utilities/security.py\n</code></pre>"},{"location":"SECURITY/#compliance","title":"Compliance","text":"<p>This system implements security best practices aligned with:</p> <ul> <li>OWASP Top 10 recommendations</li> <li>SQL injection prevention guidelines</li> <li>API security best practices</li> <li>Data protection principles</li> </ul> <p>Remember: Security is a shared responsibility. Always follow best practices and report any concerns.</p>"},{"location":"TESTING/","title":"Testing Guide","text":"<p>This guide covers the testing infrastructure and best practices for the Langchain Landuse project.</p>"},{"location":"TESTING/#overview","title":"Overview","text":"<p>The project uses pytest as the testing framework with comprehensive unit and integration tests for all major components.</p>"},{"location":"TESTING/#quick-start","title":"Quick Start","text":"<pre><code># Install dependencies (including test dependencies)\nuv sync\n\n# Run all tests\nuv run python run_tests.py\n\n# Run specific test suites\nuv run python run_tests.py unit        # Unit tests only\nuv run python run_tests.py integration # Integration tests only\nuv run python run_tests.py security    # Security tests only\nuv run python run_tests.py coverage    # Generate coverage report\n</code></pre>"},{"location":"TESTING/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py          # Shared fixtures and configuration\n\u251c\u2500\u2500 unit/                # Unit tests (fast, isolated)\n\u2502   \u251c\u2500\u2500 test_security.py # Security utilities tests\n\u2502   \u2514\u2500\u2500 test_converters.py # Data converter tests\n\u251c\u2500\u2500 integration/         # Integration tests\n\u2502   \u2514\u2500\u2500 test_secure_agent.py # Agent integration tests\n\u2514\u2500\u2500 fixtures/           # Test data files\n</code></pre>"},{"location":"TESTING/#running-tests","title":"Running Tests","text":""},{"location":"TESTING/#using-the-test-runner","title":"Using the Test Runner","text":"<p>The <code>run_tests.py</code> script provides convenient commands:</p> <pre><code># Run all tests with coverage\nuv run python run_tests.py all\n\n# Run only failed tests from last run\nuv run python run_tests.py failed\n\n# Run tests in parallel (faster)\nuv run python run_tests.py parallel\n\n# List available test markers\nuv run python run_tests.py markers\n</code></pre>"},{"location":"TESTING/#using-pytest-directly","title":"Using pytest Directly","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=scripts --cov-report=html\n\n# Run specific test file\nuv run pytest tests/unit/test_security.py\n\n# Run specific test function\nuv run pytest tests/unit/test_security.py::TestSQLQueryValidator::test_valid_queries\n\n# Run tests matching pattern\nuv run pytest -k \"security\"\n\n# Run tests with specific marker\nuv run pytest -m \"unit\"\nuv run pytest -m \"integration\"\nuv run pytest -m \"security\"\n\n# Stop on first failure\nuv run pytest -x\n\n# Drop into debugger on failure\nuv run pytest --pdb\n\n# Verbose output\nuv run pytest -v\n</code></pre>"},{"location":"TESTING/#test-markers","title":"Test Markers","text":"<p>Tests are organized with markers for easy filtering:</p> <ul> <li><code>@pytest.mark.unit</code> - Fast, isolated unit tests</li> <li><code>@pytest.mark.integration</code> - Tests requiring database or external resources</li> <li><code>@pytest.mark.security</code> - Security-specific tests</li> <li><code>@pytest.mark.slow</code> - Tests taking &gt;5 seconds</li> <li><code>@pytest.mark.requires_api</code> - Tests needing real API keys</li> <li><code>@pytest.mark.requires_db</code> - Tests needing the production database</li> </ul> <p>Example usage: <pre><code>@pytest.mark.unit\ndef test_sql_validation():\n    \"\"\"This is a unit test\"\"\"\n    pass\n\n@pytest.mark.integration\n@pytest.mark.requires_db\ndef test_database_query():\n    \"\"\"This test requires a database\"\"\"\n    pass\n</code></pre></p>"},{"location":"TESTING/#writing-tests","title":"Writing Tests","text":""},{"location":"TESTING/#unit-tests","title":"Unit Tests","text":"<p>Unit tests should be fast and isolated:</p> <pre><code># tests/unit/test_example.py\nimport pytest\nfrom scripts.utilities.security import SQLQueryValidator\n\nclass TestSQLQueryValidator:\n    def test_valid_query(self):\n        validator = SQLQueryValidator()\n        is_valid, error = validator.validate_query(\"SELECT * FROM table\")\n        assert is_valid\n        assert error is None\n\n    def test_invalid_query(self):\n        validator = SQLQueryValidator()\n        is_valid, error = validator.validate_query(\"DROP TABLE users\")\n        assert not is_valid\n        assert \"DROP\" in error\n</code></pre>"},{"location":"TESTING/#integration-tests","title":"Integration Tests","text":"<p>Integration tests can use the test database:</p> <pre><code># tests/integration/test_agent.py\nimport pytest\n\n@pytest.mark.integration\ndef test_agent_query(test_database):\n    \"\"\"Test agent with test database\"\"\"\n    from scripts.agents.secure_landuse_query_agent import SecureLanduseQueryAgent\n\n    agent = SecureLanduseQueryAgent()\n    result = agent.query(\"How many scenarios exist?\")\n    assert \"scenarios\" in result.lower()\n</code></pre>"},{"location":"TESTING/#using-fixtures","title":"Using Fixtures","text":"<p>Common fixtures are defined in <code>conftest.py</code>:</p> <pre><code>def test_with_database(test_database):\n    \"\"\"test_database fixture provides a test DuckDB instance\"\"\"\n    conn = duckdb.connect(str(test_database))\n    result = conn.execute(\"SELECT COUNT(*) FROM dim_scenario\").fetchone()\n    assert result[0] &gt; 0\n\ndef test_with_config(test_config_file):\n    \"\"\"test_config_file provides a test .env file\"\"\"\n    config = SecureConfig.from_env(test_config_file)\n    assert config.openai_api_key.startswith(\"sk-\")\n\ndef test_malicious_queries(malicious_queries):\n    \"\"\"malicious_queries provides SQL injection test cases\"\"\"\n    validator = SQLQueryValidator()\n    for query in malicious_queries:\n        is_valid, _ = validator.validate_query(query)\n        assert not is_valid\n</code></pre>"},{"location":"TESTING/#test-coverage","title":"Test Coverage","text":""},{"location":"TESTING/#viewing-coverage","title":"Viewing Coverage","text":"<pre><code># Generate coverage report\nuv run pytest --cov=scripts --cov-report=html\n\n# Open HTML report\nopen htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\nstart htmlcov/index.html  # Windows\n</code></pre>"},{"location":"TESTING/#coverage-requirements","title":"Coverage Requirements","text":"<ul> <li>Minimum coverage: 70% (configured in pytest.ini)</li> <li>Target coverage: 85%+</li> <li>Critical modules (security, agents): 90%+</li> </ul>"},{"location":"TESTING/#excluding-code-from-coverage","title":"Excluding Code from Coverage","text":"<pre><code>def debug_function():  # pragma: no cover\n    \"\"\"This function is excluded from coverage\"\"\"\n    pass\n\nif __name__ == \"__main__\":  # pragma: no cover\n    main()\n</code></pre>"},{"location":"TESTING/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"TESTING/#1-test-naming","title":"1. Test Naming","text":"<p>Use descriptive test names: <pre><code># Good\ndef test_sql_injection_with_drop_table_is_blocked():\n    pass\n\n# Bad\ndef test_1():\n    pass\n</code></pre></p>"},{"location":"TESTING/#2-test-organization","title":"2. Test Organization","text":"<p>Group related tests in classes: <pre><code>class TestSQLValidation:\n    def test_valid_queries(self):\n        pass\n\n    def test_invalid_queries(self):\n        pass\n</code></pre></p>"},{"location":"TESTING/#3-use-fixtures","title":"3. Use Fixtures","text":"<p>Don't repeat setup code: <pre><code># Good\ndef test_agent(test_database, mock_llm):\n    agent = SecureLanduseQueryAgent()\n    # ... test code\n\n# Bad\ndef test_agent():\n    db = create_test_database()\n    llm = create_mock_llm()\n    agent = SecureLanduseQueryAgent()\n    # ... test code\n    cleanup_database(db)\n</code></pre></p>"},{"location":"TESTING/#4-test-error-cases","title":"4. Test Error Cases","text":"<p>Always test error conditions: <pre><code>def test_invalid_input():\n    with pytest.raises(ValueError, match=\"Invalid FIPS code\"):\n        validate_fips_code(\"invalid\")\n</code></pre></p>"},{"location":"TESTING/#5-use-mocks-appropriately","title":"5. Use Mocks Appropriately","text":"<p>Mock external dependencies: <pre><code>@patch('requests.post')\ndef test_api_call(mock_post):\n    mock_post.return_value.json.return_value = {\"result\": \"success\"}\n    result = make_api_call()\n    assert result == \"success\"\n</code></pre></p>"},{"location":"TESTING/#continuous-integration","title":"Continuous Integration","text":"<p>Tests run automatically on: - Pull requests - Commits to main branch - Nightly schedule</p> <p>See <code>.github/workflows/tests.yml</code> for CI configuration.</p>"},{"location":"TESTING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"TESTING/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Import errors <pre><code># Ensure project is in Python path\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\n</code></pre></p> </li> <li> <p>Missing dependencies <pre><code># Install all dependencies including test deps\nuv sync\n</code></pre></p> </li> <li> <p>Database not found <pre><code># Tests use a test database, not production\n# This is created automatically by fixtures\n</code></pre></p> </li> <li> <p>API key errors <pre><code># Tests use mock API keys by default\n# For integration tests with real APIs:\nexport REAL_OPENAI_API_KEY=your-key\n</code></pre></p> </li> </ol>"},{"location":"TESTING/#debugging-tests","title":"Debugging Tests","text":"<pre><code># Drop into debugger on failure\nuv run pytest --pdb\n\n# Show print statements\nuv run pytest -s\n\n# Very verbose output\nuv run pytest -vv\n\n# Show local variables on failure\nuv run pytest -l\n</code></pre>"},{"location":"TESTING/#adding-new-tests","title":"Adding New Tests","text":"<ol> <li>Create test file in appropriate directory:</li> <li><code>tests/unit/</code> for unit tests</li> <li> <p><code>tests/integration/</code> for integration tests</p> </li> <li> <p>Import necessary modules and fixtures</p> </li> <li> <p>Write test functions with descriptive names</p> </li> <li> <p>Use appropriate markers</p> </li> <li> <p>Run tests to ensure they pass</p> </li> <li> <p>Check coverage hasn't decreased</p> </li> </ol> <p>Example: <pre><code># tests/unit/test_new_feature.py\nimport pytest\nfrom scripts.new_module import NewFeature\n\n@pytest.mark.unit\nclass TestNewFeature:\n    def test_feature_initialization(self):\n        feature = NewFeature()\n        assert feature is not None\n\n    def test_feature_process(self):\n        feature = NewFeature()\n        result = feature.process(\"input\")\n        assert result == \"expected output\"\n\n    def test_feature_error_handling(self):\n        feature = NewFeature()\n        with pytest.raises(ValueError):\n            feature.process(None)\n</code></pre></p> <p>Remember: Well-tested code is maintainable code!</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Common questions about the LangChain Land Use Analysis system.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-this-project","title":"What is this project?","text":"<p>The LangChain Land Use Analysis system allows you to query and analyze county-level land use projections using natural language. Instead of writing SQL, you can ask questions like \"Show me forest loss in California\" and get meaningful results.</p>"},{"location":"faq/#what-data-does-it-analyze","title":"What data does it analyze?","text":"<p>The system analyzes USDA Forest Service RPA (Resources Planning Act) land use projections: - Coverage: All US counties - Time Period: 2020-2100 - Scenarios: Baseline, High Crop Demand, High Forest, High Urban - Land Types: Crop, Pasture, Forest, Urban, Range</p>"},{"location":"faq/#do-i-need-to-know-sql","title":"Do I need to know SQL?","text":"<p>No! The agent converts your natural language questions into SQL automatically. You can ask questions in plain English like: - \"What counties have the most urban growth?\" - \"Show me forest to cropland transitions\" - \"Compare scenarios for agricultural land\"</p>"},{"location":"faq/#setup-questions","title":"Setup Questions","text":""},{"location":"faq/#what-are-the-system-requirements","title":"What are the system requirements?","text":"<ul> <li>Python: 3.8 or higher</li> <li>Memory: 4GB RAM minimum (8GB recommended)</li> <li>Disk Space: 2GB for data and dependencies</li> <li>OS: Windows, macOS, or Linux</li> <li>API Key: OpenAI API key required</li> </ul>"},{"location":"faq/#how-do-i-get-an-openai-api-key","title":"How do I get an OpenAI API key?","text":"<ol> <li>Visit https://platform.openai.com/signup</li> <li>Create an account</li> <li>Go to API keys section</li> <li>Create new secret key</li> <li>Add to your <code>.env</code> file</li> </ol>"},{"location":"faq/#which-openai-model-should-i-use","title":"Which OpenAI model should I use?","text":"<pre><code># Recommended (best balance of speed and accuracy)\nLANDUSE_MODEL=gpt-4o-mini\n\n# Best accuracy (more expensive)\nLANDUSE_MODEL=gpt-4o\n\n# Alternative: Anthropic models\nLANDUSE_MODEL=claude-3-sonnet-20240229\n</code></pre>"},{"location":"faq/#can-i-use-it-offline","title":"Can I use it offline?","text":"<p>The data processing and queries work offline, but the natural language interpretation requires an internet connection to reach OpenAI's API.</p>"},{"location":"faq/#data-questions","title":"Data Questions","text":""},{"location":"faq/#what-do-the-land-use-categories-mean","title":"What do the land use categories mean?","text":"<ul> <li>Crop: Agricultural land for growing crops</li> <li>Pasture: Land for livestock grazing</li> <li>Forest: Wooded areas (natural and managed)</li> <li>Urban: Developed areas (cities, towns, infrastructure)</li> <li>Range: Natural grasslands and shrublands</li> </ul>"},{"location":"faq/#whats-the-difference-between-the-tables","title":"What's the difference between the tables?","text":"Table Description Use Case <code>landuse_transitions</code> All transitions including same-to-same Complete analysis <code>landuse_transitions_ag</code> Crop+Pasture combined as Agriculture Simplified agricultural analysis <code>landuse_changes_only</code> Excludes unchanged land Focus on actual changes <code>landuse_changes_only_ag</code> Changes with agricultural aggregation Simplified change analysis"},{"location":"faq/#what-scenarios-are-available","title":"What scenarios are available?","text":"<ol> <li>Baseline: Most likely future based on current trends</li> <li>High Crop Demand: Increased agricultural pressure</li> <li>High Forest: Strong forest conservation</li> <li>High Urban: Accelerated urbanization</li> </ol>"},{"location":"faq/#why-are-areas-in-1000-acres","title":"Why are areas in \"1000 acres\"?","text":"<p>This unit makes large numbers more manageable. To convert: - Acres: multiply by 1,000 - Square miles: multiply by 1.5625 - Hectares: multiply by 404.686</p>"},{"location":"faq/#usage-questions","title":"Usage Questions","text":""},{"location":"faq/#how-do-i-start-a-query","title":"How do I start a query?","text":"<p>Simply run the agent and type your question: <pre><code>uv run python scripts/agents/test_agent.py\n\nYou&gt; Show me urban growth in Texas counties\n</code></pre></p>"},{"location":"faq/#can-i-export-results","title":"Can I export results?","text":"<p>Yes! Ask the agent to export: <pre><code>You&gt; Export the results to urban_growth_texas.csv\n</code></pre></p> <p>Supported formats: CSV, JSON, Parquet</p>"},{"location":"faq/#how-do-i-query-specific-years","title":"How do I query specific years?","text":"<p>Include the year in your question: <pre><code>You&gt; Show me forest area in 2050\nYou&gt; Compare urban growth between 2030 and 2080\nYou&gt; What changes happen in the 2040-2050 decade?\n</code></pre></p>"},{"location":"faq/#can-i-compare-scenarios","title":"Can I compare scenarios?","text":"<p>Yes! Ask comparison questions: <pre><code>You&gt; Compare forest area between all scenarios in 2100\nYou&gt; Which scenario has the most agricultural land?\nYou&gt; Show the difference between Baseline and High Urban\n</code></pre></p>"},{"location":"faq/#how-do-i-focus-on-specific-counties","title":"How do I focus on specific counties?","text":"<p>Use FIPS codes or descriptions: <pre><code>You&gt; Show data for FIPS 06037 (Los Angeles)\nYou&gt; Analyze California counties (FIPS starting with 06)\nYou&gt; Focus on Midwest agricultural counties\n</code></pre></p>"},{"location":"faq/#technical-questions","title":"Technical Questions","text":""},{"location":"faq/#how-does-the-natural-language-processing-work","title":"How does the natural language processing work?","text":"<ol> <li>Your question \u2192 LangChain agent</li> <li>Agent uses GPT model to understand intent</li> <li>Generates appropriate SQL query</li> <li>Executes query on database</li> <li>Formats results in natural language</li> </ol>"},{"location":"faq/#can-i-see-the-generated-sql","title":"Can I see the generated SQL?","text":"<p>Yes, the agent shows the SQL it generates: <pre><code>Query: SELECT * FROM landuse_transitions WHERE ...\nResults: 123 rows\n[Table of results]\n</code></pre></p>"},{"location":"faq/#how-accurate-is-the-sql-generation","title":"How accurate is the SQL generation?","text":"<p>The GPT-4 models are very accurate for: - Basic queries (&gt;95% accuracy) - Complex queries (&gt;85% accuracy) - Domain-specific terms (understands \"forest loss\", \"urban growth\", etc.)</p>"},{"location":"faq/#can-i-write-sql-directly","title":"Can I write SQL directly?","text":"<p>Yes! Use this format: <pre><code>You&gt; Query database.db: SELECT * FROM table WHERE condition\n</code></pre></p>"},{"location":"faq/#is-the-data-real-time","title":"Is the data real-time?","text":"<p>No, this is projection data created by USDA models. It represents scenarios of possible futures, not real-time monitoring.</p>"},{"location":"faq/#performance-questions","title":"Performance Questions","text":""},{"location":"faq/#why-is-my-query-slow","title":"Why is my query slow?","text":"<p>Common causes: 1. Large result sets - add limits 2. Complex aggregations - simplify query 3. Missing indexes - use indexed columns (scenario, year, fips)</p>"},{"location":"faq/#how-can-i-make-queries-faster","title":"How can I make queries faster?","text":"<ol> <li>Use filtered tables (<code>_changes_only</code>)</li> <li>Add LIMIT clauses</li> <li>Filter by indexed columns first</li> <li>Query specific years instead of all years</li> </ol>"},{"location":"faq/#whats-the-maximum-file-size-i-can-process","title":"What's the maximum file size I can process?","text":"<p>Default limit is 100MB (configurable): <pre><code>MAX_FILE_SIZE_MB=200  # Increase limit\n</code></pre></p> <p>Large files are automatically sampled for preview.</p>"},{"location":"faq/#troubleshooting-questions","title":"Troubleshooting Questions","text":""},{"location":"faq/#why-does-it-say-database-not-found","title":"Why does it say \"Database not found\"?","text":"<p>Run the data conversion first: <pre><code>uv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre></p>"},{"location":"faq/#why-am-i-getting-api-key-errors","title":"Why am I getting API key errors?","text":"<ol> <li>Check <code>.env</code> file exists in <code>config/</code></li> <li>Verify key starts with <code>sk-</code></li> <li>Ensure no extra quotes or spaces</li> <li>Check API key is active on OpenAI</li> </ol>"},{"location":"faq/#can-i-use-a-different-llm-provider","title":"Can I use a different LLM provider?","text":"<p>Currently supports OpenAI. The architecture allows for other providers (Claude, local models) with code modifications.</p>"},{"location":"faq/#how-do-i-update-the-data","title":"How do I update the data?","text":"<p>Place new JSON data in <code>data/raw/</code> and run: <pre><code>uv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre></p>"},{"location":"faq/#advanced-questions","title":"Advanced Questions","text":""},{"location":"faq/#can-i-add-custom-tools","title":"Can I add custom tools?","text":"<p>Yes! See the Contributing Guide for instructions on adding tools to the agent.</p>"},{"location":"faq/#can-i-modify-the-land-use-categories","title":"Can I modify the land use categories?","text":"<p>Yes, edit the <code>LAND_USE_MAP</code> in the converter scripts: <pre><code>LAND_USE_MAP = {\n    'cr': 'Cropland',  # Change naming\n    'new': 'NewCategory'  # Add categories\n}\n</code></pre></p>"},{"location":"faq/#can-i-integrate-this-with-other-systems","title":"Can I integrate this with other systems?","text":"<p>Yes! Options include: - Python API for programmatic access - Export functions for data pipelines - Web service wrapper possible - Jupyter notebook integration</p>"},{"location":"faq/#can-i-use-my-own-projections","title":"Can I use my own projections?","text":"<p>Yes, if your data follows the same JSON structure. See Data Processing for format requirements.</p>"},{"location":"faq/#best-practices-questions","title":"Best Practices Questions","text":""},{"location":"faq/#what-makes-a-good-query","title":"What makes a good query?","text":"<p>Good queries are: - Specific: \"Show forest loss in California between 2020-2050\" - Clear: Use standard terms (urban, forest, crop) - Focused: One question at a time</p> <p>Avoid: - Vague: \"Show me some data\" - Complex: Multiple unrelated questions - Ambiguous: \"What changes?\" (which changes?)</p>"},{"location":"faq/#how-should-i-explore-the-data","title":"How should I explore the data?","text":"<ol> <li>Start broad: \"What tables are available?\"</li> <li>Understand structure: \"Describe the main table\"</li> <li>Look at samples: \"Show me 10 example rows\"</li> <li>Focus analysis: \"Now show me specific patterns\"</li> </ol>"},{"location":"faq/#when-should-i-use-each-table","title":"When should I use each table?","text":"<ul> <li>Full analysis: Use base <code>landuse_transitions</code></li> <li>Change focus: Use <code>landuse_changes_only</code></li> <li>Agricultural studies: Use <code>_ag</code> tables</li> <li>Performance critical: Use filtered views</li> </ul>"},{"location":"faq/#getting-more-help","title":"Getting More Help","text":""},{"location":"faq/#where-can-i-find-more-examples","title":"Where can I find more examples?","text":"<ul> <li>Query Examples - Extensive query patterns</li> <li>Workflows - Step-by-step guides</li> <li>Notebooks - Interactive examples</li> </ul>"},{"location":"faq/#how-do-i-report-issues","title":"How do I report issues?","text":"<ol> <li>Check Troubleshooting Guide</li> <li>Search existing GitHub issues</li> <li>Create new issue with:</li> <li>Error message</li> <li>Steps to reproduce</li> <li>System information</li> </ol>"},{"location":"faq/#can-i-contribute","title":"Can I contribute?","text":"<p>Yes! See Contributing Guide for: - Code contributions - Documentation improvements - Bug reports - Feature requests</p>"},{"location":"faq/#where-can-i-learn-more","title":"Where can I learn more?","text":"<ul> <li>LangChain: https://python.langchain.com/</li> <li>OpenAI API: https://platform.openai.com/docs</li> <li>SQLite: https://www.sqlite.org/docs.html</li> <li>Project GitHub: Link to your repository</li> </ul>"},{"location":"mkdocs_structure_report/","title":"MkDocs Documentation Structure Report","text":""},{"location":"mkdocs_structure_report/#overview","title":"Overview","text":"<p>This report provides a comprehensive review of the MkDocs documentation implementation for the RPA Land Use Analytics project.</p>"},{"location":"mkdocs_structure_report/#directory-structure","title":"Directory Structure","text":""},{"location":"mkdocs_structure_report/#root-documentation-directory","title":"Root Documentation Directory","text":"<ul> <li>Location: <code>/docs/</code></li> <li>Status: \u2705 Exists</li> </ul>"},{"location":"mkdocs_structure_report/#documentation-files-status","title":"Documentation Files Status","text":""},{"location":"mkdocs_structure_report/#all-referenced-files-present-44-files","title":"\u2705 All Referenced Files Present (44 files)","text":"<p>All files referenced in <code>mkdocs.yml</code> are present in the <code>docs/</code> directory:</p> <ol> <li>Main Pages</li> <li><code>index.md</code> - Home page</li> <li><code>faq.md</code> - Frequently Asked Questions</li> <li> <p><code>troubleshooting.md</code> - General troubleshooting</p> </li> <li> <p>RPA Assessment Documentation</p> </li> <li><code>RPA_SCENARIOS.md</code> - RPA scenario descriptions</li> <li><code>LAND_USE_METHODOLOGY.md</code> - Land use methodology</li> <li><code>rpa/overview.md</code> - RPA overview</li> <li> <p><code>rpa/climate-models.md</code> - Climate models documentation</p> </li> <li> <p>Getting Started</p> </li> <li><code>getting-started/installation.md</code></li> <li><code>getting-started/quickstart.md</code></li> <li> <p><code>getting-started/configuration.md</code></p> </li> <li> <p>Natural Language Queries</p> </li> <li><code>queries/overview.md</code></li> <li><code>queries/basic-queries.md</code></li> <li><code>queries/advanced-queries.md</code></li> <li> <p><code>queries/examples.md</code></p> </li> <li> <p>Data &amp; Schemas</p> </li> <li><code>data/sources.md</code></li> <li><code>data/schema.md</code></li> <li><code>data/duckdb-schema.md</code></li> <li><code>data/categories.md</code></li> <li><code>data/variable-descriptions.md</code></li> <li><code>data/rpa-model-diagram.md</code></li> <li> <p><code>data/processing.md</code></p> </li> <li> <p>API Reference</p> </li> <li><code>api/langgraph-agent.md</code></li> <li><code>api/agent.md</code></li> <li><code>api/landuse-query-agent.md</code></li> <li><code>api/converters.md</code></li> <li> <p><code>api/tools.md</code></p> </li> <li> <p>Examples</p> </li> <li><code>examples/use-cases.md</code></li> <li><code>examples/workflows.md</code></li> <li> <p><code>examples/notebooks.md</code></p> </li> <li> <p>Development</p> </li> <li><code>development/architecture.md</code></li> <li><code>development/contributing.md</code></li> <li><code>development/testing.md</code></li> <li><code>development/ci-cd-pipeline.md</code></li> <li><code>development/retry-logic.md</code></li> <li><code>development/BRANDING_STRATEGY.md</code></li> <li><code>development/modern-duckdb-tools.md</code></li> <li> <p><code>development/pydantic-models.md</code></p> </li> <li> <p>Performance</p> </li> <li><code>performance/duckdb-copy-optimization.md</code></li> <li> <p><code>performance/streamlit-fragments.md</code></p> </li> <li> <p>Help &amp; Support</p> <ul> <li><code>GITHUB_PAGES_SETUP.md</code></li> <li><code>troubleshooting/streamlit-duplicate-ids.md</code></li> <li><code>troubleshooting/streamlit-fragments.md</code></li> </ul> </li> <li> <p>Project Info</p> <ul> <li><code>SECURITY.md</code></li> <li><code>TESTING.md</code></li> <li><code>CLAUDE.local.md</code> (referenced but marked as local config)</li> </ul> </li> </ol>"},{"location":"mkdocs_structure_report/#additional-documentation-files-not-in-mkdocsyml","title":"\ud83d\udcc1 Additional Documentation Files (Not in mkdocs.yml)","text":"<p>These files exist in the <code>docs/</code> directory but are not referenced in the navigation:</p> <ol> <li><code>AGENT_CONSOLIDATION.md</code> - Agent consolidation documentation</li> <li><code>CLAUDE.local.md</code> - Local Claude configuration</li> <li><code>KNOWLEDGE_BASE_INTEGRATION.md</code> - Knowledge base integration guide</li> <li><code>README.md</code> - Documentation readme</li> <li><code>agents/CONSTANTS_ARCHITECTURE.md</code> - Constants architecture documentation</li> <li><code>agents/README.md</code> - Agents readme</li> <li><code>agents/SYSTEM_PROMPT_ARCHITECTURE.md</code> - System prompt architecture</li> </ol>"},{"location":"mkdocs_structure_report/#built-site-status","title":"Built Site Status","text":""},{"location":"mkdocs_structure_report/#site-directory","title":"Site Directory","text":"<ul> <li>Location: <code>/site/</code></li> <li>Status: \u2705 Exists and contains built documentation</li> <li>Last Build: Evidence suggests site was built (contains HTML files)</li> </ul>"},{"location":"mkdocs_structure_report/#key-built-files-present","title":"Key Built Files Present","text":"<ul> <li><code>index.html</code> - Main landing page</li> <li><code>404.html</code> - Custom 404 page</li> <li>All navigation sections have corresponding directories</li> <li>Static assets in <code>assets/</code> directory</li> <li>Search index at <code>search/search_index.json</code></li> <li>Sitemap files: <code>sitemap.xml</code> and <code>sitemap.xml.gz</code></li> </ul>"},{"location":"mkdocs_structure_report/#mkdocs-configuration","title":"MkDocs Configuration","text":""},{"location":"mkdocs_structure_report/#theme","title":"Theme","text":"<ul> <li>Using Material for MkDocs theme</li> <li>Dark/light mode toggle enabled</li> <li>Search functionality configured</li> <li>Code highlighting and copying enabled</li> </ul>"},{"location":"mkdocs_structure_report/#plugins","title":"Plugins","text":"<ul> <li>Search plugin enabled</li> <li>mkdocstrings for API documentation</li> <li>Multiple markdown extensions configured</li> </ul>"},{"location":"mkdocs_structure_report/#repository-info","title":"Repository Info","text":"<ul> <li>Site URL: https://mihiarc.github.io/langchain-landuse</li> <li>GitHub Repository: https://github.com/mihiarc/langchain-landuse</li> </ul>"},{"location":"mkdocs_structure_report/#summary","title":"Summary","text":"<p>\u2705 Documentation Structure: Complete - All 44 files referenced in mkdocs.yml are present - Documentation is well-organized into logical sections - Additional documentation files available but not in navigation</p> <p>\u2705 Built Site: Present - Site directory exists with built HTML files - All sections properly generated - Static assets and search functionality included</p> <p>\ud83d\udcdd Recommendations 1. Consider adding the orphaned documentation files to mkdocs.yml if they're meant to be public 2. The site appears to be ready for deployment 3. All documentation paths are correctly structured for GitHub Pages deployment</p>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues and solutions when using the LangChain Land Use Analysis system.</p>"},{"location":"troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"troubleshooting/#python-version-error","title":"Python Version Error","text":"<p>Problem: <code>ERROR: This project requires Python 3.8+</code></p> <p>Solution: <pre><code># Check Python version\npython --version\n\n# Install Python 3.8+ if needed\n# macOS: brew install python@3.11\n# Ubuntu: sudo apt install python3.11\n# Windows: Download from python.org\n</code></pre></p>"},{"location":"troubleshooting/#uv-installation-failed","title":"uv Installation Failed","text":"<p>Problem: <code>uv: command not found</code></p> <p>Solution: <pre><code># Install uv\npip install uv\n\n# Or with pipx\npipx install uv\n\n# Verify installation\nuv --version\n</code></pre></p>"},{"location":"troubleshooting/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>Problem: <code>ERROR: pip's dependency resolver found conflicts</code></p> <p>Solution: <pre><code># Clean install in fresh environment\nrm -rf .venv\nuv venv\nsource .venv/bin/activate\nuv pip install -r config/requirements.txt\n</code></pre></p>"},{"location":"troubleshooting/#api-key-issues","title":"API Key Issues","text":""},{"location":"troubleshooting/#missing-api-key","title":"Missing API Key","text":"<p>Problem: <code>Error: OPENAI_API_KEY not found</code></p> <p>Solution: 1. Create <code>.env</code> file in <code>config/</code> directory:    <pre><code>cd config\ncp .env.example .env\n</code></pre></p> <ol> <li> <p>Add your API key:    <pre><code>OPENAI_API_KEY=sk-...your-key-here...\n</code></pre></p> </li> <li> <p>Verify it's loaded:    <pre><code>import os\nprint(os.getenv(\"OPENAI_API_KEY\"))\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#invalid-api-key","title":"Invalid API Key","text":"<p>Problem: <code>Error: Incorrect API key provided</code></p> <p>Solution: - Verify key at https://platform.openai.com/api-keys - Ensure no extra spaces or quotes - Check API key permissions - Verify billing is active</p>"},{"location":"troubleshooting/#rate-limiting","title":"Rate Limiting","text":"<p>Problem: <code>Error: Rate limit exceeded</code></p> <p>Solution: <pre><code># Add retry logic\nimport time\n\ndef retry_query(agent, query, max_retries=3):\n    for i in range(max_retries):\n        try:\n            return agent.run(query)\n        except RateLimitError:\n            time.sleep(2 ** i)  # Exponential backoff\n    raise Exception(\"Max retries exceeded\")\n</code></pre></p>"},{"location":"troubleshooting/#database-issues","title":"Database Issues","text":""},{"location":"troubleshooting/#database-not-found","title":"Database Not Found","text":"<p>Problem: <code>Error: Database file not found: landuse_transitions.db</code></p> <p>Solution: 1. Check if database exists:    <pre><code>ls data/processed/\n</code></pre></p> <ol> <li>If missing, create it:    <pre><code>uv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre></li> </ol>"},{"location":"troubleshooting/#database-locked","title":"Database Locked","text":"<p>Problem: <code>sqlite3.OperationalError: database is locked</code></p> <p>Solution: <pre><code># Close any open connections\nconn.close()\n\n# Or use context manager\nwith sqlite3.connect('database.db') as conn:\n    # Operations here\n    pass  # Connection closes automatically\n</code></pre></p>"},{"location":"troubleshooting/#query-errors","title":"Query Errors","text":"<p>Problem: <code>Error executing query: no such column</code></p> <p>Solution: 1. Check table schema:    <pre><code>You&gt; Describe the landuse_transitions table\n</code></pre></p> <ol> <li>Verify column names:    <pre><code>-- Correct column names\nfrom_land_use (not from_landuse)\narea_1000_acres (not area)\n</code></pre></li> </ol>"},{"location":"troubleshooting/#agentlangchain-issues","title":"Agent/LangChain Issues","text":""},{"location":"troubleshooting/#agent-import-error","title":"Agent Import Error","text":"<p>Problem: <code>ImportError: cannot import name 'DataEngineeringAgent'</code></p> <p>Solution: <pre><code># Ensure you're in project root\ncd /path/to/langchain-landuse\n\n# Add to Python path\nexport PYTHONPATH=\"${PYTHONPATH}:${PWD}\"\n\n# Or in Python\nimport sys\nsys.path.append('/path/to/langchain-landuse')\n</code></pre></p>"},{"location":"troubleshooting/#tool-execution-failed","title":"Tool Execution Failed","text":"<p>Problem: <code>Error: Tool execution failed</code></p> <p>Solution: 1. Check tool parameters:    <pre><code># Ensure correct format\nparams = {\n    \"file_path\": \"data.csv\",\n    \"query\": \"SELECT * FROM data\"\n}\n</code></pre></p> <ol> <li>Verify file permissions:    <pre><code>ls -la data/\nchmod 644 data/*.csv\n</code></pre></li> </ol>"},{"location":"troubleshooting/#memorycontext-issues","title":"Memory/Context Issues","text":"<p>Problem: Agent doesn't remember previous queries</p> <p>Solution: <pre><code># Ensure using same agent instance\nagent = DataEngineeringAgent()\n\n# First query\nresult1 = agent.run(\"Show tables\")\n\n# Follow-up uses same agent\nresult2 = agent.run(\"Describe the first table\")  # Uses context\n</code></pre></p>"},{"location":"troubleshooting/#file-operation-issues","title":"File Operation Issues","text":""},{"location":"troubleshooting/#file-not-found","title":"File Not Found","text":"<p>Problem: <code>Error reading file: [Errno 2] No such file or directory</code></p> <p>Solution: 1. Check file path:    <pre><code>from pathlib import Path\n\nfile_path = Path(\"data/sample.csv\")\nif file_path.exists():\n    agent.run(f\"Read {file_path}\")\nelse:\n    print(f\"File not found: {file_path.absolute()}\")\n</code></pre></p> <ol> <li>Use correct relative path:    <pre><code>You&gt; Read data/sample.csv  # Correct\nYou&gt; Read sample.csv       # May fail if not in data/\n</code></pre></li> </ol>"},{"location":"troubleshooting/#large-file-handling","title":"Large File Handling","text":"<p>Problem: <code>MemoryError</code> when processing large files</p> <p>Solution: <pre><code># Set file size limit\nos.environ['MAX_FILE_SIZE_MB'] = '200'\n\n# Or use streaming\nagent.run(\"Convert large_file.json to database format\")\n</code></pre></p>"},{"location":"troubleshooting/#permission-denied","title":"Permission Denied","text":"<p>Problem: <code>PermissionError: [Errno 13] Permission denied</code></p> <p>Solution: <pre><code># Check permissions\nls -la data/\n\n# Fix permissions\nchmod 755 data/\nchmod 644 data/*\n\n# For write operations\nchmod 766 data/output/\n</code></pre></p>"},{"location":"troubleshooting/#query-issues","title":"Query Issues","text":""},{"location":"troubleshooting/#natural-language-not-understood","title":"Natural Language Not Understood","text":"<p>Problem: Agent doesn't understand the query</p> <p>Solution: 1. Be more specific:    <pre><code>\u274c \"Show stuff\"\n\u2705 \"Show me all tables in the landuse database\"\n</code></pre></p> <ol> <li> <p>Use keywords:    <pre><code>\u2705 \"forest\", \"urban\", \"transition\", \"scenario\"\n</code></pre></p> </li> <li> <p>Break complex queries:    <pre><code># Instead of one complex query\n# Break into steps\nagent.run(\"First, show me all scenarios\")\nagent.run(\"Now compare forest area between them\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#sql-syntax-errors","title":"SQL Syntax Errors","text":"<p>Problem: <code>Error executing query: near \"FORM\": syntax error</code></p> <p>Solution: <pre><code>-- Common SQL fixes\nFROM not FORM\nWHERE not WERE  \nSELECT not SELCT\n\n-- Use agent's natural language instead\nYou&gt; Show me forest transitions\n# Instead of writing SQL directly\n</code></pre></p>"},{"location":"troubleshooting/#no-results-returned","title":"No Results Returned","text":"<p>Problem: Query returns empty results</p> <p>Solution: 1. Check filters:    <pre><code>You&gt; Remove the WHERE clause and try again\n</code></pre></p> <ol> <li> <p>Verify data exists:    <pre><code>You&gt; Count total rows in the table\n</code></pre></p> </li> <li> <p>Check case sensitivity:    <pre><code>-- Land use values are capitalized\nWHERE from_land_use = 'Forest'  -- Correct\nWHERE from_land_use = 'forest'  -- Wrong\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"troubleshooting/#slow-queries","title":"Slow Queries","text":"<p>Problem: Queries take too long to execute</p> <p>Solution: 1. Add LIMIT:    <pre><code>You&gt; Show me the first 100 forest transitions\n</code></pre></p> <ol> <li> <p>Use indexed columns:    <pre><code>You&gt; Filter by scenario, year, and fips first\n</code></pre></p> </li> <li> <p>Use filtered views:    <pre><code>You&gt; Query landuse_changes_only instead of landuse_transitions\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#memory-usage","title":"Memory Usage","text":"<p>Problem: High memory usage during processing</p> <p>Solution: <pre><code># Monitor memory\nimport psutil\n\nprocess = psutil.Process()\nprint(f\"Memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n\n# Clear large objects\ndel large_dataframe\nimport gc\ngc.collect()\n</code></pre></p>"},{"location":"troubleshooting/#environment-issues","title":"Environment Issues","text":""},{"location":"troubleshooting/#mkdocs-port-already-in-use","title":"MkDocs Port Already in Use","text":"<p>Problem: <code>OSError: [Errno 48] Address already in use</code></p> <p>Solution: <pre><code># Find process using port\nlsof -i :8000\n\n# Kill process\nkill -9 &lt;PID&gt;\n\n# Or use different port\nmkdocs serve -a localhost:8001\n</code></pre></p>"},{"location":"troubleshooting/#virtual-environment-not-activated","title":"Virtual Environment Not Activated","text":"<p>Problem: Packages not found despite installation</p> <p>Solution: <pre><code># Check if in virtual environment\nwhich python\n# Should show .venv/bin/python\n\n# Activate if needed\nsource .venv/bin/activate\n\n# Verify activation\necho $VIRTUAL_ENV\n</code></pre></p>"},{"location":"troubleshooting/#common-error-messages","title":"Common Error Messages","text":""},{"location":"troubleshooting/#error-reference-table","title":"Error Reference Table","text":"Error Message Likely Cause Quick Fix <code>KeyError: 'OPENAI_API_KEY'</code> Missing API key Add to .env file <code>FileNotFoundError</code> Wrong file path Check path exists <code>sqlite3.OperationalError</code> Database issue Check DB exists <code>JSONDecodeError</code> Invalid JSON Validate JSON format <code>AttributeError</code> Wrong method name Check API docs <code>ConnectionError</code> Network issue Check internet <code>TimeoutError</code> Slow operation Increase timeout"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"troubleshooting/#debugging-steps","title":"Debugging Steps","text":"<ol> <li> <p>Enable verbose output: <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre></p> </li> <li> <p>Check agent state: <pre><code>print(f\"Root dir: {agent.root_dir}\")\nprint(f\"Tools: {[t.name for t in agent.tools]}\")\n</code></pre></p> </li> <li> <p>Test components individually: <pre><code># Test file reading\nresult = agent._read_csv(\"test.csv\")\n\n# Test database connection\nimport sqlite3\nconn = sqlite3.connect(\"test.db\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#resources","title":"Resources","text":"<ul> <li>GitHub Issues: Report bugs and get help</li> <li>Documentation: Check docs for examples</li> <li>Community: Discord/Slack channels</li> <li>Stack Overflow: Tag with <code>langchain</code></li> </ul>"},{"location":"troubleshooting/#creating-bug-reports","title":"Creating Bug Reports","text":"<p>Include: 1. Python version 2. Package versions (<code>pip freeze</code>) 3. Error message and traceback 4. Minimal code to reproduce 5. Expected vs actual behavior</p> <p>Example: <pre><code>**Environment:**\n- Python 3.11.0\n- langchain==0.3.0\n- OS: macOS 14.0\n\n**Error:**\n</code></pre> FileNotFoundError: data.csv <pre><code>**Code to reproduce:**\n```python\nagent = DataEngineeringAgent()\nagent.run(\"Read data.csv\")\n</code></pre></p> <p>Expected: File should be read Actual: Error thrown ```</p>"},{"location":"agents/CONSTANTS_ARCHITECTURE/","title":"How Constants.py Connects to the Agent","text":""},{"location":"agents/CONSTANTS_ARCHITECTURE/#overview","title":"Overview","text":"<p>The <code>constants.py</code> file serves as a centralized configuration and knowledge base for the LanduseAgent. It contains all the domain-specific information, templates, and defaults that the agent needs to operate effectively.</p>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    constants.py                          \u2502\n\u2502                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502  \u2502  STATE_NAMES    \u2502  \u2502 SCHEMA_INFO      \u2502             \u2502\n\u2502  \u2502  - State codes  \u2502  \u2502  TEMPLATE        \u2502             \u2502\n\u2502  \u2502  - State names  \u2502  \u2502 - Table schemas  \u2502             \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2502           \u2502                     \u2502                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502  \u2502 DEFAULT_        \u2502  \u2502 QUERY_EXAMPLES   \u2502             \u2502\n\u2502  \u2502 ASSUMPTIONS     \u2502  \u2502 - SQL templates  \u2502             \u2502\n\u2502  \u2502 - Scenarios     \u2502  \u2502 - Common queries \u2502             \u2502\n\u2502  \u2502 - Time periods  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502                        \u2502\n\u2502           \u2502                     \u2502                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502  \u2502 DB_CONFIG       \u2502  \u2502 MODEL_CONFIG     \u2502             \u2502\n\u2502  \u2502 - Default path  \u2502  \u2502 - Temperature    \u2502             \u2502\n\u2502  \u2502 - Query limits  \u2502  \u2502 - Max tokens     \u2502             \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502                     \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502       agent.py              \u2502\n        \u2502                             \u2502\n        \u2502  Uses constants for:        \u2502\n        \u2502  \u2022 Configuration           \u2502\n        \u2502  \u2022 Schema knowledge        \u2502\n        \u2502  \u2022 Query templates         \u2502\n        \u2502  \u2022 State mappings         \u2502\n        \u2502  \u2022 Default behaviors      \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#how-each-constant-is-used","title":"How Each Constant is Used","text":""},{"location":"agents/CONSTANTS_ARCHITECTURE/#1-schema_info_template-database-knowledge","title":"1. SCHEMA_INFO_TEMPLATE (Database Knowledge)","text":"<p>The agent uses this to understand the database structure:</p> <pre><code># In agent.py _get_schema_info() method:\ndef _get_schema_info(self) -&gt; str:\n    # Start with template\n    schema_info = SCHEMA_INFO_TEMPLATE\n\n    # Add actual table counts...\n    # The template provides the base knowledge about tables and relationships\n</code></pre> <p>Purpose: Gives the LLM complete understanding of the database schema so it can generate correct SQL queries.</p>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#2-state_names-geographic-mapping","title":"2. STATE_NAMES (Geographic Mapping)","text":"<p>Used in the <code>get_state_code</code> tool:</p> <pre><code>@tool\ndef get_state_code(state_name: str) -&gt; str:\n    # Create reverse mapping\n    name_to_code = {v.lower(): k for k, v in STATE_NAMES.items()}\n\n    # Convert \"Texas\" \u2192 \"48\", \"California\" \u2192 \"06\", etc.\n</code></pre> <p>Purpose: Allows users to use state names naturally (\"Texas\") instead of codes (\"48\").</p>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#3-default_assumptions-query-defaults","title":"3. DEFAULT_ASSUMPTIONS (Query Defaults)","text":"<p>Used in the system prompt to handle ambiguous queries:</p> <pre><code>def _get_system_prompt(self) -&gt; str:\n    return f\"\"\"\n    DEFAULT ASSUMPTIONS (when user doesn't specify):\n    - Scenarios: {DEFAULT_ASSUMPTIONS[\"scenarios\"]}\n    - Time Periods: {DEFAULT_ASSUMPTIONS[\"time_period\"]}\n    - Geographic Scope: {DEFAULT_ASSUMPTIONS[\"geographic_scope\"]}\n    - Transition Type: {DEFAULT_ASSUMPTIONS[\"transition_type\"]}\n    \"\"\"\n</code></pre> <p>Purpose: Provides sensible defaults when users ask vague questions like \"How much forest is being lost?\"</p>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#4-query_examples-sql-templates","title":"4. QUERY_EXAMPLES (SQL Templates)","text":"<p>Used by the <code>suggest_query_examples</code> tool:</p> <pre><code>@tool\ndef suggest_query_examples(category: str = \"general\") -&gt; str:\n    if category.lower() in QUERY_EXAMPLES:\n        return f\"Example Query - {category.title()}:\\n{QUERY_EXAMPLES[category.lower()]}\"\n</code></pre> <p>Purpose: Provides tested SQL patterns for common analysis types.</p>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#5-db_config-database-configuration","title":"5. DB_CONFIG (Database Configuration)","text":"<p>Used during initialization:</p> <pre><code>config_dict = {\n    'db_path': Path(db_path or os.getenv('LANDUSE_DB_PATH', DB_CONFIG['default_path'])),\n    'max_query_rows': DB_CONFIG['max_query_limit'],\n    'default_display_limit': DB_CONFIG['default_display_limit']\n}\n</code></pre> <p>Purpose: Centralizes database-related settings and limits.</p>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#6-model_config-llm-configuration","title":"6. MODEL_CONFIG (LLM Configuration)","text":"<p>Used for model defaults:</p> <pre><code>'model_name': model_name or os.getenv('LANDUSE_MODEL', MODEL_CONFIG['default_openai_model']),\n'temperature': temperature or float(os.getenv('TEMPERATURE', str(MODEL_CONFIG['default_temperature']))),\n'max_tokens': max_tokens or int(os.getenv('MAX_TOKENS', str(MODEL_CONFIG['default_max_tokens']))),\n'max_iterations': MODEL_CONFIG['max_iterations'],\n'max_execution_time': MODEL_CONFIG['max_execution_time']\n</code></pre> <p>Purpose: Sets safe defaults for LLM behavior and execution limits.</p>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#benefits-of-this-architecture","title":"Benefits of This Architecture","text":"<ol> <li>Separation of Concerns: Domain knowledge is separated from agent logic</li> <li>Easy Updates: Change constants without touching agent code</li> <li>Reusability: Multiple agents or tools can share the same constants</li> <li>Maintainability: All configuration in one place</li> <li>Type Safety: Constants provide consistent types and values</li> </ol>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#example-flow","title":"Example Flow","text":"<p>When a user asks \"Which states have the most forest loss?\":</p> <ol> <li>Agent receives the query</li> <li>Uses SCHEMA_INFO_TEMPLATE to understand table relationships</li> <li>Applies DEFAULT_ASSUMPTIONS (all scenarios, full time period)</li> <li>May reference QUERY_EXAMPLES[\"agricultural_loss\"] as a pattern</li> <li>Uses STATE_NAMES to convert state codes to names in results</li> <li>Respects DB_CONFIG limits on query size</li> <li>Operates within MODEL_CONFIG constraints</li> </ol>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#environment-variable-overrides","title":"Environment Variable Overrides","text":"<p>Many constants can be overridden via environment variables:</p> <pre><code># Override defaults\nexport LANDUSE_MAX_QUERY_ROWS=5000\nexport LANDUSE_MAX_ITERATIONS=10\nexport LANDUSE_MODEL=gpt-4\n\n# Constants.py reads these in DB_CONFIG and MODEL_CONFIG\n</code></pre> <p>This provides flexibility without code changes.</p>"},{"location":"agents/CONSTANTS_ARCHITECTURE/#summary","title":"Summary","text":"<p>The <code>constants.py</code> file acts as the agent's \"knowledge base\" and configuration center. It provides: - Domain knowledge (schema, state mappings) - Behavioral defaults (assumptions, limits) - Query patterns (examples) - System configuration (database, model)</p> <p>This clean separation makes the agent more maintainable and allows easy customization of its behavior through a single file.</p>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/","title":"Where and How the System Prompt is Stored","text":""},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#location","title":"Location","text":"<p>The system prompt is not stored in a separate file. Instead, it's dynamically generated within the <code>agent.py</code> file by the <code>_get_system_prompt()</code> method (lines 391-429).</p>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  agent.py                        \u2502\n\u2502                                                  \u2502\n\u2502  def _get_system_prompt(self, include_maps):    \u2502\n\u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502      \u2502  Base Prompt (hardcoded)        \u2502        \u2502\n\u2502      \u2502  - Role definition              \u2502        \u2502\n\u2502      \u2502  - Instructions                 \u2502        \u2502\n\u2502      \u2502  - Query patterns               \u2502        \u2502\n\u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502                     \u2502                            \u2502\n\u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502      \u2502  Dynamic Content                \u2502        \u2502\n\u2502      \u2502  - {self.schema_info}           \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500 From SCHEMA_INFO_TEMPLATE\n\u2502      \u2502  - DEFAULT_ASSUMPTIONS          \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500 From constants.py\n\u2502      \u2502  - State codes                  \u2502        \u2502\n\u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502                     \u2502                            \u2502\n\u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502      \u2502  Conditional Content            \u2502        \u2502\n\u2502      \u2502  - Map generation instructions  \u2502        \u2502\n\u2502      \u2502  (if include_maps=True)        \u2502        \u2502\n\u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#system-prompt-structure","title":"System Prompt Structure","text":""},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#1-base-prompt-hardcoded-in-method","title":"1. Base Prompt (Hardcoded in method)","text":"<pre><code>\"\"\"You are a specialized Landuse Data Analyst AI that converts natural language questions into DuckDB SQL queries.\n\nDATABASE SCHEMA:\n{self.schema_info}  # &lt;-- Injected from constants.py\n\nINSTRUCTIONS:\n1. Convert natural language questions to appropriate SQL queries\n2. Use the star schema joins to get meaningful results\n3. Focus on relevant metrics (acres, transitions, geographic patterns)\n4. Add meaningful ORDER BY clauses\n5. Include appropriate LIMIT clauses\n6. Explain the business meaning of results\n\nDEFAULT ASSUMPTIONS (when user doesn't specify):\n- Scenarios: Average across all scenarios (typical outcome)\n- Time Periods: Full range 2012-2100\n- Geographic Scope: All states/counties\n- Transition Type: Focus on 'change' transitions\n\nALWAYS CLEARLY STATE YOUR ASSUMPTIONS in the response.\n\nCOMMON STATE CODES:\n- Texas: '48', California: '06', New York: '36', Florida: '12'\n\nQUERY PATTERNS:\n- \"Agricultural land loss\" \u2192 Agriculture \u2192 non-Agriculture transitions\n- \"Forest loss\" \u2192 Forest \u2192 non-Forest transitions\n- \"Urbanization\" \u2192 Any \u2192 Urban transitions\"\"\"\n</code></pre>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#2-dynamic-schema-section","title":"2. Dynamic Schema Section","text":"<ul> <li><code>{self.schema_info}</code> is populated from <code>SCHEMA_INFO_TEMPLATE</code> in constants.py</li> <li>Contains the full database schema description</li> <li>Updated with actual table counts during initialization</li> </ul>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#3-optional-map-section-conditional","title":"3. Optional Map Section (Conditional)","text":"<pre><code>if include_maps:\n    base_prompt += \"\"\"\n\nMAP GENERATION:\nWhen results include geographic data (state_code), consider creating choropleth maps to visualize patterns.\nUse the create_choropleth_map tool when appropriate.\"\"\"\n</code></pre>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#how-its-used","title":"How It's Used","text":"<pre><code># In _agent_node method:\ndef _agent_node(self, state: LanduseAgentState) -&gt; dict:\n    # Get system prompt with current state\n    system_prompt = self._get_system_prompt(state.get(\"include_maps\", False))\n\n    # Use it with the LLM\n    response = self.llm.bind_tools(self.tools).invoke([\n        {\"role\": \"system\", \"content\": system_prompt},\n        *messages\n    ])\n</code></pre>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#why-this-design","title":"Why This Design?","text":""},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#advantages","title":"Advantages:","text":"<ol> <li>Dynamic Generation: Can adjust based on agent configuration</li> <li>Incorporates Live Data: Uses actual schema info with table counts</li> <li>Conditional Features: Adds map instructions only when needed</li> <li>Single Source: No separate prompt file to maintain</li> </ol>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#disadvantages","title":"Disadvantages:","text":"<ol> <li>Harder to Find: Not immediately obvious where prompt lives</li> <li>Mixed with Code: Business logic mixed with implementation</li> <li>Harder to Version: Can't track prompt changes separately</li> </ol>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#relationship-to-constants","title":"Relationship to Constants","text":"<p>The system prompt pulls from constants.py: - SCHEMA_INFO_TEMPLATE \u2192 Becomes <code>{self.schema_info}</code> - DEFAULT_ASSUMPTIONS \u2192 Referenced but hardcoded in prompt - STATE_NAMES \u2192 Sample codes hardcoded in prompt</p>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#customization-options","title":"Customization Options","text":"<p>To modify the system prompt:</p> <ol> <li>Edit the method directly in <code>agent.py</code></li> <li>Override in a subclass:    <pre><code>class CustomAgent(LanduseAgent):\n    def _get_system_prompt(self, include_maps: bool = False) -&gt; str:\n        return \"Your custom prompt here\"\n</code></pre></li> <li>Make it configurable (not currently implemented):    <pre><code># Could add to constants.py:\nSYSTEM_PROMPT_TEMPLATE = \"...\"\n</code></pre></li> </ol>"},{"location":"agents/SYSTEM_PROMPT_ARCHITECTURE/#summary","title":"Summary","text":"<p>The system prompt is: - Stored: In the <code>_get_system_prompt()</code> method in <code>agent.py</code> - Type: Dynamically generated string - Location: Lines 391-429 of <code>agent.py</code> - Composition: Base template + dynamic schema + optional features - Not: In a separate file or constants.py</p> <p>This design keeps the prompt close to where it's used but makes it less discoverable and harder to maintain separately from the code.</p>"},{"location":"api/agent/","title":"LanduseAgent API Reference","text":"<p>Complete API reference for the unified RPA Land Use Analytics agent.</p>"},{"location":"api/agent/#overview","title":"Overview","text":"<p>The LanduseAgent is the primary and only agent for RPA Land Use Analytics. It provides a unified interface for natural language queries about USDA Forest Service RPA Assessment data with both simple and advanced execution modes.</p>"},{"location":"api/agent/#unified-architecture","title":"\ud83c\udf3e Unified Architecture","text":"<p>Single agent class that combines: - Natural Language Processing: Converts questions to optimized DuckDB SQL - LangGraph Integration: Graph-based workflows for complex analysis - Memory Management: Conversation history and state persistence - Rich Formatting: Beautiful terminal output with Rich library - RPA Expertise: Specialized knowledge of 2020 RPA Assessment data</p> <pre><code>from landuse.agents import LanduseAgent\nfrom landuse.config import LanduseConfig\n\n# Initialize with default configuration\nagent = LanduseAgent()\n\n# Ask natural language questions\nresult = agent.query(\"Which scenarios show the most agricultural land loss?\")\nprint(result)\n</code></pre> <pre><code>from landuse.agents import LanduseAgent\nfrom landuse.config import LanduseConfig\n\n# Initialize with default configuration\nagent = LanduseAgent()\n\n# Initialize with custom configuration\nconfig = LanduseConfig(\n    model_name=\"claude-3-5-sonnet-20241022\", \n    enable_map_generation=True,\n    enable_memory=True,\n    debug=True\n)\nagent = LanduseAgent(config=config)\n\n# Run a query\nresult = agent.query(\"Show me the tables in the database\")\n</code></pre>"},{"location":"api/agent/#class-landuseagent","title":"Class: LanduseAgent","text":""},{"location":"api/agent/#constructor","title":"Constructor","text":"<pre><code>LanduseAgent(config: LanduseConfig = None)\n</code></pre> <p>Parameters: - <code>config</code> (LanduseConfig, optional): Configuration object. If None, uses default configuration from environment variables.</p> <p>Example: <pre><code># Use default configuration\nagent = LanduseAgent()\n\n# Use agent-specific configuration\nconfig = LanduseConfig.for_agent_type('map', verbose=True)\nagent = LanduseAgent(config=config)\n</code></pre></p>"},{"location":"api/agent/#methods","title":"Methods","text":""},{"location":"api/agent/#queryquestion-str-use_graph-bool-false-thread_id-optionalstr-none-str","title":"query(question: str, use_graph: bool = False, thread_id: Optional[str] = None) -&gt; str","text":"<p>Execute a natural language query and return results.</p> <p>Parameters: - <code>question</code> (str): Natural language question about RPA data - <code>use_graph</code> (bool): Whether to use LangGraph workflow (default: False) - <code>thread_id</code> (Optional[str]): Thread ID for conversation memory</p> <p>Returns: - <code>str</code>: Query results formatted as text with business context</p> <p>Example: <pre><code>result = agent.query(\"What are the top 5 counties by urban growth?\")\nprint(result)\n\n# With graph workflow and memory\nresult = agent.query(\n    \"Compare this to agricultural land loss\", \n    use_graph=True, \n    thread_id=\"analysis_session\"\n)\n</code></pre></p>"},{"location":"api/agent/#simple_queryquestion-str-str","title":"simple_query(question: str) -&gt; str","text":"<p>Direct LLM interaction without LangGraph (recommended for production).</p> <p>Parameters: - <code>question</code> (str): Natural language question</p> <p>Returns: - <code>str</code>: Formatted response with query results and analysis</p> <p>Example: <pre><code>result = agent.simple_query(\"Show me forest transition patterns\")\nprint(result)\n</code></pre></p>"},{"location":"api/agent/#stream_queryquestion-str-thread_id-optionalstr-none-iteratorany","title":"stream_query(question: str, thread_id: Optional[str] = None) -&gt; Iterator[Any]","text":"<p>Streaming query execution for real-time responses.</p> <p>Parameters: - <code>question</code> (str): Natural language question - <code>thread_id</code> (Optional[str]): Thread ID for memory</p> <p>Yields: - Response chunks for real-time display</p> <p>Example: <pre><code>for chunk in agent.stream_query(\"Analyze urbanization trends\"):\n    print(chunk, end=\"\")\n</code></pre></p>"},{"location":"api/agent/#chat","title":"chat()","text":"<p>Start an interactive chat session with rich terminal formatting.</p> <p>Example: <pre><code># Start interactive mode\nagent.chat()\n# Type 'exit' to quit\n</code></pre></p>"},{"location":"api/agent/#available-tools","title":"Available Tools","text":"<p>The LanduseAgent has access to specialized tools for RPA data analysis:</p>"},{"location":"api/agent/#core-rpa-analysis-tools","title":"Core RPA Analysis Tools","text":"Tool Description Example Query <code>execute_landuse_query</code> Execute DuckDB SQL on RPA data \"Which scenarios show most forest loss?\" <code>analyze_landuse_results</code> Interpret results in RPA context \"Explain these urbanization patterns\" <code>get_schema_info</code> Show RPA database schema \"What tables are available?\" <code>get_state_code</code> Convert state names to FIPS codes \"Show me data for California\""},{"location":"api/agent/#optional-enhancement-tools","title":"Optional Enhancement Tools","text":"Tool Description Example Query <code>rpa_knowledge_retriever</code> Access RPA methodology docs \"What is the forest projection methodology?\" <code>create_choropleth_map</code> Generate geographic visualizations \"Map agricultural losses by county\" <code>create_heatmap</code> Create data heatmaps \"Show urbanization hotspots\" <p>Note: Map generation and knowledge base tools are optional and controlled by configuration.</p>"},{"location":"api/agent/#query-patterns","title":"Query Patterns","text":""},{"location":"api/agent/#rpa-scenario-analysis","title":"RPA Scenario Analysis","text":"<pre><code># Climate scenario comparisons\nagent.query(\"Compare forest loss between RCP45 and RCP85 scenarios\")\n\n# Socioeconomic scenario analysis\nagent.query(\"Which SSP scenarios show the most urban expansion?\")\n\n# Model ensemble analysis\nagent.query(\"Show variation across different climate models\")\n</code></pre>"},{"location":"api/agent/#geographic-analysis","title":"Geographic Analysis","text":"<pre><code># State-level analysis\nagent.query(\"Which states have the most agricultural land loss?\")\n\n# Regional comparisons\nagent.query(\"Compare urbanization between the South and Midwest\")\n\n# County-level patterns\nagent.query(\"Show me the top 10 counties for forest to urban conversion\")\n</code></pre>"},{"location":"api/agent/#land-use-transition-analysis","title":"Land Use Transition Analysis","text":"<pre><code># Transition matrices\nagent.query(\"What land use types are converting to urban?\")\n\n# Agricultural analysis\nagent.query(\"How much cropland is being lost to development?\")\n\n# Forest analysis\nagent.query(\"Show me forest conversion patterns by scenario\")\n</code></pre>"},{"location":"api/agent/#temporal-analysis","title":"Temporal Analysis","text":"<pre><code># Time series trends\nagent.query(\"Show urbanization trends from 2020 to 2070\")\n\n# Acceleration patterns\nagent.query(\"When does urban expansion accelerate the most?\")\n\n# Cumulative changes\nagent.query(\"Total land use change by 2100 under high warming\")\n</code></pre>"},{"location":"api/agent/#response-format","title":"Response Format","text":"<p>The agent returns responses in a structured format:</p> <pre><code>Query: [Generated SQL or operation]\nResults: [Number of rows]\n\n[Formatted data table or results]\n\n[Additional context or explanations]\n</code></pre>"},{"location":"api/agent/#error-handling","title":"Error Handling","text":"<p>The agent handles various error conditions gracefully:</p> <pre><code># File not found\nresult = agent.run(\"Read nonexistent.csv\")\n# Returns: \"Error reading CSV: [Errno 2] No such file or directory\"\n\n# Invalid SQL\nresult = agent.run(\"Query with invalid SQL syntax\")\n# Returns: \"Error executing query: [SQL error details]\"\n\n# Type mismatches\nresult = agent.run(\"Calculate the average of text columns\")\n# Returns: \"No numeric columns found for calculation\"\n</code></pre>"},{"location":"api/agent/#memory-and-context","title":"Memory and Context","text":"<p>The LanduseAgent maintains conversation context across queries:</p> <pre><code># Initialize conversation context\nagent.query(\"Show me counties in California\")\n\n# Follow-up queries use conversation history\nagent.query(\"Now show me just the ones with high urban growth\")\n# Agent remembers we're analyzing California counties\n\n# Context persists across multiple queries\nagent.query(\"What scenarios show the biggest changes?\")\n# Still in California context\n\n# Clear context when needed\nagent.clear_history()\nagent.query(\"Now analyze Texas counties\")  # Fresh context\n</code></pre>"},{"location":"api/agent/#memory-configuration","title":"Memory Configuration","text":"<pre><code># Enable persistent memory with thread IDs\nconfig = LanduseConfig(enable_memory=True)\nagent = LanduseAgent(config=config)\n\n# Use graph mode for advanced memory features\nresult = agent.query(\n    \"Analyze forest trends\", \n    use_graph=True, \n    thread_id=\"forest_analysis_session\"\n)\n\n# Continue conversation in same thread\nresult = agent.query(\n    \"Now compare to agricultural trends\", \n    use_graph=True, \n    thread_id=\"forest_analysis_session\"\n)\n</code></pre>"},{"location":"api/agent/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/agent/#query-optimization","title":"Query Optimization","text":"<p>The agent automatically optimizes queries: - Adds appropriate LIMIT clauses - Uses indexes when available - Filters early in query execution</p>"},{"location":"api/agent/#large-file-handling","title":"Large File Handling","text":"<p>For files over <code>MAX_FILE_SIZE_MB</code>: - Automatic sampling for preview - Streaming processing for conversions - Progress indicators for long operations</p>"},{"location":"api/agent/#configuration","title":"Configuration","text":"<p>The agent respects environment variables:</p> <pre><code>import os\n\n# Set configuration via environment variables\nos.environ['LANDUSE_MODEL'] = 'gpt-4o'\nos.environ['TEMPERATURE'] = '0.1'\nos.environ['MAX_TOKENS'] = '4000'\n\n# Initialize with configuration\nconfig = LanduseConfig.from_env()\nagent = LanduseAgent(config=config)\n</code></pre>"},{"location":"api/agent/#integration-examples","title":"Integration Examples","text":""},{"location":"api/agent/#programmatic-usage","title":"Programmatic Usage","text":"<pre><code># Batch processing\nqueries = [\n    \"List all tables\",\n    \"Count total records\",\n    \"Show summary statistics\"\n]\n\nresults = {}\nfor query in queries:\n    results[query] = agent.run(query)\n</code></pre>"},{"location":"api/agent/#rpa-analysis-pipeline","title":"RPA Analysis Pipeline","text":"<pre><code># RPA scenario analysis pipeline\ndef analyze_scenario(scenario_name):\n    config = LanduseConfig(enable_memory=True)\n    agent = LanduseAgent(config=config)\n\n    # Get scenario overview\n    overview = agent.query(f\"Analyze {scenario_name} scenario overview\")\n\n    # Agricultural impacts\n    ag_impacts = agent.query(f\"Show agricultural impacts in {scenario_name}\")\n\n    # Forest transitions\n    forest_changes = agent.query(f\"Analyze forest changes in {scenario_name}\")\n\n    # Geographic patterns\n    geo_patterns = agent.query(f\"Show geographic patterns for {scenario_name}\")\n\n    return {\n        'overview': overview,\n        'agriculture': ag_impacts,\n        'forest': forest_changes,\n        'geography': geo_patterns\n    }\n\n# Batch scenario comparison\ndef compare_scenarios(scenarios):\n    agent = LanduseAgent()\n    results = {}\n\n    for scenario in scenarios:\n        agent.clear_history()  # Fresh context for each scenario\n        results[scenario] = analyze_scenario(scenario)\n\n    return results\n</code></pre>"},{"location":"api/agent/#web-service-integration","title":"Web Service Integration","text":"<pre><code>from flask import Flask, request, jsonify\nfrom landuse.agents import LanduseAgent\nfrom landuse.config import LanduseConfig\n\napp = Flask(__name__)\n# Disable memory for stateless web service\nconfig = LanduseConfig(enable_memory=False, debug=False)\nagent = LanduseAgent(config=config)\n\n@app.route('/query', methods=['POST'])\ndef query():\n    user_query = request.json.get('query')\n    thread_id = request.json.get('thread_id')  # Optional\n\n    # Use simple_query for web service stability\n    result = agent.simple_query(user_query)\n\n    return jsonify({\n        'result': result,\n        'thread_id': thread_id,\n        'model': agent.model_name\n    })\n\n@app.route('/stream', methods=['POST'])\ndef stream_query():\n    user_query = request.json.get('query')\n    thread_id = request.json.get('thread_id')\n\n    def generate():\n        for chunk in agent.stream_query(user_query, thread_id):\n            yield f\"data: {json.dumps(chunk)}\\n\\n\"\n\n    return Response(generate(), mimetype='text/event-stream')\n</code></pre>"},{"location":"api/agent/#advanced-features","title":"Advanced Features","text":""},{"location":"api/agent/#custom-tools-and-subgraphs","title":"Custom Tools and Subgraphs","text":"<p>Extend the LanduseAgent with specialized capabilities:</p> <pre><code>from landuse.agents import LanduseAgent\nfrom landuse.config import LanduseConfig\nfrom langchain_core.tools import Tool\n\nclass CustomRPAAgent(LanduseAgent):\n    def __init__(self, config: LanduseConfig = None):\n        super().__init__(config)\n        # Add custom RPA-specific tools\n        self.custom_tools = self._create_custom_tools()\n\n    def _create_custom_tools(self):\n        return [\n            Tool(\n                name=\"calculate_carbon_impact\",\n                func=self._calculate_carbon_impact,\n                description=\"Calculate carbon impact of land use changes\"\n            ),\n            Tool(\n                name=\"assess_water_resources\",\n                func=self._assess_water_impact,\n                description=\"Assess water resource implications\"\n            )\n        ]\n\n    def create_sustainability_subgraph(self):\n        \"\"\"Create specialized subgraph for sustainability analysis.\"\"\"\n        sustainability_tools = self.tools + self.custom_tools\n        return self.create_subgraph(\"sustainability\", sustainability_tools)\n\n    def _calculate_carbon_impact(self, params: str) -&gt; str:\n        # Custom carbon analysis implementation\n        return \"Carbon impact analysis results\"\n\n    def _assess_water_impact(self, params: str) -&gt; str:\n        # Custom water resource analysis\n        return \"Water resource impact assessment\"\n</code></pre>"},{"location":"api/agent/#extending-functionality","title":"Extending Functionality","text":"<pre><code># Enable map generation in configuration\nconfig = LanduseConfig(enable_map_generation=True)\nagent = LanduseAgent(config=config)\n\n# Generate geographic visualizations\nagent.query(\"Create a map showing urban growth by county\")\n\n# Use map subgraph for complex geographic analysis\nmap_subgraph = agent.create_map_subgraph()\n\n# Access RPA methodology documentation\nconfig = LanduseConfig(enable_knowledge_base=True)\nagent = LanduseAgent(config=config)\nagent.query(\"What assumptions are used in the forest projection model?\")\n\n# Advanced analysis with custom prompts\nfrom landuse.agents.prompts import create_custom_prompt\ncustom_prompt = create_custom_prompt(\n    analysis_style=\"detailed\",\n    domain_focus=\"forest_economics\"\n)\n</code></pre>"},{"location":"api/agent/#best-practices","title":"Best Practices","text":"<ol> <li>Use RPA Terminology: Reference scenarios (LM, HL, HM, HH), models (RCP45/85, SSP\u2155), and land use types correctly</li> <li>Start with Simple Queries: Use <code>simple_query()</code> or <code>query(use_graph=False)</code> for production</li> <li>Leverage Context: Build up analysis through conversation history</li> <li>Geographic Specificity: Specify states, regions, or counties for focused analysis</li> <li>Scenario Comparisons: Compare multiple scenarios to understand uncertainty</li> <li>Error Recovery: Agent provides helpful suggestions when queries fail</li> <li>Performance: Agent automatically optimizes queries with appropriate limits</li> </ol>"},{"location":"api/agent/#next-steps","title":"Next Steps","text":"<ul> <li>See Query Examples for more patterns</li> <li>Review Converters API for data processing</li> <li>Check Tools Reference for detailed tool documentation</li> </ul>"},{"location":"api/converters/","title":"Converters API Reference","text":"<p>Documentation for the data conversion scripts that transform raw JSON data into queryable DuckDB databases.</p>"},{"location":"api/converters/#overview","title":"Overview","text":"<p>The converters module contains scripts for processing land use projection data:</p> <pre><code>scripts/converters/\n\u251c\u2500\u2500 convert_to_duckdb.py          # Modern DuckDB converter (RECOMMENDED)\n\u251c\u2500\u2500 convert_json_to_parquet.py    # JSON to Parquet conversion\n\u251c\u2500\u2500 convert_landuse_to_db.py      # Legacy SQLite converter\n\u251c\u2500\u2500 convert_landuse_transitions.py # Legacy transition converter\n\u251c\u2500\u2500 convert_landuse_with_agriculture.py # Legacy SQLite with agriculture\n\u251c\u2500\u2500 convert_landuse_nested.py     # Legacy nested converter\n\u251c\u2500\u2500 add_change_views.py           # Add views to existing database\n\u2514\u2500\u2500 add_land_area_view.py         # Add land area calculations\n</code></pre>"},{"location":"api/converters/#core-converters","title":"Core Converters","text":""},{"location":"api/converters/#convert_to_duckdbpy-recommended","title":"convert_to_duckdb.py (RECOMMENDED)","text":"<p>Modern converter that transforms raw JSON land use projections into a well-structured DuckDB database using star schema design and bulk loading optimization.</p> <pre><code># Basic usage\nuv run python scripts/converters/convert_to_duckdb.py\n</code></pre> <p>Key Features: - Star Schema Design: Normalized dimension and fact tables - Bulk Loading: 5-10x faster using DuckDB COPY with Parquet - Rich Progress Tracking: Beautiful terminal progress bars - Data Validation: Comprehensive integrity checks - Modern Architecture: Optimized for analytics workloads</p> <p>Output: - Creates <code>data/processed/landuse_analytics.duckdb</code> (1.2GB) - Tables: <code>fact_landuse_transitions</code>, <code>dim_scenario</code>, <code>dim_geography_enhanced</code>, <code>dim_landuse</code>, <code>dim_time</code> - Views: Pre-built analytical views for common queries - Indexes: Optimized for query performance</p>"},{"location":"api/converters/#convert_landuse_to_dbpy-legacy","title":"convert_landuse_to_db.py (LEGACY)","text":"<p>Legacy converter for SQLite database format. Use <code>convert_to_duckdb.py</code> for new projects.</p> <pre><code># Legacy usage (not recommended)\nuv run python scripts/converters/convert_landuse_to_db.py\n</code></pre> <p>Key Functions:</p> <pre><code>def process_matrix_data(matrix_data, scenario, year, year_range, fips):\n    \"\"\"Convert transition matrix to normalized records.\n\n    Args:\n        matrix_data: List of transition matrix rows\n        scenario: Scenario name (e.g., 'Baseline')\n        year: End year of transition period\n        year_range: Period string (e.g., '2020-2030')\n        fips: County FIPS code\n\n    Returns:\n        List of transition dictionaries\n    \"\"\"\n</code></pre> <p>Output: - Creates <code>landuse_transitions.db</code> (SQLite) - Table: <code>landuse_transitions</code> - ~1.2 million transition records</p>"},{"location":"api/converters/#convert_landuse_with_agriculturepy-legacy","title":"convert_landuse_with_agriculture.py (LEGACY)","text":"<p>Legacy enhanced converter that includes agricultural aggregation views for SQLite.</p> <pre><code># Legacy usage with agricultural aggregation\nuv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre> <p>Features: - Creates base transition table (SQLite) - Adds agricultural aggregation (Crop + Pasture) - Creates filtered views (changes only) - Adds performance indexes</p> <p>Output Tables: 1. <code>landuse_transitions</code> - All transitions 2. <code>landuse_transitions_ag</code> - With agricultural aggregation 3. <code>landuse_changes_only</code> - Excluding same-to-same 4. <code>landuse_changes_only_ag</code> - Changes with ag aggregation</p>"},{"location":"api/converters/#add_change_viewspy","title":"add_change_views.py","text":"<p>Adds filtered views to existing database (works with both SQLite and DuckDB).</p> <pre><code># Add views to existing database\nuv run python scripts/converters/add_change_views.py\n</code></pre> <p>Creates Views: <pre><code>-- Changes only view\nCREATE VIEW landuse_changes_only AS\nSELECT * FROM landuse_transitions\nWHERE from_land_use != to_land_use\n  AND from_land_use != 'Total'\n  AND to_land_use != 'Total';\n</code></pre></p>"},{"location":"api/converters/#convert_json_to_parquetpy","title":"convert_json_to_parquet.py","text":"<p>Utility converter for creating Parquet files from JSON data.</p> <pre><code># Convert JSON to Parquet for analysis\nuv run python scripts/converters/convert_json_to_parquet.py\n</code></pre> <p>Features: - Efficient Parquet format for analytics - Preserves nested data structure - Compatible with pandas and DuckDB - Smaller file sizes and faster I/O</p>"},{"location":"api/converters/#utility-functions","title":"Utility Functions","text":""},{"location":"api/converters/#land-use-mapping","title":"Land Use Mapping","text":"<pre><code>LAND_USE_MAP = {\n    'cr': 'Crop',\n    'ps': 'Pasture',\n    'rg': 'Range',\n    'fr': 'Forest',\n    'ur': 'Urban',\n    't1': 'Total',  # Row sum\n    't2': 'Total'   # Column sum\n}\n</code></pre>"},{"location":"api/converters/#year-extraction","title":"Year Extraction","text":"<pre><code>def extract_end_year(year_range):\n    \"\"\"Extract end year from range string.\n\n    Args:\n        year_range: String like '2020-2030'\n\n    Returns:\n        int: End year (2030)\n    \"\"\"\n    return int(year_range.split('-')[1])\n</code></pre>"},{"location":"api/converters/#value-conversion","title":"Value Conversion","text":"<pre><code>def convert_value(value):\n    \"\"\"Convert Decimal/numeric to float.\n\n    Handles various numeric types safely.\n    \"\"\"\n    if isinstance(value, Decimal):\n        return float(value)\n    return float(value) if value is not None else 0.0\n</code></pre>"},{"location":"api/converters/#processing-large-files","title":"Processing Large Files","text":""},{"location":"api/converters/#modern-bulk-loading-duckdb","title":"Modern Bulk Loading (DuckDB)","text":"<p>The modern converter uses DuckDB's COPY command with Parquet for optimal performance:</p> <pre><code>class LanduseDataConverter:\n    def bulk_load_fact_table(self, fact_data):\n        \"\"\"Use DuckDB COPY for 5-10x performance improvement.\"\"\"\n        parquet_path = self.temp_dir / \"fact_transitions.parquet\"\n\n        # Write to Parquet first\n        fact_df.to_parquet(parquet_path, index=False)\n\n        # Bulk load with COPY\n        self.conn.execute(f\"\"\"\n            COPY fact_landuse_transitions \n            FROM '{parquet_path}'\n            (FORMAT PARQUET)\n        \"\"\")\n</code></pre>"},{"location":"api/converters/#legacy-streaming-json-processing","title":"Legacy Streaming JSON Processing","text":"<p>For legacy converters, use streaming:</p> <pre><code>import ijson\n\ndef process_large_json(json_path):\n    \"\"\"Stream process large JSON files.\"\"\"\n    with open(json_path, 'rb') as file:\n        parser = ijson.items(file, 'item')\n\n        batch = []\n        for item in parser:\n            batch.append(process_item(item))\n\n            if len(batch) &gt;= 10000:\n                insert_batch(batch)\n                batch = []\n</code></pre>"},{"location":"api/converters/#progress-tracking","title":"Progress Tracking","text":"<p>Using Rich for progress display:</p> <pre><code>from rich.progress import Progress\n\nwith Progress() as progress:\n    task = progress.add_task(\"Converting...\", total=county_count)\n\n    for county in counties:\n        process_county(county)\n        progress.update(task, advance=1)\n</code></pre>"},{"location":"api/converters/#database-schema-creation","title":"Database Schema Creation","text":""},{"location":"api/converters/#modern-duckdb-star-schema-convert_to_duckdbpy","title":"Modern DuckDB Star Schema (convert_to_duckdb.py)","text":"<pre><code>-- Fact table\nCREATE TABLE fact_landuse_transitions (\n    scenario_id INTEGER,\n    geography_id INTEGER,\n    time_id INTEGER,\n    from_landuse_id INTEGER,\n    to_landuse_id INTEGER,\n    acres DOUBLE,\n    transition_type VARCHAR  -- 'change' or 'same'\n);\n\n-- Dimension tables\nCREATE TABLE dim_scenario (\n    scenario_id INTEGER PRIMARY KEY,\n    scenario_name VARCHAR,\n    rcp_scenario VARCHAR,\n    ssp_scenario VARCHAR,\n    description VARCHAR\n);\n\nCREATE TABLE dim_geography_enhanced (\n    geography_id INTEGER PRIMARY KEY,\n    county_fips VARCHAR,\n    county_name VARCHAR,\n    state_code VARCHAR,\n    state_name VARCHAR,\n    region_name VARCHAR,\n    land_area_sq_miles DOUBLE\n);\n</code></pre>"},{"location":"api/converters/#legacy-sqlite-schema-convert_landuse_to_dbpy","title":"Legacy SQLite Schema (convert_landuse_to_db.py)","text":"<pre><code>CREATE TABLE landuse_transitions (\n    scenario TEXT NOT NULL,\n    year INTEGER NOT NULL,\n    year_range TEXT NOT NULL,\n    fips TEXT NOT NULL,\n    from_land_use TEXT NOT NULL,\n    to_land_use TEXT NOT NULL,\n    area_1000_acres REAL\n);\n</code></pre>"},{"location":"api/converters/#indexes","title":"Indexes","text":"<p>DuckDB Indexes (Modern): <pre><code>-- Automatically optimized columnar storage\n-- Additional indexes for star schema joins\nCREATE INDEX idx_fact_scenario ON fact_landuse_transitions(scenario_id);\nCREATE INDEX idx_fact_geography ON fact_landuse_transitions(geography_id);\nCREATE INDEX idx_fact_time ON fact_landuse_transitions(time_id);\n</code></pre></p> <p>SQLite Indexes (Legacy): <pre><code>-- Performance indexes for flat table\nCREATE INDEX idx_scenario ON landuse_transitions(scenario);\nCREATE INDEX idx_year ON landuse_transitions(year);\nCREATE INDEX idx_fips ON landuse_transitions(fips);\nCREATE INDEX idx_from_to ON landuse_transitions(from_land_use, to_land_use);\n</code></pre></p>"},{"location":"api/converters/#error-handling","title":"Error Handling","text":""},{"location":"api/converters/#validation","title":"Validation","text":"<pre><code>def validate_transitions(transitions, fips, year):\n    \"\"\"Validate data integrity.\"\"\"\n    # Check total area consistency\n    total_from = sum(t['area'] for t in transitions if t['from'] != 'Total')\n    total_to = sum(t['area'] for t in transitions if t['to'] != 'Total')\n\n    if abs(total_from - total_to) &gt; 0.01:\n        raise ValueError(f\"Area mismatch for {fips} in {year}\")\n</code></pre>"},{"location":"api/converters/#error-recovery","title":"Error Recovery","text":"<pre><code>try:\n    process_county(county_data)\nexcept Exception as e:\n    logger.error(f\"Error processing {county_id}: {e}\")\n    failed_counties.append(county_id)\n    continue\n</code></pre>"},{"location":"api/converters/#custom-converters","title":"Custom Converters","text":""},{"location":"api/converters/#creating-custom-aggregations","title":"Creating Custom Aggregations","text":"<pre><code>def create_custom_aggregation(db_path, aggregation_map):\n    \"\"\"Create custom land use aggregations.\n\n    Args:\n        db_path: Database file path\n        aggregation_map: Dict mapping original to new categories\n    \"\"\"\n    conn = sqlite3.connect(db_path)\n\n    # Example: Urban + Infrastructure\n    aggregation_map = {\n        'Urban': 'Developed',\n        'Infrastructure': 'Developed',\n        'Forest': 'Natural',\n        'Range': 'Natural'\n    }\n</code></pre>"},{"location":"api/converters/#adding-calculated-fields","title":"Adding Calculated Fields","text":"<pre><code>def add_calculated_fields(db_path):\n    \"\"\"Add derived columns to database.\"\"\"\n    conn = sqlite3.connect(db_path)\n\n    # Add percentage column\n    conn.execute(\"\"\"\n        ALTER TABLE landuse_transitions \n        ADD COLUMN percent_of_county REAL\n    \"\"\")\n\n    # Calculate percentages\n    conn.execute(\"\"\"\n        UPDATE landuse_transitions\n        SET percent_of_county = \n            area_1000_acres / (\n                SELECT SUM(area_1000_acres) \n                FROM landuse_transitions t2 \n                WHERE t2.fips = landuse_transitions.fips\n                  AND t2.year = landuse_transitions.year\n            ) * 100\n    \"\"\")\n</code></pre>"},{"location":"api/converters/#performance-optimization","title":"Performance Optimization","text":""},{"location":"api/converters/#batch-operations","title":"Batch Operations","text":"<pre><code># Batch inserts\nconn.executemany(\n    \"INSERT INTO landuse_transitions VALUES (?,?,?,?,?,?,?)\",\n    batch_data\n)\n\n# Transaction wrapping\nconn.execute(\"BEGIN TRANSACTION\")\n# ... bulk operations ...\nconn.execute(\"COMMIT\")\n</code></pre>"},{"location":"api/converters/#memory-management","title":"Memory Management","text":"<pre><code># Process in chunks\nCHUNK_SIZE = 50000\n\nfor i in range(0, len(data), CHUNK_SIZE):\n    chunk = data[i:i + CHUNK_SIZE]\n    process_chunk(chunk)\n\n    # Explicit garbage collection if needed\n    if i % (CHUNK_SIZE * 10) == 0:\n        import gc\n        gc.collect()\n</code></pre>"},{"location":"api/converters/#usage-examples","title":"Usage Examples","text":""},{"location":"api/converters/#modern-duckdb-conversion-recommended","title":"Modern DuckDB Conversion (RECOMMENDED)","text":"<pre><code># Convert JSON to DuckDB with star schema\nuv run python scripts/converters/convert_to_duckdb.py\n\n# Output\n\ud83d\ude80 Using bulk COPY loading method\n\ud83d\udcca Processing county_landuse_projections_RPA.json...\n\u2705 Created 5,400,000+ transition records in star schema\n\ud83d\uddc4\ufe0f Database saved to: data/processed/landuse_analytics.duckdb (1.2GB)\n</code></pre>"},{"location":"api/converters/#legacy-sqlite-pipeline","title":"Legacy SQLite Pipeline","text":"<pre><code># Legacy complete processing pipeline\n# 1. Basic conversion\nuv run python scripts/converters/convert_landuse_to_db.py\n\n# 2. Add agricultural aggregation\nuv run python scripts/converters/convert_landuse_with_agriculture.py\n\n# 3. Add filtered views\nuv run python scripts/converters/add_change_views.py\n</code></pre>"},{"location":"api/converters/#performance-comparison","title":"Performance Comparison","text":"Method Time Output Size Query Performance DuckDB (Modern) 2-5 minutes 1.2GB Excellent (columnar) SQLite (Legacy) 15-30 minutes 800MB Good (row-based)"},{"location":"api/converters/#custom-processing","title":"Custom Processing","text":"<p>Modern DuckDB Approach: <pre><code>from landuse.converters.base_converter import LanduseDataConverter\n\n# Custom processing with DuckDB\ndef process_custom_scenario(json_data, scenario_name):\n    \"\"\"Process only specific scenario with DuckDB.\"\"\"\n    converter = LanduseDataConverter(\n        input_file=\"data.json\", \n        output_file=\"custom.duckdb\"\n    )\n\n    # Process with filtering\n    converter.process_scenarios(filter_scenarios=[scenario_name])\n    return converter\n</code></pre></p> <p>Legacy SQLite Approach: <pre><code>from scripts.converters.convert_landuse_to_db import process_matrix_data\n\n# Legacy custom processing\ndef process_custom_scenario(json_data, scenario_name):\n    \"\"\"Process only specific scenario.\"\"\"\n    transitions = []\n\n    for county in json_data:\n        if scenario_name in county['scenarios']:\n            scenario_data = county['scenarios'][scenario_name]\n            # Process this scenario\n\n    return transitions\n</code></pre></p>"},{"location":"api/converters/#migration-guide","title":"Migration Guide","text":""},{"location":"api/converters/#from-sqlite-to-duckdb","title":"From SQLite to DuckDB","text":"<p>To migrate from legacy SQLite to modern DuckDB:</p> <ol> <li>Run Modern Converter: Use <code>convert_to_duckdb.py</code> instead of legacy converters</li> <li>Update Agent Configuration: Point to new DuckDB file in config</li> <li>Benefit from Performance: Enjoy 5-10x faster queries with star schema</li> <li>Use Enhanced Features: Access new analytical views and geographic data</li> </ol>"},{"location":"api/converters/#recommendation","title":"Recommendation","text":"<p>For new projects: Use <code>convert_to_duckdb.py</code> for modern star schema design and optimal performance.</p> <p>For existing projects: Consider migrating to DuckDB for better analytics performance.</p>"},{"location":"api/converters/#next-steps","title":"Next Steps","text":"<ul> <li>See Data Processing for detailed pipeline</li> <li>Check DuckDB Schema for modern table structure</li> <li>Review Agent API for querying converted data</li> <li>See Performance Guide for optimization details</li> </ul>"},{"location":"api/landuse-query-agent/","title":"LanduseAgent: Natural Language Query Capabilities","text":""},{"location":"api/landuse-query-agent/#overview","title":"Overview","text":"<p>The LanduseAgent includes powerful natural language query capabilities that convert English questions into optimized DuckDB SQL queries for analyzing RPA landuse transition data. This document focuses specifically on the natural language processing and query generation features of the unified LanduseAgent class.</p>"},{"location":"api/landuse-query-agent/#query-processing-features","title":"Query Processing Features","text":""},{"location":"api/landuse-query-agent/#advanced-natural-language-understanding","title":"\ud83e\udd16 Advanced Natural Language Understanding","text":"<ul> <li>Converts English questions to optimized SQL queries</li> <li>Understands RPA domain terminology and scenarios</li> <li>Handles complex multi-step analytical requirements</li> <li>Provides rich business context for results</li> <li>Maintains conversation history for follow-up questions</li> </ul>"},{"location":"api/landuse-query-agent/#duckdb-query-optimization","title":"\ud83e\udd86 DuckDB Query Optimization","text":"<ul> <li>Generates efficient star schema joins across RPA tables</li> <li>Uses appropriate aggregations and filters</li> <li>Automatically adds row limits for performance</li> <li>Leverages DuckDB's columnar analytics capabilities</li> <li>Includes intelligent error handling and suggestions</li> </ul>"},{"location":"api/landuse-query-agent/#rich-rpa-analytics","title":"\ud83d\udcca Rich RPA Analytics","text":"<ul> <li>Automatic summary statistics and insights</li> <li>Formatted result tables with Rich library</li> <li>Business interpretation of RPA findings</li> <li>Scenario comparison capabilities</li> <li>Geographic and temporal analysis patterns</li> </ul>"},{"location":"api/landuse-query-agent/#beautiful-user-experience","title":"\ud83c\udfa8 Beautiful User Experience","text":"<ul> <li>Rich terminal interface with colors and tables</li> <li>Streaming responses for real-time feedback</li> <li>Interactive chat mode with memory</li> <li>Built-in help system with RPA examples</li> <li>Error recovery with helpful suggestions</li> </ul>"},{"location":"api/landuse-query-agent/#quick-start","title":"Quick Start","text":""},{"location":"api/landuse-query-agent/#interactive-mode","title":"Interactive Mode","text":"<pre><code># Start interactive chat interface\nuv run python -m landuse\n\n# Or directly run the agent module\nuv run python -m landuse.agents.landuse_agent\n</code></pre>"},{"location":"api/landuse-query-agent/#programmatic-usage","title":"Programmatic Usage","text":"<pre><code>from landuse.agents import LanduseAgent\nfrom landuse.config import LanduseConfig\n\n# Initialize agent with default configuration\nagent = LanduseAgent()\n\n# Ask natural language questions (recommended approach)\nresponse = agent.simple_query(\"Which scenarios show the most agricultural land loss?\")\nprint(response)\n\n# Or use the unified query method\nresponse = agent.query(\"Compare forest loss between RCP scenarios\")\nprint(response)\n\n# With custom configuration\nconfig = LanduseConfig(model_name=\"claude-3-5-sonnet-20241022\", debug=True)\nagent = LanduseAgent(config=config)\nresponse = agent.query(\"Analyze urbanization patterns in California\")\n</code></pre>"},{"location":"api/landuse-query-agent/#example-queries","title":"Example Queries","text":""},{"location":"api/landuse-query-agent/#agricultural-analysis","title":"\ud83c\udf3e Agricultural Analysis","text":"<p>Question: \"Which scenarios show the most agricultural land loss?\"</p> <p>LanduseAgent Processing: 1. Understands \"agricultural land loss\" as transitions FROM crop/pasture TO other uses 2. Identifies need for scenario comparison across RPA climate models 3. Generates optimized SQL using the star schema 4. Provides business context about RPA scenario implications</p> <p>Generated SQL: <pre><code>SELECT \n    s.scenario_name,\n    s.rcp_scenario,\n    s.ssp_scenario,\n    SUM(f.acres) as acres_lost\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_category IN ('Crop', 'Pasture')\n  AND tl.landuse_category NOT IN ('Crop', 'Pasture')\nGROUP BY s.scenario_name, s.rcp_scenario, s.ssp_scenario\nORDER BY acres_lost DESC\nLIMIT 1000;\n</code></pre></p> <p>Question: \"How much farmland is being converted to urban areas?\"</p> <p>LanduseAgent Analysis: 1. Recognizes \"farmland\" as both crop and pasture land uses 2. Understands \"converted to urban\" as transition TO urban development 3. Includes geographic and temporal context in results 4. Provides interpretation of urbanization patterns</p> <p>Generated SQL: <pre><code>SELECT \n    fl.landuse_name as from_landuse,\n    g.state_name,\n    t.time_period,\n    SUM(f.acres) as acres_urbanized,\n    COUNT(DISTINCT g.county_fips) as counties_affected\nFROM fact_landuse_transitions f\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nJOIN dim_geography_enhanced g ON f.geography_id = g.geography_id\nJOIN dim_time t ON f.time_id = t.time_id\nWHERE fl.landuse_category IN ('Crop', 'Pasture')\n  AND tl.landuse_name = 'Urban'\nGROUP BY fl.landuse_name, g.state_name, t.time_period\nORDER BY acres_urbanized DESC\nLIMIT 1000;\n</code></pre></p>"},{"location":"api/landuse-query-agent/#climate-environment","title":"\ud83c\udf0d Climate &amp; Environment","text":"<p>Question: \"Compare forest loss between RCP45 and RCP85 scenarios\"</p> <p>Generated SQL: <pre><code>SELECT \n    s.rcp_scenario,\n    tl.landuse_name as to_landuse,\n    SUM(f.acres) as forest_lost\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_name = 'Forest'\n  AND tl.landuse_name != 'Forest'\n  AND s.rcp_scenario IN ('rcp45', 'rcp85')\n  AND f.transition_type = 'change'\nGROUP BY s.rcp_scenario, tl.landuse_name\nORDER BY forest_lost DESC;\n</code></pre></p>"},{"location":"api/landuse-query-agent/#geographic-patterns","title":"\ud83c\udfd8\ufe0f Geographic Patterns","text":"<p>Question: \"Which states have the most urban expansion?\"</p> <p>Generated SQL: <pre><code>SELECT \n    g.state_code,\n    fl.landuse_name as from_landuse,\n    SUM(f.acres) as acres_urbanized\nFROM fact_landuse_transitions f\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE tl.landuse_name = 'Urban'\n  AND f.transition_type = 'change'\nGROUP BY g.state_code, fl.landuse_name\nORDER BY acres_urbanized DESC;\n</code></pre></p>"},{"location":"api/landuse-query-agent/#scenario-analysis","title":"\ud83c\udf21\ufe0f Scenario Analysis","text":"<p>Question: \"Compare SSP1 vs SSP5 development patterns\"</p> <p>Generated SQL: <pre><code>SELECT \n    s.ssp_scenario,\n    fl.landuse_name as from_landuse,\n    tl.landuse_name as to_landuse,\n    SUM(f.acres) as total_acres,\n    COUNT(*) as transition_count\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE s.ssp_scenario IN ('ssp1', 'ssp5')\n  AND f.transition_type = 'change'\nGROUP BY s.ssp_scenario, fl.landuse_name, tl.landuse_name\nORDER BY total_acres DESC;\n</code></pre></p>"},{"location":"api/landuse-query-agent/#interactive-chat-interface","title":"Interactive Chat Interface","text":""},{"location":"api/landuse-query-agent/#chat-commands","title":"Chat Commands","text":"<ul> <li><code>help</code>: Show RPA-specific example questions</li> <li><code>clear</code>: Clear conversation history</li> <li><code>exit</code>: Quit the agent</li> </ul>"},{"location":"api/landuse-query-agent/#example-chat-session","title":"Example Chat Session","text":"<pre><code>[Agent] RPA Land Use Analytics Agent\nAsk questions about land use projections and transitions.\nType 'exit' to quit, 'help' for examples, 'clear' to reset conversation.\n\n[You] &gt; Which scenarios show the most agricultural land loss?\n\n[Agent] Thinking...\n\n[Agent] I'll analyze agricultural land loss across RPA scenarios by looking at \ntransitions from crop and pasture lands to other uses.\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Agricultural Land Loss by Scenario                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Scenario                    \u2502 RCP  \u2502 SSP \u2502 Acres Lost (millions) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 CNRM_CM5_rcp85_ssp5         \u2502 85   \u2502 5   \u2502 26.5                  \u2502\n\u2502 MRI_CGCM3_rcp85_ssp5        \u2502 85   \u2502 5   \u2502 26.4                  \u2502\n\u2502 ...                         \u2502 ...  \u2502 ... \u2502 ...                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nKey Insights:\n\u2022 RCP85/SSP5 scenarios show highest agricultural losses\n\u2022 High warming + high socioeconomic growth drives development\n\u2022 Most losses occur in high-growth regions like the South\n\n[You] &gt; Which states are most affected?\n\n[Agent] Based on our previous agricultural loss analysis, I'll show you \nwhich states have the highest projected losses...\n</code></pre>"},{"location":"api/landuse-query-agent/#architecture","title":"Architecture","text":""},{"location":"api/landuse-query-agent/#core-components","title":"Core Components","text":"<ol> <li>LanduseAgent: Unified agent class with query capabilities</li> <li>LangGraph Integration: Graph-based workflow for complex analysis</li> <li>Configuration System: Flexible LanduseConfig for all settings</li> <li>Natural Language Processing: Claude/GPT powered query understanding</li> <li>SQL Generation: RPA star schema optimized query creation</li> <li>Rich Formatting: Beautiful terminal output with Rich library</li> <li>Memory Management: Conversation history and context persistence</li> </ol>"},{"location":"api/landuse-query-agent/#query-processing-pipeline","title":"Query Processing Pipeline","text":"<ol> <li>Input Processing: Parse natural language with RPA context</li> <li>Intent Recognition: Identify analysis type (scenario, geographic, temporal)</li> <li>SQL Generation: Create optimized DuckDB queries</li> <li>Execution: Run queries with error handling and retry logic</li> <li>Result Analysis: Provide business interpretation and insights</li> <li>Response Formatting: Rich tables, statistics, and recommendations</li> </ol>"},{"location":"api/landuse-query-agent/#integration-tools","title":"Integration Tools","text":"<ul> <li><code>execute_landuse_query</code>: Execute optimized SQL on RPA DuckDB</li> <li><code>analyze_landuse_results</code>: Interpret results in RPA business context</li> <li><code>get_schema_info</code>: Retrieve RPA star schema information</li> <li><code>get_state_code</code>: Convert state names to FIPS codes</li> <li><code>rpa_knowledge_retriever</code>: Access RPA methodology documentation (optional)</li> </ul>"},{"location":"api/landuse-query-agent/#advanced-prompt-system","title":"Advanced Prompt System","text":"<p>The agent uses sophisticated prompts that include: - Complete RPA database schema with business context - Common RPA analysis patterns and examples - Scenario-specific terminology and concepts - Geographic and temporal analysis guidelines - Error handling and optimization strategies</p>"},{"location":"api/landuse-query-agent/#advanced-features","title":"Advanced Features","text":""},{"location":"api/landuse-query-agent/#automatic-query-optimization","title":"Automatic Query Optimization","text":"<ul> <li>Adds LIMIT clauses for safety</li> <li>Uses efficient star schema joins</li> <li>Includes appropriate indexes</li> <li>Optimizes for DuckDB's columnar storage</li> </ul>"},{"location":"api/landuse-query-agent/#business-context","title":"Business Context","text":"<ul> <li>Interprets agricultural vs environmental impacts</li> <li>Explains climate scenario differences</li> <li>Provides geographic context</li> <li>Suggests follow-up analyses</li> </ul>"},{"location":"api/landuse-query-agent/#error-handling","title":"Error Handling","text":"<ul> <li>Graceful SQL error recovery</li> <li>Helpful error messages</li> <li>Query suggestion on failures</li> <li>Database connection management</li> </ul>"},{"location":"api/landuse-query-agent/#configuration","title":"Configuration","text":""},{"location":"api/landuse-query-agent/#environment-variables","title":"Environment Variables","text":"<pre><code># API Keys (one required)\nANTHROPIC_API_KEY=your_anthropic_key  # For Claude models (recommended)\nOPENAI_API_KEY=your_openai_key        # For GPT models\n\n# Model Selection (optional)\nLANDUSE_MODEL=claude-3-5-sonnet-20241022  # Default\n# LANDUSE_MODEL=gpt-4o-mini\n\n# Database Configuration (optional)\nLANDUSE_DB_PATH=data/processed/landuse_analytics.duckdb\n\n# Query Execution Limits (optional)\nLANDUSE_MAX_ITERATIONS=5\nLANDUSE_MAX_EXECUTION_TIME=120\nLANDUSE_MAX_QUERY_ROWS=1000\nLANDUSE_DEFAULT_DISPLAY_LIMIT=50\n\n# Rate Limiting (optional)\nLANDUSE_RATE_LIMIT_CALLS=60\nLANDUSE_RATE_LIMIT_WINDOW=60\n</code></pre>"},{"location":"api/landuse-query-agent/#python-configuration","title":"Python Configuration","text":"<pre><code>from landuse.agents import LanduseAgent\nfrom landuse.config import LanduseConfig\n\n# Custom configuration\nconfig = LanduseConfig(\n    model_name=\"claude-3-5-sonnet-20241022\",\n    temperature=0.1,\n    max_tokens=4000,\n    enable_memory=True,\n    enable_map_generation=True,\n    enable_knowledge_base=True,\n    debug=True\n)\n\nagent = LanduseAgent(config=config)\n\n# Or modify specific settings\nconfig = LanduseConfig()\nconfig.model_name = \"gpt-4o-mini\"\nconfig.max_query_rows = 2000\nagent = LanduseAgent(config=config)\n</code></pre>"},{"location":"api/landuse-query-agent/#performance","title":"Performance","text":""},{"location":"api/landuse-query-agent/#query-execution-times","title":"Query Execution Times","text":"<ul> <li>Simple scenario queries: &lt; 2 seconds</li> <li>Complex geographic aggregations: 2-8 seconds  </li> <li>Large multi-scenario comparisons: 5-20 seconds</li> <li>Time series analysis: 3-15 seconds</li> </ul>"},{"location":"api/landuse-query-agent/#accuracy-metrics","title":"Accuracy Metrics","text":"<ul> <li>RPA schema understanding: 98%+ accuracy</li> <li>SQL query generation: 95%+ correct syntax</li> <li>Business context interpretation: High RPA domain relevance</li> <li>Error recovery: Intelligent suggestions for failed queries</li> </ul>"},{"location":"api/landuse-query-agent/#optimization-features","title":"Optimization Features","text":"<ul> <li>Automatic row limiting: Prevents runaway queries</li> <li>Smart indexing: Uses DuckDB columnar advantages</li> <li>Query caching: Conversation context reduces redundant work</li> <li>Retry logic: Handles temporary database issues gracefully</li> </ul>"},{"location":"api/landuse-query-agent/#best-practices","title":"Best Practices","text":""},{"location":"api/landuse-query-agent/#effective-question-patterns","title":"Effective Question Patterns","text":"<ul> <li>Scenario Analysis: \"Which RCP85 scenarios show the most urban expansion?\"</li> <li>Geographic Focus: \"Compare agricultural losses between Texas and Iowa\"</li> <li>Temporal Patterns: \"Show forest transition trends from 2020 to 2070\"</li> <li>Transition Analysis: \"What land uses are converting to urban in California?\"</li> <li>Model Comparisons: \"Compare CNRM vs MRI climate model projections\"</li> </ul>"},{"location":"api/landuse-query-agent/#question-formulation-tips","title":"Question Formulation Tips","text":"<ul> <li>Be Specific: Use RPA terminology (scenarios, models, time periods)</li> <li>Geographic Context: Specify states, regions, or counties when relevant</li> <li>Comparative Analysis: Compare scenarios, time periods, or geographies</li> <li>Follow-up Questions: Build on previous queries using conversation memory</li> </ul>"},{"location":"api/landuse-query-agent/#recommended-analysis-workflow","title":"Recommended Analysis Workflow","text":"<ol> <li>Overview: Start with broad scenario or geographic questions</li> <li>Focus: Drill down into specific land use transitions or patterns</li> <li>Compare: Examine differences across scenarios, models, or regions</li> <li>Context: Use follow-up questions to explore implications</li> <li>Validation: Cross-check findings with different query approaches</li> </ol>"},{"location":"api/landuse-query-agent/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Natural Limits: Agent automatically applies appropriate row limits</li> <li>Geographic Filtering: Specify states or regions to reduce data scope</li> <li>Scenario Selection: Focus on specific RCP/SSP combinations</li> <li>Time Periods: Specify relevant time ranges for analysis</li> <li>Conversation Memory: Leverage context to avoid re-explaining parameters</li> </ul>"},{"location":"api/landuse-query-agent/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api/landuse-query-agent/#common-issues","title":"Common Issues","text":"<p>\"Database file not found\" - Ensure the DuckDB database has been created - Check the database path configuration</p> <p>\"No results returned\" - Try broader queries first - Check if filters are too restrictive - Verify scenario or geography names</p> <p>\"SQL Error\" - The agent will suggest corrections - Try rephrasing the question - Use the <code>help</code> command for examples</p>"},{"location":"api/landuse-query-agent/#getting-help","title":"Getting Help","text":"<ul> <li>Use <code>help</code> command in chat mode for RPA-specific examples</li> <li>Use <code>clear</code> command to reset conversation context</li> <li>Check the RPA Scenarios documentation for scenario details</li> <li>Review the Database Schema documentation for table structure</li> <li>See Configuration Guide for setup options</li> </ul>"},{"location":"api/landuse-query-agent/#integration","title":"Integration","text":""},{"location":"api/landuse-query-agent/#with-other-tools","title":"With Other Tools","text":"<pre><code># Use with visualization libraries\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nagent = LanduseAgent()\nresponse = agent.query(\"Agricultural land loss by scenario\")\n# Parse response and create visualizations\n</code></pre>"},{"location":"api/landuse-query-agent/#api-integration","title":"API Integration","text":"<pre><code># Create a production-ready API endpoint\nfrom flask import Flask, request, jsonify\nfrom landuse.agents import LanduseAgent\nfrom landuse.config import LanduseConfig\n\napp = Flask(__name__)\n\n# Initialize agent with production settings\nconfig = LanduseConfig(enable_memory=False, debug=False)\nagent = LanduseAgent(config=config)\n\n@app.route('/query', methods=['POST'])\ndef query_rpa_data():\n    question = request.json['question']\n    thread_id = request.json.get('thread_id')\n\n    # Use simple_query for API stability\n    result = agent.simple_query(question)\n\n    return jsonify({\n        'result': result,\n        'model': agent.model_name,\n        'thread_id': thread_id\n    })\n\n@app.route('/stream', methods=['POST'])\ndef stream_query():\n    question = request.json['question']\n    thread_id = request.json.get('thread_id')\n\n    def generate():\n        for chunk in agent.stream_query(question, thread_id):\n            yield f\"data: {json.dumps(chunk)}\\n\\n\"\n\n    return Response(generate(), mimetype='text/event-stream')\n</code></pre>"},{"location":"api/landuse-query-agent/#future-enhancements","title":"Future Enhancements","text":""},{"location":"api/landuse-query-agent/#planned-features","title":"Planned Features","text":"<ul> <li>Visualization generation: Automatic chart creation</li> <li>Export capabilities: CSV/Excel export of results</li> <li>Saved queries: Store and reuse common analyses</li> <li>Multi-database support: Query multiple databases</li> <li>Advanced analytics: Time series forecasting</li> </ul>"},{"location":"api/landuse-query-agent/#contributing","title":"Contributing","text":"<ul> <li>Add new query patterns to the examples</li> <li>Improve business context explanations</li> <li>Enhance error handling and recovery</li> <li>Optimize SQL generation patterns</li> </ul> <p>The LanduseAgent's natural language capabilities represent the cutting edge of RPA data analysis, making complex land use projections and climate scenario analysis accessible through simple English questions. With its unified architecture, conversation memory, and deep RPA domain knowledge, it provides an intuitive interface for exploring the USDA Forest Service's comprehensive 2020 RPA Assessment data. </p>"},{"location":"api/langgraph-agent/","title":"LanduseAgent API Reference","text":""},{"location":"api/langgraph-agent/#overview","title":"Overview","text":"<p>The LanduseAgent is the unified, modern natural language agent for RPA Land Use Analytics. It combines graph-based LangGraph architecture with traditional query capabilities, providing enhanced state management, conversation memory, and streaming capabilities.</p>"},{"location":"api/langgraph-agent/#key-features","title":"Key Features","text":"<ul> <li>Unified Architecture: Single agent class with both simple and graph-based execution modes</li> <li>LangGraph Integration: Graph-based workflow orchestration for complex queries</li> <li>Conversation Memory: Built-in conversation history and checkpointing</li> <li>Streaming Support: Real-time response streaming capabilities</li> <li>Enhanced Error Handling: Graceful recovery from failures with helpful suggestions</li> <li>RPA Context Aware: Specialized for 2020 RPA Assessment data analysis</li> <li>Memory-First Design: Modern 2025 architecture with persistent state</li> </ul>"},{"location":"api/langgraph-agent/#usage","title":"Usage","text":""},{"location":"api/langgraph-agent/#command-line-interface","title":"Command Line Interface","text":"<pre><code># Start the interactive agent\nuv run python -m landuse.agents.landuse_agent\n\n# Or use the package shortcut\nuv run python -m landuse\n\n# Or use the CLI shortcut if configured\nuv run rpa-analytics\n</code></pre>"},{"location":"api/langgraph-agent/#python-api","title":"Python API","text":"<pre><code>from landuse.agents import LanduseAgent\nfrom landuse.config import LanduseConfig\n\n# Initialize with default configuration\nagent = LanduseAgent()\n\n# Initialize with custom configuration\nconfig = LanduseConfig(\n    model_name=\"claude-3-5-sonnet-20241022\",  # or \"gpt-4o-mini\"\n    temperature=0.1,\n    enable_memory=True,\n    enable_map_generation=True\n)\nagent = LanduseAgent(config=config)\n\n# Simple query (recommended for stability)\nresult = agent.query(\"Which RPA scenarios show the most forest loss?\")\nprint(result)\n\n# Graph-based query with memory\nresult = agent.query(\n    \"Compare urban expansion between scenarios\", \n    use_graph=True, \n    thread_id=\"analysis_session_1\"\n)\nprint(result)\n\n# Streaming query for real-time responses\nfor chunk in agent.stream_query(\"Show me agricultural trends\", thread_id=\"stream_1\"):\n    print(chunk)\n</code></pre>"},{"location":"api/langgraph-agent/#configuration","title":"Configuration","text":""},{"location":"api/langgraph-agent/#environment-variables","title":"Environment Variables","text":"<pre><code># Model selection (optional)\nLANDUSE_MODEL=claude-3-5-sonnet-20241022  # Default\n\n# API Keys (one required)\nANTHROPIC_API_KEY=your_key\nOPENAI_API_KEY=your_key\n\n# Database path (optional)\nLANDUSE_DB_PATH=data/processed/landuse_analytics.duckdb\n\n# Execution limits (optional)\nLANDUSE_MAX_ITERATIONS=5\nLANDUSE_MAX_EXECUTION_TIME=120\nLANDUSE_MAX_QUERY_ROWS=1000\n</code></pre>"},{"location":"api/langgraph-agent/#agent-state","title":"Agent State","text":"<p>The agent maintains state using TypedDict for LangGraph operations:</p> <pre><code>class AgentState(TypedDict):\n    \"\"\"State definition for the landuse agent.\"\"\"\n    messages: list[BaseMessage]\n    context: dict[str, Any]\n    iteration_count: int\n    max_iterations: int\n</code></pre>"},{"location":"api/langgraph-agent/#configuration_1","title":"Configuration","text":"<p>The agent uses <code>LanduseConfig</code> for all configuration:</p> <pre><code>from landuse.config import LanduseConfig\n\n# Load from environment variables\nconfig = LanduseConfig()\n\n# Custom configuration\nconfig = LanduseConfig(\n    model_name=\"claude-3-5-sonnet-20241022\",\n    temperature=0.1,\n    max_tokens=4000,\n    enable_memory=True,\n    enable_map_generation=False,\n    debug=True\n)\n</code></pre>"},{"location":"api/langgraph-agent/#available-tools","title":"Available Tools","text":"<p>The LanduseAgent uses a comprehensive set of tools for RPA data analysis:</p>"},{"location":"api/langgraph-agent/#execute_landuse_query","title":"execute_landuse_query","text":"<p>Executes optimized DuckDB SQL queries on the RPA database.</p> <pre><code># The agent automatically converts natural language to SQL\n\"Which scenarios show the most agricultural land loss?\"\n# Generates and executes: SELECT s.scenario_name, SUM(f.acres) as acres_lost ...\n</code></pre>"},{"location":"api/langgraph-agent/#analyze_landuse_results","title":"analyze_landuse_results","text":"<p>Provides business context and insights for query results.</p> <pre><code># Automatically interprets results in RPA context\n\"Explain the implications of this forest loss data\"\n</code></pre>"},{"location":"api/langgraph-agent/#get_schema_info","title":"get_schema_info","text":"<p>Returns detailed schema information about the RPA star schema.</p> <pre><code># Shows table structure and relationships\n\"What tables are available in the database?\"\n</code></pre>"},{"location":"api/langgraph-agent/#get_state_code","title":"get_state_code","text":"<p>Converts state names to FIPS codes for geographic queries.</p> <pre><code># Handles state name variations\n\"Show me data for California\"  # Automatically converts to state code\n</code></pre>"},{"location":"api/langgraph-agent/#knowledge-base-integration-optional","title":"Knowledge Base Integration (Optional)","text":"<p>If enabled, provides access to RPA methodology documentation.</p> <pre><code># When knowledge base is enabled\n\"What is the methodology behind forest transition projections?\"\n</code></pre>"},{"location":"api/langgraph-agent/#example-queries","title":"Example Queries","text":""},{"location":"api/langgraph-agent/#basic-rpa-analysis","title":"Basic RPA Analysis","text":"<pre><code># Agricultural land loss\nresult = agent.query(\"How much agricultural land is projected to be lost by 2070?\")\n\n# Climate model comparison\nresult = agent.query(\"Compare forest loss between wet and dry climate models\")\n\n# Scenario analysis\nresult = agent.query(\"Which RPA scenario has the most urban expansion?\")\n</code></pre>"},{"location":"api/langgraph-agent/#advanced-analysis","title":"Advanced Analysis","text":"<pre><code># Time series with specific scenario\nresult = agent.query(\"\"\"\n    Show me annual forest loss rates under the HH scenario \n    (high warming, high growth) from 2020 to 2070\n\"\"\")\n\n# Regional comparison\nresult = agent.query(\"\"\"\n    Compare agricultural transitions between the South and \n    Midwest regions under the sustainability scenario (LM)\n\"\"\")\n\n# Climate pathway analysis\nresult = agent.query(\"\"\"\n    What's the difference in total land use change between \n    RCP4.5 and RCP8.5 pathways across all socioeconomic scenarios?\n\"\"\")\n</code></pre>"},{"location":"api/langgraph-agent/#error-handling","title":"Error Handling","text":"<p>The agent includes comprehensive error handling:</p> <pre><code>try:\n    result = agent.query(\"Invalid query\")\nexcept Exception as e:\n    print(f\"Query failed: {e}\")\n    # Agent provides helpful error messages and suggestions\n</code></pre>"},{"location":"api/langgraph-agent/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Query Optimization: Agent automatically adds appropriate filters and limits</li> <li>Memory Management: Conversation history is pruned to maintain performance</li> <li>Concurrent Queries: Thread-safe for multiple simultaneous queries</li> <li>Response Streaming: Use async methods for real-time updates</li> </ul>"},{"location":"api/langgraph-agent/#integration-with-streamlit","title":"Integration with Streamlit","text":"<p>The LanduseAgent powers the Streamlit chat interface:</p> <pre><code># In Streamlit app\nimport streamlit as st\nfrom landuse.agents import LanduseAgent\nfrom landuse.config import LanduseConfig\n\n# Initialize agent with Streamlit-optimized config\nconfig = LanduseConfig(enable_memory=False, debug=False)\nagent = LanduseAgent(config=config)\n\n# Simple query for Streamlit (most stable)\nresponse = agent.query(user_query)\nst.write(response)\n\n# Or streaming for real-time updates\nfor chunk in agent.stream_query(user_query, thread_id=st.session_state.get('thread_id')):\n    st.write(chunk)\n</code></pre>"},{"location":"api/langgraph-agent/#execution-modes","title":"Execution Modes","text":"<p>The LanduseAgent supports multiple execution modes:</p> Mode Description Use Case Stability Simple Query Direct LLM interaction Most queries, production use High Graph Workflow LangGraph state management Complex analysis, development Medium Streaming Real-time response chunks UI applications Medium Chat Interface Interactive terminal mode Development, testing High <p>Recommendation: Use <code>simple_query()</code> or <code>query(use_graph=False)</code> for production applications.</p>"},{"location":"api/langgraph-agent/#api-methods","title":"API Methods","text":""},{"location":"api/langgraph-agent/#queryquestion-str-use_graph-bool-false-thread_id-optionalstr-none-str","title":"query(question: str, use_graph: bool = False, thread_id: Optional[str] = None) -&gt; str","text":"<p>Main query method with flexible execution modes.</p> <p>Parameters: - <code>question</code>: Natural language question about RPA data - <code>use_graph</code>: Whether to use LangGraph workflow (default: False for stability) - <code>thread_id</code>: Optional thread ID for conversation memory</p>"},{"location":"api/langgraph-agent/#simple_queryquestion-str-str","title":"simple_query(question: str) -&gt; str","text":"<p>Direct LLM interaction without LangGraph state management (recommended).</p>"},{"location":"api/langgraph-agent/#stream_queryquestion-str-thread_id-optionalstr-none-iteratorany","title":"stream_query(question: str, thread_id: Optional[str] = None) -&gt; Iterator[Any]","text":"<p>Streaming method for real-time responses using LangGraph.</p>"},{"location":"api/langgraph-agent/#chat","title":"chat()","text":"<p>Interactive chat interface with rich terminal formatting.</p>"},{"location":"api/langgraph-agent/#clear_history","title":"clear_history()","text":"<p>Clears conversation history and resets state.</p>"},{"location":"api/langgraph-agent/#create_subgraphname-str-specialized_tools-listbasetool-stategraph","title":"create_subgraph(name: str, specialized_tools: list[BaseTool]) -&gt; StateGraph","text":"<p>Creates specialized subgraphs for complex workflows.</p>"},{"location":"api/langgraph-agent/#create_map_subgraph-stategraph","title":"create_map_subgraph() -&gt; StateGraph","text":"<p>Creates a specialized subgraph for map-based analysis.</p>"},{"location":"api/langgraph-agent/#best-practices","title":"Best Practices","text":"<ol> <li>Use specific RPA terminology: Reference scenarios (LM, HL, HM, HH) and models by name</li> <li>Leverage defaults: Agent uses intelligent defaults when parameters aren't specified</li> <li>Ask follow-up questions: Agent maintains context across queries</li> <li>Handle streaming: Use async methods for better user experience</li> <li>Monitor iterations: Set appropriate limits for complex queries</li> </ol>"},{"location":"api/tools/","title":"Tools API Reference","text":"<p>Detailed documentation of all tools available to the unified LanduseAgent for RPA land use analytics.</p>"},{"location":"api/tools/#overview","title":"Overview","text":"<p>The LanduseAgent uses a collection of specialized tools for RPA data analysis, geographic processing, and natural language interaction. Each tool is designed to handle specific RPA analytical tasks while maintaining consistency and error handling.</p>"},{"location":"api/tools/#tool-categories","title":"Tool Categories","text":""},{"location":"api/tools/#core-rpa-analysis-tools","title":"\ud83c\udf3e Core RPA Analysis Tools","text":"<p>Specialized tools for RPA land use data analysis:</p> Tool Function Parameters Example <code>execute_landuse_query</code> Execute DuckDB SQL on RPA data <code>query: str</code> \"Which scenarios show most forest loss?\" <code>analyze_landuse_results</code> Interpret results in RPA context <code>results: str</code> \"Explain these urbanization patterns\" <code>get_schema_info</code> Show RPA database schema <code>table_name: str</code> \"What tables are available?\" <code>get_state_code</code> Convert state names to FIPS codes <code>state_name: str</code> \"Show me data for California\""},{"location":"api/tools/#optional-geographic-tools","title":"\ud83d\uddfa\ufe0f Optional Geographic Tools","text":"<p>Enhanced tools available when map generation is enabled:</p> Tool Function Parameters Example <code>create_choropleth_map</code> Generate county-level maps <code>data_query: str</code> \"Map agricultural losses by county\" <code>create_heatmap</code> Create data heatmaps <code>data: str</code> \"Show urbanization hotspots\""},{"location":"api/tools/#optional-knowledge-tools","title":"\ud83d\udcda Optional Knowledge Tools","text":"<p>RPA methodology and documentation tools:</p> Tool Function Parameters Example <code>rpa_knowledge_retriever</code> Access RPA methodology docs <code>question: str</code> \"What is the forest projection methodology?\""},{"location":"api/tools/#core-tool-details","title":"Core Tool Details","text":""},{"location":"api/tools/#execute_landuse_query","title":"execute_landuse_query","text":"<pre><code>def execute_landuse_query(query: str) -&gt; str\n</code></pre> <p>Purpose: Execute optimized SQL queries on the RPA DuckDB database</p> <p>Features: - Star schema-aware query execution - Automatic performance optimization - Error handling with helpful suggestions - Result formatting for terminal display - Query safety with row limits</p> <p>Returns: - Formatted query results with business context - Summary statistics when appropriate - Error messages with suggestions for fixes</p> <p>Example: <pre><code>agent.query(\"Which scenarios show the most agricultural land loss?\")\n# Internally calls execute_landuse_query with optimized SQL\n</code></pre></p>"},{"location":"api/tools/#analyze_landuse_results","title":"analyze_landuse_results","text":"<pre><code>def analyze_landuse_results(results: str, context: str = \"\") -&gt; str\n</code></pre> <p>Purpose: Provide business interpretation of RPA query results</p> <p>Features: - RPA scenario expertise and context - Climate and socioeconomic impact analysis - Geographic pattern recognition - Policy and planning implications - Cross-scenario comparisons</p> <p>Returns: - Business interpretation of numerical results - Key insights and implications - Recommendations for further analysis - Context about RPA methodology</p> <p>Example: <pre><code># After executing a query about forest loss\nresults = \"RCP85/SSP5 scenarios show 15M acres of forest loss...\"\nanalysis = analyze_landuse_results(results)\n# Returns: \"This represents the highest warming scenario combined with...\"\n</code></pre></p>"},{"location":"api/tools/#get_schema_info","title":"get_schema_info","text":"<pre><code>def get_schema_info(table_name: str = None) -&gt; str\n</code></pre> <p>Purpose: Provide RPA database schema information and guidance</p> <p>Features: - Complete star schema documentation - Business-friendly column descriptions - Common query patterns and examples - Relationship mapping between tables - Data quality and coverage notes</p> <p>Parameters: - <code>table_name</code> (optional): Specific table to describe, or None for full schema</p> <p>Example: <pre><code>agent.query(\"What tables are available?\")\n# Shows: fact_landuse_transitions, dim_scenario, dim_geography_enhanced, etc.\n\nagent.query(\"Describe the scenario table\")\n# Shows: scenario_id, scenario_name, rcp_scenario, ssp_scenario, etc.\n</code></pre></p>"},{"location":"api/tools/#get_state_code","title":"get_state_code","text":"<pre><code>def get_state_code(state_name: str) -&gt; str\n</code></pre> <p>Purpose: Convert state names to FIPS codes for geographic filtering</p> <p>Features: - Fuzzy matching for state names - Abbreviation support (CA, TX, FL, etc.) - Full state name support (California, Texas, Florida) - Error handling for invalid states - Returns both FIPS codes and state names</p> <p>Example: <pre><code>agent.query(\"Show me data for California\")\n# Internally converts \"California\" to FIPS code \"06\"\n\nagent.query(\"Compare Texas and Florida urbanization\")\n# Converts \"Texas\" -&gt; \"48\" and \"Florida\" -&gt; \"12\"\n</code></pre></p>"},{"location":"api/tools/#enhanced-tool-configuration","title":"Enhanced Tool Configuration","text":""},{"location":"api/tools/#map-generation-tools","title":"Map Generation Tools","text":"<p>Enable map generation in your configuration:</p> <pre><code>from landuse.config import LanduseConfig\n\nconfig = LanduseConfig(enable_map_generation=True)\nagent = LanduseAgent(config=config)\n\n# Now you can ask for maps\nagent.query(\"Create a map showing urban growth by county\")\n</code></pre>"},{"location":"api/tools/#create_choropleth_map","title":"create_choropleth_map","text":"<pre><code>def create_choropleth_map(data_query: str, map_type: str = \"county\") -&gt; str\n</code></pre> <p>Purpose: Generate geographic visualizations of RPA data</p> <p>Features: - County-level choropleth maps - Automatic data aggregation - Professional styling and legends - Multiple map types (forest, urban, agricultural) - Saves maps to <code>maps/agent_generated/</code> directory</p> <p>Example: <pre><code>agent.query(\"Map forest loss by county in California\")\n# Creates: maps/agent_generated/county_map_forest_california_YYYYMMDD_HHMMSS.png\n</code></pre></p>"},{"location":"api/tools/#knowledge-base-tools","title":"Knowledge Base Tools","text":"<p>Enable RPA methodology access:</p> <pre><code>config = LanduseConfig(enable_knowledge_base=True)\nagent = LanduseAgent(config=config)\n\n# Now you can ask methodology questions\nagent.query(\"What assumptions are used in the forest projection model?\")\n</code></pre>"},{"location":"api/tools/#rpa_knowledge_retriever","title":"rpa_knowledge_retriever","text":"<pre><code>def rpa_knowledge_retriever(question: str) -&gt; str\n</code></pre> <p>Purpose: Access RPA Assessment methodology documentation</p> <p>Features: - Vector search across RPA technical documents - Contextual retrieval of methodology details - References to specific chapters and sections - Integration with query results for deeper analysis</p> <p>Example: <pre><code>agent.query(\"What is the economic model used for land use projections?\")\n# Retrieves relevant sections from RPA technical documentation\n</code></pre></p>"},{"location":"api/tools/#tool-error-handling","title":"Tool Error Handling","text":""},{"location":"api/tools/#database-connection-errors","title":"Database Connection Errors","text":"<pre><code># Automatic retry logic\ndef execute_landuse_query(query: str) -&gt; str:\n    try:\n        return execute_query_with_retry(query)\n    except DatabaseError as e:\n        return f\"Database error: {e}. Try rephrasing your question.\"\n</code></pre>"},{"location":"api/tools/#sql-generation-errors","title":"SQL Generation Errors","text":"<pre><code># Helpful error recovery\ndef handle_sql_error(error: str, original_query: str) -&gt; str:\n    suggestions = [\n        \"Try using specific scenario names (like 'RCP45' or 'SSP1')\",\n        \"Specify state names or FIPS codes for geographic queries\",\n        \"Check table and column names with 'What tables are available?'\"\n    ]\n    return f\"SQL Error: {error}\\n\\nSuggestions:\\n\" + \"\\n\".join(suggestions)\n</code></pre>"},{"location":"api/tools/#geographic-query-errors","title":"Geographic Query Errors","text":"<pre><code># State name validation\ndef validate_geography(location: str) -&gt; str:\n    if location not in valid_states:\n        suggestions = find_similar_states(location)\n        return f\"Unknown location: {location}. Did you mean: {suggestions}?\"\n</code></pre>"},{"location":"api/tools/#tool-integration-patterns","title":"Tool Integration Patterns","text":""},{"location":"api/tools/#sequential-tool-usage","title":"Sequential Tool Usage","text":"<pre><code># Common pattern: Query -&gt; Analyze -&gt; Map\n1. execute_landuse_query(\"Agricultural losses by county in Texas\")\n2. analyze_landuse_results(results, \"Focus on policy implications\")\n3. create_choropleth_map(\"Texas agricultural losses\")  # If maps enabled\n</code></pre>"},{"location":"api/tools/#cross-tool-validation","title":"Cross-Tool Validation","text":"<pre><code># Schema validation before queries\n1. get_schema_info(\"dim_scenario\")  # Check available scenarios\n2. execute_landuse_query(\"SELECT * FROM dim_scenario LIMIT 5\")\n3. analyze_landuse_results(results, \"Explain scenario differences\")\n</code></pre>"},{"location":"api/tools/#geographic-tool-chain","title":"Geographic Tool Chain","text":"<pre><code># Geographic analysis workflow\n1. get_state_code(\"California\")  # Convert to FIPS: \"06\"\n2. execute_landuse_query(\"Query for state_code = '06'\")\n3. create_choropleth_map(\"California county analysis\")\n</code></pre>"},{"location":"api/tools/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/tools/#query-optimization","title":"Query Optimization","text":"<ul> <li>Automatic LIMIT clauses: Tools add appropriate row limits</li> <li>Star schema awareness: Optimized joins across dimension tables</li> <li>Column selection: Only retrieve necessary columns</li> <li>Filter pushdown: Apply filters early in query execution</li> </ul>"},{"location":"api/tools/#caching","title":"Caching","text":"<ul> <li>Schema information: Cached to avoid repeated database calls</li> <li>State code mappings: Pre-loaded for instant lookup</li> <li>Common queries: Results cached for conversation continuity</li> </ul>"},{"location":"api/tools/#resource-management","title":"Resource Management","text":"<ul> <li>Connection pooling: Efficient database connection management</li> <li>Memory limits: Large result sets are automatically sampled</li> <li>Timeout handling: Prevents runaway queries</li> </ul>"},{"location":"api/tools/#best-practices","title":"Best Practices","text":""},{"location":"api/tools/#tool-selection","title":"Tool Selection","text":"<ol> <li>Start with schema: Use <code>get_schema_info</code> to understand available data</li> <li>Geography first: Use <code>get_state_code</code> for location-based queries</li> <li>Query execution: Use <code>execute_landuse_query</code> for data retrieval</li> <li>Business analysis: Use <code>analyze_landuse_results</code> for interpretation</li> <li>Visualization: Use map tools for geographic insights (if enabled)</li> </ol>"},{"location":"api/tools/#error-recovery","title":"Error Recovery","text":"<ol> <li>Read error messages: Tools provide specific guidance</li> <li>Check schema: Verify table and column names</li> <li>Simplify queries: Start with basic queries and build complexity</li> <li>Use examples: Reference help system for query patterns</li> </ol>"},{"location":"api/tools/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Be specific: Use filters to reduce data scope</li> <li>Geographic focus: Specify states or regions when possible</li> <li>Scenario selection: Filter to relevant RCP/SSP combinations</li> <li>Time periods: Specify relevant years for analysis</li> </ol>"},{"location":"api/tools/#tool-development","title":"Tool Development","text":""},{"location":"api/tools/#adding-custom-tools","title":"Adding Custom Tools","text":"<pre><code>from landuse.agents import LanduseAgent\nfrom langchain_core.tools import Tool\n\nclass CustomRPAAgent(LanduseAgent):\n    def __init__(self, config=None):\n        super().__init__(config)\n        self.tools.extend(self._create_custom_tools())\n\n    def _create_custom_tools(self):\n        return [\n            Tool(\n                name=\"calculate_carbon_impact\",\n                func=self._calculate_carbon_impact,\n                description=\"Calculate carbon impact of land use changes\"\n            )\n        ]\n\n    def _calculate_carbon_impact(self, params: str) -&gt; str:\n        # Custom carbon analysis implementation\n        return \"Carbon impact analysis results\"\n</code></pre>"},{"location":"api/tools/#tool-testing","title":"Tool Testing","text":"<pre><code>import pytest\nfrom landuse.tools.common_tools import execute_landuse_query\n\ndef test_execute_landuse_query():\n    result = execute_landuse_query(\"SELECT COUNT(*) FROM dim_scenario\")\n    assert \"scenarios\" in result.lower()\n    assert \"error\" not in result.lower()\n</code></pre>"},{"location":"api/tools/#next-steps","title":"Next Steps","text":"<ul> <li>See Agent API for complete LanduseAgent documentation</li> <li>Review Query Examples for tool usage patterns</li> <li>Check Configuration Guide for enabling optional tools</li> <li>See Development Guide for extending tools</li> </ul>"},{"location":"data/categories/","title":"Land Use Categories","text":"<p>Detailed explanation of each land use category in the database and how they relate to real-world land classification systems.</p>"},{"location":"data/categories/#overview","title":"Overview","text":"<p>The land use classification system used in this project is based on standard USDA and land cover categories, simplified into six main types for analysis.</p> <pre><code>graph TD\n    A[Total Land Area] --&gt; B[Crop]\n    A --&gt; C[Pasture]\n    A --&gt; D[Forest]\n    A --&gt; E[Urban]\n    A --&gt; F[Range]\n\n    B --&gt; G[Agriculture]\n    C --&gt; G\n\n    style G fill:#f9f,stroke:#333,stroke-width:2px</code></pre>"},{"location":"data/categories/#primary-categories","title":"Primary Categories","text":""},{"location":"data/categories/#crop-cropland","title":"\ud83c\udf3e Crop (Cropland)","text":"<p>Definition: Land used for the production of adapted crops for harvest.</p> <p>Includes: - Annual crops (corn, soybeans, wheat, etc.) - Perennial crops (orchards, vineyards) - Cultivated lands - Crop rotation areas - Fallow cropland</p> <p>Characteristics: - Actively managed for agricultural production - Regular planting and harvesting cycles - May include irrigation infrastructure - Subject to agricultural policies and subsidies</p> <p>Typical Transitions: - To Urban: Agricultural land near cities under development pressure - To Pasture: Crop-livestock integration or economic shifts - To Forest: Abandoned farmland or conservation programs - From Pasture: Intensification of agricultural use</p>"},{"location":"data/categories/#pasture","title":"\ud83d\udc04 Pasture","text":"<p>Definition: Land used primarily for grazing of livestock.</p> <p>Includes: - Improved pastures with planted grasses - Grazing lands in rotation with crops - Permanent pastures - Hayfields</p> <p>Characteristics: - Managed grasslands for livestock - May be fertilized or irrigated - Often near crop areas (mixed farming) - Can be converted relatively easily</p> <p>Typical Transitions: - To Crop: Agricultural intensification - To Urban: Development in rural-urban fringe - To Forest: Natural succession or tree planting - From Crop: Shift to livestock farming</p>"},{"location":"data/categories/#forest","title":"\ud83c\udf32 Forest","text":"<p>Definition: Land dominated by trees and woody vegetation.</p> <p>Includes: - Natural forests - Managed forests for timber - Forest plantations - Wooded wetlands - Young forest regeneration</p> <p>Characteristics: - Tree canopy coverage &gt;10% - May be managed or unmanaged - Provides ecosystem services - Subject to conservation policies</p> <p>Typical Transitions: - To Urban: Deforestation for development - To Crop: Agricultural expansion - To Pasture: Clearing for grazing - From Range: Natural succession or afforestation</p>"},{"location":"data/categories/#urban","title":"\ud83c\udfe2 Urban","text":"<p>Definition: Developed land with constructed materials and infrastructure.</p> <p>Includes: - Cities and towns - Residential areas - Commercial and industrial zones - Transportation infrastructure - Urban green spaces (parks)</p> <p>Characteristics: - Permanent land use change - High economic value - Rarely converts to other uses - Expanding in most scenarios</p> <p>Typical Transitions: - From Forest: Suburban expansion - From Crop: Agricultural land conversion - From Pasture: Rural development - To Urban: Essentially none (permanent)</p>"},{"location":"data/categories/#range-rangeland","title":"\ud83c\udf3f Range (Rangeland)","text":"<p>Definition: Natural grasslands and shrublands, typically in arid/semi-arid regions.</p> <p>Includes: - Native grasslands - Shrublands - Desert vegetation - Non-improved grazing lands - Prairie ecosystems</p> <p>Characteristics: - Natural vegetation - Minimal management - Often used for extensive grazing - Climate-limited productivity</p> <p>Typical Transitions: - To Pasture: Improvement for livestock - To Crop: Irrigation development - To Forest: Succession in wetter areas - To Urban: Limited (usually near cities)</p>"},{"location":"data/categories/#total","title":"\ud83d\udcca Total","text":"<p>Definition: Sum of all land use categories for validation.</p> <p>Purpose: - Data quality check - Ensures accounting completeness - Not a real land use category</p> <p>Usage in Queries: <pre><code>-- Always exclude Total from analyses\nWHERE from_land_use != 'Total' \n  AND to_land_use != 'Total'\n</code></pre></p>"},{"location":"data/categories/#agricultural-aggregation","title":"Agricultural Aggregation","text":"<p>In the <code>*_ag</code> tables, agricultural land is combined:</p>"},{"location":"data/categories/#agriculture-combined","title":"\ud83d\ude9c Agriculture (Combined)","text":"<p>Definition: Crop + Pasture combined into a single category.</p> <p>Rationale: - Simplifies agricultural analysis - Both are managed for food production - Often intermixed on farms - Similar policy implications</p> <p>When to Use: - Analyzing total agricultural land - Food security assessments - Comparing agricultural vs. natural land - Policy scenario analysis</p>"},{"location":"data/categories/#understanding-transitions","title":"Understanding Transitions","text":""},{"location":"data/categories/#natural-progressions","title":"Natural Progressions","text":"<p>Some transitions follow natural succession patterns:</p> <pre><code>Range \u2192 Forest (increasing precipitation)\nPasture \u2192 Forest (abandonment)\nCrop \u2192 Pasture \u2192 Forest (land retirement)\n</code></pre>"},{"location":"data/categories/#economic-drivers","title":"Economic Drivers","text":"<p>Market forces drive many transitions:</p> <pre><code>Forest \u2192 Crop (commodity prices high)\nPasture \u2192 Crop (intensification)\nRange \u2192 Pasture (livestock expansion)\nAll \u2192 Urban (development pressure)\n</code></pre>"},{"location":"data/categories/#policy-influences","title":"Policy Influences","text":"<p>Conservation and development policies affect transitions:</p> <pre><code>Crop \u2192 Forest (conservation programs)\nForest \u2192 Forest (protection policies)\nPasture \u2192 Urban (zoning changes)\n</code></pre>"},{"location":"data/categories/#regional-variations","title":"Regional Variations","text":""},{"location":"data/categories/#eastern-us","title":"Eastern US","text":"<ul> <li>More Forest \u2194 Crop transitions</li> <li>Higher Forest \u2192 Urban pressure</li> <li>Limited rangeland</li> </ul>"},{"location":"data/categories/#western-us","title":"Western US","text":"<ul> <li>Extensive rangelands</li> <li>Range \u2194 Pasture transitions</li> <li>Water-limited crop expansion</li> </ul>"},{"location":"data/categories/#midwest","title":"Midwest","text":"<ul> <li>Crop \u2194 Pasture rotations</li> <li>Stable agricultural land</li> <li>Urban expansion into farmland</li> </ul>"},{"location":"data/categories/#coastal-areas","title":"Coastal Areas","text":"<ul> <li>High Urban expansion pressure</li> <li>Forest \u2192 Urban common</li> <li>Agricultural land loss</li> </ul>"},{"location":"data/categories/#query-examples-by-category","title":"Query Examples by Category","text":""},{"location":"data/categories/#cropland-analysis","title":"Cropland Analysis","text":"<pre><code>You&gt; Show me counties with the most cropland expansion\nYou&gt; What's converting to cropland in the High Crop Demand scenario?\nYou&gt; Track cropland changes in Iowa counties\n</code></pre>"},{"location":"data/categories/#forest-conservation","title":"Forest Conservation","text":"<pre><code>You&gt; Which counties maintain the most forest cover through 2100?\nYou&gt; Show forest to urban conversion rates by decade\nYou&gt; Compare forest outcomes across scenarios\n</code></pre>"},{"location":"data/categories/#urban-growth","title":"Urban Growth","text":"<pre><code>You&gt; Calculate urban expansion rates for major metropolitan areas\nYou&gt; What land uses are consumed by urban growth?\nYou&gt; Project when urban area will double from 2020 levels\n</code></pre>"},{"location":"data/categories/#agricultural-trends","title":"Agricultural Trends","text":"<pre><code>You&gt; Show the balance between crop and pasture over time\nYou&gt; Which scenario maximizes agricultural productivity?\nYou&gt; Find counties shifting from crops to livestock\n</code></pre>"},{"location":"data/categories/#rangeland-changes","title":"Rangeland Changes","text":"<pre><code>You&gt; How much rangeland converts to other uses?\nYou&gt; Show rangeland preservation by scenario\nYou&gt; Identify counties with significant range to pasture conversion\n</code></pre>"},{"location":"data/categories/#data-quality-considerations","title":"Data Quality Considerations","text":""},{"location":"data/categories/#classification-accuracy","title":"Classification Accuracy","text":"<ul> <li>Based on remote sensing and surveys</li> <li>Some mixed land uses simplified</li> <li>Urban includes various developed types</li> </ul>"},{"location":"data/categories/#temporal-consistency","title":"Temporal Consistency","text":"<ul> <li>Categories stable across time periods</li> <li>Same definitions used throughout</li> <li>Allows valid historical comparisons</li> </ul>"},{"location":"data/categories/#spatial-resolution","title":"Spatial Resolution","text":"<ul> <li>County-level aggregation</li> <li>Sub-county variations not captured</li> <li>Edge effects at county boundaries</li> </ul>"},{"location":"data/categories/#best-practices","title":"Best Practices","text":"<ol> <li>Consider Regional Context</li> <li>Land use meanings vary by region</li> <li>Climate affects transition likelihood</li> <li> <p>Local policies matter</p> </li> <li> <p>Aggregate Thoughtfully</p> </li> <li>Use agricultural aggregation for food analysis</li> <li>Keep separate for detailed studies</li> <li> <p>Remember Total is for validation only</p> </li> <li> <p>Interpret Transitions</p> </li> <li>Some transitions are rare/unlikely</li> <li>Consider economic feasibility</li> <li>Account for policy constraints</li> </ol>"},{"location":"data/categories/#next-steps","title":"Next Steps","text":"<ul> <li>Review Database Schema for technical details</li> <li>Explore Data Sources for methodology</li> <li>See Query Examples for category-specific analyses</li> </ul>"},{"location":"data/data-dictionary/","title":"Data Dictionary","text":""},{"location":"data/data-dictionary/#overview","title":"Overview","text":"<p>This data dictionary provides comprehensive business definitions, technical specifications, and usage guidelines for all data elements in the RPA Land Use Analytics database.</p>"},{"location":"data/data-dictionary/#business-context","title":"Business Context","text":"<p>The database contains land use transition projections from the 2020 USDA Forest Service RPA Assessment, covering 3,075 US counties across 20 climate scenarios from 2012-2070. All projections focus on private land only (public lands assumed static) and include integrated socioeconomic data.</p>"},{"location":"data/data-dictionary/#core-business-concepts","title":"Core Business Concepts","text":""},{"location":"data/data-dictionary/#land-use-transitions","title":"Land Use Transitions","text":"<p>Definition: Changes in land use from one category to another over a specified time period, measured in acres.</p> <p>Business Rules: - Irreversible Development: Once land becomes Urban, it never converts back - Private Land Only: Public lands (national forests, parks) excluded from projections - County Aggregation: Sub-county variations are aggregated to county level - Decade Intervals: Transitions measured over 10-year periods (except 2012-2020: 8 years)</p> <p>Key Insights: - ~46% of new urban development comes from forest conversion - Agricultural land conversion varies significantly by economic scenario - Range to pasture conversions often occur with livestock expansion</p>"},{"location":"data/data-dictionary/#climate-scenarios","title":"Climate Scenarios","text":"<p>Definition: Combinations of climate models with Representative Concentration Pathways (RCP) and Shared Socioeconomic Pathways (SSP).</p> <p>Business Context: - Climate Models: Different climate sensitivities (wet, hot, dry, moderate) - RCP Pathways: Greenhouse gas concentration trajectories - SSP Pathways: Socioeconomic development narratives</p>"},{"location":"data/data-dictionary/#data-elements-by-category","title":"Data Elements by Category","text":""},{"location":"data/data-dictionary/#geographic-identifiers","title":"Geographic Identifiers","text":""},{"location":"data/data-dictionary/#fips-code","title":"FIPS Code","text":"<ul> <li>Field Name: <code>fips_code</code></li> <li>Type: VARCHAR(5)</li> <li>Definition: Federal Information Processing Standards county identifier</li> <li>Format: 5-digit string (SSFFF where SS=state, FFF=county)</li> <li>Business Use: Unique county identification for data joining and mapping</li> <li>Example: \"06037\" = Los Angeles County, California</li> <li>Data Quality: All 3,075 US counties represented</li> </ul>"},{"location":"data/data-dictionary/#county-name","title":"County Name","text":"<ul> <li>Field Name: <code>county_name</code></li> <li>Type: VARCHAR</li> <li>Definition: Official county name as recognized by US Census</li> <li>Business Use: Human-readable geographic identification</li> <li>Example: \"Los Angeles County\"</li> <li>Note: Includes \"County\", \"Parish\", \"Borough\" suffixes as appropriate</li> </ul>"},{"location":"data/data-dictionary/#state-information","title":"State Information","text":"<ul> <li>Field Names: <code>state_code</code>, <code>state_name</code>, <code>state_abbrev</code></li> <li>Types: VARCHAR(2), VARCHAR, VARCHAR(2)</li> <li>Definition: State identification in multiple formats</li> <li>Business Use: State-level aggregation and filtering</li> <li>Examples: \"06\", \"California\", \"CA\"</li> </ul>"},{"location":"data/data-dictionary/#region","title":"Region","text":"<ul> <li>Field Name: <code>region</code></li> <li>Type: VARCHAR</li> <li>Definition: US Census region classification</li> <li>Values: Northeast, Midwest, South, West</li> <li>Business Use: Large-scale regional analysis and comparison</li> <li>Distribution: South (45.2%), Midwest (34.3%), West (13.5%), Northeast (7.1%)</li> </ul>"},{"location":"data/data-dictionary/#land-use-categories","title":"Land Use Categories","text":""},{"location":"data/data-dictionary/#land-use-code","title":"Land Use Code","text":"<ul> <li>Field Name: <code>landuse_code</code></li> <li>Type: VARCHAR(2)</li> <li>Definition: Standardized 2-character land use identifier</li> <li>Values:</li> <li>cr: Cropland</li> <li>ps: Pasture</li> <li>rg: Rangeland</li> <li>fr: Forest</li> <li>ur: Urban</li> <li>Business Use: Compact representation for analysis and storage</li> </ul>"},{"location":"data/data-dictionary/#land-use-name","title":"Land Use Name","text":"<ul> <li>Field Name: <code>landuse_name</code></li> <li>Type: VARCHAR</li> <li>Definition: Full descriptive name for land use category</li> <li>Business Use: Human-readable reports and visualizations</li> <li>Values: Crop, Pasture, Rangeland, Forest, Urban</li> </ul>"},{"location":"data/data-dictionary/#land-use-category","title":"Land Use Category","text":"<ul> <li>Field Name: <code>landuse_category</code></li> <li>Type: VARCHAR</li> <li>Definition: High-level grouping for policy analysis</li> <li>Values:</li> <li>Agriculture: Crop, Pasture</li> <li>Natural: Rangeland, Forest</li> <li>Developed: Urban</li> <li>Business Use: Simplified analysis focusing on broad land use types</li> </ul>"},{"location":"data/data-dictionary/#scenario-definitions","title":"Scenario Definitions","text":""},{"location":"data/data-dictionary/#climate-model","title":"Climate Model","text":"<ul> <li>Field Name: <code>climate_model</code></li> <li>Type: VARCHAR</li> <li>Definition: Global Climate Model used for projections</li> <li>Business Context:</li> <li>CNRM_CM5: \"Wet\" climate model (higher precipitation)</li> <li>HadGEM2_ES365: \"Hot\" climate model (higher temperatures)</li> <li>IPSL_CM5A_MR: \"Dry\" climate model (lower precipitation)</li> <li>MRI_CGCM3: \"Least warm\" climate model (moderate temperature increase)</li> <li>NorESM1_M: \"Middle\" climate model (balanced)</li> </ul>"},{"location":"data/data-dictionary/#rcp-scenario","title":"RCP Scenario","text":"<ul> <li>Field Name: <code>rcp_scenario</code></li> <li>Type: VARCHAR</li> <li>Definition: Representative Concentration Pathway - greenhouse gas trajectory</li> <li>Values:</li> <li>rcp45: Lower emissions scenario (+2.4\u00b0C by 2100)</li> <li>rcp85: Higher emissions scenario (+4.3\u00b0C by 2100)</li> <li>Business Use: Climate impact analysis and mitigation planning</li> </ul>"},{"location":"data/data-dictionary/#ssp-scenario","title":"SSP Scenario","text":"<ul> <li>Field Name: <code>ssp_scenario</code></li> <li>Type: VARCHAR</li> <li>Definition: Shared Socioeconomic Pathway - development narrative</li> <li>Values &amp; Narratives:</li> <li>ssp1: Sustainability (low population growth, medium economic growth)</li> <li>ssp2: Middle of the Road (medium population/economic growth)</li> <li>ssp3: Regional Rivalry (high population growth, low economic growth)</li> <li>ssp4: Inequality (medium population growth, high economic growth)</li> <li>ssp5: Fossil-fueled Development (low population growth, high economic growth)</li> </ul>"},{"location":"data/data-dictionary/#temporal-elements","title":"Temporal Elements","text":""},{"location":"data/data-dictionary/#time-period","title":"Time Period","text":"<ul> <li>Field Name: <code>year_range</code></li> <li>Type: VARCHAR</li> <li>Definition: Decade-long transition period</li> <li>Format: \"YYYY-YYYY\"</li> <li>Business Context:</li> <li>2012-2020: Historical calibration period (8 years)</li> <li>2020-2070: 10-year projection intervals</li> <li>Example: \"2040-2050\"</li> </ul>"},{"location":"data/data-dictionary/#start-year-end-year","title":"Start Year / End Year","text":"<ul> <li>Field Names: <code>start_year</code>, <code>end_year</code></li> <li>Type: INTEGER</li> <li>Definition: Numeric year boundaries for calculations</li> <li>Business Use: Time-series analysis and trend calculations</li> </ul>"},{"location":"data/data-dictionary/#measurement-units","title":"Measurement Units","text":""},{"location":"data/data-dictionary/#acres","title":"Acres","text":"<ul> <li>Field Name: <code>acres</code></li> <li>Type: DECIMAL(15,4)</li> <li>Definition: Area measurement for land use transitions</li> <li>Unit: Hundreds of acres (multiply by 100 for actual acres)</li> <li>Business Context: </li> <li>Small Values: Urban development (typical: 0.1-5.0 = 10-500 actual acres)</li> <li>Large Values: Agricultural and forest areas (typical: 10-1,000 = 1,000-100,000 actual acres)</li> <li>Conversion Factors:</li> <li>Stored value \u00d7 100 = actual acres</li> <li>Stored value \u00d7 100 \u00d7 0.404686 = hectares</li> <li>Stored value \u00d7 100 \u00f7 640 = square miles</li> </ul>"},{"location":"data/data-dictionary/#population-thousands","title":"Population (Thousands)","text":"<ul> <li>Field Name: <code>population_thousands</code>, <code>value</code> (in socioeconomic data)</li> <li>Type: DECIMAL(15,4)</li> <li>Definition: County population in thousands of persons</li> <li>Business Use: Demographic pressure analysis and development planning</li> <li>Example: 9,818.5 = 9,818,500 people</li> </ul>"},{"location":"data/data-dictionary/#income-per-capita","title":"Income Per Capita","text":"<ul> <li>Field Name: <code>income_per_capita_2009usd</code>, <code>value</code> (in socioeconomic data)</li> <li>Type: DECIMAL(15,4)</li> <li>Definition: Per capita income in thousands of 2009 US dollars</li> <li>Business Context: </li> <li>Inflation Adjusted: Constant 2009 dollars for temporal comparison</li> <li>Economic Indicator: Purchasing power and development pressure</li> <li>Example: 42.6 = $42,600 per person per year</li> </ul>"},{"location":"data/data-dictionary/#transition-characteristics","title":"Transition Characteristics","text":""},{"location":"data/data-dictionary/#transition-type","title":"Transition Type","text":"<ul> <li>Field Name: <code>transition_type</code></li> <li>Type: VARCHAR</li> <li>Definition: Whether land use changed or remained the same</li> <li>Values:</li> <li>change: Land converted from one use to another</li> <li>same: Land remained in the same use category</li> <li>Business Context:</li> <li>Change Transitions: Focus of policy and environmental analysis</li> <li>Same Transitions: Baseline for calculating conversion rates</li> </ul>"},{"location":"data/data-dictionary/#fromto-land-use","title":"From/To Land Use","text":"<ul> <li>Field Names: <code>from_landuse_id</code>, <code>to_landuse_id</code></li> <li>Type: INTEGER (foreign keys)</li> <li>Definition: Source and destination land use categories</li> <li>Business Use: Transition matrix analysis and conversion pattern identification</li> <li>Common Patterns:</li> <li>Forest \u2192 Urban (suburban development)</li> <li>Crop \u2194 Pasture (agricultural intensification/extensification)</li> <li>Range \u2192 Pasture (livestock expansion)</li> </ul>"},{"location":"data/data-dictionary/#socioeconomic-indicators","title":"Socioeconomic Indicators","text":""},{"location":"data/data-dictionary/#population-projections","title":"Population Projections","text":"<ul> <li>Definition: County-level population forecasts by SSP scenario</li> <li>Data Source: Integrated from SSP scenario narratives</li> <li>Business Use: </li> <li>Development pressure assessment</li> <li>Infrastructure planning</li> <li>Environmental impact analysis</li> <li>Coverage: 2010-2050 (historical + projections)</li> </ul>"},{"location":"data/data-dictionary/#income-projections","title":"Income Projections","text":"<ul> <li>Definition: Per capita income forecasts by SSP scenario</li> <li>Data Source: Economic growth assumptions from SSP narratives</li> <li>Business Use:</li> <li>Economic development planning</li> <li>Land value and conversion pressure analysis</li> <li>Environmental justice considerations</li> <li>Unit: Constant 2009 US dollars (inflation-adjusted)</li> </ul>"},{"location":"data/data-dictionary/#data-quality-and-validation","title":"Data Quality and Validation","text":""},{"location":"data/data-dictionary/#completeness","title":"Completeness","text":"<ul> <li>Geographic Coverage: All 3,075 US counties included</li> <li>Temporal Coverage: Complete time series 2012-2070</li> <li>Scenario Coverage: All 20 climate/socioeconomic combinations</li> <li>Land Use Coverage: All major land use categories tracked</li> </ul>"},{"location":"data/data-dictionary/#accuracy-considerations","title":"Accuracy Considerations","text":"<ul> <li>Model Calibration: 2012-2020 period used for historical validation</li> <li>County Aggregation: Sub-county variations smoothed to county level</li> <li>Private Land Focus: Public lands excluded (may underestimate total change)</li> <li>Edge Effects: County boundary effects not captured</li> </ul>"},{"location":"data/data-dictionary/#business-rules-validation","title":"Business Rules Validation","text":"<ul> <li>Total Area Conservation: County total land area remains constant</li> <li>Urban Irreversibility: No urban-to-other transitions (verified)</li> <li>Logical Transitions: Unrealistic transitions flagged during processing</li> </ul>"},{"location":"data/data-dictionary/#usage-guidelines","title":"Usage Guidelines","text":""},{"location":"data/data-dictionary/#query-patterns","title":"Query Patterns","text":""},{"location":"data/data-dictionary/#basic-land-use-analysis","title":"Basic Land Use Analysis","text":"<pre><code>-- Focus on actual changes\nWHERE transition_type = 'change'\n\n-- Exclude validation/total rows  \nWHERE from_landuse != 'Total' AND to_landuse != 'Total'\n\n-- Current land use (unchanged areas)\nWHERE from_landuse_id = to_landuse_id\n</code></pre>"},{"location":"data/data-dictionary/#scenario-comparison","title":"Scenario Comparison","text":"<pre><code>-- Compare emission scenarios\nWHERE rcp_scenario IN ('rcp45', 'rcp85')\n\n-- Focus on specific socioeconomic narrative\nWHERE ssp_scenario = 'ssp1'  -- Sustainability\n\n-- Climate model sensitivity analysis\nWHERE climate_model IN ('HadGEM2_ES365', 'IPSL_CM5A_MR')  -- Hot vs Dry\n</code></pre>"},{"location":"data/data-dictionary/#geographic-analysis","title":"Geographic Analysis","text":"<pre><code>-- Regional analysis\nWHERE region = 'West'\n\n-- State-level analysis\nWHERE state_name = 'California'\n\n-- Large counties (development pressure)\nWHERE area_sqmi &gt; 1000\n</code></pre>"},{"location":"data/data-dictionary/#temporal-analysis","title":"Temporal Analysis","text":"<pre><code>-- Near-term projections\nWHERE start_year &gt;= 2020 AND end_year &lt;= 2040\n\n-- Long-term trends\nWHERE end_year = 2070\n\n-- Historical calibration period\nWHERE year_range = '2012-2020'\n</code></pre>"},{"location":"data/data-dictionary/#common-business-questions","title":"Common Business Questions","text":""},{"location":"data/data-dictionary/#development-pressure","title":"Development Pressure","text":"<ul> <li>Question: \"Which counties face the highest urban development pressure?\"</li> <li>Data Elements: Urban transitions, population growth, income trends</li> <li>Key Metrics: Acres converted to urban, population density, economic growth</li> </ul>"},{"location":"data/data-dictionary/#agricultural-impact","title":"Agricultural Impact","text":"<ul> <li>Question: \"How much agricultural land is lost under different scenarios?\"</li> <li>Data Elements: Crop/Pasture to other transitions, scenario comparisons</li> <li>Key Metrics: Total agricultural acres lost, conversion rates by scenario</li> </ul>"},{"location":"data/data-dictionary/#climate-sensitivity","title":"Climate Sensitivity","text":"<ul> <li>Question: \"How do land use outcomes vary between climate models?\"</li> <li>Data Elements: Climate model comparisons, transition patterns</li> <li>Key Metrics: Forest loss rates, agricultural adaptation patterns</li> </ul>"},{"location":"data/data-dictionary/#regional-planning","title":"Regional Planning","text":"<ul> <li>Question: \"What are the regional patterns of land use change?\"</li> <li>Data Elements: Regional aggregations, state-level comparisons</li> <li>Key Metrics: Land use change by region, cross-state patterns</li> </ul>"},{"location":"data/data-dictionary/#integration-considerations","title":"Integration Considerations","text":""},{"location":"data/data-dictionary/#external-data-sources","title":"External Data Sources","text":"<ul> <li>Census Data: Population and economic statistics for validation</li> <li>Agricultural Statistics: USDA NASS for agricultural trends</li> <li>Land Cover Data: Remote sensing for land use verification</li> <li>Climate Data: Temperature and precipitation for model validation</li> </ul>"},{"location":"data/data-dictionary/#data-relationships","title":"Data Relationships","text":"<ul> <li>Hierarchical Geography: County \u2192 State \u2192 Region \u2192 Nation</li> <li>Temporal Sequences: Historical \u2192 Near-term \u2192 Long-term projections</li> <li>Scenario Families: Climate Model \u00d7 RCP \u00d7 SSP combinations</li> <li>Land Use Transitions: Source \u2192 Destination patterns</li> </ul>"},{"location":"data/data-dictionary/#business-intelligence-applications","title":"Business Intelligence Applications","text":"<ul> <li>Dashboards: County-level land use dashboards for planners</li> <li>Reports: Scenario comparison reports for policy makers</li> <li>APIs: Programmatic access for research applications</li> <li>Visualizations: Maps and charts for public communication</li> </ul>"},{"location":"data/data-dictionary/#technical-notes","title":"Technical Notes","text":""},{"location":"data/data-dictionary/#data-types-and-precision","title":"Data Types and Precision","text":"<ul> <li>Spatial Precision: County-level aggregation (~3,000 units)</li> <li>Temporal Precision: Decade-level intervals</li> <li>Measurement Precision: 4 decimal places for acres (0.1 square meter accuracy)</li> <li>Scenario Precision: 20 distinct scenario combinations</li> </ul>"},{"location":"data/data-dictionary/#performance-characteristics","title":"Performance Characteristics","text":"<ul> <li>Query Performance: Star schema optimized for analytical queries</li> <li>Storage Efficiency: 98.99% database block utilization</li> <li>Index Strategy: Composite indexes on frequently joined columns</li> <li>View Performance: Pre-computed views for common query patterns</li> </ul>"},{"location":"data/data-dictionary/#maintenance-and-updates","title":"Maintenance and Updates","text":"<ul> <li>Static Data: Historical and projection data (no ongoing updates)</li> <li>Schema Stability: Core structure stable for analytical consistency</li> <li>Data Lineage: Clear transformation pipeline from raw to analytical data</li> <li>Quality Monitoring: Automated validation checks during data loading</li> </ul>"},{"location":"data/data-dictionary/#glossary","title":"Glossary","text":"<p>RPA Assessment: Resources Planning Act - periodic assessment of US forest and rangeland resources mandated by Congress</p> <p>County FIPS: Federal Information Processing Standard codes uniquely identifying US counties</p> <p>Star Schema: Data warehouse design with central fact table surrounded by dimension tables</p> <p>Land Use Transition: Change (or lack of change) in land use category over a time period</p> <p>Private Land: Non-government owned land subject to market forces and development pressure</p> <p>Climate Model: Mathematical representation of Earth's climate system for future projections</p> <p>Socioeconomic Pathway: Narrative describing potential societal development trajectories</p> <p>Representative Concentration Pathway: Greenhouse gas concentration trajectory used in climate models</p>"},{"location":"data/data-dictionary/#next-steps","title":"Next Steps","text":"<ul> <li>Technical Implementation: See Table Reference for technical specifications</li> <li>Query Examples: See Basic Queries for practical usage</li> <li>Business Context: See Land Use Categories for detailed category definitions</li> <li>Methodology: See Land Use Methodology for projection methods</li> </ul>"},{"location":"data/database-overview/","title":"Database Overview","text":""},{"location":"data/database-overview/#executive-summary","title":"Executive Summary","text":"<p>The RPA Land Use Analytics database is a comprehensive 372 MB DuckDB repository containing 5.7+ million land use transition records across 3,075 US counties, 20 climate scenarios, and 6 time periods (2012-2070). The database uses an optimized star schema design with 8 tables and 4 analytical views, achieving 98.99% storage efficiency.</p>"},{"location":"data/database-overview/#quick-statistics","title":"Quick Statistics","text":"Metric Value Database Size 372 MB (390,070,272 bytes) Total Records 5,724,134 records Land Use Transitions 5.4+ million transitions Geographic Coverage 3,075 US counties Climate Scenarios 20 scenarios (5 models \u00d7 4 combinations) Time Periods 6 periods (2012-2070) Total Land Tracked 16.7 million (1.67 billion actual acres) Storage Efficiency 98.99% block utilization"},{"location":"data/database-overview/#database-architecture","title":"Database Architecture","text":""},{"location":"data/database-overview/#star-schema-design","title":"Star Schema Design","text":"<p>The database follows modern data warehousing best practices with a star schema optimized for analytical queries:</p> <pre><code>erDiagram\n    fact_landuse_transitions {\n        bigint transition_id PK\n        int scenario_id FK\n        int time_id FK\n        int geography_id FK\n        int from_landuse_id FK\n        int to_landuse_id FK\n        decimal acres\n        varchar transition_type\n        timestamp created_at\n    }\n\n    fact_socioeconomic_projections {\n        bigint projection_id PK\n        int geography_id FK\n        int socioeconomic_id FK\n        int indicator_id FK\n        int year\n        decimal value\n        boolean is_historical\n        timestamp created_at\n    }\n\n    dim_scenario {\n        int scenario_id PK\n        varchar scenario_name\n        varchar climate_model\n        varchar rcp_scenario\n        varchar ssp_scenario\n        timestamp created_at\n    }\n\n    dim_time {\n        int time_id PK\n        varchar year_range\n        int start_year\n        int end_year\n        int period_length\n        timestamp created_at\n    }\n\n    dim_geography {\n        int geography_id PK\n        varchar fips_code\n        varchar county_name\n        varchar state_code\n        varchar state_name\n        varchar state_abbrev\n        varchar region\n        geometry geometry\n        double area_sqmi\n        double centroid_lat\n        double centroid_lon\n        timestamp created_at\n        timestamp updated_at\n    }\n\n    dim_landuse {\n        int landuse_id PK\n        varchar landuse_code\n        varchar landuse_name\n        varchar landuse_category\n        varchar description\n        timestamp created_at\n    }\n\n    dim_socioeconomic {\n        int socioeconomic_id PK\n        varchar ssp_scenario\n        varchar scenario_name\n        varchar narrative_description\n        varchar population_growth_trend\n        varchar economic_growth_trend\n        varchar urbanization_level\n        timestamp created_at\n    }\n\n    dim_indicators {\n        int indicator_id PK\n        varchar indicator_name\n        varchar indicator_type\n        varchar unit_of_measure\n        varchar description\n        timestamp created_at\n    }\n\n    fact_landuse_transitions ||--|| dim_scenario : scenario_id\n    fact_landuse_transitions ||--|| dim_time : time_id\n    fact_landuse_transitions ||--|| dim_geography : geography_id\n    fact_landuse_transitions ||--|| dim_landuse : from_landuse_id\n    fact_landuse_transitions ||--|| dim_landuse : to_landuse_id\n\n    fact_socioeconomic_projections ||--|| dim_geography : geography_id\n    fact_socioeconomic_projections ||--|| dim_socioeconomic : socioeconomic_id\n    fact_socioeconomic_projections ||--|| dim_indicators : indicator_id</code></pre>"},{"location":"data/database-overview/#table-summary","title":"Table Summary","text":""},{"location":"data/database-overview/#fact-tables-data-heavy","title":"Fact Tables (Data-Heavy)","text":"Table Records Size Purpose <code>fact_landuse_transitions</code> 5,432,198 5.18 MB Core land use transitions between categories <code>fact_socioeconomic_projections</code> 291,936 0.28 MB Population and income projections"},{"location":"data/database-overview/#dimension-tables-reference-data","title":"Dimension Tables (Reference Data)","text":"Table Records Size Purpose <code>dim_geography</code> 3,075 0.003 MB County-level geographic information <code>dim_scenario</code> 20 0.00002 MB Climate and socioeconomic scenarios <code>dim_time</code> 6 0.000006 MB Time period definitions <code>dim_landuse</code> 5 0.000005 MB Land use category definitions <code>dim_socioeconomic</code> 5 0.000005 MB SSP scenario descriptions <code>dim_indicators</code> 2 0.000002 MB Socioeconomic indicator definitions"},{"location":"data/database-overview/#data-coverage","title":"Data Coverage","text":""},{"location":"data/database-overview/#geographic-distribution","title":"Geographic Distribution","text":"Region Counties Avg Size (sq mi) % of Total South 1,389 624 45.2% Midwest 1,055 711 34.3% West 414 2,836 13.5% Northeast 217 746 7.1%"},{"location":"data/database-overview/#climate-scenarios","title":"Climate Scenarios","text":"<p>5 Climate Models: - CNRM_CM5: \"wet\" climate model - HadGEM2_ES365: \"hot\" climate model - IPSL_CM5A_MR: \"dry\" climate model - MRI_CGCM3: \"least warm\" climate model - NorESM1_M: \"middle\" climate model</p> <p>4 RCP/SSP Combinations: - rcp45_ssp1: Low emissions, medium growth - rcp85_ssp2: High emissions, medium growth - rcp85_ssp3: High emissions, low growth - rcp85_ssp5: High emissions, high growth</p>"},{"location":"data/database-overview/#land-use-categories","title":"Land Use Categories","text":"Category Code Type Description Crop cr Agriculture Agricultural cropland Pasture ps Agriculture Livestock grazing land Rangeland rg Natural Natural grasslands/shrublands Forest fr Natural Forested areas Urban ur Developed Developed/built areas"},{"location":"data/database-overview/#time-coverage","title":"Time Coverage","text":"Period Years Length Purpose 2012-2020 8 years Calibration period 2020-2030 10 years Near-term projections 2030-2040 10 years Medium-term projections 2040-2050 10 years Mid-century projections 2050-2060 10 years Extended projections 2060-2070 10 years Long-term projections"},{"location":"data/database-overview/#data-quality-metrics","title":"Data Quality Metrics","text":""},{"location":"data/database-overview/#transition-distribution","title":"Transition Distribution","text":"Type Records Percentage Avg Acres Change 3,887,318 71.5% 0.133 (13.3 actual acres) Same 1,544,880 28.5% 10.456 (1,045.6 actual acres)"},{"location":"data/database-overview/#top-land-use-transitions","title":"Top Land Use Transitions","text":"Transition Total Acres Number of Transitions Crop \u2192 Pasture 153.2 thousand (15.32 million actual acres) 347,000 Pasture \u2192 Crop 126.3 thousand (12.63 million actual acres) 347,000 Forest \u2192 Urban 51.0 thousand (5.10 million actual acres) 336,000 Pasture \u2192 Forest 37.1 thousand (3.71 million actual acres) 333,000 Crop \u2192 Urban 24.7 thousand (2.47 million actual acres) 348,000"},{"location":"data/database-overview/#analytical-views","title":"Analytical Views","text":"<p>The database includes 4 pre-built analytical views for common query patterns:</p> View Purpose Records <code>v_scenarios_combined</code> Climate + socioeconomic scenario integration 20 <code>v_landuse_socioeconomic</code> Comprehensive transitions with demographics 5.4M <code>v_population_trends</code> County population projections by scenario 291,936 <code>v_income_trends</code> County income projections by scenario 291,936"},{"location":"data/database-overview/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"data/database-overview/#storage-optimization","title":"Storage Optimization","text":"<ul> <li>Block Utilization: 98.99% (1,472 of 1,487 blocks used)</li> <li>Memory Usage: 512.0 KiB working memory</li> <li>File Compression: Efficient columnar storage</li> </ul>"},{"location":"data/database-overview/#query-performance","title":"Query Performance","text":"<ul> <li>Star Schema: Optimized for analytical queries</li> <li>Strategic Indexing: 10 indexes on frequently queried columns</li> <li>Pre-built Views: Common patterns pre-computed</li> <li>DuckDB Engine: Columnar storage optimized for aggregation</li> </ul>"},{"location":"data/database-overview/#index-strategy","title":"Index Strategy","text":"<p>Primary Indexes: - <code>idx_geography_fips</code> - County lookups - <code>idx_geography_state</code> - State-level filtering - <code>idx_scenario_name</code> - Scenario comparisons - <code>idx_landuse_code</code> - Land use filtering</p> <p>Composite Indexes: - <code>idx_fact_composite</code> - Multi-dimensional fact table queries - <code>idx_fact_landuse</code> - Land use transition patterns - <code>idx_socioeconomic_composite</code> - Demographic analysis</p>"},{"location":"data/database-overview/#use-cases","title":"Use Cases","text":""},{"location":"data/database-overview/#policy-analysis","title":"Policy Analysis","text":"<ul> <li>Compare land use outcomes across climate scenarios</li> <li>Analyze agricultural land loss under different policies</li> <li>Assess urban growth impacts on natural areas</li> </ul>"},{"location":"data/database-overview/#economic-research","title":"Economic Research","text":"<ul> <li>Study relationships between population growth and land use</li> <li>Analyze income effects on development patterns</li> <li>Compare regional economic and environmental tradeoffs</li> </ul>"},{"location":"data/database-overview/#environmental-planning","title":"Environmental Planning","text":"<ul> <li>Track forest loss across different climate futures</li> <li>Monitor agricultural land preservation</li> <li>Plan conservation strategies by scenario</li> </ul>"},{"location":"data/database-overview/#geographic-analysis","title":"Geographic Analysis","text":"<ul> <li>State and county-level land use trends</li> <li>Regional development pattern analysis</li> <li>Cross-state comparative studies</li> </ul>"},{"location":"data/database-overview/#access-methods","title":"Access Methods","text":""},{"location":"data/database-overview/#direct-database-access","title":"Direct Database Access","text":"<pre><code># DuckDB Browser UI\nduckdb data/processed/landuse_analytics.duckdb -ui\n\n# DuckDB Command Line\nduckdb data/processed/landuse_analytics.duckdb\n</code></pre>"},{"location":"data/database-overview/#application-interfaces","title":"Application Interfaces","text":"<pre><code># Streamlit Web Dashboard\nuv run streamlit run streamlit_app.py\n\n# Natural Language Query Agent\nuv run python -m landuse.agents.agent\n</code></pre>"},{"location":"data/database-overview/#python-integration","title":"Python Integration","text":"<pre><code>import duckdb\nconn = duckdb.connect('data/processed/landuse_analytics.duckdb')\nresult = conn.execute(\"SELECT * FROM v_scenarios_combined\").fetchall()\n</code></pre>"},{"location":"data/database-overview/#file-information","title":"File Information","text":"<ul> <li>Path: <code>data/processed/landuse_analytics.duckdb</code></li> <li>Format: DuckDB v0.11.0+ database</li> <li>Encoding: UTF-8</li> <li>Created: 2025 (latest schema version)</li> <li>Update Frequency: Static (historical + projection data)</li> </ul>"},{"location":"data/database-overview/#data-lineage","title":"Data Lineage","text":"<pre><code>graph TD\n    A[Raw JSON Data&lt;br/&gt;20M+ lines] --&gt; B[Data Converter&lt;br/&gt;convert_to_duckdb.py]\n    B --&gt; C[DuckDB Database&lt;br/&gt;landuse_analytics.duckdb]\n    C --&gt; D[Streamlit Dashboard]\n    C --&gt; E[Natural Language Agent]\n    C --&gt; F[Direct SQL Access]\n    C --&gt; G[Python Analytics]</code></pre>"},{"location":"data/database-overview/#next-steps","title":"Next Steps","text":"<ul> <li>Technical Details: See DuckDB Schema for table specifications</li> <li>Land Use Definitions: See Land Use Categories for business definitions  </li> <li>Query Examples: See Basic Queries for usage patterns</li> <li>API Reference: See Tools &amp; Utilities for programmatic access</li> </ul>"},{"location":"data/duckdb-schema/","title":"DuckDB Schema Design","text":""},{"location":"data/duckdb-schema/#overview","title":"Overview","text":"<p>The landuse database has been redesigned from a single denormalized table to a star schema optimized for analytical queries. This follows modern data warehousing best practices and significantly improves query performance.</p>"},{"location":"data/duckdb-schema/#schema-architecture","title":"Schema Architecture","text":""},{"location":"data/duckdb-schema/#star-schema-design","title":"Star Schema Design","text":"<pre><code>erDiagram\n    fact_landuse_transitions {\n        bigint transition_id PK\n        int scenario_id FK\n        int time_id FK\n        int geography_id FK\n        int from_landuse_id FK\n        int to_landuse_id FK\n        decimal acres\n        varchar transition_type\n        timestamp created_at\n    }\n\n    dim_scenario {\n        int scenario_id PK\n        varchar scenario_name\n        varchar climate_model\n        varchar rcp_scenario\n        varchar ssp_scenario\n        timestamp created_at\n    }\n\n    dim_time {\n        int time_id PK\n        varchar year_range\n        int start_year\n        int end_year\n        int period_length\n        timestamp created_at\n    }\n\n    dim_geography {\n        int geography_id PK\n        varchar fips_code\n        varchar county_name\n        varchar state_code\n        varchar state_name\n        varchar region\n        timestamp created_at\n    }\n\n    dim_landuse {\n        int landuse_id PK\n        varchar landuse_code\n        varchar landuse_name\n        varchar landuse_category\n        text description\n        timestamp created_at\n    }\n\n    fact_landuse_transitions ||--|| dim_scenario : scenario_id\n    fact_landuse_transitions ||--|| dim_time : time_id\n    fact_landuse_transitions ||--|| dim_geography : geography_id\n    fact_landuse_transitions ||--|| dim_landuse : from_landuse_id\n    fact_landuse_transitions ||--|| dim_landuse : to_landuse_id</code></pre>"},{"location":"data/duckdb-schema/#tables","title":"Tables","text":""},{"location":"data/duckdb-schema/#dimension-tables","title":"Dimension Tables","text":""},{"location":"data/duckdb-schema/#dim_scenario","title":"<code>dim_scenario</code>","text":"<p>Climate and socioeconomic scenarios - scenario_id: Primary key - scenario_name: Full scenario name (e.g., \"CNRM_CM5_rcp45_ssp1\") - climate_model: Climate model used (e.g., \"CNRM_CM5\") - rcp_scenario: Representative Concentration Pathway (e.g., \"rcp45\") - ssp_scenario: Shared Socioeconomic Pathway (e.g., \"ssp1\")</p>"},{"location":"data/duckdb-schema/#dim_time","title":"<code>dim_time</code>","text":"<p>Time periods and ranges - time_id: Primary key - year_range: Year range string (e.g., \"2012-2020\") - start_year: Starting year - end_year: Ending year - period_length: Duration in years</p>"},{"location":"data/duckdb-schema/#dim_geography","title":"<code>dim_geography</code>","text":"<p>Geographic locations - geography_id: Primary key - fips_code: 5-digit FIPS county code - county_name: County name (to be populated) - state_code: 2-digit state code - state_name: State name (to be populated) - region: Geographic region (to be populated)</p>"},{"location":"data/duckdb-schema/#dim_landuse","title":"<code>dim_landuse</code>","text":"<p>Land use types and categories - landuse_id: Primary key - landuse_code: Short code (cr, ps, rg, fr, ur) - landuse_name: Full name (Crop, Pasture, Rangeland, Forest, Urban) - landuse_category: Category (Agriculture, Natural, Developed) - description: Detailed description</p>"},{"location":"data/duckdb-schema/#fact-table","title":"Fact Table","text":""},{"location":"data/duckdb-schema/#fact_landuse_transitions","title":"<code>fact_landuse_transitions</code>","text":"<p>Main fact table containing all land use transitions - transition_id: Primary key - scenario_id: Foreign key to dim_scenario - time_id: Foreign key to dim_time - geography_id: Foreign key to dim_geography - from_landuse_id: Foreign key to dim_landuse (source) - to_landuse_id: Foreign key to dim_landuse (destination) - acres: Area in acres for this transition - transition_type: 'same' or 'change'</p>"},{"location":"data/duckdb-schema/#analytical-views","title":"Analytical Views","text":""},{"location":"data/duckdb-schema/#v_agriculture_transitions","title":"<code>v_agriculture_transitions</code>","text":"<p>Pre-filtered view for agricultural transitions <pre><code>SELECT \n    s.scenario_name,\n    t.year_range,\n    g.fips_code,\n    g.state_code,\n    fl.landuse_name as from_landuse,\n    tl.landuse_name as to_landuse,\n    f.acres,\n    f.transition_type\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_time t ON f.time_id = t.time_id\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_category = 'Agriculture' OR tl.landuse_category = 'Agriculture'\n</code></pre></p>"},{"location":"data/duckdb-schema/#v_scenario_summary","title":"<code>v_scenario_summary</code>","text":"<p>Aggregated summary by scenario <pre><code>SELECT \n    s.scenario_name,\n    t.year_range,\n    fl.landuse_name as from_landuse,\n    tl.landuse_name as to_landuse,\n    COUNT(*) as transition_count,\n    SUM(f.acres) as total_acres,\n    AVG(f.acres) as avg_acres\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_time t ON f.time_id = t.time_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nGROUP BY s.scenario_name, t.year_range, fl.landuse_name, tl.landuse_name\n</code></pre></p>"},{"location":"data/duckdb-schema/#v_total_land_area","title":"<code>v_total_land_area</code>","text":"<p>Total land area calculations for percentage-based analysis <pre><code>WITH land_totals AS (\n    SELECT \n        g.geography_id,\n        g.fips_code,\n        g.state_code,\n        SUM(f.acres) as total_land_acres\n    FROM fact_landuse_transitions f\n    JOIN dim_geography g ON f.geography_id = g.geography_id\n    JOIN dim_time t ON f.time_id = t.time_id\n    JOIN dim_scenario s ON f.scenario_id = s.scenario_id\n    WHERE t.start_year = (SELECT MIN(start_year) FROM dim_time)\n      AND s.scenario_name = (SELECT MIN(scenario_name) FROM dim_scenario)\n    GROUP BY g.geography_id, g.fips_code, g.state_code\n),\nstate_totals AS (\n    SELECT \n        state_code,\n        SUM(total_land_acres) as state_total_acres,\n        COUNT(*) as counties_in_state\n    FROM land_totals\n    GROUP BY state_code\n)\nSELECT \n    lt.geography_id,\n    lt.fips_code,\n    lt.state_code,\n    lt.total_land_acres as county_total_acres,\n    st.state_total_acres,\n    st.counties_in_state,\n    ROUND((lt.total_land_acres / st.state_total_acres) * 100, 2) as pct_of_state\nFROM land_totals lt\nJOIN state_totals st ON lt.state_code = st.state_code\n</code></pre></p> <p>Key Features: - Baseline Consistency: Uses earliest time period and first scenario for consistent totals - County Level: Total acres for each county - State Level: Total acres for each state - Percentage Calculations: County as percentage of state - Use Cases:    - \"Rank states by percentage of forest loss\"   - \"Counties with highest percentage of agricultural land\"   - \"Urban expansion as percentage of total land area\"</p>"},{"location":"data/duckdb-schema/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"data/duckdb-schema/#indexes","title":"Indexes","text":"<ul> <li>Primary keys on all dimension tables</li> <li>Foreign key indexes on fact table</li> <li>Composite index on (scenario_id, time_id, geography_id)</li> <li>Individual indexes on commonly queried columns</li> </ul>"},{"location":"data/duckdb-schema/#query-patterns","title":"Query Patterns","text":"<p>The star schema is optimized for: - Aggregation queries: Sum acres by scenario, time, geography - Filtering: Fast filtering by any dimension - Joins: Efficient joins between fact and dimension tables - Time series analysis: Easy querying across time periods - Geographic analysis: Fast geographic filtering and grouping</p>"},{"location":"data/duckdb-schema/#benefits-over-previous-design","title":"Benefits Over Previous Design","text":""},{"location":"data/duckdb-schema/#before-single-table","title":"Before (Single Table)","text":"<ul> <li>\u274c 8.6M rows with repeated dimension data</li> <li>\u274c No referential integrity</li> <li>\u274c Inefficient storage due to string repetition</li> <li>\u274c Slow aggregation queries</li> <li>\u274c No clear separation of concerns</li> </ul>"},{"location":"data/duckdb-schema/#after-star-schema","title":"After (Star Schema)","text":"<ul> <li>\u2705 Normalized dimension tables with referential integrity</li> <li>\u2705 Efficient storage through integer foreign keys</li> <li>\u2705 Fast analytical queries optimized for DuckDB</li> <li>\u2705 Clear separation between facts and dimensions</li> <li>\u2705 Extensible design for adding new dimensions</li> <li>\u2705 Better data quality through constraints</li> </ul>"},{"location":"data/duckdb-schema/#usage-examples","title":"Usage Examples","text":""},{"location":"data/duckdb-schema/#basic-queries","title":"Basic Queries","text":"<pre><code>-- Get all scenarios\nSELECT * FROM dim_scenario;\n\n-- Get landuse categories\nSELECT landuse_category, COUNT(*) \nFROM dim_landuse \nGROUP BY landuse_category;\n\n-- Total acres by scenario\nSELECT s.scenario_name, SUM(f.acres) as total_acres\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nGROUP BY s.scenario_name;\n</code></pre>"},{"location":"data/duckdb-schema/#advanced-analytics","title":"Advanced Analytics","text":"<pre><code>-- Agricultural land loss by state and scenario\nSELECT \n    s.scenario_name,\n    g.state_code,\n    SUM(f.acres) as acres_lost\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_category = 'Agriculture' \n  AND tl.landuse_category != 'Agriculture'\n  AND f.transition_type = 'change'\nGROUP BY s.scenario_name, g.state_code\nORDER BY acres_lost DESC;\n</code></pre>"},{"location":"data/duckdb-schema/#file-location","title":"File Location","text":"<ul> <li>Database: <code>data/processed/landuse_analytics.duckdb</code></li> <li>Size: Optimized for analytical workloads</li> <li>Format: DuckDB (columnar storage, optimized for analytics)</li> </ul>"},{"location":"data/duckdb-schema/#tools-integration","title":"Tools Integration","text":"<ul> <li>SQL Query Agent: Full support for DuckDB queries</li> <li>DuckDB CLI: Direct database access</li> <li>Python: pandas integration via DuckDB</li> <li>BI Tools: Compatible with most analytics tools </li> </ul>"},{"location":"data/processing/","title":"Data Processing","text":"<p>Detailed explanation of how raw land use projection data is transformed into the queryable database format.</p>"},{"location":"data/processing/#processing-pipeline-overview","title":"Processing Pipeline Overview","text":"<pre><code>graph TD\n    A[Raw JSON Data] --&gt; B[Parse &amp; Validate]\n    B --&gt; C[Transform to Long Format]\n    C --&gt; D[Create Base Tables]\n    D --&gt; E[Add Agricultural Aggregation]\n    E --&gt; F[Create Filtered Views]\n    F --&gt; G[Add Indexes]\n    G --&gt; H[Final Database]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style H fill:#9f9,stroke:#333,stroke-width:2px</code></pre>"},{"location":"data/processing/#step-1-raw-data-structure","title":"Step 1: Raw Data Structure","text":""},{"location":"data/processing/#input-format","title":"Input Format","text":"<p>The raw JSON file (<code>county_landuse_projections_RPA.json</code>) has a nested structure:</p> <pre><code>{\n  \"06037\": {  // FIPS code\n    \"county_name\": \"Los Angeles\",\n    \"state\": \"CA\",\n    \"scenarios\": {\n      \"Baseline\": {\n        \"2012-2020\": {\n          \"transition_matrix\": [\n            {\"_row\": \"cr\", \"cr\": 100.5, \"ps\": 2.3, \"ur\": 5.7, ...},\n            {\"_row\": \"ps\", \"cr\": 1.2, \"ps\": 89.4, \"ur\": 3.1, ...},\n            ...\n          ]\n        },\n        \"2020-2030\": {...}\n      },\n      \"High Crop Demand\": {...}\n    }\n  }\n}\n</code></pre>"},{"location":"data/processing/#matrix-interpretation","title":"Matrix Interpretation","text":"<p>Each transition matrix represents land use changes: - Rows: Original land use (from) - Columns: New land use (to) - Values: Area in 1000 acres</p>"},{"location":"data/processing/#step-2-conversion-scripts","title":"Step 2: Conversion Scripts","text":""},{"location":"data/processing/#main-converter","title":"Main Converter","text":"<p><code>convert_landuse_to_db.py</code> performs the initial conversion:</p> <pre><code>def process_matrix_data(matrix_data, scenario, year, year_range, fips):\n    \"\"\"Convert matrix format to transition records.\"\"\"\n    transitions = []\n\n    for row in matrix_data:\n        from_type = LAND_USE_MAP.get(row.get('_row', ''), row.get('_row', ''))\n\n        if from_type != 'Total':  # Skip total row\n            for col, value in row.items():\n                if col not in ['_row', 't1'] and col in LAND_USE_MAP:\n                    to_type = LAND_USE_MAP[col]\n\n                    if to_type != 'Total':  # Skip total column\n                        transitions.append({\n                            'scenario': scenario,\n                            'year': year,\n                            'year_range': year_range,\n                            'fips': fips,\n                            'from_land_use': from_type,\n                            'to_land_use': to_type,\n                            'area_1000_acres': float(value)\n                        })\n\n    return transitions\n</code></pre>"},{"location":"data/processing/#processing-large-files","title":"Processing Large Files","text":"<p>For large JSON files, streaming processing is used:</p> <pre><code>import ijson\n\ndef process_large_json(json_path):\n    \"\"\"Stream process large JSON files.\"\"\"\n    with open(json_path, 'rb') as file:\n        parser = ijson.items(file, 'item')\n\n        for county_data in parser:\n            process_county(county_data)\n\n            # Batch insert for efficiency\n            if len(batch) &gt;= 10000:\n                insert_batch(batch)\n                batch = []\n</code></pre>"},{"location":"data/processing/#step-3-agricultural-aggregation","title":"Step 3: Agricultural Aggregation","text":""},{"location":"data/processing/#creating-combined-agriculture","title":"Creating Combined Agriculture","text":"<p><code>convert_landuse_with_agriculture.py</code> adds agricultural aggregation:</p> <pre><code>def aggregate_agriculture(transitions):\n    \"\"\"Combine Crop and Pasture into Agriculture.\"\"\"\n    ag_transitions = []\n\n    for t in transitions:\n        # Map individual categories to aggregated\n        from_ag = 'Agriculture' if t['from_land_use'] in ['Crop', 'Pasture'] else t['from_land_use']\n        to_ag = 'Agriculture' if t['to_land_use'] in ['Crop', 'Pasture'] else t['to_land_use']\n\n        # Find or create aggregated transition\n        key = (t['scenario'], t['year'], t['fips'], from_ag, to_ag)\n        # Sum areas for same aggregated transition\n</code></pre>"},{"location":"data/processing/#aggregation-logic","title":"Aggregation Logic","text":"<pre><code>-- Example: Combining crop and pasture transitions\n-- Original: Crop\u2192Urban (10) + Pasture\u2192Urban (5)\n-- Becomes: Agriculture\u2192Urban (15)\n\nINSERT INTO landuse_transitions_ag\nSELECT \n    scenario, year, year_range, fips,\n    CASE \n        WHEN from_land_use IN ('Crop', 'Pasture') THEN 'Agriculture'\n        ELSE from_land_use \n    END as from_land_use,\n    CASE \n        WHEN to_land_use IN ('Crop', 'Pasture') THEN 'Agriculture'\n        ELSE to_land_use \n    END as to_land_use,\n    SUM(area_1000_acres) as area_1000_acres\nFROM landuse_transitions\nGROUP BY scenario, year, year_range, fips, from_land_use, to_land_use;\n</code></pre>"},{"location":"data/processing/#step-4-creating-filtered-views","title":"Step 4: Creating Filtered Views","text":""},{"location":"data/processing/#change-only-views","title":"Change-Only Views","text":"<p><code>add_change_views.py</code> creates views excluding unchanged land:</p> <pre><code>CREATE VIEW landuse_changes_only AS\nSELECT * FROM landuse_transitions\nWHERE from_land_use != to_land_use\n  AND from_land_use != 'Total'\n  AND to_land_use != 'Total';\n\nCREATE VIEW landuse_changes_only_ag AS\nSELECT * FROM landuse_transitions_ag\nWHERE from_land_use != to_land_use\n  AND from_land_use != 'Total'\n  AND to_land_use != 'Total';\n</code></pre>"},{"location":"data/processing/#benefits-of-views","title":"Benefits of Views","text":"<ol> <li>Smaller datasets - Fewer rows to process</li> <li>Focused analysis - Only actual changes</li> <li>Better performance - Less data to scan</li> <li>Cleaner results - No diagonal values</li> </ol>"},{"location":"data/processing/#step-5-database-optimization","title":"Step 5: Database Optimization","text":""},{"location":"data/processing/#index-creation","title":"Index Creation","text":"<pre><code>-- Optimize common query patterns\nCREATE INDEX idx_scenario ON landuse_transitions(scenario);\nCREATE INDEX idx_year ON landuse_transitions(year);\nCREATE INDEX idx_fips ON landuse_transitions(fips);\nCREATE INDEX idx_from_to ON landuse_transitions(from_land_use, to_land_use);\n\n-- Composite indexes for complex queries\nCREATE INDEX idx_scenario_year_fips ON landuse_transitions(scenario, year, fips);\n</code></pre>"},{"location":"data/processing/#performance-statistics","title":"Performance Statistics","text":"<pre><code>-- Analyze table for query optimization\nANALYZE landuse_transitions;\n\n-- Check index usage\nEXPLAIN QUERY PLAN\nSELECT * FROM landuse_transitions\nWHERE scenario = 'Baseline' AND year = 2050;\n</code></pre>"},{"location":"data/processing/#quality-control","title":"Quality Control","text":""},{"location":"data/processing/#data-validation","title":"Data Validation","text":"<p>During processing, several checks ensure data quality:</p> <pre><code>def validate_transitions(transitions, fips, year):\n    \"\"\"Validate transition data integrity.\"\"\"\n\n    # Check 1: Total area should be consistent\n    total_from = sum(t['area'] for t in transitions if t['from'] != 'Total')\n    total_to = sum(t['area'] for t in transitions if t['to'] != 'Total')\n    assert abs(total_from - total_to) &lt; 0.01, f\"Area mismatch for {fips} in {year}\"\n\n    # Check 2: No negative areas\n    assert all(t['area'] &gt;= 0 for t in transitions), \"Negative area found\"\n\n    # Check 3: Valid land use categories\n    valid_categories = {'Crop', 'Pasture', 'Forest', 'Urban', 'Range', 'Total'}\n    assert all(t['from'] in valid_categories for t in transitions), \"Invalid category\"\n</code></pre>"},{"location":"data/processing/#error-handling","title":"Error Handling","text":"<pre><code>def process_county_safe(county_data):\n    \"\"\"Process with error handling.\"\"\"\n    try:\n        transitions = process_county(county_data)\n        validate_transitions(transitions)\n        return transitions\n    except Exception as e:\n        logger.error(f\"Error processing county {county_data.get('fips')}: {e}\")\n        return []\n</code></pre>"},{"location":"data/processing/#processing-performance","title":"Processing Performance","text":""},{"location":"data/processing/#optimization-techniques","title":"Optimization Techniques","text":"<ol> <li> <p>Batch Processing <pre><code># Insert in batches instead of one-by-one\ncursor.executemany(\n    \"INSERT INTO landuse_transitions VALUES (?,?,?,?,?,?,?)\",\n    batch_data\n)\n</code></pre></p> </li> <li> <p>Transaction Management <pre><code>conn.execute(\"BEGIN TRANSACTION\")\n# ... bulk inserts ...\nconn.execute(\"COMMIT\")\n</code></pre></p> </li> <li> <p>Memory Management <pre><code># Process in chunks for large files\nfor chunk in pd.read_json(file_path, chunksize=10000):\n    process_chunk(chunk)\n</code></pre></p> </li> </ol>"},{"location":"data/processing/#processing-statistics","title":"Processing Statistics","text":"<p>Typical processing performance: - Raw JSON size: ~500 MB - Processing time: 2-5 minutes - Final database size: ~200 MB - Row count: ~1.2 million transitions</p>"},{"location":"data/processing/#running-the-processors","title":"Running the Processors","text":""},{"location":"data/processing/#basic-conversion","title":"Basic Conversion","text":"<pre><code># Convert JSON to basic SQLite database\nuv run python scripts/converters/convert_landuse_to_db.py\n</code></pre>"},{"location":"data/processing/#with-agricultural-aggregation","title":"With Agricultural Aggregation","text":"<pre><code># Create database with ag aggregation\nuv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre>"},{"location":"data/processing/#add-views-to-existing-database","title":"Add Views to Existing Database","text":"<pre><code># Add filtered views\nuv run python scripts/converters/add_change_views.py\n</code></pre>"},{"location":"data/processing/#full-pipeline","title":"Full Pipeline","text":"<pre><code># Run complete processing pipeline\n./scripts/process_all.sh\n</code></pre>"},{"location":"data/processing/#customization-options","title":"Customization Options","text":""},{"location":"data/processing/#modifying-land-use-categories","title":"Modifying Land Use Categories","text":"<p>Edit the mapping in converter scripts:</p> <pre><code>LAND_USE_MAP = {\n    'cr': 'Cropland',      # Change names\n    'ps': 'Pasture',\n    'rg': 'Rangeland',     # Alternative naming\n    'fr': 'Forest',\n    'ur': 'Developed',     # Different term\n    'wt': 'Wetland'        # Add new category\n}\n</code></pre>"},{"location":"data/processing/#custom-aggregations","title":"Custom Aggregations","text":"<p>Create your own groupings:</p> <pre><code># Example: Natural vs Developed\nNATURAL_LANDS = ['Forest', 'Range', 'Wetland']\nDEVELOPED_LANDS = ['Urban', 'Infrastructure']\nAGRICULTURAL_LANDS = ['Crop', 'Pasture']\n</code></pre>"},{"location":"data/processing/#additional-processing","title":"Additional Processing","text":"<p>Add custom calculations during conversion:</p> <pre><code># Calculate net change during processing\nnet_change = area_new - area_original\n\n# Add percentage calculations\npercent_change = (net_change / area_original) * 100 if area_original &gt; 0 else 0\n</code></pre>"},{"location":"data/processing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"data/processing/#common-issues","title":"Common Issues","text":"<ol> <li>Memory Errors</li> <li>Use streaming processing</li> <li>Increase chunk size</li> <li> <p>Process by scenario</p> </li> <li> <p>Data Inconsistencies</p> </li> <li>Check total validations</li> <li>Review error logs</li> <li> <p>Verify source data</p> </li> <li> <p>Performance Problems</p> </li> <li>Add appropriate indexes</li> <li>Use batch operations</li> <li>Consider partitioning</li> </ol>"},{"location":"data/processing/#debugging-tools","title":"Debugging Tools","text":"<pre><code>-- Check for data issues\nSELECT fips, year, \n       SUM(area_1000_acres) as total,\n       COUNT(*) as transitions\nFROM landuse_transitions\nGROUP BY fips, year\nHAVING total &lt; 100  -- Suspiciously small counties\n    OR transitions &lt; 25;  -- Missing transitions\n</code></pre>"},{"location":"data/processing/#next-steps","title":"Next Steps","text":"<ul> <li>Understand the Database Schema</li> <li>Learn about Land Use Categories</li> <li>Start Querying the Data</li> <li>Explore API Documentation</li> </ul>"},{"location":"data/rpa-model-diagram/","title":"RPA Land Use Model Diagram","text":"<pre><code>graph LR\n    %% Data nodes (yellow ovals)\n    PRISM[\"PRISM Historical&lt;br/&gt;Climate\"]:::data\n    NetReturns[\"Net Returns to Land&lt;br/&gt;Production\"]:::data\n    SoilQuality[\"Soil Quality (NRI)\"]:::data\n    MACA[\"MACA Climate&lt;br/&gt;Projections\"]:::data\n    SSP[\"Downscaled SSP&lt;br/&gt;Projections\"]:::data\n\n    %% Ricardian Climate Functions box\n    subgraph RCF[\"Ricardian Climate Functions\"]\n        Forest[\"Forest\"]:::process\n        Crop[\"Crop\"]:::process\n        Urban[\"Urban\"]:::process\n    end\n\n    %% Process nodes (gray rectangles)\n    LandUseModel[\"Land-use&lt;br/&gt;Change Model\"]:::process\n\n    %% Output nodes (red hexagons)\n    ClimateParam[\"Climate&lt;br/&gt;Parameterized&lt;br/&gt;Net Returns\"]:::output\n    Transition[\"Transition&lt;br/&gt;Probability as&lt;br/&gt;Function of&lt;br/&gt;Climate / SSP\"]:::output\n    SimulatedChange[\"Simulated Land&lt;br/&gt;Area Change&lt;br/&gt;(Gross &amp; Net)\"]:::output\n\n    %% Simplified connections to the RCF box\n    PRISM --&gt; RCF\n    NetReturns --&gt; RCF\n    SoilQuality --&gt; RCF\n\n    %% Connections from RCF components to other nodes\n    Forest --&gt; ClimateParam\n    Crop --&gt; ClimateParam\n    Urban --&gt; ClimateParam\n\n    ClimateParam --&gt; LandUseModel\n    LandUseModel --&gt; Transition\n    MACA --&gt; Transition\n    SSP --&gt; Transition\n\n    Transition --&gt; SimulatedChange\n\n    %% Styling\n    classDef data fill:#ffecb3,stroke:#333,stroke-width:2px\n    classDef process fill:#e0e0e0,stroke:#333,stroke-width:2px\n    classDef output fill:#ffcdd2,stroke:#333,stroke-width:2px,shape:hexagon\n    style RCF fill:#fff5e6,stroke:#be9b3e,stroke-width:3px</code></pre> <p>This diagram represents the RPA Land Use Model's data flow and components, showing how various inputs like climate data and soil quality flow through the Ricardian Climate Functions and ultimately produce simulated land area changes. </p>"},{"location":"data/schema/","title":"Database Schema","text":"<p>This page documents the structure of the RPA land use analytics database, including all tables, columns, and relationships.</p>"},{"location":"data/schema/#database-overview","title":"Database Overview","text":"<p>The DuckDB database (<code>landuse_analytics.duckdb</code>) uses a modern star schema design optimized for analytical queries. For comprehensive details, see the Database Overview and Table Reference.</p>"},{"location":"data/schema/#current-star-schema","title":"Current Star Schema","text":"<p>The system uses a normalized star schema with: - <code>fact_landuse_transitions</code> - Central fact table with all transitions - <code>fact_socioeconomic_projections</code> - Population and income projections - <code>dim_scenario</code> - Climate and socioeconomic scenarios - <code>dim_geography</code> - County geography with enhanced metadata - <code>dim_landuse</code> - Land use type definitions - <code>dim_time</code> - Time period dimensions - <code>dim_socioeconomic</code> - SSP scenario descriptions - <code>dim_indicators</code> - Socioeconomic indicator definitions</p>"},{"location":"data/schema/#current-database-structure","title":"Current Database Structure","text":"<p>Note: This page contains legacy information. For complete current database documentation, see: - Database Overview - Executive summary and architecture - Table Reference - Detailed table specifications - View Definitions - Analytical views and usage - Data Dictionary - Business definitions and guidelines</p>"},{"location":"data/schema/#key-concepts","title":"Key Concepts","text":""},{"location":"data/schema/#climate-scenarios","title":"Climate Scenarios","text":"<p>The database contains 20 climate scenarios combining: - 5 Climate models (CNRM_CM5, HadGEM2_ES365, IPSL_CM5A_MR, MRI_CGCM3, NorESM1_M) - 4 RCP/SSP combinations (rcp45_ssp1, rcp85_ssp2, rcp85_ssp3, rcp85_ssp5)</p>"},{"location":"data/schema/#land-use-categories","title":"Land Use Categories","text":"<ul> <li>Crop (cr): Agricultural cropland</li> <li>Pasture (ps): Livestock grazing land  </li> <li>Rangeland (rg): Natural grasslands/shrublands</li> <li>Forest (fr): Forested areas</li> <li>Urban (ur): Developed/built areas</li> </ul>"},{"location":"data/schema/#time-coverage","title":"Time Coverage","text":"<p>6 time periods from 2012-2070: - 2012-2020 (calibration period) - 2020-2030, 2030-2040, 2040-2050, 2050-2060, 2060-2070</p>"},{"location":"data/schema/#geographic-coverage","title":"Geographic Coverage","text":"<ul> <li>3,075 US counties across all 50 states</li> <li>Organized by US Census regions (Northeast, Midwest, South, West)</li> </ul>"},{"location":"data/schema/#basic-query-examples","title":"Basic Query Examples","text":"<p>For detailed query patterns and examples, see Basic Queries and Advanced Queries.</p> <pre><code>-- Get all scenarios\nSELECT * FROM dim_scenario;\n\n-- Find counties in California\nSELECT * FROM dim_geography WHERE state_name = 'California';\n\n-- Basic land use transition query\nSELECT \n    g.county_name,\n    s.scenario_name,\n    lu_from.landuse_name as from_landuse,\n    lu_to.landuse_name as to_landuse,\n    f.acres\nFROM fact_landuse_transitions f\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_landuse lu_from ON f.from_landuse_id = lu_from.landuse_id\nJOIN dim_landuse lu_to ON f.to_landuse_id = lu_to.landuse_id\nWHERE f.transition_type = 'change'\nLIMIT 10;\n</code></pre>"},{"location":"data/schema/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Land Use Categories in detail</li> <li>See Data Sources for data provenance</li> <li>Review Processing Steps for data pipeline</li> </ul>"},{"location":"data/sources/","title":"Data Sources","text":"<p>Understanding the origin, methodology, and reliability of the land use projection data.</p>"},{"location":"data/sources/#primary-data-source","title":"Primary Data Source","text":""},{"location":"data/sources/#rpa-land-use-projections","title":"RPA Land Use Projections","text":"<p>The data comes from the USDA Forest Service Resources Planning Act (RPA) Assessment, which provides long-term projections of land use change in the United States.</p> <p>Key Features: - County-level projections - Multiple scenarios - 2020-2100 timeframe - Decade intervals - All US counties included</p> <p>Citation: <pre><code>USDA Forest Service. (2024). Resources Planning Act (RPA) \nLand Use Projections. Fort Collins, CO: Rocky Mountain \nResearch Station.\n</code></pre></p>"},{"location":"data/sources/#projection-methodology","title":"Projection Methodology","text":""},{"location":"data/sources/#modeling-approach","title":"Modeling Approach","text":"<p>The RPA projections use an integrated assessment model that combines:</p> <ol> <li>Economic Drivers</li> <li>Population growth</li> <li>Income changes</li> <li>Commodity prices</li> <li> <p>Land values</p> </li> <li> <p>Policy Assumptions</p> </li> <li>Conservation programs</li> <li>Zoning regulations</li> <li>Agricultural subsidies</li> <li> <p>Environmental protections</p> </li> <li> <p>Biophysical Constraints</p> </li> <li>Soil quality</li> <li>Water availability</li> <li>Climate conditions</li> <li>Topography</li> </ol>"},{"location":"data/sources/#model-components","title":"Model Components","text":"<pre><code>graph LR\n    A[Economic Module] --&gt; D[Land Use Change Model]\n    B[Demographic Module] --&gt; D\n    C[Climate Module] --&gt; D\n    D --&gt; E[County Projections]\n    E --&gt; F[Scenario Outputs]</code></pre>"},{"location":"data/sources/#scenario-descriptions","title":"Scenario Descriptions","text":""},{"location":"data/sources/#baseline-scenario","title":"Baseline Scenario","text":"<p>Assumptions: - Moderate population growth - Historical economic trends continue - Current policies maintained - Average climate change impacts</p> <p>Key Characteristics: - Most likely future pathway - Balanced land use changes - Reference for comparisons</p>"},{"location":"data/sources/#high-crop-demand","title":"High Crop Demand","text":"<p>Assumptions: - Increased global food demand - Higher commodity prices - Agricultural expansion incentivized - Biofuel demand growth</p> <p>Expected Outcomes: - More forest/range \u2192 cropland - Pasture \u2192 crop conversion - Reduced natural lands</p>"},{"location":"data/sources/#high-forest","title":"High Forest","text":"<p>Assumptions: - Strong conservation policies - Carbon sequestration valued - Reduced deforestation - Afforestation programs</p> <p>Expected Outcomes: - Forest area maintained/increased - Limited agricultural expansion - More sustainable land use</p>"},{"location":"data/sources/#high-urban","title":"High Urban","text":"<p>Assumptions: - Accelerated population growth - Concentrated in metro areas - Higher development rates - Sprawl patterns continue</p> <p>Expected Outcomes: - Rapid urban expansion - Agricultural land loss - Forest fragmentation - Infrastructure demands</p>"},{"location":"data/sources/#data-processing-pipeline","title":"Data Processing Pipeline","text":""},{"location":"data/sources/#1-original-format","title":"1. Original Format","text":"<p>Raw data structure: <pre><code>{\n  \"county\": {\n    \"fips\": \"06037\",\n    \"name\": \"Los Angeles\",\n    \"scenarios\": {\n      \"Baseline\": {\n        \"2020-2030\": {\n          \"transitions\": [\n            {\"from\": \"cr\", \"to\": \"ur\", \"area\": 12.5},\n            ...\n          ]\n        }\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"data/sources/#2-conversion-process","title":"2. Conversion Process","text":"<p>The conversion scripts (<code>scripts/converters/</code>) transform this into:</p> <pre><code>-- Normalized relational format\nINSERT INTO landuse_transitions VALUES\n('Baseline', 2030, '2020-2030', '06037', 'Crop', 'Urban', 12.5);\n</code></pre>"},{"location":"data/sources/#3-data-enhancements","title":"3. Data Enhancements","text":"<p>Additional processing creates: - Agricultural aggregation views - Change-only filtered tables - Indexed columns for performance - Validation totals</p>"},{"location":"data/sources/#data-quality-and-limitations","title":"Data Quality and Limitations","text":""},{"location":"data/sources/#strengths","title":"Strengths","text":"<p>\u2705 Comprehensive Coverage - All US counties included - Consistent methodology - Multiple scenarios - Long time horizon</p> <p>\u2705 Scientific Basis - Peer-reviewed methods - Validated against historical data - Uncertainty quantified - Regular updates</p> <p>\u2705 Policy Relevance - Used for federal planning - Informs resource management - Scenario analysis capability</p>"},{"location":"data/sources/#limitations","title":"Limitations","text":"<p>\u26a0\ufe0f Spatial Resolution - County-level only - Sub-county variation lost - Edge effects possible - Urban detail limited</p> <p>\u26a0\ufe0f Temporal Resolution - Decade intervals - Annual variation smoothed - Sudden changes averaged - No seasonal data</p> <p>\u26a0\ufe0f Uncertainty - Future projections inherently uncertain - Economic assumptions may not hold - Climate impacts simplified - Policy changes unpredictable</p>"},{"location":"data/sources/#known-issues","title":"Known Issues","text":"<ol> <li>Urban Definition</li> <li>Includes all developed land</li> <li>Mixed-use areas simplified</li> <li> <p>Green space within cities included</p> </li> <li> <p>Agricultural Categories</p> </li> <li>Crop/pasture distinction sometimes blurred</li> <li>Rotation systems simplified</li> <li> <p>Specialty crops aggregated</p> </li> <li> <p>Edge Counties</p> </li> <li>Small counties may have rounding effects</li> <li>Cross-border influences not captured</li> <li>Island counties special cases</li> </ol>"},{"location":"data/sources/#validation-methods","title":"Validation Methods","text":""},{"location":"data/sources/#historical-validation","title":"Historical Validation","text":"<p>The model was validated against: - USDA Census of Agriculture - National Land Cover Database (NLCD) - Forest Inventory and Analysis (FIA) - Economic census data</p>"},{"location":"data/sources/#cross-validation","title":"Cross-Validation","text":"<pre><code>-- Check total area consistency\nSELECT fips, year, \n       SUM(area_1000_acres) as total_area,\n       COUNT(*) as transition_count\nFROM landuse_transitions\nWHERE from_land_use != 'Total'\nGROUP BY fips, year\nHAVING COUNT(DISTINCT total_area) &gt; 1;\n</code></pre>"},{"location":"data/sources/#scenario-consistency","title":"Scenario Consistency","text":"<pre><code>-- Verify scenario relationships\nSELECT scenario,\n       SUM(CASE WHEN to_land_use = 'Urban' THEN area_1000_acres END) as urban_total\nFROM landuse_transitions\nWHERE year = 2050\nGROUP BY scenario\nORDER BY urban_total;\n-- High Urban should have highest value\n</code></pre>"},{"location":"data/sources/#updates-and-versions","title":"Updates and Versions","text":""},{"location":"data/sources/#current-version","title":"Current Version","text":"<ul> <li>Data version: 2024 RPA Assessment</li> <li>Processing date: 2024</li> <li>Database format: DuckDB (modern), SQLite 3 (legacy)</li> </ul>"},{"location":"data/sources/#update-cycle","title":"Update Cycle","text":"<ul> <li>RPA assessments every 10 years</li> <li>Interim updates for major changes</li> <li>Methodology improvements ongoing</li> </ul>"},{"location":"data/sources/#version-control","title":"Version Control","text":"<pre><code># Check data version\nSELECT * FROM metadata WHERE key = 'data_version';\n\n# Processing timestamp\nSELECT * FROM metadata WHERE key = 'processed_date';\n</code></pre>"},{"location":"data/sources/#related-datasets","title":"Related Datasets","text":""},{"location":"data/sources/#complementary-data-sources","title":"Complementary Data Sources","text":"<ol> <li>National Land Cover Database (NLCD)</li> <li>30m resolution land cover</li> <li>Historical validation</li> <li> <p>Urban detail</p> </li> <li> <p>Census of Agriculture</p> </li> <li>Farm-level data</li> <li>Crop specifics</li> <li> <p>Economic variables</p> </li> <li> <p>Forest Inventory Analysis (FIA)</p> </li> <li>Detailed forest data</li> <li>Species composition</li> <li>Management practices</li> </ol>"},{"location":"data/sources/#integration-opportunities","title":"Integration Opportunities","text":"<pre><code># Example: Combining with other data\nimport geopandas as gpd\n\n# Load county boundaries\ncounties = gpd.read_file('counties.shp')\n\n# Join with land use projections\nlanduse_2050 = query_database(\n    \"SELECT fips, SUM(area_1000_acres) as urban_area \"\n    \"FROM landuse_transitions \"\n    \"WHERE to_land_use = 'Urban' AND year = 2050 \"\n    \"GROUP BY fips\"\n)\n\n# Spatial analysis\ncounties_with_landuse = counties.merge(\n    landuse_2050, \n    left_on='GEOID', \n    right_on='fips'\n)\n</code></pre>"},{"location":"data/sources/#usage-rights-and-citation","title":"Usage Rights and Citation","text":""},{"location":"data/sources/#license","title":"License","text":"<ul> <li>Public domain data</li> <li>No usage restrictions</li> <li>Attribution appreciated</li> </ul>"},{"location":"data/sources/#recommended-citation","title":"Recommended Citation","text":"<pre><code>When using this data, please cite:\n\n[Your Project Name]. (2025). Land Use Transition Analysis \nusing RPA Projections. Based on USDA Forest Service RPA \nAssessment data.\n\nOriginal data: USDA Forest Service. (2024). 2020 RPA \nAssessment. Fort Collins, CO: RMRS.\n</code></pre>"},{"location":"data/sources/#acknowledgments","title":"Acknowledgments","text":"<p>This project builds upon the extensive work of: - USDA Forest Service researchers - RPA Assessment team - Land use modeling community</p>"},{"location":"data/sources/#data-access","title":"Data Access","text":""},{"location":"data/sources/#raw-data-location","title":"Raw Data Location","text":"<pre><code>data/raw/county_landuse_projections_RPA.json\n</code></pre>"},{"location":"data/sources/#processed-databases","title":"Processed Databases","text":"<pre><code>data/processed/landuse_transitions.db\ndata/processed/landuse_transitions_with_ag.db\n</code></pre>"},{"location":"data/sources/#query-access","title":"Query Access","text":"<pre><code># Direct database access (modern DuckDB)\nimport duckdb\nconn = duckdb.connect('data/processed/landuse_analytics.duckdb')\n\n# Legacy SQLite access\nimport sqlite3\nconn = sqlite3.connect('data/processed/landuse_transitions_with_ag.db')\n\n# Through the agent\nagent.run(\"Query the landuse database...\")\n</code></pre>"},{"location":"data/sources/#next-steps","title":"Next Steps","text":"<ul> <li>Review Database Schema for structure</li> <li>Understand Land Use Categories</li> <li>Learn about Processing Steps</li> <li>Start Querying Data</li> </ul>"},{"location":"data/table-reference/","title":"Table Reference Guide","text":""},{"location":"data/table-reference/#overview","title":"Overview","text":"<p>This document provides detailed specifications for all 8 tables in the RPA Land Use Analytics database, including column definitions, data types, constraints, and usage examples.</p>"},{"location":"data/table-reference/#fact-tables","title":"Fact Tables","text":""},{"location":"data/table-reference/#fact_landuse_transitions","title":"fact_landuse_transitions","text":"<p>Purpose: Core table containing all land use transitions between categories across scenarios, time periods, and counties.</p> <p>Records: 5,432,198 | Size: 5.18 MB | Type: Fact Table</p>"},{"location":"data/table-reference/#schema-definition","title":"Schema Definition","text":"Column Data Type Constraints Description <code>transition_id</code> BIGINT Unique identifier for each transition record <code>scenario_id</code> INTEGER NOT NULL, FK Reference to dim_scenario table <code>time_id</code> INTEGER NOT NULL, FK Reference to dim_time table <code>geography_id</code> INTEGER NOT NULL, FK Reference to dim_geography table <code>from_landuse_id</code> INTEGER NOT NULL, FK Reference to dim_landuse (source land use) <code>to_landuse_id</code> INTEGER NOT NULL, FK Reference to dim_landuse (destination land use) <code>acres</code> DECIMAL(15,4) Area in hundreds of acres for this transition <code>transition_type</code> VARCHAR 'change' or 'same' <code>created_at</code> TIMESTAMP Record creation timestamp"},{"location":"data/table-reference/#sample-data","title":"Sample Data","text":"<pre><code>SELECT * FROM fact_landuse_transitions LIMIT 5;\n</code></pre> transition_id scenario_id time_id geography_id from_landuse_id to_landuse_id acres transition_type 737281 3 4 459 4 3 3.7577 change 737282 3 4 459 4 4 265.0467 same 737283 3 4 459 4 5 0.1956 change 737284 3 4 459 5 1 0.0000 change 737285 3 4 459 5 2 0.0000 change"},{"location":"data/table-reference/#data-distribution","title":"Data Distribution","text":"Transition Type Count Percentage Avg Acres change 3,887,318 71.5% 0.133 (13.3 actual acres) same 1,544,880 28.5% 10.456 (1,045.6 actual acres)"},{"location":"data/table-reference/#performance-notes","title":"Performance Notes","text":"<ul> <li>Primary composite index on <code>(scenario_id, time_id, geography_id)</code></li> <li>Secondary indexes on <code>from_landuse_id</code>, <code>to_landuse_id</code>, <code>acres</code>, <code>transition_type</code></li> <li>Optimized for analytical queries with dimensional filtering</li> </ul>"},{"location":"data/table-reference/#fact_socioeconomic_projections","title":"fact_socioeconomic_projections","text":"<p>Purpose: Population and income projections by county and SSP scenario.</p> <p>Records: 291,936 | Size: 0.28 MB | Type: Fact Table</p>"},{"location":"data/table-reference/#schema-definition_1","title":"Schema Definition","text":"Column Data Type Constraints Description <code>projection_id</code> BIGINT NOT NULL, PK Unique identifier for each projection <code>geography_id</code> INTEGER NOT NULL, FK Reference to dim_geography table <code>socioeconomic_id</code> INTEGER NOT NULL, FK Reference to dim_socioeconomic table <code>indicator_id</code> INTEGER NOT NULL, FK Reference to dim_indicators table <code>year</code> INTEGER NOT NULL Projection year <code>value</code> DECIMAL(15,4) NOT NULL Indicator value (population in thousands, income in 2009 USD thousands) <code>is_historical</code> BOOLEAN DEFAULT FALSE Whether this is historical (TRUE) or projected (FALSE) data <code>created_at</code> TIMESTAMP DEFAULT CURRENT_TIMESTAMP Record creation timestamp"},{"location":"data/table-reference/#sample-data_1","title":"Sample Data","text":"<pre><code>SELECT * FROM fact_socioeconomic_projections LIMIT 5;\n</code></pre> projection_id geography_id socioeconomic_id indicator_id year value is_historical 1 1 1 1 2010 54.4210 TRUE 2 1 1 1 2020 55.3690 FALSE 3 1 1 1 2030 56.2520 FALSE 4 1 1 1 2040 56.9500 FALSE 5 1 1 1 2050 57.4030 FALSE"},{"location":"data/table-reference/#performance-notes_1","title":"Performance Notes","text":"<ul> <li>Composite index on <code>(geography_id, socioeconomic_id, indicator_id, year)</code></li> <li>Optimized for time-series analysis and demographic queries</li> </ul>"},{"location":"data/table-reference/#dimension-tables","title":"Dimension Tables","text":""},{"location":"data/table-reference/#dim_geography","title":"dim_geography","text":"<p>Purpose: Geographic reference data for all US counties with enhanced metadata.</p> <p>Records: 3,075 | Size: 0.003 MB | Type: Dimension Table</p>"},{"location":"data/table-reference/#schema-definition_2","title":"Schema Definition","text":"Column Data Type Constraints Description <code>geography_id</code> INTEGER PK Unique identifier for each county <code>fips_code</code> VARCHAR UNIQUE 5-digit FIPS county code <code>county_name</code> VARCHAR County name <code>state_code</code> VARCHAR 2-character state code <code>state_name</code> VARCHAR Full state name <code>state_abbrev</code> VARCHAR 2-character state abbreviation <code>region</code> VARCHAR US Census region (Northeast, Midwest, South, West) <code>geometry</code> GEOMETRY County boundary geometry (spatial data) <code>area_sqmi</code> DOUBLE County area in square miles <code>centroid_lat</code> DOUBLE County centroid latitude <code>centroid_lon</code> DOUBLE County centroid longitude <code>created_at</code> TIMESTAMP Record creation timestamp <code>updated_at</code> TIMESTAMP Last update timestamp"},{"location":"data/table-reference/#sample-data_2","title":"Sample Data","text":"<pre><code>SELECT fips_code, county_name, state_name, region, area_sqmi \nFROM dim_geography LIMIT 5;\n</code></pre> fips_code county_name state_name region area_sqmi 01001 Autauga County Alabama South 594.44 01003 Baldwin County Alabama South 1589.78 01005 Barbour County Alabama South 884.88 01007 Bibb County Alabama South 622.58 01009 Blount County Alabama South 644.78"},{"location":"data/table-reference/#regional-distribution","title":"Regional Distribution","text":"Region Counties Avg Size (sq mi) Percentage South 1,389 624 45.2% Midwest 1,055 711 34.3% West 414 2,836 13.5% Northeast 217 746 7.1%"},{"location":"data/table-reference/#performance-notes_2","title":"Performance Notes","text":"<ul> <li>Primary index on <code>geography_id</code></li> <li>Secondary indexes on <code>fips_code</code> and <code>state_name</code> for fast lookups</li> <li>Spatial index on <code>geometry</code> for geographic queries</li> </ul>"},{"location":"data/table-reference/#dim_scenario","title":"dim_scenario","text":"<p>Purpose: Climate and socioeconomic scenario definitions combining climate models with RCP/SSP pathways.</p> <p>Records: 20 | Size: 0.00002 MB | Type: Dimension Table</p>"},{"location":"data/table-reference/#schema-definition_3","title":"Schema Definition","text":"Column Data Type Constraints Description <code>scenario_id</code> INTEGER NOT NULL, PK Unique identifier for each scenario <code>scenario_name</code> VARCHAR NOT NULL, UNIQUE Full scenario name (e.g., \"CNRM_CM5_rcp45_ssp1\") <code>climate_model</code> VARCHAR Climate model used <code>rcp_scenario</code> VARCHAR Representative Concentration Pathway <code>ssp_scenario</code> VARCHAR Shared Socioeconomic Pathway <code>created_at</code> TIMESTAMP DEFAULT CURRENT_TIMESTAMP Record creation timestamp"},{"location":"data/table-reference/#climate-models","title":"Climate Models","text":"Model Description Characteristics CNRM_CM5 \"Wet\" climate model Higher precipitation scenarios HadGEM2_ES365 \"Hot\" climate model Higher temperature scenarios IPSL_CM5A_MR \"Dry\" climate model Lower precipitation scenarios MRI_CGCM3 \"Least warm\" climate model More moderate temperature increases NorESM1_M \"Middle\" climate model Balanced temperature/precipitation"},{"location":"data/table-reference/#rcpssp-combinations","title":"RCP/SSP Combinations","text":"Combination Emissions Growth Description rcp45_ssp1 Low Medium Sustainability pathway rcp85_ssp2 High Medium Middle of the road rcp85_ssp3 High Low Regional rivalry rcp85_ssp5 High High Fossil-fueled development"},{"location":"data/table-reference/#sample-data_3","title":"Sample Data","text":"<pre><code>SELECT * FROM dim_scenario LIMIT 5;\n</code></pre> scenario_id scenario_name climate_model rcp_scenario ssp_scenario 1 CNRM_CM5_rcp45_ssp1 CNRM_CM5 rcp45 ssp1 2 CNRM_CM5_rcp85_ssp2 CNRM_CM5 rcp85 ssp2 3 CNRM_CM5_rcp85_ssp3 CNRM_CM5 rcp85 ssp3 4 CNRM_CM5_rcp85_ssp5 CNRM_CM5 rcp85 ssp5 5 HadGEM2_ES365_rcp45_ssp1 HadGEM2_ES365 rcp45 ssp1"},{"location":"data/table-reference/#dim_time","title":"dim_time","text":"<p>Purpose: Time period definitions for land use projection intervals.</p> <p>Records: 6 | Size: 0.000006 MB | Type: Dimension Table</p>"},{"location":"data/table-reference/#schema-definition_4","title":"Schema Definition","text":"Column Data Type Constraints Description <code>time_id</code> INTEGER NOT NULL, PK Unique identifier for each time period <code>year_range</code> VARCHAR NOT NULL, UNIQUE Year range string (e.g., \"2012-2020\") <code>start_year</code> INTEGER Starting year of the period <code>end_year</code> INTEGER Ending year of the period <code>period_length</code> INTEGER Duration in years <code>created_at</code> TIMESTAMP DEFAULT CURRENT_TIMESTAMP Record creation timestamp"},{"location":"data/table-reference/#time-periods","title":"Time Periods","text":"time_id year_range start_year end_year period_length Purpose 1 2012-2020 2012 2020 8 Historical calibration 2 2020-2030 2020 2030 10 Near-term projections 3 2030-2040 2030 2040 10 Medium-term projections 4 2040-2050 2040 2050 10 Mid-century projections 5 2050-2060 2050 2060 10 Extended projections 6 2060-2070 2060 2070 10 Long-term projections"},{"location":"data/table-reference/#dim_landuse","title":"dim_landuse","text":"<p>Purpose: Land use category definitions with business descriptions.</p> <p>Records: 5 | Size: 0.000005 MB | Type: Dimension Table</p>"},{"location":"data/table-reference/#schema-definition_5","title":"Schema Definition","text":"Column Data Type Constraints Description <code>landuse_id</code> INTEGER NOT NULL, PK Unique identifier for each land use type <code>landuse_code</code> VARCHAR UNIQUE Short code (cr, ps, rg, fr, ur) <code>landuse_name</code> VARCHAR Full descriptive name <code>landuse_category</code> VARCHAR High-level category (Agriculture, Natural, Developed) <code>description</code> VARCHAR Detailed description of land use type <code>created_at</code> TIMESTAMP Record creation timestamp"},{"location":"data/table-reference/#land-use-types","title":"Land Use Types","text":"landuse_id landuse_code landuse_name landuse_category Description 1 cr Crop Agriculture Agricultural cropland for food production 2 ps Pasture Agriculture Grazing land for livestock 3 rg Rangeland Natural Natural grasslands and shrublands 4 fr Forest Natural Forested areas including managed timber 5 ur Urban Developed Developed areas with infrastructure"},{"location":"data/table-reference/#dim_socioeconomic","title":"dim_socioeconomic","text":"<p>Purpose: Shared Socioeconomic Pathway (SSP) scenario definitions with narrative descriptions.</p> <p>Records: 5 | Size: 0.000005 MB | Type: Dimension Table</p>"},{"location":"data/table-reference/#schema-definition_6","title":"Schema Definition","text":"Column Data Type Constraints Description <code>socioeconomic_id</code> INTEGER NOT NULL, PK Unique identifier for each SSP scenario <code>ssp_scenario</code> VARCHAR NOT NULL, UNIQUE SSP identifier (ssp1, ssp2, etc.) <code>scenario_name</code> VARCHAR NOT NULL Descriptive scenario name <code>narrative_description</code> VARCHAR Detailed scenario narrative <code>population_growth_trend</code> VARCHAR Population growth characterization <code>economic_growth_trend</code> VARCHAR Economic growth characterization <code>urbanization_level</code> VARCHAR Urbanization trend description <code>created_at</code> TIMESTAMP DEFAULT CURRENT_TIMESTAMP Record creation timestamp"},{"location":"data/table-reference/#ssp-scenarios","title":"SSP Scenarios","text":"ssp_scenario scenario_name Population Growth Economic Growth Urbanization ssp1 Sustainability Low Medium Moderate ssp2 Middle of the Road Medium Medium Moderate ssp3 Regional Rivalry High Low Slow ssp4 Inequality Medium High Fast ssp5 Fossil-fueled Development Low High Fast"},{"location":"data/table-reference/#dim_indicators","title":"dim_indicators","text":"<p>Purpose: Socioeconomic indicator definitions for measurement units and descriptions.</p> <p>Records: 2 | Size: 0.000002 MB | Type: Dimension Table</p>"},{"location":"data/table-reference/#schema-definition_7","title":"Schema Definition","text":"Column Data Type Constraints Description <code>indicator_id</code> INTEGER NOT NULL, PK Unique identifier for each indicator <code>indicator_name</code> VARCHAR NOT NULL, UNIQUE Indicator name <code>indicator_type</code> VARCHAR NOT NULL Type category (demographic, economic) <code>unit_of_measure</code> VARCHAR NOT NULL Measurement units <code>description</code> VARCHAR Detailed indicator description <code>created_at</code> TIMESTAMP DEFAULT CURRENT_TIMESTAMP Record creation timestamp"},{"location":"data/table-reference/#available-indicators","title":"Available Indicators","text":"indicator_id indicator_name indicator_type unit_of_measure Description 1 Population Demographic Thousands County population in thousands 2 Income Per Capita Economic 2009 USD Thousands Per capita income in thousands of 2009 USD"},{"location":"data/table-reference/#common-query-patterns","title":"Common Query Patterns","text":""},{"location":"data/table-reference/#basic-table-queries","title":"Basic Table Queries","text":"<pre><code>-- Get all scenarios with their climate models\nSELECT scenario_name, climate_model, rcp_scenario, ssp_scenario \nFROM dim_scenario;\n\n-- Find counties in a specific state\nSELECT fips_code, county_name, area_sqmi \nFROM dim_geography \nWHERE state_name = 'California';\n\n-- Get all time periods\nSELECT year_range, start_year, end_year, period_length \nFROM dim_time \nORDER BY start_year;\n</code></pre>"},{"location":"data/table-reference/#join-patterns","title":"Join Patterns","text":"<pre><code>-- Land use transitions with readable names\nSELECT \n    g.county_name,\n    g.state_name,\n    s.scenario_name,\n    t.year_range,\n    lu_from.landuse_name as from_landuse,\n    lu_to.landuse_name as to_landuse,\n    f.acres\nFROM fact_landuse_transitions f\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_time t ON f.time_id = t.time_id\nJOIN dim_landuse lu_from ON f.from_landuse_id = lu_from.landuse_id\nJOIN dim_landuse lu_to ON f.to_landuse_id = lu_to.landuse_id\nWHERE f.transition_type = 'change'\nLIMIT 10;\n</code></pre>"},{"location":"data/table-reference/#aggregation-patterns","title":"Aggregation Patterns","text":"<pre><code>-- Total acres by land use category and region\nSELECT \n    g.region,\n    lu.landuse_category,\n    SUM(f.acres) as total_acres\nFROM fact_landuse_transitions f\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse lu ON f.to_landuse_id = lu.landuse_id\nWHERE f.transition_type = 'same'  -- Only current land use\nGROUP BY g.region, lu.landuse_category\nORDER BY g.region, total_acres DESC;\n</code></pre>"},{"location":"data/table-reference/#data-relationships","title":"Data Relationships","text":""},{"location":"data/table-reference/#foreign-key-constraints","title":"Foreign Key Constraints","text":"<ul> <li><code>fact_landuse_transitions.scenario_id</code> \u2192 <code>dim_scenario.scenario_id</code></li> <li><code>fact_landuse_transitions.time_id</code> \u2192 <code>dim_time.time_id</code></li> <li><code>fact_landuse_transitions.geography_id</code> \u2192 <code>dim_geography.geography_id</code></li> <li><code>fact_landuse_transitions.from_landuse_id</code> \u2192 <code>dim_landuse.landuse_id</code></li> <li><code>fact_landuse_transitions.to_landuse_id</code> \u2192 <code>dim_landuse.landuse_id</code></li> <li><code>fact_socioeconomic_projections.geography_id</code> \u2192 <code>dim_geography.geography_id</code></li> <li><code>fact_socioeconomic_projections.socioeconomic_id</code> \u2192 <code>dim_socioeconomic.socioeconomic_id</code></li> <li><code>fact_socioeconomic_projections.indicator_id</code> \u2192 <code>dim_indicators.indicator_id</code></li> </ul>"},{"location":"data/table-reference/#data-integrity","title":"Data Integrity","text":"<p>All foreign key relationships are enforced at the application level and validated during data loading. The star schema design ensures referential integrity and optimal query performance.</p>"},{"location":"data/table-reference/#usage-guidelines","title":"Usage Guidelines","text":"<ol> <li>Always filter dimension tables first to reduce the size of fact table joins</li> <li>Use appropriate indexes by including indexed columns in WHERE clauses</li> <li>Exclude validation rows with <code>WHERE transition_type != 'Total'</code> when applicable</li> <li>Consider using views for complex, frequently-used join patterns</li> <li>Aggregate before filtering when possible for better performance</li> </ol>"},{"location":"data/table-reference/#next-steps","title":"Next Steps","text":"<ul> <li>View Documentation: See View Definitions for pre-built analytical views</li> <li>Query Examples: See Advanced Queries for complex analysis patterns</li> <li>Performance Guide: See DuckDB Optimization for performance tuning</li> </ul>"},{"location":"data/technical-specifications/","title":"Technical Specifications","text":""},{"location":"data/technical-specifications/#database-technical-overview","title":"Database Technical Overview","text":"<p>The RPA Land Use Analytics database is implemented using DuckDB 0.11.0+ with optimized configuration for analytical workloads and large-scale time-series data processing.</p>"},{"location":"data/technical-specifications/#system-requirements","title":"System Requirements","text":""},{"location":"data/technical-specifications/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>Storage: 500 MB available disk space</li> <li>Memory: 1 GB RAM  </li> <li>CPU: Single core (any modern processor)</li> <li>OS: Windows 10+, macOS 10.14+, Linux (any recent distribution)</li> </ul>"},{"location":"data/technical-specifications/#recommended-requirements","title":"Recommended Requirements","text":"<ul> <li>Storage: 2 GB available disk space (for working files and indexes)</li> <li>Memory: 4 GB+ RAM for complex analytical queries</li> <li>CPU: Multi-core processor for parallel query execution</li> <li>OS: 64-bit operating system</li> </ul>"},{"location":"data/technical-specifications/#production-environment","title":"Production Environment","text":"<ul> <li>Storage: SSD recommended for optimal query performance</li> <li>Memory: 8-16 GB RAM for concurrent user access</li> <li>CPU: 4+ cores for optimal DuckDB parallel processing</li> <li>Network: High-bandwidth connection for web dashboard access</li> </ul>"},{"location":"data/technical-specifications/#database-configuration","title":"Database Configuration","text":""},{"location":"data/technical-specifications/#file-specifications","title":"File Specifications","text":"Property Value File Path <code>data/processed/landuse_analytics.duckdb</code> File Size 372 MB (390,070,272 bytes) Database Format DuckDB v0.11.0+ Encoding UTF-8 Compression Native DuckDB columnar compression Block Size 262,144 bytes (256 KB)"},{"location":"data/technical-specifications/#storage-utilization","title":"Storage Utilization","text":"Metric Value Percentage Total Blocks 1,487 100% Used Blocks 1,472 98.99% Free Blocks 15 1.01% WAL Size 0 bytes - Storage Efficiency Excellent 98.99%"},{"location":"data/technical-specifications/#memory-configuration","title":"Memory Configuration","text":"Setting Value Purpose Working Memory 512.0 KiB Query execution buffer Memory Limit 12.7 GiB Maximum memory usage Parallel Threads Auto-detected Concurrent query processing Enable Optimizer TRUE Query plan optimization"},{"location":"data/technical-specifications/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"data/technical-specifications/#query-performance-metrics","title":"Query Performance Metrics","text":"Query Type Typical Response Time Complexity Simple Lookups &lt; 1ms Single table, indexed columns Star Schema Joins 10-100ms Multi-table analytical queries Large Aggregations 100ms-1s Full table scans with grouping Cross-Scenario Analysis 1-5s Multiple scenario comparisons Complex Analytics 5-30s Advanced statistical computations"},{"location":"data/technical-specifications/#throughput-characteristics","title":"Throughput Characteristics","text":"Metric Value Records Scanned/sec 1M+ records Concurrent Queries 10-50 (read-only) Data Transfer Rate 100+ MB/sec Index Lookup Speed 10,000+ lookups/sec"},{"location":"data/technical-specifications/#scalability-limits","title":"Scalability Limits","text":"Dimension Current Maximum Supported Total Records 5.7M 100M+ Concurrent Users 10-20 100+ Query Complexity High Very High Database Size 372 MB 100+ GB"},{"location":"data/technical-specifications/#index-strategy-and-performance","title":"Index Strategy and Performance","text":""},{"location":"data/technical-specifications/#primary-indexes","title":"Primary Indexes","text":"Index Name Table Columns Type Purpose <code>pk_scenario</code> dim_scenario scenario_id Primary Key Scenario lookups <code>pk_geography</code> dim_geography geography_id Primary Key Geographic lookups <code>pk_time</code> dim_time time_id Primary Key Time period lookups <code>pk_landuse</code> dim_landuse landuse_id Primary Key Land use lookups <code>pk_socioeconomic</code> dim_socioeconomic socioeconomic_id Primary Key SSP lookups <code>pk_indicators</code> dim_indicators indicator_id Primary Key Indicator lookups"},{"location":"data/technical-specifications/#secondary-indexes","title":"Secondary Indexes","text":"Index Name Table Columns Selectivity Usage Pattern <code>idx_geography_fips</code> dim_geography fips_code High County identification <code>idx_geography_state</code> dim_geography state_name Medium State-level filtering <code>idx_landuse_code</code> dim_landuse landuse_code High Land use filtering <code>idx_scenario_name</code> dim_scenario scenario_name High Scenario identification <code>idx_time_range</code> dim_time year_range High Time period filtering"},{"location":"data/technical-specifications/#composite-indexes","title":"Composite Indexes","text":"Index Name Table Columns Cardinality Query Patterns <code>idx_fact_composite</code> fact_landuse_transitions scenario_id, time_id, geography_id High Multi-dimensional queries <code>idx_fact_landuse</code> fact_landuse_transitions from_landuse_id, to_landuse_id Medium Transition analysis <code>idx_fact_acres</code> fact_landuse_transitions acres Low Area-based filtering <code>idx_fact_transition_type</code> fact_landuse_transitions transition_type Very Low Change vs. same filtering <code>idx_socioeconomic_composite</code> fact_socioeconomic_projections geography_id, socioeconomic_id, indicator_id, year High Demographic queries"},{"location":"data/technical-specifications/#index-performance-characteristics","title":"Index Performance Characteristics","text":"Index Type Avg Lookup Time Memory Usage Maintenance Cost Primary Key &lt; 0.1ms Low Minimal Secondary &lt; 1ms Low-Medium Low Composite 1-5ms Medium Medium Covering 0.5-2ms Medium-High Medium-High"},{"location":"data/technical-specifications/#query-optimization","title":"Query Optimization","text":""},{"location":"data/technical-specifications/#duckdb-optimizer-features","title":"DuckDB Optimizer Features","text":"Feature Status Benefit Cost-Based Optimization Enabled Optimal join order selection Predicate Pushdown Enabled Early filtering Projection Pushdown Enabled Reduced data transfer Join Elimination Enabled Simplified query plans Constant Folding Enabled Compile-time optimization Statistics-Based Enabled Accurate cardinality estimates"},{"location":"data/technical-specifications/#recommended-query-patterns","title":"Recommended Query Patterns","text":""},{"location":"data/technical-specifications/#optimal-pattern","title":"Optimal Pattern","text":"<pre><code>-- Filter on indexed columns first, then join\nSELECT g.state_name, lu.landuse_name, SUM(f.acres)\nFROM fact_landuse_transitions f\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse lu ON f.to_landuse_id = lu.landuse_id\nWHERE \n    f.scenario_id = 1               -- Indexed filter\n    AND f.time_id IN (4, 5, 6)      -- Indexed filter\n    AND g.region = 'West'           -- Secondary filter\n    AND f.transition_type = 'change' -- Final filter\nGROUP BY g.state_name, lu.landuse_name;\n</code></pre>"},{"location":"data/technical-specifications/#anti-patterns-to-avoid","title":"Anti-Patterns to Avoid","text":"<pre><code>-- Avoid: Cartesian products\nSELECT * FROM fact_landuse_transitions f, dim_geography g;\n\n-- Avoid: Non-indexed function calls in WHERE\nSELECT * FROM fact_landuse_transitions \nWHERE UPPER(transition_type) = 'CHANGE';\n\n-- Avoid: Leading wildcards\nSELECT * FROM dim_geography WHERE county_name LIKE '%County';\n</code></pre>"},{"location":"data/technical-specifications/#query-execution-plans","title":"Query Execution Plans","text":"<p>DuckDB provides detailed execution plans for optimization:</p> <pre><code>-- Analyze query performance\nEXPLAIN ANALYZE \nSELECT g.state_name, SUM(f.acres)\nFROM fact_landuse_transitions f\nJOIN dim_geography g ON f.geography_id = g.geography_id\nWHERE f.scenario_id = 1\nGROUP BY g.state_name;\n</code></pre>"},{"location":"data/technical-specifications/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"data/technical-specifications/#backup-strategy","title":"Backup Strategy","text":"Backup Type Frequency Retention Method Full Database Daily 30 days File copy Incremental Not applicable - Static data Point-in-Time Not applicable - Read-only database"},{"location":"data/technical-specifications/#backup-implementation","title":"Backup Implementation","text":"<pre><code># Simple file-based backup\ncp data/processed/landuse_analytics.duckdb \\\n   backups/landuse_analytics_$(date +%Y%m%d).duckdb\n\n# Compressed backup\ntar -czf backups/landuse_analytics_$(date +%Y%m%d).tar.gz \\\n    data/processed/landuse_analytics.duckdb\n\n# Cloud backup (example)\naws s3 cp data/processed/landuse_analytics.duckdb \\\n    s3://bucket/backups/landuse_analytics_$(date +%Y%m%d).duckdb\n</code></pre>"},{"location":"data/technical-specifications/#recovery-procedures","title":"Recovery Procedures","text":"<pre><code># Restore from backup\ncp backups/landuse_analytics_20250126.duckdb \\\n   data/processed/landuse_analytics.duckdb\n\n# Verify database integrity\nduckdb data/processed/landuse_analytics.duckdb \\\n    \"SELECT COUNT(*) FROM fact_landuse_transitions;\"\n\n# Test basic functionality\nduckdb data/processed/landuse_analytics.duckdb \\\n    \"SELECT * FROM v_scenarios_combined LIMIT 1;\"\n</code></pre>"},{"location":"data/technical-specifications/#security-configuration","title":"Security Configuration","text":""},{"location":"data/technical-specifications/#access-control","title":"Access Control","text":"Level Configuration Implementation File System Read-only access OS permissions Database No authentication Single-user/read-only Application Environment variables API key management Network Local access only No remote connections"},{"location":"data/technical-specifications/#data-protection","title":"Data Protection","text":"Protection Type Implementation Purpose Encryption at Rest File system level Sensitive data protection Encryption in Transit HTTPS for web interface Network security Data Masking Not required Public/research data Audit Logging Application level Usage tracking"},{"location":"data/technical-specifications/#security-best-practices","title":"Security Best Practices","text":"<pre><code># Set appropriate file permissions\nchmod 644 data/processed/landuse_analytics.duckdb\n\n# Use environment variables for configuration\nexport DUCKDB_DATABASE_PATH=\"data/processed/landuse_analytics.duckdb\"\nexport DUCKDB_READ_ONLY=\"true\"\n\n# Application-level access control\nexport ANTHROPIC_API_KEY=\"your_key_here\"\nexport OPENAI_API_KEY=\"your_key_here\"\n</code></pre>"},{"location":"data/technical-specifications/#monitoring-and-diagnostics","title":"Monitoring and Diagnostics","text":""},{"location":"data/technical-specifications/#health-check-queries","title":"Health Check Queries","text":"<pre><code>-- Database connectivity\nSELECT 'Database Connected' as status;\n\n-- Data integrity check\nSELECT \n    COUNT(*) as total_transitions,\n    COUNT(DISTINCT scenario_id) as scenarios,\n    COUNT(DISTINCT geography_id) as counties,\n    MIN(created_at) as earliest_record,\n    MAX(created_at) as latest_record\nFROM fact_landuse_transitions;\n\n-- Performance baseline\nSELECT \n    table_name,\n    estimated_size as size_bytes,\n    column_count,\n    has_stats\nFROM duckdb_tables();\n</code></pre>"},{"location":"data/technical-specifications/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>-- Query performance profiling\nPRAGMA enable_profiling;\n-- Run query here\nPRAGMA disable_profiling;\n\n-- Table statistics\nSELECT table_name, \n       estimated_size, \n       has_stats \nFROM duckdb_tables() \nWHERE schema_name = 'main';\n\n-- Index usage statistics\nPRAGMA show_tables;\n</code></pre>"},{"location":"data/technical-specifications/#system-diagnostics","title":"System Diagnostics","text":"<pre><code>-- Memory usage\nPRAGMA memory_limit;\nPRAGMA threads;\n\n-- Database configuration\nPRAGMA table_info('fact_landuse_transitions');\n\n-- Storage statistics\nPRAGMA database_size;\n</code></pre>"},{"location":"data/technical-specifications/#integration-specifications","title":"Integration Specifications","text":""},{"location":"data/technical-specifications/#python-integration","title":"Python Integration","text":"<pre><code>import duckdb\nimport pandas as pd\n\n# Connection patterns\nconn = duckdb.connect('data/processed/landuse_analytics.duckdb', read_only=True)\n\n# Query execution\ndf = conn.execute(\"\"\"\n    SELECT * FROM v_scenarios_combined\n\"\"\").fetchdf()\n\n# Pandas integration\nresult = conn.execute(\"SELECT * FROM fact_landuse_transitions LIMIT 1000\")\ndf = result.df()\n\n# Resource management\nconn.close()\n</code></pre>"},{"location":"data/technical-specifications/#streamlit-integration","title":"Streamlit Integration","text":"<pre><code>import streamlit as st\nfrom src.landuse.connections.duckdb_connection import DuckDBConnection\n\n# Streamlit connection pattern\n@st.cache_data\ndef get_data(query: str):\n    conn = st.connection(\"duckdb\", type=DuckDBConnection)\n    return conn.query(query, ttl=3600)\n\n# Usage\ndata = get_data(\"SELECT * FROM v_scenarios_combined\")\n</code></pre>"},{"location":"data/technical-specifications/#api-integration","title":"API Integration","text":"<pre><code>from src.landuse.tools.common_tools import execute_landuse_query\n\n# Agent tool integration\nresult = execute_landuse_query(\n    query=\"SELECT * FROM dim_scenario\",\n    params={}\n)\n</code></pre>"},{"location":"data/technical-specifications/#deployment-configurations","title":"Deployment Configurations","text":""},{"location":"data/technical-specifications/#development-environment","title":"Development Environment","text":"<pre><code># Development configuration\ndatabase:\n  path: \"data/processed/landuse_analytics.duckdb\"\n  read_only: true\n  memory_limit: \"2GB\"\n  threads: 2\n\nlogging:\n  level: \"DEBUG\"\n  performance: true\n</code></pre>"},{"location":"data/technical-specifications/#production-environment_1","title":"Production Environment","text":"<pre><code># Production configuration\ndatabase:\n  path: \"/data/landuse_analytics.duckdb\"\n  read_only: true\n  memory_limit: \"8GB\"\n  threads: 4\n\ncaching:\n  enabled: true\n  ttl: 3600\n\nmonitoring:\n  enabled: true\n  health_check_interval: 300\n</code></pre>"},{"location":"data/technical-specifications/#cloud-deployment","title":"Cloud Deployment","text":"<pre><code># Cloud configuration\ndatabase:\n  path: \"s3://bucket/landuse_analytics.duckdb\"\n  read_only: true\n  memory_limit: \"16GB\"\n  threads: 8\n\nscaling:\n  auto_scaling: true\n  min_instances: 2\n  max_instances: 10\n</code></pre>"},{"location":"data/technical-specifications/#performance-tuning","title":"Performance Tuning","text":""},{"location":"data/technical-specifications/#memory-optimization","title":"Memory Optimization","text":"<pre><code>-- Set memory limit\nPRAGMA memory_limit='4GB';\n\n-- Enable memory monitoring\nPRAGMA enable_profiling='memory';\n\n-- Optimize for analytical workloads\nPRAGMA enable_object_cache;\n</code></pre>"},{"location":"data/technical-specifications/#query-optimization_1","title":"Query Optimization","text":"<pre><code>-- Update table statistics\nANALYZE fact_landuse_transitions;\nANALYZE dim_geography;\n\n-- Verify index usage\nEXPLAIN SELECT * FROM fact_landuse_transitions \nWHERE scenario_id = 1 AND geography_id = 100;\n</code></pre>"},{"location":"data/technical-specifications/#storage-optimization","title":"Storage Optimization","text":"<pre><code># Vacuum database (reclaim space)\nduckdb landuse_analytics.duckdb \"VACUUM;\"\n\n# Checkpoint WAL\nduckdb landuse_analytics.duckdb \"CHECKPOINT;\"\n</code></pre>"},{"location":"data/technical-specifications/#version-compatibility","title":"Version Compatibility","text":""},{"location":"data/technical-specifications/#duckdb-version-requirements","title":"DuckDB Version Requirements","text":"Component Minimum Version Recommended Notes DuckDB Core 0.9.0 0.11.0+ Core functionality Python Client 0.9.0 0.11.0+ Python integration CLI Tools 0.9.0 0.11.0+ Command line access"},{"location":"data/technical-specifications/#application-dependencies","title":"Application Dependencies","text":"Library Version Purpose pandas 1.5.0+ Data manipulation streamlit 1.40.0+ Web interface plotly 5.0.0+ Visualizations geopandas 0.14.0+ Spatial analysis"},{"location":"data/technical-specifications/#troubleshooting","title":"Troubleshooting","text":""},{"location":"data/technical-specifications/#common-issues","title":"Common Issues","text":"Issue Symptom Solution File Lock Error \"Database is locked\" Close all connections Memory Error \"Out of memory\" Increase memory limit Slow Queries High response time Check index usage Connection Failed Cannot connect Verify file path"},{"location":"data/technical-specifications/#diagnostic-commands","title":"Diagnostic Commands","text":"<pre><code># Test database connectivity\nduckdb data/processed/landuse_analytics.duckdb \"SELECT 1;\"\n\n# Check database integrity\nduckdb data/processed/landuse_analytics.duckdb \"PRAGMA integrity_check;\"\n\n# Verify table counts\nduckdb data/processed/landuse_analytics.duckdb \\\n    \"SELECT table_name, estimated_size FROM duckdb_tables();\"\n\n# Performance test\ntime duckdb data/processed/landuse_analytics.duckdb \\\n    \"SELECT COUNT(*) FROM fact_landuse_transitions;\"\n</code></pre>"},{"location":"data/technical-specifications/#next-steps","title":"Next Steps","text":"<ul> <li>Query Optimization: See DuckDB Optimization</li> <li>Application Integration: See API Reference</li> <li>Performance Guide: See Streamlit Fragments</li> <li>Monitoring Setup: See Development Guide</li> </ul>"},{"location":"data/variable-descriptions/","title":"Variable Descriptions","text":"<p>The following variables are found in the county land use projections data files.</p>"},{"location":"data/variable-descriptions/#rpa-scenario","title":"RPA Scenario","text":"<ul> <li>File: county_landuse_projections_RPA.*</li> <li>Units: Not applicable</li> <li>Precision: Not applicable</li> </ul> <p>RPA Scenarios are defined by Global Climate Model (GCM), Representative Concentration Pathway (RCP), and Shared Socioeconomic Pathway (SSP).</p>"},{"location":"data/variable-descriptions/#climate-models","title":"Climate Models:","text":"<ul> <li>CNRM_CM5: \"wet\" climate model</li> <li>HadGEM2_ES365: \"hot\" climate model</li> <li>IPSL_CM5A_MR: \"dry\" climate model</li> <li>MRI_CGCM3: \"least warm\" climate model</li> <li>NorESM1_M: \"middle\" climate model</li> </ul>"},{"location":"data/variable-descriptions/#rpa-scenario-combinations","title":"RPA Scenario Combinations:","text":"<ul> <li>rcp45_ssp1: Low emissions forcing, medium growth</li> <li>rcp85_ssp2: High emissions forcing, medium growth</li> <li>rcp85_ssp3: High emissions forcing, low growth</li> <li>rcp85_ssp5: High emissions forcing, high growth</li> </ul>"},{"location":"data/variable-descriptions/#time-step","title":"Time Step","text":"<ul> <li>File: county_landuse_projections_RPA.*</li> <li>Units: Years</li> <li>Precision: Integer</li> </ul> <p>Projections are made in 10-year time steps from 2020-2070. For completeness we have included an additional time step (2012-2020) that was used to calibrate the projections for use in subsequent modeling efforts as part of the 2020 RPA Assessment.</p>"},{"location":"data/variable-descriptions/#us-county-identifier","title":"U.S. County Identifier","text":"<ul> <li>File: county_landuse_projections_RPA.*</li> <li>Units: Not applicable</li> <li>Precision: Integer</li> </ul> <p>5 Digit FIPS (Federal Information Processing Standards) code.</p>"},{"location":"data/variable-descriptions/#6-x-6-transition-table","title":"[6 x 6 transition table]","text":"<ul> <li>File: county_landuse_projections_RPA.*</li> <li>Units: 100s of acres</li> <li>Precision: Double-Precision Floating-Point</li> </ul> <p>Area of land transitioned between land use categories: - cr: cropland - ps: pasture land - rg: rangeland - fr: forest land - ur: urban developed land - t1: total area of land in use category at starting year - t2: total area of land in use category at ending year </p>"},{"location":"data/view-definitions/","title":"View Definitions","text":""},{"location":"data/view-definitions/#overview","title":"Overview","text":"<p>The RPA Land Use Analytics database includes 4 pre-built analytical views that simplify common query patterns and provide optimized access to integrated data across multiple tables.</p> View Records Purpose <code>v_scenarios_combined</code> 20 Climate + socioeconomic scenario integration <code>v_landuse_socioeconomic</code> 5.4M Complete land use transitions with demographics <code>v_population_trends</code> 291,936 County population projections by scenario <code>v_income_trends</code> 291,936 County income projections by scenario"},{"location":"data/view-definitions/#scenario-integration-views","title":"Scenario Integration Views","text":""},{"location":"data/view-definitions/#v_scenarios_combined","title":"v_scenarios_combined","text":"<p>Purpose: Combines climate scenarios with socioeconomic scenarios to provide complete scenario context in a single view.</p> <p>Records: 20</p>"},{"location":"data/view-definitions/#view-definition","title":"View Definition","text":"<pre><code>CREATE VIEW v_scenarios_combined AS \nSELECT \n    s.scenario_id, \n    s.scenario_name AS climate_scenario, \n    s.climate_model, \n    s.rcp_scenario, \n    s.ssp_scenario, \n    se.scenario_name AS ssp_name, \n    se.narrative_description, \n    se.population_growth_trend, \n    se.economic_growth_trend, \n    se.urbanization_level \nFROM dim_scenario AS s \nLEFT JOIN dim_socioeconomic AS se ON (s.ssp_scenario = se.ssp_scenario);\n</code></pre>"},{"location":"data/view-definitions/#sample-output","title":"Sample Output","text":"<pre><code>SELECT * FROM v_scenarios_combined LIMIT 5;\n</code></pre> scenario_id climate_scenario climate_model rcp_scenario ssp_scenario ssp_name population_growth_trend economic_growth_trend urbanization_level 1 CNRM_CM5_rcp45_ssp1 CNRM_CM5 rcp45 ssp1 Sustainability Low Medium Moderate 2 CNRM_CM5_rcp85_ssp2 CNRM_CM5 rcp85 ssp2 Middle of the Road Medium Medium Moderate 3 CNRM_CM5_rcp85_ssp3 CNRM_CM5 rcp85 ssp3 Regional Rivalry High Low Slow 4 CNRM_CM5_rcp85_ssp5 CNRM_CM5 rcp85 ssp5 Fossil-fueled Development Low High Fast 5 HadGEM2_ES365_rcp45_ssp1 HadGEM2_ES365 rcp45 ssp1 Sustainability Low Medium Moderate"},{"location":"data/view-definitions/#use-cases","title":"Use Cases","text":"<ul> <li>Scenario Selection: Choose scenarios based on combined climate/socioeconomic characteristics</li> <li>Narrative Analysis: Understand the storyline behind each projection scenario</li> <li>Comparative Studies: Group scenarios by climate model or socioeconomic pathway</li> </ul>"},{"location":"data/view-definitions/#example-queries","title":"Example Queries","text":"<pre><code>-- Find all \"hot\" climate scenarios with high economic growth\nSELECT climate_scenario, ssp_name, economic_growth_trend\nFROM v_scenarios_combined\nWHERE climate_model = 'HadGEM2_ES365' \n  AND economic_growth_trend = 'High';\n\n-- Group scenarios by urbanization trend\nSELECT urbanization_level, \n       COUNT(*) as scenario_count,\n       STRING_AGG(climate_scenario, ', ') as scenarios\nFROM v_scenarios_combined\nGROUP BY urbanization_level;\n</code></pre>"},{"location":"data/view-definitions/#comprehensive-analysis-views","title":"Comprehensive Analysis Views","text":""},{"location":"data/view-definitions/#v_landuse_socioeconomic","title":"v_landuse_socioeconomic","text":"<p>Purpose: Comprehensive view combining land use transitions with full demographic and geographic context for integrated analysis.</p> <p>Records: 5,432,198 (all land use transitions)</p>"},{"location":"data/view-definitions/#view-definition_1","title":"View Definition","text":"<pre><code>CREATE VIEW v_landuse_socioeconomic AS \nSELECT \n    f.transition_id, \n    g.fips_code, \n    g.county_name, \n    g.state_name, \n    g.region, \n    s.scenario_name AS climate_scenario, \n    s.rcp_scenario, \n    s.ssp_scenario, \n    t.start_year, \n    t.end_year, \n    lu_from.landuse_name AS from_landuse, \n    lu_to.landuse_name AS to_landuse, \n    f.acres, \n    f.transition_type, \n    pop.population_thousands AS population_start, \n    inc.income_per_capita_2009usd AS income_start \nFROM fact_landuse_transitions AS f \nINNER JOIN dim_scenario AS s ON (f.scenario_id = s.scenario_id) \nINNER JOIN dim_time AS t ON (f.time_id = t.time_id) \nINNER JOIN dim_geography AS g ON (f.geography_id = g.geography_id) \nINNER JOIN dim_landuse AS lu_from ON (f.from_landuse_id = lu_from.landuse_id) \nINNER JOIN dim_landuse AS lu_to ON (f.to_landuse_id = lu_to.landuse_id) \nLEFT JOIN v_population_trends AS pop ON ((g.fips_code = pop.fips_code) \n    AND (s.ssp_scenario = pop.ssp_scenario) \n    AND (t.start_year = pop.year)) \nLEFT JOIN v_income_trends AS inc ON ((g.fips_code = inc.fips_code) \n    AND (s.ssp_scenario = inc.ssp_scenario) \n    AND (t.start_year = inc.year));\n</code></pre>"},{"location":"data/view-definitions/#sample-output_1","title":"Sample Output","text":"<pre><code>SELECT fips_code, county_name, state_name, climate_scenario, \n       from_landuse, to_landuse, acres, population_start, income_start\nFROM v_landuse_socioeconomic \nWHERE transition_type = 'change' \nLIMIT 5;\n</code></pre> fips_code county_name state_name climate_scenario from_landuse to_landuse acres population_start income_start 06037 Los Angeles County California CNRM_CM5_rcp45_ssp1 Forest Urban 125.32 9818.5 42.6 48201 Harris County Texas CNRM_CM5_rcp45_ssp1 Crop Urban 89.45 4092.4 41.2 12086 Miami-Dade County Florida CNRM_CM5_rcp45_ssp1 Pasture Urban 156.78 2496.4 35.8"},{"location":"data/view-definitions/#use-cases_1","title":"Use Cases","text":"<ul> <li>Integrated Analysis: Analyze land use changes in context of population and economic trends</li> <li>Policy Impact Studies: Understand how demographic pressures affect land use transitions</li> <li>Regional Comparisons: Compare land use patterns across different socioeconomic contexts</li> </ul>"},{"location":"data/view-definitions/#example-queries_1","title":"Example Queries","text":"<pre><code>-- Counties with highest population growth and urban expansion\nSELECT county_name, state_name, \n       SUM(acres) as urban_expansion,\n       AVG(population_start) as avg_population\nFROM v_landuse_socioeconomic\nWHERE to_landuse = 'Urban' \n  AND transition_type = 'change'\n  AND start_year = 2020\nGROUP BY county_name, state_name\nORDER BY urban_expansion DESC\nLIMIT 10;\n\n-- Correlation between income and agricultural land conversion\nSELECT \n    CASE WHEN income_start &lt; 30 THEN 'Low Income'\n         WHEN income_start &lt; 50 THEN 'Medium Income'\n         ELSE 'High Income' END as income_bracket,\n    SUM(CASE WHEN from_landuse IN ('Crop', 'Pasture') \n             AND to_landuse = 'Urban' THEN acres ELSE 0 END) as ag_to_urban\nFROM v_landuse_socioeconomic\nWHERE transition_type = 'change'\nGROUP BY income_bracket;\n</code></pre>"},{"location":"data/view-definitions/#demographic-trend-views","title":"Demographic Trend Views","text":""},{"location":"data/view-definitions/#v_population_trends","title":"v_population_trends","text":"<p>Purpose: County-level population projections across all SSP scenarios for demographic analysis.</p> <p>Records: 291,936</p>"},{"location":"data/view-definitions/#view-definition_2","title":"View Definition","text":"<pre><code>CREATE VIEW v_population_trends AS \nSELECT \n    g.fips_code, \n    g.county_name, \n    g.state_name, \n    g.region, \n    se.ssp_scenario, \n    se.scenario_name, \n    sp.year, \n    sp.value AS population_thousands, \n    sp.is_historical \nFROM fact_socioeconomic_projections AS sp \nINNER JOIN dim_geography AS g ON (sp.geography_id = g.geography_id) \nINNER JOIN dim_socioeconomic AS se ON (sp.socioeconomic_id = se.socioeconomic_id) \nINNER JOIN dim_indicators AS i ON (sp.indicator_id = i.indicator_id) \nWHERE (i.indicator_name = 'Population');\n</code></pre>"},{"location":"data/view-definitions/#sample-output_2","title":"Sample Output","text":"<pre><code>SELECT * FROM v_population_trends \nWHERE fips_code = '06037' AND ssp_scenario = 'ssp1'\nORDER BY year;\n</code></pre> fips_code county_name state_name region ssp_scenario scenario_name year population_thousands is_historical 06037 Los Angeles County California West ssp1 Sustainability 2010 9818.5 TRUE 06037 Los Angeles County California West ssp1 Sustainability 2020 10014.2 FALSE 06037 Los Angeles County California West ssp1 Sustainability 2030 10156.8 FALSE 06037 Los Angeles County California West ssp1 Sustainability 2040 10234.1 FALSE 06037 Los Angeles County California West ssp1 Sustainability 2050 10267.9 FALSE"},{"location":"data/view-definitions/#use-cases_2","title":"Use Cases","text":"<ul> <li>Demographic Planning: Understand population growth patterns by scenario</li> <li>Urban Planning: Project infrastructure needs based on population trends</li> <li>Regional Analysis: Compare population trajectories across different regions</li> </ul>"},{"location":"data/view-definitions/#example-queries_2","title":"Example Queries","text":"<pre><code>-- Fastest growing counties by scenario\nSELECT county_name, state_name, ssp_scenario,\n       MAX(population_thousands) - MIN(population_thousands) as growth\nFROM v_population_trends\nWHERE year BETWEEN 2020 AND 2050\nGROUP BY county_name, state_name, ssp_scenario\nORDER BY growth DESC\nLIMIT 10;\n\n-- Regional population distribution by scenario\nSELECT region, ssp_scenario, year,\n       SUM(population_thousands) as total_population\nFROM v_population_trends\nWHERE year IN (2020, 2030, 2040, 2050)\nGROUP BY region, ssp_scenario, year\nORDER BY region, ssp_scenario, year;\n</code></pre>"},{"location":"data/view-definitions/#v_income_trends","title":"v_income_trends","text":"<p>Purpose: County-level income per capita projections across all SSP scenarios for economic analysis.</p> <p>Records: 291,936</p>"},{"location":"data/view-definitions/#view-definition_3","title":"View Definition","text":"<pre><code>CREATE VIEW v_income_trends AS \nSELECT \n    g.fips_code, \n    g.county_name, \n    g.state_name, \n    g.region, \n    se.ssp_scenario, \n    se.scenario_name, \n    sp.year, \n    sp.value AS income_per_capita_2009usd, \n    sp.is_historical \nFROM fact_socioeconomic_projections AS sp \nINNER JOIN dim_geography AS g ON (sp.geography_id = g.geography_id) \nINNER JOIN dim_socioeconomic AS se ON (sp.socioeconomic_id = se.socioeconomic_id) \nINNER JOIN dim_indicators AS i ON (sp.indicator_id = i.indicator_id) \nWHERE (i.indicator_name = 'Income Per Capita');\n</code></pre>"},{"location":"data/view-definitions/#sample-output_3","title":"Sample Output","text":"<pre><code>SELECT * FROM v_income_trends \nWHERE fips_code = '06037' AND ssp_scenario = 'ssp5'\nORDER BY year;\n</code></pre> fips_code county_name state_name region ssp_scenario scenario_name year income_per_capita_2009usd is_historical 06037 Los Angeles County California West ssp5 Fossil-fueled Development 2010 42.6 TRUE 06037 Los Angeles County California West ssp5 Fossil-fueled Development 2020 48.2 FALSE 06037 Los Angeles County California West ssp5 Fossil-fueled Development 2030 55.8 FALSE 06037 Los Angeles County California West ssp5 Fossil-fueled Development 2040 64.1 FALSE 06037 Los Angeles County California West ssp5 Fossil-fueled Development 2050 73.9 FALSE"},{"location":"data/view-definitions/#use-cases_3","title":"Use Cases","text":"<ul> <li>Economic Planning: Understand income growth patterns across scenarios</li> <li>Development Analysis: Correlate economic growth with land use changes</li> <li>Regional Economics: Compare economic trajectories across regions</li> </ul>"},{"location":"data/view-definitions/#example-queries_3","title":"Example Queries","text":"<pre><code>-- Income inequality across scenarios\nSELECT ssp_scenario, year,\n       MAX(income_per_capita_2009usd) as max_income,\n       MIN(income_per_capita_2009usd) as min_income,\n       MAX(income_per_capita_2009usd) - MIN(income_per_capita_2009usd) as income_gap\nFROM v_income_trends\nWHERE year IN (2020, 2030, 2040, 2050)\nGROUP BY ssp_scenario, year\nORDER BY ssp_scenario, year;\n\n-- Economic growth rates by region\nSELECT region, ssp_scenario,\n       (MAX(income_per_capita_2009usd) - MIN(income_per_capita_2009usd)) / \n       MIN(income_per_capita_2009usd) * 100 as growth_rate_pct\nFROM v_income_trends\nWHERE year BETWEEN 2020 AND 2050\nGROUP BY region, ssp_scenario\nORDER BY region, growth_rate_pct DESC;\n</code></pre>"},{"location":"data/view-definitions/#performance-considerations","title":"Performance Considerations","text":""},{"location":"data/view-definitions/#query-optimization","title":"Query Optimization","text":"<p>All views are optimized for analytical queries with the following characteristics:</p> <ul> <li>Indexed Joins: All joins use indexed columns for optimal performance</li> <li>Minimal Computation: Complex calculations are performed at query time, not in views</li> <li>Selective Filtering: Views include the most commonly filtered columns</li> </ul>"},{"location":"data/view-definitions/#best-practices","title":"Best Practices","text":"<ol> <li>Filter Early: Apply WHERE clauses on geographic or scenario columns first</li> <li>Use Appropriate Views: Choose the most specific view for your analysis needs</li> <li>Aggregate Wisely: Group by dimensions before calculating complex metrics</li> <li>Limit Results: Use LIMIT clauses for exploratory queries</li> </ol>"},{"location":"data/view-definitions/#example-optimized-query-pattern","title":"Example Optimized Query Pattern","text":"<pre><code>-- Efficient pattern: filter on indexed columns first, then aggregate\nSELECT \n    region,\n    ssp_scenario,\n    AVG(population_thousands) as avg_population,\n    SUM(acres) as total_urban_expansion\nFROM v_landuse_socioeconomic\nWHERE \n    region = 'West'                    -- Geographic filter (indexed)\n    AND ssp_scenario = 'ssp1'          -- Scenario filter (indexed)  \n    AND to_landuse = 'Urban'           -- Land use filter\n    AND transition_type = 'change'     -- Transition filter\n    AND start_year &gt;= 2020             -- Time filter\nGROUP BY region, ssp_scenario;\n</code></pre>"},{"location":"data/view-definitions/#cross-view-analysis","title":"Cross-View Analysis","text":""},{"location":"data/view-definitions/#combining-multiple-views","title":"Combining Multiple Views","text":"<p>Views can be combined for complex analytical queries:</p> <pre><code>-- Population growth vs. agricultural land loss\nWITH pop_growth AS (\n    SELECT fips_code, ssp_scenario,\n           MAX(population_thousands) - MIN(population_thousands) as growth\n    FROM v_population_trends\n    WHERE year BETWEEN 2020 AND 2050\n    GROUP BY fips_code, ssp_scenario\n),\nag_loss AS (\n    SELECT fips_code, ssp_scenario,\n           SUM(acres) as agricultural_loss\n    FROM v_landuse_socioeconomic\n    WHERE from_landuse IN ('Crop', 'Pasture')\n      AND to_landuse = 'Urban'\n      AND transition_type = 'change'\n    GROUP BY fips_code, ssp_scenario\n)\nSELECT p.fips_code, p.ssp_scenario, p.growth, a.agricultural_loss,\n       a.agricultural_loss / p.growth as loss_per_capita\nFROM pop_growth p\nJOIN ag_loss a ON p.fips_code = a.fips_code AND p.ssp_scenario = a.ssp_scenario\nWHERE p.growth &gt; 0\nORDER BY loss_per_capita DESC;\n</code></pre>"},{"location":"data/view-definitions/#maintenance-and-updates","title":"Maintenance and Updates","text":""},{"location":"data/view-definitions/#view-dependencies","title":"View Dependencies","text":"<p>Views are automatically updated when underlying tables change. The dependency chain is:</p> <ol> <li>Base Tables: fact and dimension tables</li> <li>Simple Views: v_population_trends, v_income_trends, v_scenarios_combined  </li> <li>Complex Views: v_landuse_socioeconomic (depends on simple views)</li> </ol>"},{"location":"data/view-definitions/#performance-monitoring","title":"Performance Monitoring","text":"<p>Monitor view performance using DuckDB's query profiling:</p> <pre><code>-- Profile a view query\nPRAGMA enable_profiling;\nSELECT * FROM v_landuse_socioeconomic WHERE region = 'West' LIMIT 1000;\nPRAGMA disable_profiling;\n</code></pre>"},{"location":"data/view-definitions/#next-steps","title":"Next Steps","text":"<ul> <li>Advanced Analysis: See Advanced Queries for complex analytical patterns</li> <li>Table Details: See Table Reference for underlying table specifications</li> <li>Performance Tuning: See DuckDB Optimization for query optimization techniques</li> </ul>"},{"location":"development/BRANDING_STRATEGY/","title":"RPA Land Use Analytics - Branding Strategy","text":""},{"location":"development/BRANDING_STRATEGY/#project-name","title":"Project Name","text":"<p>RPA Land Use Analytics An AI-powered analysis tool for USDA Forest Service RPA Assessment data</p>"},{"location":"development/BRANDING_STRATEGY/#branding-elements","title":"Branding Elements","text":""},{"location":"development/BRANDING_STRATEGY/#primary-name-options","title":"Primary Name Options","text":"<ol> <li>RPA Land Use Analytics (Recommended)</li> <li>Clear connection to RPA Assessment</li> <li>Descriptive of functionality</li> <li> <p>Professional and government-appropriate</p> </li> <li> <p>RPA Assessment Explorer</p> </li> <li>Emphasizes exploration capabilities</li> <li> <p>Direct tie to source data</p> </li> <li> <p>Forest &amp; Rangeland Analytics</p> </li> <li>Broader appeal</li> <li>Matches RPA Assessment subtitle</li> </ol>"},{"location":"development/BRANDING_STRATEGY/#tagline","title":"Tagline","text":"<p>\"Transforming America's land use data into actionable insights\"</p>"},{"location":"development/BRANDING_STRATEGY/#visual-identity","title":"Visual Identity","text":""},{"location":"development/BRANDING_STRATEGY/#color-palette","title":"Color Palette","text":"<p>Based on USDA Forest Service branding: - Primary Green: #2E7D32 (Forest green) - Secondary Blue: #1976D2 (Sky blue for water resources) - Accent Brown: #6D4C41 (Earth/soil tone) - Neutral Gray: #424242 (Text and UI elements) - Background: #FAFAFA (Light gray/white)</p>"},{"location":"development/BRANDING_STRATEGY/#typography","title":"Typography","text":"<ul> <li>Headers: Inter or Roboto (clean, modern, accessible)</li> <li>Body: Open Sans or Source Sans Pro</li> <li>Monospace: Fira Code or JetBrains Mono (for code/queries)</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#logo-concept","title":"Logo Concept","text":"<ul> <li>Simple tree/forest icon combined with data visualization elements</li> <li>Could incorporate chart bars growing like trees</li> <li>Keep it minimal and professional for government context</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#implementation-areas","title":"Implementation Areas","text":""},{"location":"development/BRANDING_STRATEGY/#1-streamlit-dashboard","title":"1. Streamlit Dashboard","text":"<ul> <li>Custom theme with brand colors</li> <li>Header with logo and project name</li> <li>Consistent color use in charts (Plotly)</li> <li>Professional sidebar styling</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#2-command-line-interface","title":"2. Command Line Interface","text":"<ul> <li>ASCII art logo for terminal</li> <li>Colored output matching brand palette (using Rich)</li> <li>Consistent header/footer branding</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#3-documentation","title":"3. Documentation","text":"<ul> <li>README with branded header</li> <li>Consistent use of project name</li> <li>Professional screenshots with branding visible</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#4-code-structure","title":"4. Code Structure","text":"<ul> <li>Update package name from <code>landuse</code> to <code>rpa_landuse</code></li> <li>Consistent module naming</li> <li>Clear attribution to USDA Forest Service data</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#key-messages","title":"Key Messages","text":""},{"location":"development/BRANDING_STRATEGY/#for-users","title":"For Users","text":"<ul> <li>\"Official analytics tool for RPA Assessment data\"</li> <li>\"Ask questions in plain English, get data-driven answers\"</li> <li>\"Explore 50-year projections across climate scenarios\"</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#technical-positioning","title":"Technical Positioning","text":"<ul> <li>Built on modern data stack (DuckDB, LangChain)</li> <li>AI-powered natural language interface</li> <li>Open source and extensible</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#attribution-requirements","title":"Attribution Requirements","text":"<p>Always include: - \"Data source: USDA Forest Service 2020 RPA Assessment\" - Link to official RPA Assessment: https://www.fs.usda.gov/research/rpa - Proper citations per RPA documentation</p>"},{"location":"development/BRANDING_STRATEGY/#next-steps","title":"Next Steps","text":"<ol> <li>Update pyproject.toml with new name</li> <li>Create logo assets</li> <li>Implement Streamlit custom theme</li> <li>Update CLI with Rich formatting</li> <li>Revise all documentation</li> </ol>"},{"location":"development/architecture/","title":"System Architecture","text":"<p>Understanding the technical architecture of the LangChain Land Use Analysis system.</p>"},{"location":"development/architecture/#overview","title":"Overview","text":"<p>The system follows a modular architecture that separates data processing, storage, and natural language interaction into distinct layers.</p> <pre><code>graph TB\n    subgraph \"User Interface\"\n        CLI[CLI Interface]\n        API[Python API]\n    end\n\n    subgraph \"LangChain Layer\"\n        Agent[Data Engineering Agent]\n        Memory[Conversation Memory]\n        Tools[Tool Collection]\n    end\n\n    subgraph \"Processing Layer\"\n        Converters[Data Converters]\n        Validators[Data Validators]\n        Optimizers[Query Optimizers]\n    end\n\n    subgraph \"Data Layer\"\n        JSON[JSON Files]\n        SQLite[SQLite Databases]\n        Parquet[Parquet Files]\n    end\n\n    CLI --&gt; Agent\n    API --&gt; Agent\n    Agent --&gt; Memory\n    Agent --&gt; Tools\n    Tools --&gt; Converters\n    Tools --&gt; Validators\n    Tools --&gt; Optimizers\n    Converters --&gt; JSON\n    Converters --&gt; SQLite\n    Tools --&gt; SQLite\n    Tools --&gt; Parquet</code></pre>"},{"location":"development/architecture/#component-architecture","title":"Component Architecture","text":""},{"location":"development/architecture/#1-user-interface-layer","title":"1. User Interface Layer","text":"<p>CLI Interface (<code>test_agent.py</code>) - Rich terminal UI - Interactive chat loop - Progress indicators - Syntax highlighting</p> <p>Python API - Programmatic access - Batch processing - Integration points</p>"},{"location":"development/architecture/#2-langchain-layer","title":"2. LangChain Layer","text":"<p>Data Engineering Agent <pre><code>class DataEngineeringAgent:\n    def __init__(self, root_dir: str = None):\n        self.llm = ChatOpenAI(...)\n        self.memory = MemorySaver()\n        self.tools = self._create_tools()\n        self.agent = self._create_agent()\n</code></pre></p> <p>Key Components: - LLM Integration: OpenAI GPT models - Memory System: Conversation context retention - Tool Registry: Dynamic tool loading - Prompt Engineering: Structured prompts</p>"},{"location":"development/architecture/#3-tool-system","title":"3. Tool System","text":"<p>Tool Architecture: <pre><code>Tool(\n    name=\"tool_name\",\n    func=implementation_function,\n    description=\"Natural language description\",\n    args_schema=PydanticModel  # Optional\n)\n</code></pre></p> <p>Tool Categories: - File Operations - Data Analysis - SQL Execution - Format Conversion - Visualization</p>"},{"location":"development/architecture/#4-data-processing-layer","title":"4. Data Processing Layer","text":"<p>Converter Pipeline: <pre><code>Raw JSON \u2192 Parser \u2192 Transformer \u2192 Validator \u2192 Database\n</code></pre></p> <p>Processing Steps: 1. Parsing: Extract nested JSON structure 2. Transformation: Normalize to relational format 3. Aggregation: Create derived views 4. Optimization: Add indexes and statistics</p>"},{"location":"development/architecture/#5-storage-layer","title":"5. Storage Layer","text":"<p>Database Design: <pre><code>-- Core tables\nlanduse_transitions\nlanduse_transitions_ag\n\n-- Filtered views\nlanduse_changes_only\nlanduse_changes_only_ag\n\n-- Indexes for performance\nidx_scenario, idx_year, idx_fips\n</code></pre></p>"},{"location":"development/architecture/#data-flow-architecture","title":"Data Flow Architecture","text":""},{"location":"development/architecture/#query-processing-flow","title":"Query Processing Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Agent\n    participant LLM\n    participant Tools\n    participant Database\n\n    User-&gt;&gt;Agent: Natural language query\n    Agent-&gt;&gt;LLM: Parse intent\n    LLM-&gt;&gt;Agent: Structured request\n    Agent-&gt;&gt;Tools: Execute tool\n    Tools-&gt;&gt;Database: SQL query\n    Database-&gt;&gt;Tools: Results\n    Tools-&gt;&gt;Agent: Formatted data\n    Agent-&gt;&gt;User: Natural language response</code></pre>"},{"location":"development/architecture/#memory-architecture","title":"Memory Architecture","text":"<p>The agent uses LangGraph's MemorySaver for context:</p> <pre><code># Memory stores:\n- Conversation history\n- Previous query results\n- User preferences\n- Context markers\n</code></pre>"},{"location":"development/architecture/#technical-stack","title":"Technical Stack","text":""},{"location":"development/architecture/#core-dependencies","title":"Core Dependencies","text":"Component Technology Purpose LLM Framework LangChain 0.3+ Agent orchestration LLM Provider OpenAI GPT-4 Natural language understanding Database SQLite 3 Local data storage Query Engine DuckDB SQL on files Data Processing Pandas 2.2+ Data manipulation CLI Rich 14+ Terminal interface Validation Pydantic 2+ Data validation"},{"location":"development/architecture/#file-processing-stack","title":"File Processing Stack","text":"<pre><code># JSON Processing\n- ijson: Streaming large files\n- json: Standard library\n\n# Tabular Data\n- pandas: DataFrames\n- pyarrow: Parquet support\n- openpyxl: Excel files\n\n# Geospatial\n- geopandas: Spatial data\n- Parquet: GeoParquet format\n</code></pre>"},{"location":"development/architecture/#security-architecture","title":"Security Architecture","text":""},{"location":"development/architecture/#api-key-management","title":"API Key Management","text":"<pre><code># Environment-based configuration\nload_dotenv(dotenv_path=\"config/.env\")\n\n# Never in code\napi_key = os.getenv(\"OPENAI_API_KEY\")\n</code></pre>"},{"location":"development/architecture/#file-access-control","title":"File Access Control","text":"<pre><code># Restricted to root directory\nself.root_dir = root_dir or \"./data\"\n\n# Path validation\nfull_path = Path(self.root_dir) / file_path\nif not full_path.resolve().is_relative_to(self.root_dir):\n    raise SecurityError(\"Path traversal detected\")\n</code></pre>"},{"location":"development/architecture/#query-safety","title":"Query Safety","text":"<ul> <li>SQL injection prevention via parameterization</li> <li>File path sanitization</li> <li>Size limits on operations</li> </ul>"},{"location":"development/architecture/#performance-architecture","title":"Performance Architecture","text":""},{"location":"development/architecture/#optimization-strategies","title":"Optimization Strategies","text":"<ol> <li>Query Optimization</li> <li>Index usage</li> <li>Query plan analysis</li> <li> <p>Result limiting</p> </li> <li> <p>Memory Management</p> </li> <li>Streaming for large files</li> <li>Chunk processing</li> <li> <p>Garbage collection</p> </li> <li> <p>Caching</p> </li> <li>15-minute web fetch cache</li> <li>Query result caching</li> <li>Schema caching</li> </ol>"},{"location":"development/architecture/#scalability-considerations","title":"Scalability Considerations","text":"<pre><code># Chunked processing\nCHUNK_SIZE = 10000\n\n# Parallel processing potential\nfrom concurrent.futures import ThreadPoolExecutor\n\n# Database partitioning\n# Could partition by year or scenario\n</code></pre>"},{"location":"development/architecture/#extension-architecture","title":"Extension Architecture","text":""},{"location":"development/architecture/#adding-new-tools","title":"Adding New Tools","text":"<pre><code>class CustomAgent(DataEngineeringAgent):\n    def _create_tools(self):\n        tools = super()._create_tools()\n        tools.append(self._create_custom_tool())\n        return tools\n\n    def _create_custom_tool(self):\n        return Tool(\n            name=\"custom_tool\",\n            func=self._custom_implementation,\n            description=\"Custom functionality\"\n        )\n</code></pre>"},{"location":"development/architecture/#plugin-system-potential","title":"Plugin System Potential","text":"<pre><code># Future: Dynamic tool loading\ndef load_tools_from_plugins():\n    plugin_dir = Path(\"plugins\")\n    for plugin_file in plugin_dir.glob(\"*.py\"):\n        module = import_module(plugin_file.stem)\n        if hasattr(module, \"create_tools\"):\n            tools.extend(module.create_tools())\n</code></pre>"},{"location":"development/architecture/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"development/architecture/#local-deployment","title":"Local Deployment","text":"<pre><code># Current: Single-user local\npython scripts/agents/test_agent.py\n</code></pre>"},{"location":"development/architecture/#server-deployment-potential","title":"Server Deployment Potential","text":"<pre><code># Future: Multi-user server\nfrom fastapi import FastAPI\nfrom celery import Celery\n\napp = FastAPI()\ncelery = Celery()\n\n@app.post(\"/query\")\nasync def query(request: QueryRequest):\n    task = celery.send_task(\"process_query\", args=[request])\n    return {\"task_id\": task.id}\n</code></pre>"},{"location":"development/architecture/#container-architecture","title":"Container Architecture","text":"<pre><code># Potential Dockerfile\nFROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY . .\nCMD [\"python\", \"scripts/agents/test_agent.py\"]\n</code></pre>"},{"location":"development/architecture/#monitoring-architecture","title":"Monitoring Architecture","text":""},{"location":"development/architecture/#logging-structure","title":"Logging Structure","text":"<pre><code>import logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('agent.log'),\n        logging.StreamHandler()\n    ]\n)\n</code></pre>"},{"location":"development/architecture/#metrics-collection","title":"Metrics Collection","text":"<pre><code># Future: Metrics tracking\nmetrics = {\n    \"queries_processed\": Counter(),\n    \"query_duration\": Histogram(),\n    \"tool_usage\": Counter(),\n    \"error_rate\": Rate()\n}\n</code></pre>"},{"location":"development/architecture/#health-checks","title":"Health Checks","text":"<pre><code>def health_check():\n    checks = {\n        \"database\": check_database_connection(),\n        \"llm\": check_llm_availability(),\n        \"disk_space\": check_disk_space(),\n        \"memory\": check_memory_usage()\n    }\n    return all(checks.values())\n</code></pre>"},{"location":"development/architecture/#error-handling-architecture","title":"Error Handling Architecture","text":""},{"location":"development/architecture/#layered-error-handling","title":"Layered Error Handling","text":"<pre><code># Level 1: Tool-level errors\ntry:\n    result = execute_tool()\nexcept SpecificError as e:\n    return handle_specific_error(e)\n\n# Level 2: Agent-level errors\ntry:\n    response = agent.run(query)\nexcept AgentError as e:\n    return fallback_response(e)\n\n# Level 3: System-level errors\ntry:\n    start_system()\nexcept SystemError as e:\n    log_and_alert(e)\n</code></pre>"},{"location":"development/architecture/#testing-architecture","title":"Testing Architecture","text":""},{"location":"development/architecture/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/\n\u2502   \u251c\u2500\u2500 test_converters.py\n\u2502   \u251c\u2500\u2500 test_tools.py\n\u2502   \u2514\u2500\u2500 test_agent.py\n\u251c\u2500\u2500 integration/\n\u2502   \u251c\u2500\u2500 test_database_queries.py\n\u2502   \u2514\u2500\u2500 test_full_pipeline.py\n\u2514\u2500\u2500 e2e/\n    \u2514\u2500\u2500 test_user_workflows.py\n</code></pre>"},{"location":"development/architecture/#test-data-management","title":"Test Data Management","text":"<pre><code># Fixtures for testing\n@pytest.fixture\ndef sample_database():\n    # Create test database\n    return test_db_path\n\n@pytest.fixture\ndef mock_llm():\n    # Mock LLM responses\n    return MockLLM()\n</code></pre>"},{"location":"development/architecture/#future-architecture-considerations","title":"Future Architecture Considerations","text":""},{"location":"development/architecture/#microservices-potential","title":"Microservices Potential","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Query     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Agent     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502    Data     \u2502\n\u2502  Service    \u2502     \u2502  Service    \u2502     \u2502  Service    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"development/architecture/#event-driven-architecture","title":"Event-Driven Architecture","text":"<pre><code># Future: Event-based processing\nclass EventBus:\n    def publish(self, event: Event):\n        for handler in self.handlers[event.type]:\n            handler.handle(event)\n\n# Query events, completion events, error events\n</code></pre>"},{"location":"development/architecture/#multi-model-support","title":"Multi-Model Support","text":"<pre><code># Future: Multiple LLM providers\nclass ModelRouter:\n    def route_query(self, query):\n        if is_complex_sql(query):\n            return self.gpt4_model\n        else:\n            return self.gpt35_model\n</code></pre>"},{"location":"development/architecture/#best-practices","title":"Best Practices","text":"<ol> <li>Separation of Concerns</li> <li>Keep data processing separate from UI</li> <li>Isolate LLM interactions</li> <li> <p>Modular tool design</p> </li> <li> <p>Error Boundaries</p> </li> <li>Handle errors at appropriate levels</li> <li>Provide meaningful feedback</li> <li> <p>Graceful degradation</p> </li> <li> <p>Performance First</p> </li> <li>Design for large datasets</li> <li>Optimize critical paths</li> <li> <p>Monitor resource usage</p> </li> <li> <p>Extensibility</p> </li> <li>Plugin-friendly architecture</li> <li>Clear extension points</li> <li>Documented interfaces</li> </ol>"},{"location":"development/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Review Contributing Guide for development</li> <li>See Testing Guide for quality assurance</li> <li>Check API Reference for implementation details</li> </ul>"},{"location":"development/ci-cd-pipeline/","title":"CI/CD Pipeline Documentation","text":"<p>This document describes the comprehensive CI/CD pipeline implemented for the landuse project using GitHub Actions.</p>"},{"location":"development/ci-cd-pipeline/#overview","title":"Overview","text":"<p>The CI/CD pipeline provides automated testing, security scanning, performance monitoring, documentation building, and release management. It ensures code quality, security, and reliability while enabling rapid development and deployment.</p>"},{"location":"development/ci-cd-pipeline/#pipeline-components","title":"Pipeline Components","text":""},{"location":"development/ci-cd-pipeline/#1-continuous-integration-ciyml","title":"1. Continuous Integration (<code>ci.yml</code>)","text":"<p>Triggers: - Push to <code>main</code> or <code>develop</code> branches - Pull requests to <code>main</code> or <code>develop</code> branches</p> <p>Matrix Testing: - Python 3.11 and 3.12 - Ubuntu Linux environment</p> <p>Steps: 1. Environment Setup    - Checkout code    - Install Python and uv    - Cache dependencies for faster builds    - Install project dependencies</p> <ol> <li>Code Quality Checks</li> <li>Linting: <code>ruff check</code> for code style and potential issues</li> <li> <p>Type Checking: <code>mypy</code> for static type analysis</p> </li> <li> <p>Testing</p> </li> <li>Unit and integration tests with <code>pytest</code></li> <li>Code coverage analysis with minimum 50% threshold</li> <li> <p>Test result artifacts and coverage reports</p> </li> <li> <p>Artifacts</p> </li> <li>Coverage reports (HTML and XML)</li> <li>Security scan results</li> <li>Test artifacts</li> </ol>"},{"location":"development/ci-cd-pipeline/#2-security-scanning-securityyml","title":"2. Security Scanning (<code>security.yml</code>)","text":"<p>Triggers: - Push to <code>main</code> or <code>develop</code> branches - Pull requests to <code>main</code> or <code>develop</code> branches - Daily scheduled scans at 2 AM UTC</p> <p>Security Checks:</p>"},{"location":"development/ci-cd-pipeline/#dependency-scanning","title":"Dependency Scanning","text":"<ul> <li>Safety: Check for known vulnerabilities in dependencies</li> <li>pip-audit: Additional vulnerability scanning</li> <li>Reports generated in JSON format</li> </ul>"},{"location":"development/ci-cd-pipeline/#code-analysis","title":"Code Analysis","text":"<ul> <li>Bandit: Python security linter for common security issues</li> <li>Semgrep: Advanced static analysis with security rules</li> <li>SARIF output for GitHub Security tab integration</li> </ul>"},{"location":"development/ci-cd-pipeline/#secrets-detection","title":"Secrets Detection","text":"<ul> <li>TruffleHog: Scan for committed secrets and credentials</li> <li>Verified secrets detection only</li> </ul>"},{"location":"development/ci-cd-pipeline/#license-compliance","title":"License Compliance","text":"<ul> <li>pip-licenses: Check dependency licenses</li> <li>Alert on GPL licenses that might conflict with MIT</li> <li>Generate license compatibility reports</li> </ul>"},{"location":"development/ci-cd-pipeline/#3-performance-testing-performanceyml","title":"3. Performance Testing (<code>performance.yml</code>)","text":"<p>Triggers: - Push to <code>main</code> or <code>develop</code> branches - Pull requests to <code>main</code> or <code>develop</code> branches - Weekly scheduled runs on Sundays at 3 AM UTC</p> <p>Performance Tests:</p>"},{"location":"development/ci-cd-pipeline/#duckdb-benchmarking","title":"DuckDB Benchmarking","text":"<ul> <li>Bulk loading performance tests</li> <li>Traditional INSERT vs COPY command comparison</li> <li>Performance regression detection</li> <li>Detailed timing and throughput metrics</li> </ul>"},{"location":"development/ci-cd-pipeline/#memory-profiling","title":"Memory Profiling","text":"<ul> <li>Memory usage analysis with <code>memory-profiler</code></li> <li>Bulk loading memory consumption</li> <li>Connection pooling memory efficiency</li> </ul>"},{"location":"development/ci-cd-pipeline/#load-testing","title":"Load Testing","text":"<ul> <li>Concurrent query simulation</li> <li>Response time analysis</li> <li>Performance threshold monitoring</li> <li>Regression detection and alerting</li> </ul>"},{"location":"development/ci-cd-pipeline/#4-documentation-documentationyml","title":"4. Documentation (<code>documentation.yml</code>)","text":"<p>Triggers: - Push to <code>main</code> branch (docs changes) - Pull requests affecting documentation - Changes to <code>docs/</code>, <code>mkdocs.yml</code>, <code>README.md</code>, or <code>CLAUDE.md</code></p> <p>Documentation Workflow:</p>"},{"location":"development/ci-cd-pipeline/#build-and-deploy","title":"Build and Deploy","text":"<ul> <li>MkDocs Build: Generate static documentation site</li> <li>Link Checking: Validate internal and external links</li> <li>GitHub Pages: Automatic deployment to GitHub Pages</li> </ul>"},{"location":"development/ci-cd-pipeline/#quality-assessment","title":"Quality Assessment","text":"<ul> <li>Readability Analysis: Flesch reading ease scores</li> <li>Writing Quality: Grammar and style checking</li> <li>Issue Detection: Find TODO items and broken links</li> <li>PR Comments: Automated quality reports on pull requests</li> </ul>"},{"location":"development/ci-cd-pipeline/#5-release-management-releaseyml","title":"5. Release Management (<code>release.yml</code>)","text":"<p>Triggers: - Git tags starting with <code>v</code> (e.g., <code>v1.0.0</code>) - Manual workflow dispatch with version input</p> <p>Release Process:</p>"},{"location":"development/ci-cd-pipeline/#pre-release-testing","title":"Pre-Release Testing","text":"<ul> <li>Full test suite execution</li> <li>Minimum 70% code coverage requirement</li> <li>All quality checks must pass</li> </ul>"},{"location":"development/ci-cd-pipeline/#build-artifacts","title":"Build Artifacts","text":"<ul> <li>Python Package: Build wheel and source distribution</li> <li>Documentation: Generate complete documentation site</li> <li>Artifacts: Upload all build outputs</li> </ul>"},{"location":"development/ci-cd-pipeline/#release-creation","title":"Release Creation","text":"<ul> <li>GitHub Release: Automatic release creation</li> <li>Changelog: Extract relevant changelog sections</li> <li>Assets: Attach wheel and source distribution</li> <li>Pre-release Detection: Automatic detection of alpha/beta/rc versions</li> </ul>"},{"location":"development/ci-cd-pipeline/#configuration-files","title":"Configuration Files","text":""},{"location":"development/ci-cd-pipeline/#1-dependabot-dependabotyml","title":"1. Dependabot (<code>dependabot.yml</code>)","text":"<p>Automated Dependency Management: - Python Dependencies: Weekly updates on Mondays - GitHub Actions: Weekly updates on Mondays - PR Limits: 10 for Python, 5 for Actions - Automatic Labels: Dependencies and language tags - Team Assignment: Auto-assign to landuse-team</p>"},{"location":"development/ci-cd-pipeline/#2-issue-templates","title":"2. Issue Templates","text":""},{"location":"development/ci-cd-pipeline/#bug-report-bug_reportyml","title":"Bug Report (<code>bug_report.yml</code>)","text":"<ul> <li>Structured bug reporting form</li> <li>Environment and reproduction details</li> <li>Component and severity classification</li> <li>Contact information and additional context</li> </ul>"},{"location":"development/ci-cd-pipeline/#feature-request-feature_requestyml","title":"Feature Request (<code>feature_request.yml</code>)","text":"<ul> <li>Feature suggestion template</li> <li>Problem description and proposed solution</li> <li>Use case documentation</li> <li>Implementation ideas and contribution offers</li> </ul>"},{"location":"development/ci-cd-pipeline/#3-pull-request-template-pull_request_templatemd","title":"3. Pull Request Template (<code>pull_request_template.md</code>)","text":"<p>Comprehensive PR Checklist: - Change type classification - Related issues linking - Testing requirements - Documentation updates - Performance and security considerations - Review guidance and focus areas</p>"},{"location":"development/ci-cd-pipeline/#environment-configuration","title":"Environment Configuration","text":""},{"location":"development/ci-cd-pipeline/#required-environment-variables","title":"Required Environment Variables","text":"<p>Basic Configuration: <pre><code>LANDUSE_MODEL=gpt-4o-mini\nTEMPERATURE=0.1\nMAX_TOKENS=1000\n</code></pre></p> <p>CI-Specific Variables: <pre><code># Test environment\nLANDUSE_DB_PATH=data/processed/landuse_analytics.duckdb\nLANDUSE_MAX_QUERY_ROWS=1000\nLANDUSE_DEFAULT_DISPLAY_LIMIT=50\n</code></pre></p>"},{"location":"development/ci-cd-pipeline/#secrets-management","title":"Secrets Management","text":"<p>Required GitHub Secrets: - <code>GITHUB_TOKEN</code>: Automatic token for releases and actions - <code>CODECOV_TOKEN</code>: For coverage report uploads (optional)</p> <p>API Keys (for integration tests): - API keys should be stored as GitHub secrets - Use minimal permissions and test-specific keys - Rotate keys regularly</p>"},{"location":"development/ci-cd-pipeline/#quality-gates","title":"Quality Gates","text":""},{"location":"development/ci-cd-pipeline/#code-quality-standards","title":"Code Quality Standards","text":"<p>Linting Requirements: - Ruff: No linting errors allowed - Style: Consistent code formatting - Complexity: Maximum cyclomatic complexity limits</p> <p>Type Checking: - MyPy: Type hints validation (advisory) - Coverage: Gradual improvement of type coverage</p>"},{"location":"development/ci-cd-pipeline/#testing-requirements","title":"Testing Requirements","text":"<p>Coverage Thresholds: - Minimum: 50% for CI (allowing incremental improvement) - Target: 70% for releases - Trend: Must not decrease significantly</p> <p>Test Types: - Unit Tests: Fast, isolated component tests - Integration Tests: End-to-end functionality tests - Performance Tests: Regression detection tests</p>"},{"location":"development/ci-cd-pipeline/#security-standards","title":"Security Standards","text":"<p>Vulnerability Management: - Critical/High: Must be addressed before merge - Medium: Should be addressed in next release - Low: Can be tracked as technical debt</p> <p>Secret Management: - No Secrets: Never commit secrets to repository - Detection: Automated scanning with TruffleHog - Rotation: Regular API key rotation</p>"},{"location":"development/ci-cd-pipeline/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"development/ci-cd-pipeline/#benchmark-tracking","title":"Benchmark Tracking","text":"<p>DuckDB Operations: - Bulk loading performance metrics - Query response times - Memory usage patterns</p> <p>Regression Detection: - Thresholds: 20% performance degradation triggers alert - Trending: Track performance over time - Reporting: Automated performance reports</p>"},{"location":"development/ci-cd-pipeline/#load-testing_1","title":"Load Testing","text":"<p>Concurrent Operations: - Database connection pooling - Query execution under load - Memory usage under stress</p> <p>Thresholds: - Average response time: &lt; 5 seconds - Maximum response time: &lt; 10 seconds - Memory usage: Within system limits</p>"},{"location":"development/ci-cd-pipeline/#deployment-strategy","title":"Deployment Strategy","text":""},{"location":"development/ci-cd-pipeline/#branching-strategy","title":"Branching Strategy","text":"<p>Main Branches: - <code>main</code>: Production-ready code - <code>develop</code>: Integration branch for features</p> <p>Feature Branches: - <code>feature/*</code>: New features and enhancements - <code>bugfix/*</code>: Bug fixes - <code>hotfix/*</code>: Critical production fixes</p>"},{"location":"development/ci-cd-pipeline/#release-process","title":"Release Process","text":"<p>Versioning: - Semantic Versioning: MAJOR.MINOR.PATCH - Pre-releases: alpha, beta, rc suffixes - Tags: Git tags trigger automated releases</p> <p>Release Notes: - Automated: Extract from CHANGELOG.md - Manual: Override with workflow dispatch - Assets: Include built packages and documentation</p>"},{"location":"development/ci-cd-pipeline/#monitoring-and-alerting","title":"Monitoring and Alerting","text":""},{"location":"development/ci-cd-pipeline/#github-integration","title":"GitHub Integration","text":"<p>Status Checks: - All CI workflows must pass for merge - Security scans must not have critical issues - Documentation must build successfully</p> <p>Notifications: - Failed workflows notify team - Security alerts escalated immediately - Performance regressions flagged for review</p>"},{"location":"development/ci-cd-pipeline/#artifact-management","title":"Artifact Management","text":"<p>Storage: - Test results and coverage reports - Security scan outputs - Performance benchmarks - Documentation builds</p> <p>Retention: - Artifacts retained for 30 days - Release assets permanent - Security reports archived</p>"},{"location":"development/ci-cd-pipeline/#local-development","title":"Local Development","text":""},{"location":"development/ci-cd-pipeline/#pre-commit-setup","title":"Pre-commit Setup","text":"<p>Install Pre-commit Hooks: <pre><code># Install pre-commit\nuv add --dev pre-commit\n\n# Install hooks\nuv run pre-commit install\n\n# Run hooks manually\nuv run pre-commit run --all-files\n</code></pre></p> <p>Hook Configuration (<code>.pre-commit-config.yaml</code>): <pre><code>repos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.0\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.5.1\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-requests]\n</code></pre></p>"},{"location":"development/ci-cd-pipeline/#testing-locally","title":"Testing Locally","text":"<p>Run Full Test Suite: <pre><code># Install dependencies\nuv sync --all-extras --dev\n\n# Run tests with coverage\nuv run python -m pytest tests/ \\\n  --cov=src \\\n  --cov-report=html \\\n  --cov-report=term-missing\n\n# Run specific test categories\nuv run python -m pytest tests/unit/\nuv run python -m pytest tests/integration/\n</code></pre></p> <p>Performance Testing: <pre><code># Run DuckDB benchmarks\nuv run python -m landuse.converters.performance_benchmark\n\n# Memory profiling\nuv run python -m memory_profiler your_script.py\n</code></pre></p> <p>Security Scanning: <pre><code># Check for vulnerabilities\nuv run safety check\n\n# Security linting\nuv run bandit -r src/\n\n# License checking\nuv run pip-licenses\n</code></pre></p>"},{"location":"development/ci-cd-pipeline/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/ci-cd-pipeline/#common-ci-issues","title":"Common CI Issues","text":"<p>Test Failures: 1. Check test logs in GitHub Actions 2. Reproduce locally with same Python version 3. Check for environment-specific issues 4. Verify test data and configuration</p> <p>Coverage Drops: 1. Add tests for new code 2. Remove dead code 3. Check test configuration 4. Review coverage reports</p> <p>Security Alerts: 1. Review Bandit and Safety reports 2. Update vulnerable dependencies 3. Fix code security issues 4. Document risk acceptance if needed</p>"},{"location":"development/ci-cd-pipeline/#performance-issues","title":"Performance Issues","text":"<p>Benchmark Failures: 1. Check system resources during tests 2. Compare with baseline metrics 3. Profile memory and CPU usage 4. Review algorithm changes</p> <p>Memory Leaks: 1. Use memory profiler for analysis 2. Check connection cleanup 3. Review data structure usage 4. Monitor garbage collection</p>"},{"location":"development/ci-cd-pipeline/#best-practices","title":"Best Practices","text":""},{"location":"development/ci-cd-pipeline/#cicd-optimization","title":"CI/CD Optimization","text":"<p>Build Speed: - Use dependency caching - Parallel job execution - Minimal test data sets - Efficient Docker layers</p> <p>Resource Usage: - Monitor GitHub Actions minutes - Optimize workflow triggers - Use appropriate runner sizes - Cache dependencies effectively</p>"},{"location":"development/ci-cd-pipeline/#quality-assurance","title":"Quality Assurance","text":"<p>Test Strategy: - Fast unit tests for rapid feedback - Comprehensive integration tests - Performance regression tests - Security validation tests</p> <p>Code Reviews: - Automated checks before human review - Clear PR templates and guidelines - Focus areas for reviewers - Definition of done criteria</p>"},{"location":"development/ci-cd-pipeline/#security-practices","title":"Security Practices","text":"<p>Secret Management: - Never commit secrets - Use GitHub secrets for sensitive data - Rotate keys regularly - Principle of least privilege</p> <p>Vulnerability Response: - Monitor security alerts - Patch critical issues immediately - Track and remediate medium/low issues - Document security decisions</p>"},{"location":"development/ci-cd-pipeline/#future-enhancements","title":"Future Enhancements","text":""},{"location":"development/ci-cd-pipeline/#planned-improvements","title":"Planned Improvements","text":"<p>Advanced Testing: - Contract testing for APIs - Visual regression testing - End-to-end user journey tests - Chaos engineering experiments</p> <p>Enhanced Security: - Container vulnerability scanning - Infrastructure as Code security - Runtime security monitoring - Compliance reporting</p> <p>Performance Optimization: - Automated performance optimization - Machine learning for anomaly detection - Resource usage optimization - Scalability testing</p>"},{"location":"development/ci-cd-pipeline/#tool-integration","title":"Tool Integration","text":"<p>Potential Additions: - SonarQube for code quality - Snyk for vulnerability scanning - Lighthouse for web performance - Terraform for infrastructure</p> <p>Monitoring: - Application Performance Monitoring (APM) - Error tracking and alerting - User analytics and feedback - Infrastructure monitoring</p>"},{"location":"development/ci-cd-pipeline/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Overview</li> <li>Contributing Guide</li> <li>Testing Guide</li> <li>Branding Strategy</li> </ul>"},{"location":"development/contributing/","title":"Contributing Guide","text":"<p>Thank you for your interest in contributing to the LangChain Land Use Analysis project! This guide will help you get started.</p>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":""},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>Git</li> <li>uv (Python package manager)</li> <li>OpenAI API key</li> </ul>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Fork and Clone <pre><code>git clone https://github.com/yourusername/langchain-landuse.git\ncd langchain-landuse\n</code></pre></p> </li> <li> <p>Create Virtual Environment <pre><code>uv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install Dependencies <pre><code>uv pip install -r config/requirements.txt\n</code></pre></p> </li> <li> <p>Set Up Environment <pre><code>cp config/.env.example config/.env\n# Edit .env with your OpenAI API key\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#1-create-a-feature-branch","title":"1. Create a Feature Branch","text":"<pre><code>git checkout -b feature/your-feature-name\n</code></pre> <p>Branch naming conventions: - <code>feature/</code> - New features - <code>fix/</code> - Bug fixes - <code>docs/</code> - Documentation updates - <code>refactor/</code> - Code refactoring - <code>test/</code> - Test additions/updates</p>"},{"location":"development/contributing/#2-make-your-changes","title":"2. Make Your Changes","text":"<p>Follow the coding standards and ensure your changes are well-tested.</p>"},{"location":"development/contributing/#3-run-tests","title":"3. Run Tests","text":"<pre><code># Run tests (when available)\nuv run pytest\n\n# Run linting\nuv run flake8 scripts/\n\n# Type checking\nuv run mypy scripts/\n</code></pre>"},{"location":"development/contributing/#4-commit-your-changes","title":"4. Commit Your Changes","text":"<p>Use clear, descriptive commit messages:</p> <pre><code>git add .\ngit commit -m \"feat: add natural language support for scenario comparisons\"\n</code></pre> <p>Commit message format: - <code>feat:</code> - New feature - <code>fix:</code> - Bug fix - <code>docs:</code> - Documentation changes - <code>style:</code> - Code style changes - <code>refactor:</code> - Code refactoring - <code>test:</code> - Test changes - <code>chore:</code> - Build process or auxiliary tool changes</p>"},{"location":"development/contributing/#5-push-and-create-pull-request","title":"5. Push and Create Pull Request","text":"<pre><code>git push origin feature/your-feature-name\n</code></pre> <p>Then create a pull request on GitHub.</p>"},{"location":"development/contributing/#code-standards","title":"Code Standards","text":""},{"location":"development/contributing/#python-style-guide","title":"Python Style Guide","text":"<p>Follow PEP 8 with these specific guidelines:</p> <pre><code># Good: Descriptive variable names\nland_use_transitions = process_data(county_data)\n\n# Bad: Single letter variables\nt = p(c)\n\n# Good: Type hints\ndef calculate_area_change(\n    from_area: float, \n    to_area: float\n) -&gt; Dict[str, float]:\n    \"\"\"Calculate the change in area between two time periods.\"\"\"\n    pass\n\n# Good: Docstrings\ndef process_county_data(county: Dict[str, Any]) -&gt; List[Transition]:\n    \"\"\"\n    Process raw county data into transition records.\n\n    Args:\n        county: Dictionary containing county land use data\n\n    Returns:\n        List of Transition objects\n\n    Raises:\n        ValueError: If county data is invalid\n    \"\"\"\n    pass\n</code></pre>"},{"location":"development/contributing/#tool-development-guidelines","title":"Tool Development Guidelines","text":"<p>When creating new tools for the agent:</p> <pre><code>def _create_new_tool(self) -&gt; Tool:\n    \"\"\"Create a tool following the standard pattern.\"\"\"\n    return Tool(\n        name=\"descriptive_tool_name\",\n        func=self._tool_implementation,\n        description=\"Clear description of what the tool does for natural language understanding\"\n    )\n\ndef _tool_implementation(self, params: Union[str, Dict[str, Any]]) -&gt; str:\n    \"\"\"\n    Implement the tool functionality.\n\n    Args:\n        params: Tool parameters (handle both string and dict)\n\n    Returns:\n        String result for the agent to interpret\n    \"\"\"\n    try:\n        # Validate parameters\n        if isinstance(params, str):\n            params = self._parse_params(params)\n\n        # Perform operation\n        result = self._do_operation(params)\n\n        # Format result\n        return self._format_result(result)\n\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n</code></pre>"},{"location":"development/contributing/#natural-language-query-patterns","title":"Natural Language Query Patterns","text":"<p>When adding query capabilities:</p> <pre><code># Support multiple phrasings\npatterns = [\n    \"show me forest loss\",\n    \"display forest reduction\",\n    \"what areas lost forest\",\n    \"forest to other land uses\"\n]\n\n# Provide helpful examples\nEXAMPLES = \"\"\"\nNatural language: \"Which counties have the most urban growth?\"\nSQL generated: SELECT fips, SUM(area) as urban_growth \n               FROM transitions \n               WHERE to_land_use = 'Urban' \n               GROUP BY fips \n               ORDER BY urban_growth DESC\n\"\"\"\n</code></pre>"},{"location":"development/contributing/#adding-features","title":"Adding Features","text":""},{"location":"development/contributing/#1-new-data-analysis-tools","title":"1. New Data Analysis Tools","text":"<p>To add a new analysis capability:</p> <ol> <li>Create the tool method in <code>data_engineering_agent.py</code></li> <li>Add to <code>_create_tools()</code> method</li> <li>Include parameter validation</li> <li>Add rich output formatting</li> <li>Document in <code>docs/api/tools.md</code></li> </ol> <p>Example: <pre><code>def _seasonal_analysis(self, params: Dict[str, Any]) -&gt; str:\n    \"\"\"Analyze seasonal patterns in land use changes.\"\"\"\n    # Implementation\n    pass\n</code></pre></p>"},{"location":"development/contributing/#2-new-query-patterns","title":"2. New Query Patterns","text":"<p>To support new types of natural language queries:</p> <ol> <li>Identify the query pattern</li> <li>Add examples to documentation</li> <li>Test with the agent</li> <li>Update query examples</li> </ol>"},{"location":"development/contributing/#3-new-data-formats","title":"3. New Data Formats","text":"<p>To support additional file formats:</p> <ol> <li>Add read method</li> <li>Add to format detection</li> <li>Support in query tool</li> <li>Add transformation support</li> <li>Update documentation</li> </ol>"},{"location":"development/contributing/#testing","title":"Testing","text":""},{"location":"development/contributing/#unit-tests","title":"Unit Tests","text":"<pre><code># test_converters.py\ndef test_land_use_mapping():\n    \"\"\"Test that land use codes map correctly.\"\"\"\n    assert LAND_USE_MAP['cr'] == 'Crop'\n    assert LAND_USE_MAP['ur'] == 'Urban'\n\ndef test_year_extraction():\n    \"\"\"Test year extraction from range.\"\"\"\n    assert extract_end_year('2020-2030') == 2030\n</code></pre>"},{"location":"development/contributing/#integration-tests","title":"Integration Tests","text":"<pre><code># test_agent_queries.py\ndef test_basic_query():\n    \"\"\"Test basic natural language query.\"\"\"\n    agent = DataEngineeringAgent()\n    result = agent.run(\"List all tables\")\n    assert \"landuse_transitions\" in result\n</code></pre>"},{"location":"development/contributing/#test-data","title":"Test Data","text":"<p>Keep test data minimal and in <code>tests/data/</code>: <pre><code>tests/\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 sample_transitions.json\n    \u251c\u2500\u2500 test_database.db\n    \u2514\u2500\u2500 fixtures.py\n</code></pre></p>"},{"location":"development/contributing/#documentation","title":"Documentation","text":""},{"location":"development/contributing/#adding-documentation","title":"Adding Documentation","text":"<ol> <li>API Documentation: Update relevant files in <code>docs/api/</code></li> <li>Query Examples: Add to <code>docs/queries/examples.md</code></li> <li>Use Cases: Document in <code>docs/examples/use-cases.md</code></li> <li>Docstrings: Always include in code</li> </ol>"},{"location":"development/contributing/#documentation-style","title":"Documentation Style","text":"<pre><code># Clear Heading\n\nBrief description of the topic.\n\n## Subsection\n\n### Code Example\n\n\\```python\n# Always include examples\nagent.run(\"Your natural language query here\")\n\\```\n\n### Expected Output\n\n\\```\nShow what users should expect to see\n\\```\n</code></pre>"},{"location":"development/contributing/#performance-considerations","title":"Performance Considerations","text":""},{"location":"development/contributing/#optimize-for-large-datasets","title":"Optimize for Large Datasets","text":"<pre><code># Good: Streaming for large files\ndef process_large_file(file_path):\n    with open(file_path, 'r') as f:\n        for chunk in iter(lambda: f.read(4096), ''):\n            process_chunk(chunk)\n\n# Good: Batch database operations\ndef insert_batch(data, batch_size=10000):\n    for i in range(0, len(data), batch_size):\n        batch = data[i:i + batch_size]\n        cursor.executemany(sql, batch)\n</code></pre>"},{"location":"development/contributing/#memory-management","title":"Memory Management","text":"<pre><code># Good: Clear large objects\ndef process_data():\n    large_df = read_large_file()\n    result = analyze(large_df)\n    del large_df  # Explicitly free memory\n    return result\n</code></pre>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Update Documentation: Ensure docs reflect your changes</li> <li>Add Tests: Include tests for new functionality</li> <li>Check Standards: Run linting and formatting</li> <li>Update CHANGELOG: Note significant changes</li> <li>Request Review: Tag appropriate reviewers</li> </ol>"},{"location":"development/contributing/#pr-template","title":"PR Template","text":"<pre><code>## Description\nBrief description of changes\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Documentation update\n- [ ] Performance improvement\n\n## Testing\n- [ ] Unit tests pass\n- [ ] Integration tests pass\n- [ ] Manual testing completed\n\n## Documentation\n- [ ] Code includes docstrings\n- [ ] Documentation updated\n- [ ] Examples added\n</code></pre>"},{"location":"development/contributing/#common-development-tasks","title":"Common Development Tasks","text":""},{"location":"development/contributing/#adding-a-new-scenario","title":"Adding a New Scenario","text":"<pre><code># 1. Update scenario list\nSCENARIOS = ['Baseline', 'High Crop Demand', 'High Forest', 'High Urban', 'New Scenario']\n\n# 2. Update documentation\n# docs/data/sources.md - Add scenario description\n\n# 3. Test with agent\nagent.run(\"Show me data for the New Scenario\")\n</code></pre>"},{"location":"development/contributing/#improving-query-performance","title":"Improving Query Performance","text":"<pre><code># 1. Add appropriate index\nCREATE INDEX idx_scenario_year ON landuse_transitions(scenario, year);\n\n# 2. Update query patterns\ndef optimize_query(original_query):\n    # Add query optimization logic\n    pass\n</code></pre>"},{"location":"development/contributing/#enhancing-natural-language-understanding","title":"Enhancing Natural Language Understanding","text":"<pre><code># 1. Add synonyms\nSYNONYMS = {\n    'urban': ['city', 'developed', 'built'],\n    'forest': ['trees', 'woodland', 'timber'],\n    'agricultural': ['farming', 'ag', 'crops and pasture']\n}\n\n# 2. Improve query parsing\ndef parse_natural_language(query):\n    # Enhanced parsing logic\n    pass\n</code></pre>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":""},{"location":"development/contributing/#resources","title":"Resources","text":"<ul> <li>Project Issues: GitHub Issues</li> <li>LangChain Docs: langchain.com</li> <li>OpenAI API: platform.openai.com</li> </ul>"},{"location":"development/contributing/#communication-channels","title":"Communication Channels","text":"<ul> <li>GitHub Issues: Bug reports and feature requests</li> <li>Discussions: General questions and ideas</li> <li>Pull Requests: Code contributions</li> </ul>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":""},{"location":"development/contributing/#be-respectful","title":"Be Respectful","text":"<ul> <li>Use welcoming and inclusive language</li> <li>Respect differing viewpoints and experiences</li> <li>Accept constructive criticism gracefully</li> </ul>"},{"location":"development/contributing/#contribute-positively","title":"Contribute Positively","text":"<ul> <li>Focus on what is best for the community</li> <li>Show empathy towards other community members</li> <li>Help others learn and grow</li> </ul>"},{"location":"development/contributing/#recognition","title":"Recognition","text":"<p>Contributors will be recognized in: - CONTRIBUTORS.md file - Release notes - Project documentation</p> <p>Thank you for contributing to make land use analysis more accessible through natural language!</p>"},{"location":"development/modern-duckdb-tools/","title":"Modern DuckDB Tools &amp; Database Redesign","text":""},{"location":"development/modern-duckdb-tools/#project-transformation","title":"\ud83c\udfaf Project Transformation","text":"<p>We've successfully redesigned your landuse data from a single denormalized table (8.6M rows) into a modern star schema optimized for analytics. This follows 2025 best practices for data warehousing and analytics.</p>"},{"location":"development/modern-duckdb-tools/#before-vs-after","title":"Before vs After","text":"Aspect Before (SQLite) After (DuckDB) Schema Single table with repeated data Star schema with 5 normalized tables Storage String repetition, inefficient Integer foreign keys, columnar storage Performance Slow aggregations Fast analytical queries Scalability Limited Optimized for large datasets Analytics Manual SQL only Built-in views + modern tooling Data Quality No constraints Referential integrity"},{"location":"development/modern-duckdb-tools/#our-new-duckdb-schema","title":"\ud83e\udd86 Our New DuckDB Schema","text":"<pre><code>\ud83d\udcca Fact Table: fact_landuse_transitions (main data)\n\u251c\u2500\u2500 \ud83c\udf0d dim_geography (counties, states, regions)\n\u251c\u2500\u2500 \u23f0 dim_time (year ranges, periods)\n\u251c\u2500\u2500 \ud83c\udfde\ufe0f dim_landuse (crop, forest, urban, etc.)\n\u2514\u2500\u2500 \ud83c\udf21\ufe0f dim_scenario (climate models, RCP/SSP scenarios)\n</code></pre>"},{"location":"development/modern-duckdb-tools/#modern-duckdb-tools-2025","title":"\ud83d\udd27 Modern DuckDB Tools (2025)","text":""},{"location":"development/modern-duckdb-tools/#1-duckdb-native-ui-official-2025","title":"1. DuckDB Native UI (Official, 2025)","text":"<pre><code># Launch built-in web UI (DuckDB v1.2.1+)\nduckdb data/processed/landuse_analytics.duckdb -ui\n</code></pre> <p>Features: - \u2705 Notebook-style interface (like Jupyter) - \u2705 Interactive SQL editor with syntax highlighting - \u2705 Data explorer with schema browsing - \u2705 Query history and results visualization - \u2705 No installation required - runs in browser - \u2705 Completely local (data never leaves your computer)</p>"},{"location":"development/modern-duckdb-tools/#2-duck-ui-community","title":"2. Duck-UI (Community)","text":"<pre><code># Web-based DuckDB interface\ndocker run -p 5522:5522 ghcr.io/caioricciuti/duck-ui:latest\n</code></pre> <p>Features: - \u2705 Modern React-based interface - \u2705 File import/export (CSV, JSON, Parquet) - \u2705 Data visualization capabilities - \u2705 Query management and history - \u2705 WebAssembly-powered (runs in browser)</p>"},{"location":"development/modern-duckdb-tools/#3-our-enhanced-sql-query-agent","title":"3. Our Enhanced SQL Query Agent","text":"<pre><code># Run our custom agent with DuckDB support\nuv run python scripts/agents/sql_query_agent.py\n</code></pre> <p>Features: - \u2705 DuckDB-optimized queries with <code>query_duckdb</code> tool - \u2705 Rich terminal interface with progress bars - \u2705 Automatic summary statistics for numeric columns - \u2705 Integration with LangChain for AI-powered analysis - \u2705 Smart query suggestions and error handling</p>"},{"location":"development/modern-duckdb-tools/#analytics-capabilities","title":"\ud83d\udcc8 Analytics Capabilities","text":""},{"location":"development/modern-duckdb-tools/#pre-built-views","title":"Pre-built Views","text":"<pre><code>-- Agricultural transitions analysis\nSELECT * FROM v_agriculture_transitions \nWHERE scenario_name = 'CNRM_CM5_rcp45_ssp1';\n\n-- Scenario summary with aggregations\nSELECT * FROM v_scenario_summary \nORDER BY total_acres DESC;\n</code></pre>"},{"location":"development/modern-duckdb-tools/#advanced-analytics-examples","title":"Advanced Analytics Examples","text":"<pre><code>-- Agricultural land loss by state\nSELECT \n    s.scenario_name,\n    g.state_code,\n    SUM(f.acres) as acres_lost\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_category = 'Agriculture' \n  AND tl.landuse_category != 'Agriculture'\n  AND f.transition_type = 'change'\nGROUP BY s.scenario_name, g.state_code\nORDER BY acres_lost DESC;\n\n-- Time series analysis\nSELECT \n    t.start_year,\n    t.end_year,\n    fl.landuse_name as from_landuse,\n    tl.landuse_name as to_landuse,\n    SUM(f.acres) as total_acres\nFROM fact_landuse_transitions f\nJOIN dim_time t ON f.time_id = t.time_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE f.transition_type = 'change'\nGROUP BY t.start_year, t.end_year, fl.landuse_name, tl.landuse_name\nORDER BY t.start_year, total_acres DESC;\n</code></pre>"},{"location":"development/modern-duckdb-tools/#performance-benefits","title":"\ud83d\ude80 Performance Benefits","text":""},{"location":"development/modern-duckdb-tools/#query-speed-improvements","title":"Query Speed Improvements","text":"<ul> <li>Aggregations: 10-100x faster with columnar storage</li> <li>Filtering: Instant filtering on any dimension</li> <li>Joins: Optimized star schema joins</li> <li>Memory Usage: Reduced through integer foreign keys</li> </ul>"},{"location":"development/modern-duckdb-tools/#storage-efficiency","title":"Storage Efficiency","text":"<ul> <li>Before: Repeated strings in 8.6M rows</li> <li>After: Normalized dimensions + integer references</li> <li>Compression: DuckDB's columnar compression</li> <li>Indexing: Strategic indexes on common query patterns</li> </ul>"},{"location":"development/modern-duckdb-tools/#development-workflow","title":"\ud83d\udee0\ufe0f Development Workflow","text":""},{"location":"development/modern-duckdb-tools/#1-data-exploration","title":"1. Data Exploration","text":"<pre><code># Use DuckDB UI for interactive exploration\nduckdb data/processed/landuse_analytics.duckdb -ui\n\n# Or use our SQL Query Agent\nuv run python scripts/agents/sql_query_agent.py\n</code></pre>"},{"location":"development/modern-duckdb-tools/#2-advanced-analytics","title":"2. Advanced Analytics","text":"<pre><code># Python integration\nimport duckdb\nconn = duckdb.connect('data/processed/landuse_analytics.duckdb')\ndf = conn.execute(\"SELECT * FROM v_scenario_summary\").df()\n</code></pre>"},{"location":"development/modern-duckdb-tools/#3-visualization","title":"3. Visualization","text":"<pre><code># Direct pandas integration for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Query and visualize\ndf = conn.execute(\"\"\"\n    SELECT s.scenario_name, SUM(f.acres) as total_acres\n    FROM fact_landuse_transitions f\n    JOIN dim_scenario s ON f.scenario_id = s.scenario_id\n    GROUP BY s.scenario_name\n\"\"\").df()\n\nsns.barplot(data=df, x='scenario_name', y='total_acres')\nplt.xticks(rotation=45)\nplt.show()\n</code></pre>"},{"location":"development/modern-duckdb-tools/#next-steps-modern-practices","title":"\ud83d\udd2e Next Steps &amp; Modern Practices","text":""},{"location":"development/modern-duckdb-tools/#1-data-quality-testing","title":"1. Data Quality &amp; Testing","text":"<pre><code>-- Add data quality checks\nSELECT COUNT(*) as null_acres \nFROM fact_landuse_transitions \nWHERE acres IS NULL;\n\n-- Referential integrity checks\nSELECT COUNT(*) as orphaned_records\nFROM fact_landuse_transitions f\nLEFT JOIN dim_scenario s ON f.scenario_id = s.scenario_id\nWHERE s.scenario_id IS NULL;\n</code></pre>"},{"location":"development/modern-duckdb-tools/#2-performance-monitoring","title":"2. Performance Monitoring","text":"<pre><code>-- Query performance analysis\nEXPLAIN ANALYZE SELECT ...;\n\n-- Table statistics\nSELECT table_name, estimated_size \nFROM duckdb_tables();\n</code></pre>"},{"location":"development/modern-duckdb-tools/#3-integration-with-modern-stack","title":"3. Integration with Modern Stack","text":"<ul> <li>dbt: Data transformation and testing</li> <li>Great Expectations: Data quality validation</li> <li>Streamlit: Interactive dashboards</li> <li>Observable: Collaborative analytics notebooks</li> <li>Evidence: BI reporting from SQL</li> </ul>"},{"location":"development/modern-duckdb-tools/#4-advanced-duckdb-features","title":"4. Advanced DuckDB Features","text":"<pre><code>-- Spatial analysis (if geographic data available)\nINSTALL spatial;\nLOAD spatial;\n\n-- Time series analysis\nINSTALL icu;\nLOAD icu;\n\n-- Machine learning\nINSTALL ml;\nLOAD ml;\n</code></pre>"},{"location":"development/modern-duckdb-tools/#learning-resources","title":"\ud83d\udcda Learning Resources","text":""},{"location":"development/modern-duckdb-tools/#official-documentation","title":"Official Documentation","text":"<ul> <li>DuckDB Documentation</li> <li>DuckDB UI Guide</li> <li>SQL Reference</li> </ul>"},{"location":"development/modern-duckdb-tools/#community-tools","title":"Community Tools","text":"<ul> <li>Awesome DuckDB</li> <li>DuckDB Extensions</li> <li>DuckDB Cookbook</li> </ul>"},{"location":"development/modern-duckdb-tools/#books-courses","title":"Books &amp; Courses","text":"<ul> <li>\"DuckDB: Up and Running\" by Wei-Meng Lee (2024)</li> <li>Modern data stack courses focusing on DuckDB</li> <li>Analytics engineering best practices</li> </ul>"},{"location":"development/modern-duckdb-tools/#your-learning-path","title":"\ud83c\udfaf Your Learning Path","text":"<ol> <li>Explore the new schema using DuckDB UI</li> <li>Write analytical queries using our SQL Query Agent</li> <li>Build visualizations with Python integration</li> <li>Learn modern analytics patterns with star schema</li> <li>Experiment with DuckDB extensions for advanced features</li> </ol> <p>This redesign positions your project at the cutting edge of 2025 data analytics, using modern tools and practices that are becoming industry standard! </p>"},{"location":"development/pydantic-models/","title":"Pydantic Models Implementation","text":""},{"location":"development/pydantic-models/#overview","title":"Overview","text":"<p>This guide documents the comprehensive Pydantic v2 models implementation for the landuse project. These models provide type safety, automatic validation, and clear data contracts throughout the application.</p>"},{"location":"development/pydantic-models/#benefits-of-pydantic-models","title":"Benefits of Pydantic Models","text":"<ol> <li>Type Safety: Compile-time type checking with mypy</li> <li>Runtime Validation: Automatic input validation with helpful error messages</li> <li>Documentation: Self-documenting data structures</li> <li>Serialization: Easy conversion to/from JSON, dict, etc.</li> <li>IDE Support: Excellent autocomplete and type hints</li> </ol>"},{"location":"development/pydantic-models/#core-models","title":"Core Models","text":""},{"location":"development/pydantic-models/#agent-configuration","title":"Agent Configuration","text":"<pre><code>from landuse import AgentConfig\n\n# Create config with validation\nconfig = AgentConfig(\n    db_path=\"data/processed/landuse_analytics.duckdb\",\n    model_name=\"claude-3-5-sonnet-20241022\",\n    temperature=0.1,\n    max_tokens=4000,\n    max_iterations=5,\n    max_execution_time=120\n)\n\n# Access validated attributes\nprint(config.db_path)  # Path object, verified to exist\nprint(config.temperature)  # Float between 0-2\n</code></pre>"},{"location":"development/pydantic-models/#query-models","title":"Query Models","text":"<pre><code>from landuse import QueryInput, SQLQuery, QueryResult\n\n# Natural language query validation\nquery_input = QueryInput(\n    query=\"Show me agricultural land loss\",\n    include_assumptions=True\n)\n\n# SQL query validation\nsql_query = SQLQuery(\n    sql=\"SELECT * FROM dim_landuse\",\n    description=\"List all land use types\"\n)\n# Automatically validates:\n# - Only SELECT/WITH queries allowed\n# - No destructive operations\n\n# Query results with metadata\nresult = QueryResult(\n    success=True,\n    data=df,  # pandas DataFrame\n    execution_time=1.23,\n    query=\"SELECT COUNT(*) FROM fact_landuse_transitions\"\n)\nprint(f\"Processed {result.row_count:,} rows in {result.execution_time:.2f}s\")\n</code></pre>"},{"location":"development/pydantic-models/#data-models","title":"Data Models","text":"<pre><code>from landuse import (\n    LandUseType, LandUseCategory, \n    RCPScenario, SSPScenario,\n    TransitionType\n)\n\n# Enums provide controlled vocabularies\nland_use = LandUseType.CROP  # \"cr\"\ncategory = LandUseCategory.AGRICULTURE\nrcp = RCPScenario.RCP45  # \"4.5\"\nssp = SSPScenario.SSP1\ntransition = TransitionType.CHANGE\n\n# Dimension models with validation\nfrom landuse.models import GeographyDimension\n\ngeography = GeographyDimension(\n    geography_id=1,\n    fips_code=\"12345\",  # Validated as 5 digits\n    county_name=\"Example County\",\n    state_code=\"CA\",\n    state_name=\"California\"\n)\n</code></pre>"},{"location":"development/pydantic-models/#tool-input-models","title":"Tool Input Models","text":"<pre><code>from landuse.models import (\n    ExecuteQueryInput,\n    SchemaInfoInput,\n    StateCodeInput\n)\n\n# Tool inputs are validated before execution\nexecute_input = ExecuteQueryInput(\n    sql_query=\"SELECT COUNT(*) FROM dim_scenario\"\n)\n\nstate_input = StateCodeInput(\n    state_name=\"California\"\n)\n</code></pre>"},{"location":"development/pydantic-models/#converter-models","title":"Converter Models","text":""},{"location":"development/pydantic-models/#conversion-configuration","title":"Conversion Configuration","text":"<pre><code>from landuse import ConversionConfig, ConversionMode\n\nconfig = ConversionConfig(\n    input_file=\"data/raw/landuse.json\",\n    output_file=\"data/processed/landuse.duckdb\",\n    mode=ConversionMode.STREAMING,\n    batch_size=100000,\n    parallel_workers=8,\n    memory_limit=\"16GB\",\n    show_progress=True\n)\n\n# Validates:\n# - Input file exists and is JSON\n# - Memory limit format (e.g., \"8GB\", \"512MB\")\n# - Reasonable batch sizes and worker counts\n</code></pre>"},{"location":"development/pydantic-models/#processing-models","title":"Processing Models","text":"<pre><code>from landuse import ProcessedTransition, ConversionStats\n\n# Validated transition record\ntransition = ProcessedTransition(\n    scenario_name=\"GCAM_RCP45_SSP1\",\n    climate_model=\"GCAM\",\n    rcp_scenario=\"4.5\",\n    ssp_scenario=\"SSP1\",\n    time_period=\"2020-2030\",\n    start_year=2020,\n    end_year=2030,\n    fips_code=\"06037\",  # Validated FIPS\n    county_name=\"Los Angeles\",\n    state_code=\"06\",\n    from_landuse=\"Crop\",\n    to_landuse=\"Urban\",\n    acres=1234.56,\n    transition_type=\"change\"  # Validated as change/stable\n)\n\n# Conversion statistics\nstats = ConversionStats(\n    total_records=5_400_000,\n    processed_records=5_399_950,\n    failed_records=50,\n    processing_time=123.45\n)\nprint(f\"Success rate: {stats.success_rate():.2f}%\")\nprint(f\"Speed: {stats.records_per_second():.0f} records/sec\")\n</code></pre>"},{"location":"development/pydantic-models/#integration-examples","title":"Integration Examples","text":""},{"location":"development/pydantic-models/#agent-usage","title":"Agent Usage","text":"<pre><code>from landuse.agents import LanduseAgent\nfrom landuse import AgentConfig, QueryInput\n\n# Initialize with Pydantic config\nconfig = AgentConfig(\n    model_name=\"gpt-4o-mini\",\n    temperature=0.1,\n    max_iterations=10\n)\n\nagent = LanduseAgent(config=config)\n\n# Query with validation\nquery_input = QueryInput(\n    query=\"Which states have the most urban expansion?\"\n)\nresponse = agent.query(query_input.query)\n</code></pre>"},{"location":"development/pydantic-models/#database-connection","title":"Database Connection","text":"<pre><code>from landuse.connections import DuckDBConnection\nfrom landuse import QueryResult\n\nconn = DuckDBConnection(\"landuse_db\")\n\n# Get validated query results\nresult: QueryResult = conn.query_with_result(\n    \"SELECT COUNT(*) as total FROM fact_landuse_transitions\"\n)\n\nif result.success:\n    print(f\"Total transitions: {result.data['total'][0]:,}\")\n    print(f\"Query took {result.execution_time:.3f}s\")\nelse:\n    print(f\"Error: {result.error}\")\n</code></pre>"},{"location":"development/pydantic-models/#streamlit-integration","title":"Streamlit Integration","text":"<pre><code>import streamlit as st\nfrom landuse import ChatMessage, SystemStatus\n\n# Track chat messages with validation\nmessage = ChatMessage(\n    role=\"user\",\n    content=\"Show me forest loss trends\"\n)\nst.session_state.messages.append(message)\n\n# System status monitoring\nstatus = SystemStatus(\n    database_connected=True,\n    agent_initialized=True,\n    model_name=\"claude-3-5-sonnet\",\n    database_path=\"/path/to/db\",\n    table_count=5,\n    total_records=5_400_000\n)\n</code></pre>"},{"location":"development/pydantic-models/#error-handling","title":"Error Handling","text":"<p>Pydantic provides detailed validation errors:</p> <pre><code>from landuse import AgentConfig\nfrom pydantic import ValidationError\n\ntry:\n    config = AgentConfig(\n        temperature=3.0,  # Too high!\n        max_tokens=-100   # Negative!\n    )\nexcept ValidationError as e:\n    print(e.json(indent=2))\n    # {\n    #   \"errors\": [\n    #     {\n    #       \"loc\": [\"temperature\"],\n    #       \"msg\": \"ensure this value is less than or equal to 2\",\n    #       \"type\": \"value_error.number.not_le\"\n    #     },\n    #     {\n    #       \"loc\": [\"max_tokens\"],\n    #       \"msg\": \"ensure this value is greater than 0\",\n    #       \"type\": \"value_error.number.not_gt\"\n    #     }\n    #   ]\n    # }\n</code></pre>"},{"location":"development/pydantic-models/#best-practices","title":"Best Practices","text":"<ol> <li>Use Models at Boundaries: Validate data at API endpoints, user inputs, and external data sources</li> <li>Leverage Validators: Add custom validators for business logic</li> <li>Export Common Models: Make models easily importable from package root</li> <li>Document Fields: Use Field descriptions for self-documenting APIs</li> <li>Handle Validation Errors: Catch ValidationError and provide user-friendly messages</li> </ol>"},{"location":"development/pydantic-models/#migration-guide","title":"Migration Guide","text":"<p>To migrate existing code to use Pydantic models:</p> <ol> <li> <p>Replace dict parameters with model instances:    <pre><code># Before\nagent.query({\"query\": \"...\", \"limit\": 50})\n\n# After\nagent.query(QueryInput(query=\"...\", limit=50))\n</code></pre></p> </li> <li> <p>Use enums instead of strings:    <pre><code># Before\nif landuse_type == \"cr\":\n\n# After\nif landuse_type == LandUseType.CROP:\n</code></pre></p> </li> <li> <p>Return structured results:    <pre><code># Before\nreturn {\"success\": True, \"data\": df, \"error\": None}\n\n# After\nreturn QueryResult(success=True, data=df)\n</code></pre></p> </li> </ol>"},{"location":"development/pydantic-models/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Pydantic v2 is 5-50x faster than v1</li> <li>Use <code>model_config = ConfigDict(extra=\"forbid\")</code> to catch typos</li> <li>Leverage <code>.model_dump()</code> for efficient serialization</li> <li>Use <code>exclude=True</code> on fields that shouldn't be serialized</li> </ul>"},{"location":"development/pydantic-models/#testing-with-models","title":"Testing with Models","text":"<pre><code>import pytest\nfrom landuse import QueryInput\nfrom pydantic import ValidationError\n\ndef test_query_validation():\n    # Valid query\n    query = QueryInput(query=\"Show me data\")\n    assert query.include_assumptions is True  # Default\n\n    # Invalid query (empty)\n    with pytest.raises(ValidationError):\n        QueryInput(query=\"\")\n\n    # Invalid query (too long)\n    with pytest.raises(ValidationError):\n        QueryInput(query=\"x\" * 1001)\n</code></pre>"},{"location":"development/pydantic-models/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>JSON Schema Generation: Auto-generate API documentation</li> <li>OpenAPI Integration: Use models for API spec generation</li> <li>Settings Management: Use pydantic-settings for configuration</li> <li>Async Support: Add async validators for I/O operations</li> </ol>"},{"location":"development/retry-logic/","title":"Retry Logic with Tenacity","text":"<p>This document describes the implementation of robust retry logic throughout the landuse project using the tenacity library and custom fallback mechanisms.</p>"},{"location":"development/retry-logic/#overview","title":"Overview","text":"<p>The retry system provides automatic error recovery for transient failures in database connections, API calls, file operations, and network requests. This improves reliability and user experience by handling temporary issues gracefully.</p>"},{"location":"development/retry-logic/#implementation","title":"Implementation","text":""},{"location":"development/retry-logic/#core-components","title":"Core Components","text":"<ol> <li>Retry Decorators (<code>src/landuse/utils/retry_decorators.py</code>)</li> <li>Specialized decorators for different operation types</li> <li>Configurable retry strategies and wait times</li> <li> <p>Fallback implementation when tenacity is unavailable</p> </li> <li> <p>Integration Points</p> </li> <li>Database connections and queries</li> <li>Bulk loading operations</li> <li>Agent tool executions</li> <li>File I/O operations</li> </ol>"},{"location":"development/retry-logic/#retry-decorators","title":"Retry Decorators","text":""},{"location":"development/retry-logic/#database-operations","title":"Database Operations","text":"<pre><code>from landuse.utils.retry_decorators import database_retry\n\n@database_retry(max_attempts=3, min_wait=1.0, max_wait=10.0)\ndef connect_to_database():\n    return duckdb.connect(\"database.duckdb\")\n</code></pre> <p>Configuration: - Max Attempts: 3 (reasonable for database operations) - Wait Strategy: Exponential backoff (1s \u2192 2s \u2192 4s \u2192 ...) - Max Wait: 10 seconds (prevents excessive delays) - Retryable Exceptions: <code>ConnectionError</code>, <code>TimeoutError</code>, <code>OSError</code></p>"},{"location":"development/retry-logic/#api-operations","title":"API Operations","text":"<pre><code>from landuse.utils.retry_decorators import api_retry\n\n@api_retry(max_attempts=5, base_wait=2.0, max_wait=60.0)\ndef call_external_api():\n    response = requests.get(\"https://api.example.com/data\")\n    return response.json()\n</code></pre> <p>Configuration: - Max Attempts: 5 (APIs may have intermittent issues) - Wait Strategy: Exponential backoff with base 2 seconds - Max Wait: 60 seconds (API rate limiting consideration) - Retryable Exceptions: <code>ConnectionError</code>, <code>TimeoutError</code>, <code>OSError</code></p>"},{"location":"development/retry-logic/#file-operations","title":"File Operations","text":"<pre><code>from landuse.utils.retry_decorators import file_retry\n\n@file_retry(max_attempts=3, wait_time=2.0)\ndef write_to_file(filename, data):\n    with open(filename, 'w') as f:\n        f.write(data)\n</code></pre> <p>Configuration: - Max Attempts: 3 (file locks usually resolve quickly) - Wait Strategy: Fixed wait time - Wait Time: 2 seconds (allows file locks to clear) - Retryable Exceptions: <code>FileNotFoundError</code>, <code>PermissionError</code>, <code>OSError</code></p>"},{"location":"development/retry-logic/#network-operations","title":"Network Operations","text":"<pre><code>from landuse.utils.retry_decorators import network_retry\n\n@network_retry(max_attempts=5, min_wait=2.0, max_wait=30.0)\ndef download_data():\n    response = urllib.request.urlopen(\"https://example.com/data.json\")\n    return response.read()\n</code></pre> <p>Configuration: - Max Attempts: 5 (network issues can be intermittent) - Wait Strategy: Exponential backoff - Wait Range: 2-30 seconds - Retryable Exceptions: <code>ConnectionError</code>, <code>TimeoutError</code></p>"},{"location":"development/retry-logic/#advanced-retry-patterns","title":"Advanced Retry Patterns","text":""},{"location":"development/retry-logic/#result-based-retries","title":"Result-Based Retries","text":"<pre><code>from landuse.utils.retry_decorators import retry_on_result\n\n@retry_on_result(\n    result_predicate=lambda x: x is None or x.get('status') == 'pending',\n    max_attempts=10,\n    wait_time=5.0\n)\ndef poll_for_completion():\n    \"\"\"Retry until we get a complete result\"\"\"\n    status = check_processing_status()\n    return status\n</code></pre>"},{"location":"development/retry-logic/#custom-retry-logic","title":"Custom Retry Logic","text":"<pre><code>from landuse.utils.retry_decorators import custom_retry\nfrom tenacity import stop_after_delay, wait_random_exponential\n\n@custom_retry(\n    stop_condition=stop_after_delay(300),  # Stop after 5 minutes\n    wait_strategy=wait_random_exponential(multiplier=1, max=60),\n    retry_condition=retry_if_exception_type((ConnectionError, TimeoutError))\n)\ndef complex_operation():\n    # Complex operation with custom retry logic\n    pass\n</code></pre>"},{"location":"development/retry-logic/#context-manager-approach","title":"Context Manager Approach","text":"<pre><code>from landuse.utils.retry_decorators import RetryableOperation\n\nwith RetryableOperation(\n    \"Database migration\",\n    max_attempts=5,\n    wait_strategy=\"exponential\",\n    min_wait=2.0,\n    max_wait=60.0\n) as op:\n    result = op.execute(migrate_database_schema)\n</code></pre>"},{"location":"development/retry-logic/#utility-function-approach","title":"Utility Function Approach","text":"<pre><code>from landuse.utils.retry_decorators import execute_with_retry\n\nresult = execute_with_retry(\n    func=complex_database_operation,\n    operation_name=\"Complex DB Operation\",\n    max_attempts=3,\n    wait_strategy=\"exponential\",\n    min_wait=1.0,\n    max_wait=30.0,\n    exceptions=(ConnectionError, TimeoutError),\n    # Function arguments\n    table_name=\"landuse_data\",\n    batch_size=10000\n)\n</code></pre>"},{"location":"development/retry-logic/#integration-examples","title":"Integration Examples","text":""},{"location":"development/retry-logic/#database-connections","title":"Database Connections","text":"<p>Before (no retry): <pre><code>def connect_to_database():\n    return duckdb.connect(\"database.duckdb\")  # Fails on temporary issues\n</code></pre></p> <p>After (with retry): <pre><code>@database_retry(max_attempts=3, min_wait=1.0, max_wait=10.0)\ndef connect_to_database():\n    try:\n        return duckdb.connect(\"database.duckdb\")\n    except Exception as e:\n        raise ConnectionError(f\"Failed to connect: {e}\") from e\n</code></pre></p>"},{"location":"development/retry-logic/#bulk-loading-operations","title":"Bulk Loading Operations","text":"<p>Enhanced bulk loader with retry logic: <pre><code>class DuckDBBulkLoader:\n    @contextmanager\n    def connection(self):\n        try:\n            self.conn = execute_with_retry(\n                duckdb.connect,\n                operation_name=f\"DuckDB connection to {self.db_path}\",\n                max_attempts=3,\n                wait_strategy=\"exponential\",\n                exceptions=(ConnectionError, OSError, RuntimeError),\n                database=str(self.db_path)\n            )\n            yield self.conn\n        finally:\n            if self.conn:\n                self.conn.close()\n\n    def bulk_load_dataframe(self, df, table_name):\n        # Write Parquet with retry\n        execute_with_retry(\n            df.to_parquet,\n            operation_name=f\"Writing Parquet file\",\n            max_attempts=3,\n            exceptions=(OSError, PermissionError, IOError),\n            path=temp_file,\n            index=False,\n            compression=self.compression\n        )\n\n        # Execute COPY with retry\n        with self.connection() as conn:\n            execute_with_retry(\n                conn.execute,\n                operation_name=f\"COPY command for {table_name}\",\n                max_attempts=3,\n                wait_strategy=\"exponential\",\n                exceptions=(ConnectionError, RuntimeError, OSError),\n                query=copy_sql\n            )\n</code></pre></p>"},{"location":"development/retry-logic/#agent-query-execution","title":"Agent Query Execution","text":"<p>Enhanced agent with retry logic: <pre><code>class LanduseAgent:\n    @database_retry(max_attempts=3, min_wait=1.0, max_wait=10.0, \n                   exceptions=(ConnectionError, TimeoutError, OSError))\n    def _execute_landuse_query(self, sql_query: str) -&gt; str:\n        try:\n            # Query execution with automatic retry on connection issues\n            conn = duckdb.connect(str(self.db_path), read_only=True)\n            result = conn.execute(sql_query)\n            df = result.df()\n            conn.close()\n            return format_query_results(df, sql_query)\n        except (ConnectionError, TimeoutError, OSError):\n            # These will trigger retries via the decorator\n            raise\n        except Exception as e:\n            # Other errors (syntax, etc.) should not be retried\n            return f\"\u274c Error: {e}\"\n</code></pre></p>"},{"location":"development/retry-logic/#configuration","title":"Configuration","text":""},{"location":"development/retry-logic/#environment-variables","title":"Environment Variables","text":"<p>Configure retry behavior via environment variables:</p> <pre><code># Retry configuration\nLANDUSE_DB_RETRY_ATTEMPTS=3\nLANDUSE_DB_RETRY_MIN_WAIT=1.0\nLANDUSE_DB_RETRY_MAX_WAIT=10.0\n\nLANDUSE_API_RETRY_ATTEMPTS=5\nLANDUSE_API_RETRY_BASE_WAIT=2.0\nLANDUSE_API_RETRY_MAX_WAIT=60.0\n\nLANDUSE_FILE_RETRY_ATTEMPTS=3\nLANDUSE_FILE_RETRY_WAIT=2.0\n</code></pre>"},{"location":"development/retry-logic/#pydantic-configuration-model","title":"Pydantic Configuration Model","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass RetryConfig(BaseModel):\n    \"\"\"Configuration for retry behavior\"\"\"\n\n    # Database retries\n    db_max_attempts: int = Field(default=3, ge=1, le=10)\n    db_min_wait: float = Field(default=1.0, ge=0.1, le=60.0)\n    db_max_wait: float = Field(default=10.0, ge=1.0, le=300.0)\n\n    # API retries\n    api_max_attempts: int = Field(default=5, ge=1, le=20)\n    api_base_wait: float = Field(default=2.0, ge=0.1, le=60.0)\n    api_max_wait: float = Field(default=60.0, ge=1.0, le=600.0)\n\n    # File retries\n    file_max_attempts: int = Field(default=3, ge=1, le=10)\n    file_wait_time: float = Field(default=2.0, ge=0.1, le=60.0)\n</code></pre>"},{"location":"development/retry-logic/#best-practices","title":"Best Practices","text":""},{"location":"development/retry-logic/#when-to-use-retries","title":"When to Use Retries","text":"<p>\u2705 Good candidates for retries: - Database connection failures - Network timeouts - Temporary file access issues - API rate limiting (with backoff) - Cloud service intermittent failures</p> <p>\u274c Poor candidates for retries: - SQL syntax errors - Authentication failures - Permission denied errors - Invalid input data - Logic errors in code</p>"},{"location":"development/retry-logic/#retry-strategy-selection","title":"Retry Strategy Selection","text":"<ol> <li>Exponential Backoff (recommended for most cases)</li> <li>Good for handling increasing load</li> <li>Prevents thundering herd problems</li> <li> <p>Self-adapting to system recovery time</p> </li> <li> <p>Fixed Wait (good for known recovery times)</p> </li> <li>Predictable timing</li> <li>Good for file locking scenarios</li> <li> <p>Simple and deterministic</p> </li> <li> <p>Linear Backoff (middle ground)</p> </li> <li>Gradual increase in wait time</li> <li>Less aggressive than exponential</li> <li>Good for rate-limited APIs</li> </ol>"},{"location":"development/retry-logic/#error-classification","title":"Error Classification","text":"<p>Retryable Errors: <pre><code>RETRYABLE_EXCEPTIONS = (\n    ConnectionError,      # Network/DB connection issues\n    TimeoutError,        # Request timeouts\n    OSError,             # System-level errors\n    RuntimeError,        # DuckDB runtime issues (sometimes)\n)\n</code></pre></p> <p>Non-Retryable Errors: <pre><code>NON_RETRYABLE_EXCEPTIONS = (\n    ValueError,          # Input validation errors\n    TypeError,           # Programming errors\n    KeyError,           # Missing keys/columns\n    AttributeError,     # Object attribute errors\n    SyntaxError,        # SQL syntax errors\n    PermissionError,    # Authorization failures (usually)\n)\n</code></pre></p>"},{"location":"development/retry-logic/#monitoring-and-logging","title":"Monitoring and Logging","text":"<p>Rich Console Integration: <pre><code>from rich.console import Console\n\nconsole = Console()\n\n@database_retry(max_attempts=3)\ndef database_operation():\n    try:\n        # Operation logic\n        console.print(\"\u2705 Database operation succeeded\")\n        return result\n    except Exception as e:\n        console.print(f\"\u26a0\ufe0f Database operation failed: {e}\")\n        raise\n</code></pre></p> <p>Structured Logging: <pre><code>import logging\nfrom landuse.utils.retry_decorators import database_retry\n\nlogger = logging.getLogger(__name__)\n\n@database_retry(max_attempts=3)\ndef database_operation():\n    logger.info(\"Starting database operation\")\n    try:\n        result = perform_operation()\n        logger.info(\"Database operation completed successfully\")\n        return result\n    except Exception as e:\n        logger.warning(f\"Database operation failed, will retry: {e}\")\n        raise\n</code></pre></p>"},{"location":"development/retry-logic/#fallback-implementation","title":"Fallback Implementation","text":"<p>When tenacity is not available, the system provides a fallback implementation:</p> <pre><code>def _fallback_retry(max_attempts: int, wait_time: float):\n    \"\"\"Basic retry implementation without tenacity\"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            last_exception = None\n\n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    last_exception = e\n                    if attempt &lt; max_attempts - 1:\n                        console.print(f\"\u26a0\ufe0f Attempt {attempt + 1} failed: {e}\")\n                        console.print(f\"\ud83d\udd04 Retrying in {wait_time}s...\")\n                        time.sleep(wait_time)\n\n            raise last_exception\n        return wrapper\n    return decorator\n</code></pre> <p>Features of fallback: - Basic retry functionality - Fixed wait times - Rich console output - Exception preservation - No external dependencies</p>"},{"location":"development/retry-logic/#testing","title":"Testing","text":""},{"location":"development/retry-logic/#unit-tests","title":"Unit Tests","text":"<pre><code>def test_retry_with_eventual_success():\n    call_count = 0\n\n    @database_retry(max_attempts=3, min_wait=0.1)\n    def mock_operation():\n        nonlocal call_count\n        call_count += 1\n        if call_count &lt; 3:\n            raise ConnectionError(\"Temporary failure\")\n        return \"success\"\n\n    result = mock_operation()\n    assert result == \"success\"\n    assert call_count == 3\n</code></pre>"},{"location":"development/retry-logic/#integration-tests","title":"Integration Tests","text":"<pre><code>def test_database_retry_integration():\n    \"\"\"Test retry behavior with real database operations\"\"\"\n    with temporary_database() as db_path:\n        # Test connection retry\n        @database_retry(max_attempts=3)\n        def connect_and_query():\n            conn = duckdb.connect(db_path)\n            result = conn.execute(\"SELECT 1\").fetchone()\n            conn.close()\n            return result[0]\n\n        result = connect_and_query()\n        assert result == 1\n</code></pre>"},{"location":"development/retry-logic/#mocking-for-tests","title":"Mocking for Tests","text":"<pre><code>from unittest.mock import patch, Mock\n\ndef test_retry_with_mocked_failures():\n    mock_func = Mock()\n    mock_func.side_effect = [\n        ConnectionError(\"First failure\"),\n        ConnectionError(\"Second failure\"), \n        \"success\"\n    ]\n\n    @database_retry(max_attempts=3, min_wait=0.1)\n    def operation():\n        return mock_func()\n\n    result = operation()\n    assert result == \"success\"\n    assert mock_func.call_count == 3\n</code></pre>"},{"location":"development/retry-logic/#performance-considerations","title":"Performance Considerations","text":""},{"location":"development/retry-logic/#retry-overhead","title":"Retry Overhead","text":"<ul> <li>Minimal overhead for successful operations (single decorator call)</li> <li>Exponential cost for failing operations (wait times increase)</li> <li>Memory usage remains constant (no accumulation)</li> </ul>"},{"location":"development/retry-logic/#timing-considerations","title":"Timing Considerations","text":"<pre><code># Fast operations - shorter timeouts\n@database_retry(max_attempts=3, min_wait=0.5, max_wait=5.0)\ndef quick_query():\n    pass\n\n# Slow operations - longer timeouts  \n@database_retry(max_attempts=5, min_wait=2.0, max_wait=60.0)\ndef heavy_computation():\n    pass\n</code></pre>"},{"location":"development/retry-logic/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<p>For high-failure scenarios, consider implementing circuit breaker:</p> <pre><code>from landuse.utils.retry_decorators import RetryableOperation\n\nclass CircuitBreaker:\n    def __init__(self, failure_threshold=5, recovery_timeout=60):\n        self.failure_threshold = failure_threshold\n        self.recovery_timeout = recovery_timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n\n    def call(self, func, *args, **kwargs):\n        if self.state == \"OPEN\":\n            if time.time() - self.last_failure_time &gt; self.recovery_timeout:\n                self.state = \"HALF_OPEN\"\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n\n        try:\n            with RetryableOperation(\"Circuit breaker operation\") as op:\n                result = op.execute(func, *args, **kwargs)\n\n            # Success - reset circuit breaker\n            self.failure_count = 0\n            self.state = \"CLOSED\"\n            return result\n\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n\n            if self.failure_count &gt;= self.failure_threshold:\n                self.state = \"OPEN\"\n\n            raise\n</code></pre>"},{"location":"development/retry-logic/#dependencies","title":"Dependencies","text":""},{"location":"development/retry-logic/#required-dependencies","title":"Required Dependencies","text":"<pre><code># pyproject.toml\n[project]\ndependencies = [\n    \"tenacity&gt;=8.0.0\",  # Advanced retry functionality\n    \"rich&gt;=13.0.0\",     # Console output\n]\n\n[project.optional-dependencies]\nretry = [\n    \"tenacity&gt;=8.0.0\",\n]\n</code></pre>"},{"location":"development/retry-logic/#installation","title":"Installation","text":"<pre><code># Install with retry functionality\nuv add tenacity\n\n# Or install optional retry dependencies\nuv sync --extras retry\n</code></pre>"},{"location":"development/retry-logic/#migration-guide","title":"Migration Guide","text":""},{"location":"development/retry-logic/#adding-retries-to-existing-code","title":"Adding Retries to Existing Code","text":"<ol> <li> <p>Identify retry candidates: <pre><code># Before: No error handling\ndef fragile_operation():\n    conn = duckdb.connect(\"database.duckdb\")\n    return conn.execute(\"SELECT * FROM table\").fetchall()\n</code></pre></p> </li> <li> <p>Add appropriate retry decorator: <pre><code># After: With retry logic\nfrom landuse.utils.retry_decorators import database_retry\n\n@database_retry(max_attempts=3, min_wait=1.0, max_wait=10.0)\ndef robust_operation():\n    try:\n        conn = duckdb.connect(\"database.duckdb\")\n        return conn.execute(\"SELECT * FROM table\").fetchall()\n    except Exception as e:\n        # Convert to retryable exception if appropriate\n        if \"connection\" in str(e).lower():\n            raise ConnectionError(f\"Database connection failed: {e}\")\n        raise  # Re-raise non-retryable exceptions\n</code></pre></p> </li> <li> <p>Test retry behavior: <pre><code># Test with mocked failures\nwith patch('duckdb.connect') as mock_connect:\n    mock_connect.side_effect = [\n        ConnectionError(\"First failure\"),\n        ConnectionError(\"Second failure\"),\n        Mock()  # Success on third attempt\n    ]\n\n    result = robust_operation()\n    assert mock_connect.call_count == 3\n</code></pre></p> </li> </ol>"},{"location":"development/retry-logic/#gradual-migration-strategy","title":"Gradual Migration Strategy","text":"<ol> <li>Phase 1: Add retries to critical database operations</li> <li>Phase 2: Add retries to file I/O operations  </li> <li>Phase 3: Add retries to API calls and network operations</li> <li>Phase 4: Implement circuit breaker for high-failure scenarios</li> </ol>"},{"location":"development/retry-logic/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/retry-logic/#common-issues","title":"Common Issues","text":"<p>Problem: Retries not working <pre><code># Check if tenacity is installed\nfrom landuse.utils.retry_decorators import HAS_TENACITY\nprint(f\"Tenacity available: {HAS_TENACITY}\")\n\n# Verify exception types are retryable\n@database_retry(exceptions=(YourExceptionType,))\ndef your_function():\n    pass\n</code></pre></p> <p>Problem: Too many retries <pre><code># Reduce retry attempts for faster failure\n@database_retry(max_attempts=2, min_wait=0.5, max_wait=5.0)\ndef quick_fail_operation():\n    pass\n</code></pre></p> <p>Problem: Retries too slow <pre><code># Use fixed wait for predictable timing\n@file_retry(max_attempts=3, wait_time=1.0)\ndef fast_retry_operation():\n    pass\n</code></pre></p>"},{"location":"development/retry-logic/#debugging-retry-behavior","title":"Debugging Retry Behavior","text":"<pre><code>import logging\n\n# Enable tenacity logging\nlogging.getLogger('tenacity').setLevel(logging.DEBUG)\n\n# Add custom retry callback\nfrom tenacity import before_sleep_log, after_log\n\n@database_retry(\n    max_attempts=3,\n    before_sleep=before_sleep_log(logging.getLogger(__name__), logging.WARNING),\n    after=after_log(logging.getLogger(__name__), logging.INFO)\n)\ndef debug_operation():\n    pass\n</code></pre>"},{"location":"development/retry-logic/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Overview</li> <li>Contributing Guide</li> <li>Testing Guide</li> <li>CI/CD Pipeline</li> </ul>"},{"location":"development/testing/","title":"Testing Guide","text":"<p>Comprehensive guide for testing the LangChain Land Use Analysis system.</p>"},{"location":"development/testing/#overview","title":"Overview","text":"<p>The project uses a multi-layered testing approach to ensure reliability:</p> <pre><code>graph TD\n    A[Unit Tests] --&gt; B[Integration Tests]\n    B --&gt; C[End-to-End Tests]\n    C --&gt; D[Manual Testing]\n\n    E[Test Data] --&gt; A\n    E --&gt; B\n    E --&gt; C</code></pre>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 conftest.py              # Shared fixtures\n\u251c\u2500\u2500 unit/                    # Unit tests\n\u2502   \u251c\u2500\u2500 test_converters.py\n\u2502   \u251c\u2500\u2500 test_tools.py\n\u2502   \u251c\u2500\u2500 test_validators.py\n\u2502   \u2514\u2500\u2500 test_utils.py\n\u251c\u2500\u2500 integration/             # Integration tests\n\u2502   \u251c\u2500\u2500 test_agent.py\n\u2502   \u251c\u2500\u2500 test_database.py\n\u2502   \u2514\u2500\u2500 test_pipeline.py\n\u251c\u2500\u2500 e2e/                     # End-to-end tests\n\u2502   \u251c\u2500\u2500 test_workflows.py\n\u2502   \u2514\u2500\u2500 test_queries.py\n\u2514\u2500\u2500 data/                    # Test data\n    \u251c\u2500\u2500 sample.json\n    \u251c\u2500\u2500 test.db\n    \u2514\u2500\u2500 fixtures.py\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run specific test file\nuv run pytest tests/unit/test_converters.py\n\n# Run specific test\nuv run pytest tests/unit/test_converters.py::test_land_use_mapping\n\n# Run with coverage\nuv run pytest --cov=scripts --cov-report=html\n\n# Run with verbose output\nuv run pytest -v\n</code></pre>"},{"location":"development/testing/#test-categories","title":"Test Categories","text":"<pre><code># Run only unit tests\nuv run pytest tests/unit/\n\n# Run only integration tests\nuv run pytest tests/integration/\n\n# Run tests by marker\nuv run pytest -m \"not slow\"\n</code></pre>"},{"location":"development/testing/#unit-testing","title":"Unit Testing","text":""},{"location":"development/testing/#testing-converters","title":"Testing Converters","text":"<pre><code># tests/unit/test_converters.py\nimport pytest\nfrom scripts.converters.convert_landuse_to_db import (\n    process_matrix_data, \n    extract_end_year,\n    LAND_USE_MAP\n)\n\nclass TestConverters:\n    def test_land_use_mapping(self):\n        \"\"\"Test land use code mappings.\"\"\"\n        assert LAND_USE_MAP['cr'] == 'Crop'\n        assert LAND_USE_MAP['ps'] == 'Pasture'\n        assert LAND_USE_MAP['ur'] == 'Urban'\n\n    def test_extract_end_year(self):\n        \"\"\"Test year extraction from range.\"\"\"\n        assert extract_end_year('2020-2030') == 2030\n        assert extract_end_year('2090-2100') == 2100\n\n    def test_process_matrix_data(self):\n        \"\"\"Test matrix data processing.\"\"\"\n        matrix_data = [\n            {'_row': 'cr', 'cr': 100.0, 'ur': 5.0, 'fr': 2.0}\n        ]\n\n        transitions = process_matrix_data(\n            matrix_data, \n            'Baseline', \n            2030, \n            '2020-2030', \n            '06037'\n        )\n\n        assert len(transitions) == 3\n        assert transitions[0]['from_land_use'] == 'Crop'\n        assert transitions[0]['area_1000_acres'] == 100.0\n</code></pre>"},{"location":"development/testing/#testing-tools","title":"Testing Tools","text":"<pre><code># tests/unit/test_tools.py\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\n\nclass TestTools:\n    @pytest.fixture\n    def agent(self):\n        \"\"\"Create agent instance for testing.\"\"\"\n        return DataEngineeringAgent(root_dir=\"tests/data\")\n\n    def test_read_csv(self, agent):\n        \"\"\"Test CSV reading tool.\"\"\"\n        result = agent._read_csv(\"sample.csv\")\n        assert \"Shape:\" in result\n        assert \"Columns:\" in result\n\n    def test_analyze_dataframe(self, agent):\n        \"\"\"Test dataframe analysis.\"\"\"\n        result = agent._analyze_dataframe(\"sample.csv\")\n        analysis = json.loads(result)\n        assert \"shape\" in analysis\n        assert \"column_analysis\" in analysis\n\n    @pytest.mark.parametrize(\"file_path,expected\", [\n        (\"data.csv\", \"csv\"),\n        (\"data.json\", \"json\"), \n        (\"data.parquet\", \"parquet\")\n    ])\n    def test_file_format_detection(self, agent, file_path, expected):\n        \"\"\"Test file format detection.\"\"\"\n        format = agent._detect_format(file_path)\n        assert format == expected\n</code></pre>"},{"location":"development/testing/#testing-validators","title":"Testing Validators","text":"<pre><code># tests/unit/test_validators.py\nimport pytest\nfrom pydantic import ValidationError\n\ndef test_query_params_validation():\n    \"\"\"Test query parameter validation.\"\"\"\n    from scripts.agents.data_engineering_agent import FileQueryParams\n\n    # Valid params\n    params = FileQueryParams(\n        file_path=\"data.csv\",\n        query=\"SELECT * FROM data\"\n    )\n    assert params.file_path == \"data.csv\"\n\n    # Invalid params\n    with pytest.raises(ValidationError):\n        FileQueryParams(query=\"SELECT *\")  # Missing file_path\n</code></pre>"},{"location":"development/testing/#integration-testing","title":"Integration Testing","text":""},{"location":"development/testing/#testing-agent-integration","title":"Testing Agent Integration","text":"<pre><code># tests/integration/test_agent.py\nimport pytest\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\n\nclass TestAgentIntegration:\n    @pytest.fixture\n    def agent(self):\n        \"\"\"Create real agent instance.\"\"\"\n        return DataEngineeringAgent()\n\n    def test_natural_language_query(self, agent):\n        \"\"\"Test natural language to SQL conversion.\"\"\"\n        result = agent.run(\"Show me all tables in test.db\")\n        assert \"Tables:\" in result\n        assert \"rows\" in result\n\n    def test_multi_step_query(self, agent):\n        \"\"\"Test agent memory and context.\"\"\"\n        # First query\n        result1 = agent.run(\"Read sample.csv\")\n        assert \"Shape:\" in result1\n\n        # Follow-up query using context\n        result2 = agent.run(\"Now query it for values &gt; 100\")\n        assert \"Query Result\" in result2\n\n    @pytest.mark.slow\n    def test_large_file_processing(self, agent):\n        \"\"\"Test handling of large files.\"\"\"\n        result = agent.run(\"Process large_dataset.json\")\n        assert \"LARGE FILE\" in result\n</code></pre>"},{"location":"development/testing/#testing-database-operations","title":"Testing Database Operations","text":"<pre><code># tests/integration/test_database.py\nimport sqlite3\nimport pytest\n\nclass TestDatabaseIntegration:\n    @pytest.fixture\n    def test_db(self, tmp_path):\n        \"\"\"Create test database.\"\"\"\n        db_path = tmp_path / \"test.db\"\n        conn = sqlite3.connect(db_path)\n\n        # Create test schema\n        conn.execute(\"\"\"\n            CREATE TABLE landuse_transitions (\n                scenario TEXT,\n                year INTEGER,\n                from_land_use TEXT,\n                to_land_use TEXT,\n                area_1000_acres REAL\n            )\n        \"\"\")\n\n        # Insert test data\n        test_data = [\n            ('Baseline', 2030, 'Forest', 'Urban', 100.5),\n            ('Baseline', 2030, 'Crop', 'Urban', 50.2)\n        ]\n        conn.executemany(\n            \"INSERT INTO landuse_transitions VALUES (?,?,?,?,?)\",\n            test_data\n        )\n        conn.commit()\n        conn.close()\n\n        return db_path\n\n    def test_database_query(self, agent, test_db):\n        \"\"\"Test database querying.\"\"\"\n        result = agent.run(f\"Query {test_db}: SELECT COUNT(*) FROM landuse_transitions\")\n        assert \"2\" in result\n</code></pre>"},{"location":"development/testing/#end-to-end-testing","title":"End-to-End Testing","text":""},{"location":"development/testing/#testing-complete-workflows","title":"Testing Complete Workflows","text":"<pre><code># tests/e2e/test_workflows.py\nimport pytest\nfrom pathlib import Path\n\nclass TestWorkflows:\n    def test_county_analysis_workflow(self, agent):\n        \"\"\"Test complete county analysis workflow.\"\"\"\n        # Step 1: Identify county\n        result = agent.run(\"What's the FIPS code for Los Angeles County?\")\n        assert \"06037\" in result\n\n        # Step 2: Get current land use\n        result = agent.run(\"Show land use for FIPS 06037 in 2020\")\n        assert \"Urban\" in result\n        assert \"Forest\" in result\n\n        # Step 3: Analyze changes\n        result = agent.run(\"Show land use changes for this county through 2050\")\n        assert \"transitions\" in result.lower()\n\n        # Step 4: Export results\n        result = agent.run(\"Export this analysis to la_county_analysis.csv\")\n        assert Path(\"la_county_analysis.csv\").exists()\n\n    def test_scenario_comparison_workflow(self, agent):\n        \"\"\"Test scenario comparison workflow.\"\"\"\n        queries = [\n            \"List all available scenarios\",\n            \"Compare forest area between scenarios in 2050\",\n            \"Which scenario preserves the most forest?\",\n            \"Create a summary table of scenario differences\"\n        ]\n\n        for query in queries:\n            result = agent.run(query)\n            assert \"Error\" not in result\n</code></pre>"},{"location":"development/testing/#testing-query-patterns","title":"Testing Query Patterns","text":"<pre><code># tests/e2e/test_queries.py\nimport pytest\n\nclass TestQueryPatterns:\n    @pytest.mark.parametrize(\"query,expected_terms\", [\n        (\"Show forest loss\", [\"Forest\", \"area\", \"decrease\"]),\n        (\"Urban growth by decade\", [\"Urban\", \"decade\", \"growth\"]),\n        (\"Agricultural transitions\", [\"Crop\", \"Pasture\", \"transition\"])\n    ])\n    def test_query_understanding(self, agent, query, expected_terms):\n        \"\"\"Test that queries return relevant results.\"\"\"\n        result = agent.run(query)\n        for term in expected_terms:\n            assert term in result or term.lower() in result.lower()\n</code></pre>"},{"location":"development/testing/#test-data-management","title":"Test Data Management","text":""},{"location":"development/testing/#creating-test-fixtures","title":"Creating Test Fixtures","text":"<pre><code># tests/data/fixtures.py\nimport json\nimport sqlite3\nfrom pathlib import Path\n\ndef create_test_json():\n    \"\"\"Create minimal test JSON data.\"\"\"\n    test_data = {\n        \"06037\": {\n            \"county_name\": \"Los Angeles\",\n            \"scenarios\": {\n                \"Baseline\": {\n                    \"2020-2030\": {\n                        \"transition_matrix\": [\n                            {\"_row\": \"cr\", \"cr\": 100, \"ur\": 10},\n                            {\"_row\": \"ur\", \"cr\": 0, \"ur\": 200}\n                        ]\n                    }\n                }\n            }\n        }\n    }\n\n    with open(\"tests/data/test.json\", \"w\") as f:\n        json.dump(test_data, f)\n\ndef create_test_database():\n    \"\"\"Create minimal test database.\"\"\"\n    conn = sqlite3.connect(\"tests/data/test.db\")\n\n    # Create schema\n    conn.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS landuse_transitions (\n            scenario TEXT,\n            year INTEGER,\n            fips TEXT,\n            from_land_use TEXT,\n            to_land_use TEXT,\n            area_1000_acres REAL\n        )\n    \"\"\")\n\n    # Insert test data\n    conn.execute(\"\"\"\n        INSERT INTO landuse_transitions VALUES\n        ('Baseline', 2030, '06037', 'Forest', 'Urban', 100.5)\n    \"\"\")\n\n    conn.commit()\n    conn.close()\n</code></pre>"},{"location":"development/testing/#test-data-best-practices","title":"Test Data Best Practices","text":"<ol> <li>Keep It Minimal: Use smallest dataset that tests functionality</li> <li>Make It Readable: Clear, understandable test data</li> <li>Version Control: Include test data in repository</li> <li>Isolation: Each test should be independent</li> </ol>"},{"location":"development/testing/#mocking-and-fixtures","title":"Mocking and Fixtures","text":""},{"location":"development/testing/#mocking-llm-responses","title":"Mocking LLM Responses","text":"<pre><code># tests/conftest.py\nimport pytest\nfrom unittest.mock import Mock, patch\n\n@pytest.fixture\ndef mock_llm():\n    \"\"\"Mock LLM for testing without API calls.\"\"\"\n    with patch('langchain_openai.ChatOpenAI') as mock:\n        instance = Mock()\n        instance.invoke.return_value = Mock(content=\"Mocked response\")\n        mock.return_value = instance\n        yield instance\n\n@pytest.fixture\ndef agent_with_mock_llm(mock_llm):\n    \"\"\"Agent instance with mocked LLM.\"\"\"\n    from scripts.agents.data_engineering_agent import DataEngineeringAgent\n    agent = DataEngineeringAgent()\n    agent.llm = mock_llm\n    return agent\n</code></pre>"},{"location":"development/testing/#database-fixtures","title":"Database Fixtures","text":"<pre><code>@pytest.fixture\ndef temp_database(tmp_path):\n    \"\"\"Create temporary database for testing.\"\"\"\n    db_path = tmp_path / \"temp.db\"\n\n    # Create and populate\n    conn = sqlite3.connect(db_path)\n    # ... setup schema and data ...\n    conn.close()\n\n    yield db_path\n\n    # Cleanup happens automatically with tmp_path\n</code></pre>"},{"location":"development/testing/#performance-testing","title":"Performance Testing","text":""},{"location":"development/testing/#benchmarking-queries","title":"Benchmarking Queries","text":"<pre><code># tests/performance/test_performance.py\nimport pytest\nimport time\n\nclass TestPerformance:\n    @pytest.mark.benchmark\n    def test_query_performance(self, agent, benchmark):\n        \"\"\"Benchmark query execution time.\"\"\"\n        def run_query():\n            return agent.run(\"SELECT COUNT(*) FROM landuse_transitions\")\n\n        result = benchmark(run_query)\n        assert \"Error\" not in result\n\n    def test_large_file_processing_speed(self, agent):\n        \"\"\"Test processing speed for large files.\"\"\"\n        start_time = time.time()\n        result = agent.run(\"Process large_test_file.json\")\n        duration = time.time() - start_time\n\n        assert duration &lt; 60  # Should complete within 1 minute\n        assert \"Error\" not in result\n</code></pre>"},{"location":"development/testing/#manual-testing-checklist","title":"Manual Testing Checklist","text":""},{"location":"development/testing/#agent-functionality","title":"Agent Functionality","text":"<ul> <li> Agent starts without errors</li> <li> Natural language queries work</li> <li> File operations complete successfully</li> <li> Database queries return results</li> <li> Error messages are helpful</li> <li> Memory/context works between queries</li> </ul>"},{"location":"development/testing/#query-testing","title":"Query Testing","text":"<ul> <li> Basic queries (\"Show me all tables\")</li> <li> Complex queries (multi-condition WHERE)</li> <li> Aggregation queries (GROUP BY, SUM)</li> <li> Join queries (if applicable)</li> <li> Export functionality works</li> <li> Visualization generation works</li> </ul>"},{"location":"development/testing/#edge-cases","title":"Edge Cases","text":"<ul> <li> Empty database handling</li> <li> Missing file handling</li> <li> Invalid query syntax</li> <li> Large result sets</li> <li> Special characters in data</li> <li> Concurrent operations</li> </ul>"},{"location":"development/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"development/testing/#github-actions-configuration","title":"GitHub Actions Configuration","text":"<pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n\n    - name: Install dependencies\n      run: |\n        pip install uv\n        uv pip install -r config/requirements.txt\n\n    - name: Run tests\n      env:\n        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n      run: |\n        uv run pytest --cov=scripts --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"development/testing/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"development/testing/#1-test-organization","title":"1. Test Organization","text":"<ul> <li>Group related tests in classes</li> <li>Use descriptive test names</li> <li>One assertion per test (when possible)</li> <li>Use fixtures for common setup</li> </ul>"},{"location":"development/testing/#2-test-independence","title":"2. Test Independence","text":"<ul> <li>Tests should not depend on each other</li> <li>Clean up after tests</li> <li>Use temporary files/databases</li> <li>Reset agent state between tests</li> </ul>"},{"location":"development/testing/#3-test-coverage","title":"3. Test Coverage","text":"<ul> <li>Aim for &gt;80% code coverage</li> <li>Test happy paths and edge cases</li> <li>Test error conditions</li> <li>Test performance characteristics</li> </ul>"},{"location":"development/testing/#4-test-documentation","title":"4. Test Documentation","text":"<pre><code>def test_complex_scenario():\n    \"\"\"\n    Test that scenario comparison works correctly.\n\n    This test verifies:\n    1. Multiple scenarios can be loaded\n    2. Comparisons calculate differences correctly\n    3. Results are formatted properly\n    \"\"\"\n    # Test implementation\n</code></pre>"},{"location":"development/testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"development/testing/#running-tests-in-debug-mode","title":"Running Tests in Debug Mode","text":"<pre><code># Run with debugger\nuv run pytest --pdb\n\n# Run with print statements visible\nuv run pytest -s\n\n# Run with full traceback\nuv run pytest --tb=long\n</code></pre>"},{"location":"development/testing/#common-test-issues","title":"Common Test Issues","text":"<ol> <li>Import Errors: Ensure PYTHONPATH includes project root</li> <li>API Key Issues: Mock LLM calls or use test keys</li> <li>File Path Issues: Use relative paths or fixtures</li> <li>Database Locks: Ensure connections are closed</li> </ol>"},{"location":"development/testing/#next-steps","title":"Next Steps","text":"<ul> <li>Review Architecture for system design</li> <li>See Contributing for development workflow</li> <li>Check API Reference for implementation details</li> </ul>"},{"location":"examples/notebooks/","title":"Jupyter Notebook Examples","text":"<p>Interactive Jupyter notebooks for exploring land use data with the LangChain agent.</p>"},{"location":"examples/notebooks/#overview","title":"Overview","text":"<p>Jupyter notebooks provide an interactive environment for data exploration, visualization, and analysis. This page contains example notebooks demonstrating various use cases.</p>"},{"location":"examples/notebooks/#getting-started-with-notebooks","title":"Getting Started with Notebooks","text":""},{"location":"examples/notebooks/#setup","title":"Setup","text":"<pre><code># Install Jupyter\nuv pip install jupyter ipykernel\n\n# Create kernel for this project\nuv run python -m ipykernel install --name langchain-landuse --user\n\n# Start Jupyter\nuv run jupyter notebook\n</code></pre>"},{"location":"examples/notebooks/#example-notebooks","title":"Example Notebooks","text":""},{"location":"examples/notebooks/#1-basic-agent-interaction","title":"1. Basic Agent Interaction","text":"<p>Notebook: <code>01_basic_agent_usage.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nfrom rich.console import Console\n\nconsole = Console()\nagent = DataEngineeringAgent()\n\n# Cell 2: Basic Query\nresult = agent.run(\"Show me all tables in landuse_transitions.db\")\nprint(result)\n\n# Cell 3: Explore Schema\nresult = agent.run(\"Describe the landuse_transitions table\")\nprint(result)\n\n# Cell 4: Simple Analysis\nresult = agent.run(\"What are the total land areas by type in 2050?\")\nprint(result)\n</code></pre>"},{"location":"examples/notebooks/#2-land-use-transition-analysis","title":"2. Land Use Transition Analysis","text":"<p>Notebook: <code>02_transition_analysis.ipynb</code></p> <pre><code># Cell 1: Import and Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Query Transition Data\nquery = \"\"\"\nQuery processed/landuse_transitions.db:\nSELECT from_land_use, to_land_use, SUM(area_1000_acres) as total_area\nFROM landuse_transitions\nWHERE scenario = 'Baseline' AND year = 2050\nGROUP BY from_land_use, to_land_use\nORDER BY total_area DESC\n\"\"\"\nresult = agent.run(query)\n\n# Cell 3: Parse Results to DataFrame\n# Extract data from agent response\n# This would need parsing logic based on agent output format\n\n# Cell 4: Create Transition Matrix Visualization\n# Create pivot table\ntransition_matrix = df.pivot(\n    index='from_land_use', \n    columns='to_land_use', \n    values='total_area'\n)\n\n# Heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(transition_matrix, annot=True, fmt='.0f', cmap='YlOrRd')\nplt.title('Land Use Transition Matrix (1000 acres)')\nplt.xlabel('To Land Use')\nplt.ylabel('From Land Use')\nplt.show()\n</code></pre>"},{"location":"examples/notebooks/#3-scenario-comparison","title":"3. Scenario Comparison","text":"<p>Notebook: <code>03_scenario_comparison.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nagent = DataEngineeringAgent()\nscenarios = ['Baseline', 'High Crop Demand', 'High Forest', 'High Urban']\n\n# Cell 2: Query Multiple Scenarios\nresults = {}\nfor scenario in scenarios:\n    query = f\"\"\"\n    Query processed/landuse_transitions.db:\n    SELECT year, to_land_use, SUM(area_1000_acres) as area\n    FROM landuse_transitions\n    WHERE scenario = '{scenario}' \n      AND from_land_use = to_land_use\n      AND to_land_use != 'Total'\n    GROUP BY year, to_land_use\n    \"\"\"\n    results[scenario] = agent.run(query)\n\n# Cell 3: Process and Visualize\n# Parse results into DataFrames\n# Create multi-panel plot\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\naxes = axes.flatten()\n\nfor idx, scenario in enumerate(scenarios):\n    ax = axes[idx]\n    # Plot logic here\n    ax.set_title(f'{scenario} Scenario')\n    ax.set_xlabel('Year')\n    ax.set_ylabel('Area (1000 acres)')\n    ax.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"examples/notebooks/#4-geographic-analysis","title":"4. Geographic Analysis","text":"<p>Notebook: <code>04_geographic_patterns.ipynb</code></p> <pre><code># Cell 1: Setup with Geospatial Libraries\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Query County-Level Changes\nquery = \"\"\"\nQuery processed/landuse_transitions.db:\nSELECT fips, \n       SUM(CASE WHEN to_land_use = 'Urban' THEN area_1000_acres ELSE 0 END) -\n       SUM(CASE WHEN from_land_use = 'Urban' THEN area_1000_acres ELSE 0 END) as urban_change\nFROM landuse_transitions\nWHERE scenario = 'Baseline' AND year = 2050\nGROUP BY fips\n\"\"\"\nresult = agent.run(query)\n\n# Cell 3: Load County Boundaries\n# Assuming you have county shapefiles\ncounties = gpd.read_file('data/counties.shp')\n\n# Cell 4: Create Choropleth Map\nfig, ax = plt.subplots(1, 1, figsize=(15, 10))\n\n# Merge data with geometries\n# Create map\ncounties.plot(\n    column='urban_change',\n    ax=ax,\n    legend=True,\n    cmap='RdYlBu_r',\n    legend_kwds={'label': 'Urban Change (1000 acres)'}\n)\n\nax.set_title('Urban Land Change by County (2020-2050)', fontsize=16)\nax.axis('off')\nplt.show()\n</code></pre>"},{"location":"examples/notebooks/#5-time-series-analysis","title":"5. Time Series Analysis","text":"<p>Notebook: <code>05_time_series.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Query Time Series Data\nquery = \"\"\"\nQuery processed/landuse_transitions.db:\nSELECT year, to_land_use, SUM(area_1000_acres) as total_area\nFROM landuse_transitions\nWHERE scenario = 'Baseline' \n  AND from_land_use = to_land_use\n  AND to_land_use IN ('Crop', 'Forest', 'Urban', 'Pasture')\nGROUP BY year, to_land_use\nORDER BY year, to_land_use\n\"\"\"\nresult = agent.run(query)\n\n# Cell 3: Create Animated Visualization\n# Parse data\n# Create animation showing land use change over time\n\n# Cell 4: Trend Analysis\n# Calculate growth rates\n# Fit trend lines\n# Project future values\n</code></pre>"},{"location":"examples/notebooks/#6-natural-language-query-explorer","title":"6. Natural Language Query Explorer","text":"<p>Notebook: <code>06_query_explorer.ipynb</code></p> <pre><code># Cell 1: Interactive Query Interface\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nfrom ipywidgets import interact, widgets\nfrom IPython.display import display, HTML\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Create Query Widget\nquery_input = widgets.Textarea(\n    value='Show me forest loss by decade',\n    placeholder='Enter your natural language query',\n    description='Query:',\n    layout=widgets.Layout(width='100%', height='100px')\n)\n\noutput = widgets.Output()\n\ndef run_query(b):\n    with output:\n        output.clear_output()\n        print(f\"Running: {query_input.value}\")\n        result = agent.run(query_input.value)\n        print(\"\\nResult:\")\n        print(result)\n\nbutton = widgets.Button(description=\"Run Query\")\nbutton.on_click(run_query)\n\ndisplay(query_input, button, output)\n\n# Cell 3: Query Templates\ntemplates = {\n    \"Forest Analysis\": \"Show me counties with the most forest loss\",\n    \"Urban Growth\": \"Which areas have the fastest urban expansion?\",\n    \"Agricultural\": \"Compare crop and pasture changes over time\",\n    \"Scenarios\": \"How do the different scenarios compare for urban growth?\"\n}\n\nfor name, query in templates.items():\n    btn = widgets.Button(description=name)\n    btn.on_click(lambda b, q=query: query_input.value.update(q))\n    display(btn)\n</code></pre>"},{"location":"examples/notebooks/#7-statistical-analysis","title":"7. Statistical Analysis","text":"<p>Notebook: <code>07_statistical_analysis.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.api as sm\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Get Data for Statistical Analysis\n# Query for correlations between land use changes\n\n# Cell 3: Correlation Analysis\n# Calculate correlation matrix\n# Test for significant correlations\n\n# Cell 4: Regression Analysis\n# Predict urban growth based on other factors\n\n# Cell 5: Statistical Tests\n# Test hypothesis about land use changes\n# ANOVA for scenario comparisons\n</code></pre>"},{"location":"examples/notebooks/#best-practices-for-notebooks","title":"Best Practices for Notebooks","text":""},{"location":"examples/notebooks/#1-organization","title":"1. Organization","text":"<pre><code># Clear section headers\n# %% [markdown]\n# # Section 1: Data Loading\n\n# %% \n# Code for data loading\n\n# %% [markdown]\n# # Section 2: Analysis\n\n# %%\n# Analysis code\n</code></pre>"},{"location":"examples/notebooks/#2-reproducibility","title":"2. Reproducibility","text":"<pre><code># Cell 1: Always set random seeds\nimport random\nimport numpy as np\n\nrandom.seed(42)\nnp.random.seed(42)\n\n# Cell 2: Document package versions\nimport sys\nprint(f\"Python: {sys.version}\")\nprint(f\"Pandas: {pd.__version__}\")\n</code></pre>"},{"location":"examples/notebooks/#3-error-handling","title":"3. Error Handling","text":"<pre><code># Wrap agent calls in try-except\ntry:\n    result = agent.run(query)\n    # Process result\nexcept Exception as e:\n    print(f\"Query failed: {e}\")\n    # Handle error gracefully\n</code></pre>"},{"location":"examples/notebooks/#4-visualization-standards","title":"4. Visualization Standards","text":"<pre><code># Set consistent plot style\nplt.style.use('seaborn-v0_8-darkgrid')\n\n# Create reusable plot function\ndef plot_land_use_trends(data, title):\n    fig, ax = plt.subplots(figsize=(12, 6))\n    # Plotting logic\n    ax.set_title(title, fontsize=16)\n    ax.set_xlabel('Year')\n    ax.set_ylabel('Area (1000 acres)')\n    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n    plt.tight_layout()\n    return fig\n</code></pre>"},{"location":"examples/notebooks/#sharing-notebooks","title":"Sharing Notebooks","text":""},{"location":"examples/notebooks/#export-options","title":"Export Options","text":"<pre><code># Export to HTML\njupyter nbconvert --to html notebook.ipynb\n\n# Export to PDF\njupyter nbconvert --to pdf notebook.ipynb\n\n# Export to Python script\njupyter nbconvert --to python notebook.ipynb\n</code></pre>"},{"location":"examples/notebooks/#notebook-templates","title":"Notebook Templates","text":"<p>Create template notebooks for common analyses:</p> <ol> <li><code>template_county_analysis.ipynb</code> - County-specific analysis</li> <li><code>template_scenario_comparison.ipynb</code> - Compare scenarios</li> <li><code>template_time_series.ipynb</code> - Temporal analysis</li> <li><code>template_visualization.ipynb</code> - Creating charts</li> </ol>"},{"location":"examples/notebooks/#interactive-dashboards","title":"Interactive Dashboards","text":""},{"location":"examples/notebooks/#using-voila","title":"Using Voila","text":"<pre><code># Install Voila\nuv pip install voila\n\n# Create dashboard from notebook\nvoila dashboard_notebook.ipynb\n</code></pre>"},{"location":"examples/notebooks/#example-dashboard-code","title":"Example Dashboard Code","text":"<pre><code># Cell 1: Dashboard Setup\nimport ipywidgets as widgets\nfrom IPython.display import display\nimport plotly.graph_objects as go\n\n# Create controls\nscenario_dropdown = widgets.Dropdown(\n    options=['Baseline', 'High Crop Demand', 'High Forest', 'High Urban'],\n    description='Scenario:'\n)\n\nyear_slider = widgets.IntSlider(\n    value=2050,\n    min=2020,\n    max=2100,\n    step=10,\n    description='Year:'\n)\n\n# Cell 2: Interactive Plot\n@widgets.interact(scenario=scenario_dropdown, year=year_slider)\ndef update_plot(scenario, year):\n    # Query data\n    query = f\"\"\"\n    Query processed/landuse_transitions.db:\n    SELECT to_land_use, SUM(area_1000_acres) as area\n    FROM landuse_transitions\n    WHERE scenario = '{scenario}' AND year = {year}\n    GROUP BY to_land_use\n    \"\"\"\n\n    result = agent.run(query)\n    # Parse and plot with Plotly\n</code></pre>"},{"location":"examples/notebooks/#resources","title":"Resources","text":""},{"location":"examples/notebooks/#example-notebook-repository","title":"Example Notebook Repository","text":"<p>Find complete example notebooks at: - GitHub: <code>examples/notebooks/</code> - Each notebook includes:   - Full code   - Expected outputs   - Explanations   - Exercises</p>"},{"location":"examples/notebooks/#learning-resources","title":"Learning Resources","text":"<ol> <li>Jupyter Documentation: https://jupyter.org/documentation</li> <li>Pandas Tutorials: For data manipulation</li> <li>Matplotlib Gallery: For visualization ideas</li> <li>Geopandas Examples: For geographic analysis</li> </ol>"},{"location":"examples/notebooks/#next-steps","title":"Next Steps","text":"<ul> <li>Download example notebooks from the repository</li> <li>Try modifying queries for your specific needs</li> <li>Create custom visualizations</li> <li>Share your notebooks with the community</li> </ul>"},{"location":"examples/use-cases/","title":"Real-World Use Cases","text":"<p>Practical applications of the LangChain Land Use Analysis system for various stakeholders and decision-making scenarios.</p>"},{"location":"examples/use-cases/#policy-analysis","title":"\ud83c\udfdb\ufe0f Policy Analysis","text":""},{"location":"examples/use-cases/#use-case-evaluating-conservation-policy-impact","title":"Use Case: Evaluating Conservation Policy Impact","text":"<p>Scenario: A state environmental agency wants to assess the effectiveness of forest conservation policies.</p> <p>Approach: <pre><code>You&gt; Compare forest area outcomes between the Baseline and High Forest scenarios for our state\n\nYou&gt; Which counties show the biggest difference in forest preservation between these scenarios?\n\nYou&gt; Calculate the total forest area saved under the High Forest scenario by 2050\n\nYou&gt; What types of land use conversions are prevented in the High Forest scenario?\n</code></pre></p> <p>Insights Generated: - Quantify conservation policy benefits - Identify high-impact counties - Understand trade-offs with other land uses - Support funding allocation decisions</p>"},{"location":"examples/use-cases/#use-case-agricultural-policy-planning","title":"Use Case: Agricultural Policy Planning","text":"<p>Scenario: USDA needs to understand future agricultural land availability.</p> <p>Analysis Workflow: 1. Assess total agricultural land trends 2. Identify regions losing farmland 3. Compare crop vs. pasture dynamics 4. Evaluate scenario impacts</p> <pre><code>You&gt; Show me the net change in agricultural land (crop + pasture) by decade for each scenario\n\nYou&gt; Which regions are losing agricultural land the fastest?\n\nYou&gt; In the High Crop Demand scenario, where does the additional cropland come from?\n\nYou&gt; Project when agricultural land might fall below critical thresholds in major farming states\n</code></pre>"},{"location":"examples/use-cases/#urban-planning","title":"\ud83c\udfd7\ufe0f Urban Planning","text":""},{"location":"examples/use-cases/#use-case-metropolitan-growth-management","title":"Use Case: Metropolitan Growth Management","text":"<p>Scenario: A regional planning council needs to prepare for urban expansion.</p> <p>Key Questions: <pre><code>You&gt; Map urban growth projections for our metropolitan area through 2100\n\nYou&gt; What are the primary sources of land for urban expansion in our region?\n\nYou&gt; Compare urban growth rates between the Baseline and High Urban scenarios\n\nYou&gt; Which adjacent counties will experience the most development pressure?\n</code></pre></p> <p>Applications: - Infrastructure planning - Transportation network design - Utility capacity planning - Housing development strategies</p>"},{"location":"examples/use-cases/#use-case-smart-growth-analysis","title":"Use Case: Smart Growth Analysis","text":"<p>Scenario: City planners want to minimize sprawl and protect natural areas.</p> <p>Investigation Process: <pre><code>You&gt; Find examples of counties that accommodate urban growth while preserving forest\n\nYou&gt; Calculate the efficiency of urban land use (area per projected population)\n\nYou&gt; Identify counties with the most compact urban development patterns\n\nYou&gt; Show me areas where urban growth threatens critical natural habitats\n</code></pre></p>"},{"location":"examples/use-cases/#environmental-assessment","title":"\ud83c\udf0d Environmental Assessment","text":""},{"location":"examples/use-cases/#use-case-climate-change-mitigation","title":"Use Case: Climate Change Mitigation","text":"<p>Scenario: Environmental groups need data on land use impacts on carbon storage.</p> <p>Carbon Analysis Queries: <pre><code>You&gt; Calculate total forest area changes that impact carbon sequestration\n\nYou&gt; Which scenario maintains the most carbon-storing land uses?\n\nYou&gt; Show me the trade-off between agricultural expansion and forest carbon storage\n\nYou&gt; Identify counties where reforestation could have the biggest impact\n</code></pre></p> <p>Decision Support: - Carbon credit program design - Reforestation prioritization - Climate policy advocacy - Investment targeting</p>"},{"location":"examples/use-cases/#use-case-watershed-protection","title":"Use Case: Watershed Protection","text":"<p>Scenario: Water management districts need to protect water resources.</p> <p>Watershed Analysis: <pre><code>You&gt; Show land use changes in counties within our watershed\n\nYou&gt; How much forest buffer is lost along waterways?\n\nYou&gt; Which scenarios best protect natural land in water-sensitive areas?\n\nYou&gt; Calculate impervious surface increase from urban expansion\n</code></pre></p>"},{"location":"examples/use-cases/#economic-development","title":"\ud83d\udcca Economic Development","text":""},{"location":"examples/use-cases/#use-case-rural-economic-planning","title":"Use Case: Rural Economic Planning","text":"<p>Scenario: Rural counties need to plan for economic transitions.</p> <p>Economic Analysis: <pre><code>You&gt; Identify rural counties with significant agricultural land loss\n\nYou&gt; What's replacing agricultural land in rural areas?\n\nYou&gt; Show me counties successfully maintaining agricultural economies\n\nYou&gt; Compare economic land use patterns between thriving and declining rural counties\n</code></pre></p> <p>Strategic Planning: - Economic diversification strategies - Agricultural preservation programs - Tourism development opportunities - Infrastructure investments</p>"},{"location":"examples/use-cases/#use-case-real-estate-market-analysis","title":"Use Case: Real Estate Market Analysis","text":"<p>Scenario: Real estate developers need long-term market insights.</p> <p>Market Research Queries: <pre><code>You&gt; Which counties will have the most urban growth pressure?\n\nYou&gt; Show me areas transitioning from agricultural to urban use\n\nYou&gt; Identify counties with limited developable land by 2050\n\nYou&gt; Compare development potential across different scenarios\n</code></pre></p>"},{"location":"examples/use-cases/#conservation-planning","title":"\ud83c\udfde\ufe0f Conservation Planning","text":""},{"location":"examples/use-cases/#use-case-habitat-corridor-design","title":"Use Case: Habitat Corridor Design","text":"<p>Scenario: Conservation organizations planning wildlife corridors.</p> <p>Connectivity Analysis: <pre><code>You&gt; Show me forest fragmentation patterns over time\n\nYou&gt; Which counties maintain the largest contiguous forest areas?\n\nYou&gt; Identify critical linkages between protected areas threatened by development\n\nYou&gt; Calculate habitat loss for forest-dependent species\n</code></pre></p> <p>Conservation Strategy: - Land acquisition priorities - Conservation easement targeting - Habitat restoration planning - Species protection strategies</p>"},{"location":"examples/use-cases/#use-case-biodiversity-hotspot-protection","title":"Use Case: Biodiversity Hotspot Protection","text":"<p>Scenario: Protecting areas of high biodiversity value.</p> <p>Biodiversity Queries: <pre><code>You&gt; Identify counties with diverse land use types that support biodiversity\n\nYou&gt; Show me areas where multiple natural land types are converting to developed uses\n\nYou&gt; Which scenario best maintains landscape heterogeneity?\n\nYou&gt; Find counties where conservation could protect multiple ecosystem types\n</code></pre></p>"},{"location":"examples/use-cases/#agricultural-sustainability","title":"\ud83c\udf3e Agricultural Sustainability","text":""},{"location":"examples/use-cases/#use-case-food-security-assessment","title":"Use Case: Food Security Assessment","text":"<p>Scenario: State agricultural departments assessing future food production capacity.</p> <p>Food Security Analysis: <pre><code>You&gt; Calculate total cropland availability by decade\n\nYou&gt; Show me the balance between population growth and agricultural land\n\nYou&gt; Which regions maintain the most productive agricultural land?\n\nYou&gt; Identify counties at risk of losing critical agricultural infrastructure\n</code></pre></p> <p>Policy Applications: - Farmland preservation programs - Agricultural zoning policies - Food system planning - Investment priorities</p>"},{"location":"examples/use-cases/#use-case-sustainable-farming-transitions","title":"Use Case: Sustainable Farming Transitions","text":"<p>Scenario: Supporting transitions to sustainable agriculture.</p> <p>Sustainability Queries: <pre><code>You&gt; Show me areas transitioning between crop and pasture (indicating diverse farming)\n\nYou&gt; Identify counties with stable agricultural land use patterns\n\nYou&gt; Which areas show agricultural intensification vs. extensification?\n\nYou&gt; Find opportunities for agricultural conservation programs\n</code></pre></p>"},{"location":"examples/use-cases/#investment-analysis","title":"\ud83d\udcc8 Investment Analysis","text":""},{"location":"examples/use-cases/#use-case-green-infrastructure-investment","title":"Use Case: Green Infrastructure Investment","text":"<p>Scenario: Impact investors seeking environmental returns.</p> <p>Investment Research: <pre><code>You&gt; Identify counties where forest conservation has the highest value\n\nYou&gt; Show me areas with opportunities for agricultural sustainability investments\n\nYou&gt; Which regions show the best potential for natural climate solutions?\n\nYou&gt; Calculate potential returns from ecosystem service payments\n</code></pre></p>"},{"location":"examples/use-cases/#use-case-infrastructure-planning","title":"Use Case: Infrastructure Planning","text":"<p>Scenario: State DOT planning long-term transportation investments.</p> <p>Infrastructure Analysis: <pre><code>You&gt; Show me projected urban growth along major transportation corridors\n\nYou&gt; Which rural areas will urbanize and need infrastructure upgrades?\n\nYou&gt; Identify counties where agricultural traffic will increase\n\nYou&gt; Calculate future infrastructure demand based on land use changes\n</code></pre></p>"},{"location":"examples/use-cases/#integrated-assessments","title":"\ud83d\udd04 Integrated Assessments","text":""},{"location":"examples/use-cases/#use-case-comprehensive-sustainability-assessment","title":"Use Case: Comprehensive Sustainability Assessment","text":"<p>Scenario: Multi-stakeholder coalition evaluating regional sustainability.</p> <p>Holistic Analysis Approach:</p> <pre><code># Step 1: Environmental Health\nYou&gt; Calculate natural land preservation rates by scenario\n\n# Step 2: Economic Viability  \nYou&gt; Assess agricultural economic sustainability\n\n# Step 3: Social Equity\nYou&gt; Identify communities most impacted by land use change\n\n# Step 4: Integrated Score\nYou&gt; Create a composite sustainability index combining all factors\n</code></pre> <p>Stakeholder Benefits: - Shared understanding of trade-offs - Evidence-based compromise - Long-term vision alignment - Performance monitoring framework</p>"},{"location":"examples/use-cases/#best-practices-for-use-cases","title":"Best Practices for Use Cases","text":""},{"location":"examples/use-cases/#1-start-with-clear-objectives","title":"1. Start with Clear Objectives","text":"<ul> <li>Define specific decisions to support</li> <li>Identify key metrics</li> <li>Set analysis boundaries</li> <li>Determine required precision</li> </ul>"},{"location":"examples/use-cases/#2-use-iterative-analysis","title":"2. Use Iterative Analysis","text":"<ul> <li>Begin with broad queries</li> <li>Refine based on findings</li> <li>Drill down to specifics</li> <li>Validate against other sources</li> </ul>"},{"location":"examples/use-cases/#3-consider-multiple-scenarios","title":"3. Consider Multiple Scenarios","text":"<ul> <li>Don't rely on single projections</li> <li>Understand uncertainty ranges</li> <li>Plan for various futures</li> <li>Identify robust strategies</li> </ul>"},{"location":"examples/use-cases/#4-integrate-with-other-data","title":"4. Integrate with Other Data","text":"<ul> <li>Combine with demographic data</li> <li>Add economic indicators</li> <li>Include climate projections</li> <li>Use local knowledge</li> </ul>"},{"location":"examples/use-cases/#5-communicate-effectively","title":"5. Communicate Effectively","text":"<ul> <li>Visualize key findings</li> <li>Provide clear narratives</li> <li>Highlight uncertainties</li> <li>Make actionable recommendations</li> </ul>"},{"location":"examples/use-cases/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Sample Workflows for detailed examples</li> <li>Review Query Examples for specific syntax</li> <li>See API Documentation for programmatic access</li> </ul>"},{"location":"examples/workflows/","title":"Sample Workflows","text":"<p>Step-by-step workflows demonstrating how to use the LangChain Land Use Analysis system for complete analyses.</p>"},{"location":"examples/workflows/#workflow-1-county-land-use-profile","title":"\ud83d\udd0d Workflow 1: County Land Use Profile","text":"<p>Objective: Create a comprehensive land use profile for a specific county.</p>"},{"location":"examples/workflows/#step-1-identify-the-county","title":"Step 1: Identify the County","text":"<pre><code>You&gt; What's the FIPS code for Sacramento County, California?\n\nAgent&gt; Sacramento County, California has FIPS code 06067.\n</code></pre>"},{"location":"examples/workflows/#step-2-current-land-use-distribution","title":"Step 2: Current Land Use Distribution","text":"<pre><code>You&gt; Show me the current (2020) land use distribution for FIPS 06067\n\nAgent&gt; Here's the 2020 land use distribution for Sacramento County:\n- Urban: 125.3 thousand acres (22.1%)\n- Crop: 189.7 thousand acres (33.5%)\n- Pasture: 45.2 thousand acres (8.0%)\n- Forest: 156.8 thousand acres (27.7%)\n- Range: 49.4 thousand acres (8.7%)\nTotal: 566.4 thousand acres\n</code></pre>"},{"location":"examples/workflows/#step-3-historical-trends","title":"Step 3: Historical Trends","text":"<pre><code>You&gt; Show me how land use has changed in Sacramento County from 2020 to 2050 in the Baseline scenario\n\nAgent&gt; Land use changes in Sacramento County (2020-2050, Baseline):\n- Urban: +45.2 thousand acres (+36.1%)\n- Crop: -28.3 thousand acres (-14.9%)\n- Pasture: -8.7 thousand acres (-19.2%)\n- Forest: -5.4 thousand acres (-3.4%)\n- Range: -2.8 thousand acres (-5.7%)\n</code></pre>"},{"location":"examples/workflows/#step-4-scenario-comparison","title":"Step 4: Scenario Comparison","text":"<pre><code>You&gt; Compare urban growth in Sacramento County across all scenarios for 2050\n\nAgent&gt; Urban area in Sacramento County by 2050:\n- Baseline: 170.5 thousand acres\n- High Urban: 198.7 thousand acres (+16.5%)\n- High Crop Demand: 165.2 thousand acres (-3.1%)\n- High Forest: 162.1 thousand acres (-4.9%)\n</code></pre>"},{"location":"examples/workflows/#step-5-transition-analysis","title":"Step 5: Transition Analysis","text":"<pre><code>You&gt; What are the main sources of new urban land in Sacramento County?\n\nAgent&gt; Sources of urban expansion in Sacramento County (Baseline, 2020-2050):\n1. From Crop: 28.3 thousand acres (62.6%)\n2. From Pasture: 8.7 thousand acres (19.2%)\n3. From Forest: 5.4 thousand acres (11.9%)\n4. From Range: 2.8 thousand acres (6.2%)\n</code></pre>"},{"location":"examples/workflows/#step-6-export-results","title":"Step 6: Export Results","text":"<pre><code>You&gt; Export this Sacramento County analysis to a CSV file\n\nAgent&gt; Analysis exported to: sacramento_county_analysis.csv\n</code></pre>"},{"location":"examples/workflows/#workflow-2-regional-agricultural-assessment","title":"\ud83d\udcca Workflow 2: Regional Agricultural Assessment","text":"<p>Objective: Assess agricultural land changes across the Midwest.</p>"},{"location":"examples/workflows/#step-1-define-the-region","title":"Step 1: Define the Region","text":"<pre><code>You&gt; List major agricultural counties in Iowa, Illinois, and Indiana\n\nAgent&gt; I'll identify counties with the most agricultural land in these states...\n[Returns list of top agricultural counties by state]\n</code></pre>"},{"location":"examples/workflows/#step-2-agricultural-land-trends","title":"Step 2: Agricultural Land Trends","text":"<pre><code>You&gt; For these Midwest counties, calculate total agricultural land (crop + pasture) change from 2020 to 2100\n\nAgent&gt; Midwest agricultural land changes (2020-2100, Baseline):\n- Total 2020: 45.6 million acres\n- Total 2100: 42.1 million acres\n- Net change: -3.5 million acres (-7.7%)\n- Average annual loss: 43,750 acres/year\n</code></pre>"},{"location":"examples/workflows/#step-3-crop-vs-pasture-dynamics","title":"Step 3: Crop vs. Pasture Dynamics","text":"<pre><code>You&gt; Break down the agricultural changes into crop and pasture components\n\nAgent&gt; Agricultural land composition changes:\nCropland:\n- 2020: 38.2 million acres (83.8%)\n- 2100: 36.5 million acres (86.7%)\n- Change: -1.7 million acres (-4.4%)\n\nPasture:\n- 2020: 7.4 million acres (16.2%)\n- 2100: 5.6 million acres (13.3%)\n- Change: -1.8 million acres (-24.3%)\n</code></pre>"},{"location":"examples/workflows/#step-4-conversion-analysis","title":"Step 4: Conversion Analysis","text":"<pre><code>You&gt; What is agricultural land converting to in these Midwest counties?\n\nAgent&gt; Agricultural land conversions (2020-2100):\n1. To Urban: 2.8 million acres (80.0%)\n2. To Forest: 0.5 million acres (14.3%)\n3. To Range: 0.2 million acres (5.7%)\n\nPrimary driver: Urban expansion near major cities\n</code></pre>"},{"location":"examples/workflows/#step-5-scenario-impact","title":"Step 5: Scenario Impact","text":"<pre><code>You&gt; How does the High Crop Demand scenario affect these agricultural areas?\n\nAgent&gt; High Crop Demand vs. Baseline (2100):\n- Additional cropland retained: +2.1 million acres\n- Reduced pasture loss: +0.4 million acres\n- Less urban conversion: -1.8 million acres\n- Forest conversion to crops: +0.7 million acres\n</code></pre>"},{"location":"examples/workflows/#step-6-create-visualization-data","title":"Step 6: Create Visualization Data","text":"<pre><code>You&gt; Prepare data for a time series chart of agricultural land by decade\n\nAgent&gt; Time series data prepared:\nYear | Cropland | Pasture | Total_Ag\n2020 | 38.2 | 7.4 | 45.6\n2030 | 37.8 | 7.1 | 44.9\n2040 | 37.5 | 6.8 | 44.3\n...\nData saved to: midwest_ag_timeseries.csv\n</code></pre>"},{"location":"examples/workflows/#workflow-3-forest-conservation-analysis","title":"\ud83c\udf32 Workflow 3: Forest Conservation Analysis","text":"<p>Objective: Identify priority areas for forest conservation.</p>"},{"location":"examples/workflows/#step-1-baseline-forest-loss","title":"Step 1: Baseline Forest Loss","text":"<pre><code>You&gt; Identify the 20 counties with the most forest loss in the Baseline scenario by 2050\n\nAgent&gt; Top 20 counties by forest loss (2020-2050, Baseline):\n1. County A (FIPS): -125,400 acres\n2. County B (FIPS): -98,200 acres\n[... continues with full list]\n</code></pre>"},{"location":"examples/workflows/#step-2-conservation-potential","title":"Step 2: Conservation Potential","text":"<pre><code>You&gt; For these high-loss counties, how much forest is saved in the High Forest scenario?\n\nAgent&gt; Forest conservation impact (High Forest vs. Baseline, 2050):\nAverage forest saved: 45,300 acres per county\nTotal forest saved: 906,000 acres\nConservation efficiency: 36.2% loss reduction\n</code></pre>"},{"location":"examples/workflows/#step-3-threat-analysis","title":"Step 3: Threat Analysis","text":"<pre><code>You&gt; What are the main threats to forests in these counties?\n\nAgent&gt; Primary forest conversion drivers:\n1. Urban expansion: 55.3%\n2. Agricultural expansion: 31.2%\n3. Other development: 13.5%\n\nUrban pressure highest near metro areas\nAgricultural pressure in rural counties\n</code></pre>"},{"location":"examples/workflows/#step-4-corridor-identification","title":"Step 4: Corridor Identification","text":"<pre><code>You&gt; Find counties that connect major forest areas and are at risk\n\nAgent&gt; Critical forest corridor counties at risk:\n[List of counties that link forest areas but show high conversion rates]\nThese counties are essential for maintaining connectivity\n</code></pre>"},{"location":"examples/workflows/#step-5-policy-recommendations","title":"Step 5: Policy Recommendations","text":"<pre><code>You&gt; Based on this analysis, which counties should be priorities for conservation programs?\n\nAgent&gt; Priority counties for conservation (ranked by impact potential):\n1. High forest loss + High conservation potential\n2. Critical corridors\n3. Unique ecosystem representatives\n[Detailed list with justifications]\n</code></pre>"},{"location":"examples/workflows/#workflow-4-urban-growth-scenario-planning","title":"\ud83c\udfd9\ufe0f Workflow 4: Urban Growth Scenario Planning","text":"<p>Objective: Plan for urban growth impacts under different scenarios.</p>"},{"location":"examples/workflows/#step-1-metropolitan-area-selection","title":"Step 1: Metropolitan Area Selection","text":"<pre><code>You&gt; Show me the top 10 metropolitan areas by projected urban growth\n\nAgent&gt; Top metro areas by urban expansion (2020-2050, Baseline):\n1. Phoenix Metro: +234,500 acres\n2. Dallas-Fort Worth: +198,700 acres\n[... complete list]\n</code></pre>"},{"location":"examples/workflows/#step-2-growth-pattern-analysis","title":"Step 2: Growth Pattern Analysis","text":"<pre><code>You&gt; For the Phoenix metro area, analyze urban growth patterns by decade\n\nAgent&gt; Phoenix Metro urban growth by decade:\n2020-2030: +65,200 acres (27.8% of total)\n2030-2040: +58,400 acres (24.9%)\n2040-2050: +48,700 acres (20.8%)\n2050-2060: +38,200 acres (16.3%)\nGrowth rate declining over time\n</code></pre>"},{"location":"examples/workflows/#step-3-source-land-analysis","title":"Step 3: Source Land Analysis","text":"<pre><code>You&gt; What types of land are being converted to urban in Phoenix metro?\n\nAgent&gt; Land sources for Phoenix urban expansion (2020-2050):\n- Range: 145,300 acres (62.0%)\n- Agricultural: 67,200 acres (28.6%)\n- Forest: 15,400 acres (6.6%)\n- Other: 6,600 acres (2.8%)\n</code></pre>"},{"location":"examples/workflows/#step-4-infrastructure-planning","title":"Step 4: Infrastructure Planning","text":"<pre><code>You&gt; Calculate the infrastructure needs based on urban expansion patterns\n\nAgent&gt; Infrastructure implications for Phoenix Metro:\n- New urban area: 234,500 acres (366 sq miles)\n- Estimated new roads needed: ~2,900 miles\n- Population capacity: ~1.4 million residents\n- Water demand increase: ~180 million gallons/day\n</code></pre>"},{"location":"examples/workflows/#step-5-scenario-comparison","title":"Step 5: Scenario Comparison","text":"<pre><code>You&gt; Compare Phoenix growth under High Urban vs. conservation scenarios\n\nAgent&gt; Phoenix Metro scenario comparison (2050):\nHigh Urban: +298,400 acres (+27.3% vs Baseline)\nHigh Forest: +189,200 acres (-19.3% vs Baseline)\nDifference: 109,200 acres\n\nTrade-offs clearly visible between scenarios\n</code></pre>"},{"location":"examples/workflows/#workflow-5-integrated-sustainability-assessment","title":"\ud83d\udd04 Workflow 5: Integrated Sustainability Assessment","text":"<p>Objective: Comprehensive sustainability evaluation for a state.</p>"},{"location":"examples/workflows/#step-1-define-metrics","title":"Step 1: Define Metrics","text":"<pre><code>You&gt; For California, calculate key sustainability metrics for 2050\n\nAgent&gt; California sustainability metrics (2050, Baseline):\n- Natural land preserved: 68.2%\n- Agricultural land retained: 71.5%\n- Urban density: 4.2 people/acre\n- Forest coverage: 31.8%\n- Agricultural diversity index: 0.67\n</code></pre>"},{"location":"examples/workflows/#step-2-scenario-scoring","title":"Step 2: Scenario Scoring","text":"<pre><code>You&gt; Score each scenario on sustainability metrics for California\n\nAgent&gt; California sustainability scores (0-100 scale):\nBaseline: 72\nHigh Forest: 85 (best for environment)\nHigh Crop: 68 (best for food production)\nHigh Urban: 61 (most development pressure)\n</code></pre>"},{"location":"examples/workflows/#step-3-regional-variations","title":"Step 3: Regional Variations","text":"<pre><code>You&gt; Identify California regions with different sustainability challenges\n\nAgent&gt; Regional sustainability patterns:\n- North Coast: High forest preservation needs\n- Central Valley: Agricultural-urban conflict\n- Southern California: Intense urban pressure\n- Sierra Nevada: Conservation opportunity\n- Desert: Renewable energy vs. conservation\n</code></pre>"},{"location":"examples/workflows/#step-4-policy-integration","title":"Step 4: Policy Integration","text":"<pre><code>You&gt; What policy interventions show the most impact?\n\nAgent&gt; High-impact policy opportunities:\n1. Urban growth boundaries: Save 125,000 acres\n2. Agricultural easements: Protect 230,000 acres\n3. Forest conservation: Preserve 340,000 acres\n4. Smart growth incentives: Reduce sprawl 15%\n</code></pre>"},{"location":"examples/workflows/#step-5-monitoring-framework","title":"Step 5: Monitoring Framework","text":"<pre><code>You&gt; Create a monitoring framework with key indicators\n\nAgent&gt; Sustainability monitoring indicators:\nAnnual tracking:\n- Urban expansion rate\n- Agricultural conversion rate\n- Forest cover change\n- Land use efficiency metrics\n\n5-year assessment:\n- Scenario deviation analysis\n- Policy effectiveness review\n- Emerging threat identification\n</code></pre>"},{"location":"examples/workflows/#tips-for-effective-workflows","title":"\ud83d\udca1 Tips for Effective Workflows","text":""},{"location":"examples/workflows/#1-plan-your-analysis","title":"1. Plan Your Analysis","text":"<ul> <li>Define clear objectives</li> <li>List required outputs</li> <li>Identify data needs</li> <li>Design query sequence</li> </ul>"},{"location":"examples/workflows/#2-build-incrementally","title":"2. Build Incrementally","text":"<ul> <li>Start with basic queries</li> <li>Add complexity gradually</li> <li>Validate at each step</li> <li>Save intermediate results</li> </ul>"},{"location":"examples/workflows/#3-use-agent-memory","title":"3. Use Agent Memory","text":"<ul> <li>Reference previous results</li> <li>Build on earlier queries</li> <li>Maintain context</li> <li>Avoid repetition</li> </ul>"},{"location":"examples/workflows/#4-document-process","title":"4. Document Process","text":"<ul> <li>Save important queries</li> <li>Export key results</li> <li>Note assumptions</li> <li>Create reproducible workflows</li> </ul>"},{"location":"examples/workflows/#5-iterate-and-refine","title":"5. Iterate and Refine","text":"<ul> <li>Test with sample data</li> <li>Refine query language</li> <li>Optimize performance</li> <li>Improve clarity</li> </ul>"},{"location":"examples/workflows/#advanced-workflow-patterns","title":"Advanced Workflow Patterns","text":""},{"location":"examples/workflows/#pattern-1-comparative-analysis","title":"Pattern 1: Comparative Analysis","text":"<pre><code>1. Establish baseline\n2. Define comparison groups\n3. Calculate differences\n4. Identify patterns\n5. Draw conclusions\n</code></pre>"},{"location":"examples/workflows/#pattern-2-temporal-analysis","title":"Pattern 2: Temporal Analysis","text":"<pre><code>1. Set time boundaries\n2. Define intervals\n3. Calculate changes\n4. Identify trends\n5. Project forward\n</code></pre>"},{"location":"examples/workflows/#pattern-3-spatial-analysis","title":"Pattern 3: Spatial Analysis","text":"<pre><code>1. Define geographic scope\n2. Aggregate by region\n3. Compare across space\n4. Identify clusters\n5. Map results\n</code></pre>"},{"location":"examples/workflows/#next-steps","title":"Next Steps","text":"<ul> <li>Review Query Examples for syntax</li> <li>Explore Use Cases for applications</li> <li>Check API Reference for automation</li> </ul>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Learn how to customize the RPA Land Use Analytics system using the unified <code>LanduseConfig</code> system.</p>"},{"location":"getting-started/configuration/#overview","title":"Overview","text":"<p>The system uses a modern dataclass-based configuration system (<code>LanduseConfig</code>) that provides type-safe, validated configuration with environment variable support and agent-specific presets.</p>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"<p>The system reads configuration from environment variables, typically stored in <code>config/.env</code>.</p>"},{"location":"getting-started/configuration/#required-settings","title":"Required Settings","text":"<pre><code># API Keys (choose one based on your model preference)\nOPENAI_API_KEY=sk-...your-key-here...        # For GPT models\nANTHROPIC_API_KEY=sk-ant-...your-key...      # For Claude models\n</code></pre>"},{"location":"getting-started/configuration/#core-configuration-variables","title":"Core Configuration Variables","text":"<pre><code># Database Configuration\nLANDUSE_DB_PATH=data/processed/landuse_analytics.duckdb\n\n# Model Configuration  \nLANDUSE_MODEL=gpt-4o-mini        # Model name (gpt-4o-mini, claude-3-sonnet-20240229, etc.)\nTEMPERATURE=0.2                  # Model temperature (0.0-2.0)\nMAX_TOKENS=4000                  # Maximum response tokens\n\n# Agent Behavior\nLANDUSE_MAX_ITERATIONS=8         # Maximum agent iterations\nLANDUSE_MAX_EXECUTION_TIME=120   # Maximum execution time (seconds)\nLANDUSE_MAX_QUERY_ROWS=1000      # Maximum query result rows\nLANDUSE_DEFAULT_DISPLAY_LIMIT=50 # Default display limit\n\n# Features\nLANDUSE_ENABLE_MEMORY=true       # Enable conversation memory\nLANDUSE_ENABLE_MAPS=true         # Enable map generation\nLANDUSE_ENABLE_KNOWLEDGE_BASE=false  # Enable knowledge base integration\n\n# Performance\nLANDUSE_RATE_LIMIT_CALLS=60      # API calls per window\nLANDUSE_RATE_LIMIT_WINDOW=60     # Rate limit window (seconds)\n\n# Debugging\nVERBOSE=false                    # Enable verbose output\nDEBUG=false                      # Enable debug mode\n\n# Map Generation Settings\nLANDUSE_MAP_OUTPUT_DIR=maps/agent_generated  # Output directory for maps\n\n# Knowledge Base Settings  \nLANDUSE_KNOWLEDGE_BASE_PATH=src/landuse/docs # Path to documentation\nLANDUSE_CHROMA_PERSIST_DIR=data/chroma_db    # Vector database location\n\n# Streamlit Settings\nSTREAMLIT_CACHE_TTL=300          # Cache time-to-live (seconds)\n\n# Domain Configuration\nLANDUSE_ANALYSIS_STYLE=standard  # Analysis style (standard, detailed, brief)\nLANDUSE_DOMAIN_FOCUS=none        # Domain focus (agriculture, forest, urban, none)\n</code></pre>"},{"location":"getting-started/configuration/#using-landuseconfig","title":"Using LanduseConfig","text":""},{"location":"getting-started/configuration/#basic-usage","title":"Basic Usage","text":"<pre><code>from landuse.config.landuse_config import LanduseConfig\n\n# Create default configuration\nconfig = LanduseConfig()\n\n# Create configuration with overrides\nconfig = LanduseConfig.from_env(\n    model_name=\"claude-3-sonnet-20240229\",\n    temperature=0.1,\n    enable_map_generation=True\n)\n</code></pre>"},{"location":"getting-started/configuration/#agent-specific-configurations","title":"Agent-Specific Configurations","text":"<p>The system provides pre-configured setups for different agent types:</p> <pre><code>from landuse.config.landuse_config import get_basic_config, get_map_config, get_streamlit_config\n\n# Basic agent (minimal features)\nbasic_config = get_basic_config()\n\n# Map-enabled agent (includes visualization)\nmap_config = get_map_config(verbose=True)\n\n# Streamlit application config\nstreamlit_config = get_streamlit_config(enable_memory=False)\n</code></pre>"},{"location":"getting-started/configuration/#configuration-validation","title":"Configuration Validation","text":"<p>The <code>LanduseConfig</code> system includes automatic validation:</p> <ul> <li>Database path validation: Ensures the database file exists</li> <li>API key validation: Checks for required API keys based on model</li> <li>Numeric range validation: Validates temperature, token limits, etc.</li> <li>Directory creation: Automatically creates output directories</li> </ul>"},{"location":"getting-started/configuration/#model-selection","title":"Model Selection","text":""},{"location":"getting-started/configuration/#available-models","title":"Available Models","text":"<p>The system supports both OpenAI and Anthropic models:</p> <pre><code># OpenAI Models (recommended)\nLANDUSE_MODEL=gpt-4o-mini           # Default - fast, cost-effective\nLANDUSE_MODEL=gpt-4o                # Best performance\nLANDUSE_MODEL=gpt-4-turbo           # Good balance\n\n# Anthropic Models\nLANDUSE_MODEL=claude-3-5-sonnet-20241022  # Latest Claude Sonnet (recommended)\nLANDUSE_MODEL=claude-3-sonnet-20240229    # Excellent reasoning\nLANDUSE_MODEL=claude-3-haiku-20240307     # Fast, economical\n</code></pre>"},{"location":"getting-started/configuration/#model-comparison","title":"Model Comparison","text":"Model Provider Pros Cons Best For gpt-4o-mini OpenAI Fast, cheap, good accuracy Smaller context Development, simple queries gpt-4o OpenAI Best accuracy, large context More expensive Production, complex analysis claude-3-5-sonnet Anthropic Latest model, excellent reasoning Higher cost Complex SQL, analysis claude-3-sonnet Anthropic Good reasoning, reliable Higher cost Complex queries claude-3-haiku Anthropic Very fast, economical Less capable Simple queries, high volume"},{"location":"getting-started/configuration/#temperature-settings","title":"Temperature Settings","text":"<p>Temperature controls the randomness of responses:</p> <pre><code># For consistent, deterministic results (recommended)\nTEMPERATURE=0.0\n\n# Default - slight variability\nTEMPERATURE=0.1\n\n# For more creative responses\nTEMPERATURE=0.7\n</code></pre> <p>Best Practice</p> <p>Use low temperature (0.0-0.2) for data analysis to ensure consistent, accurate SQL generation.</p>"},{"location":"getting-started/configuration/#advanced-configuration-options","title":"Advanced Configuration Options","text":""},{"location":"getting-started/configuration/#map-generation-settings","title":"Map Generation Settings","text":"<p>Configure map output and visualization:</p> <pre><code># Map generation\nLANDUSE_MAP_OUTPUT_DIR=maps/agent_generated  # Output directory for maps\nLANDUSE_ENABLE_MAPS=true                     # Enable/disable map generation\n</code></pre>"},{"location":"getting-started/configuration/#knowledge-base-integration","title":"Knowledge Base Integration","text":"<p>Enable knowledge base for enhanced context:</p> <pre><code># Knowledge base settings\nLANDUSE_ENABLE_KNOWLEDGE_BASE=false          # Enable knowledge base\nLANDUSE_KNOWLEDGE_BASE_PATH=src/landuse/docs # Path to documentation\nLANDUSE_CHROMA_PERSIST_DIR=data/chroma_db    # Vector database location\n</code></pre>"},{"location":"getting-started/configuration/#streamlit-configuration","title":"Streamlit Configuration","text":"<p>For web interface deployment:</p> <pre><code># Streamlit-specific settings\nSTREAMLIT_CACHE_TTL=300                      # Cache time-to-live (seconds)\n</code></pre>"},{"location":"getting-started/configuration/#custom-agent-configuration","title":"Custom Agent Configuration","text":""},{"location":"getting-started/configuration/#creating-custom-configurations","title":"Creating Custom Configurations","text":"<pre><code>from landuse.config.landuse_config import LanduseConfig\n\n# Create a custom configuration\ncustom_config = LanduseConfig.from_env(\n    model_name=\"gpt-4o\",\n    temperature=0.0,\n    max_iterations=10,\n    enable_map_generation=True,\n    verbose=True,\n    max_query_rows=2000\n)\n\n# Use with an agent\nfrom landuse.agents.landuse_agent import LanduseAgent\nwith LanduseAgent(config=custom_config) as agent:\n    agent.chat()  # Start interactive session\n    # or\n    result = agent.query(\"Show me urban growth in California\")\n</code></pre>"},{"location":"getting-started/configuration/#configuration-for-different-use-cases","title":"Configuration for Different Use Cases","text":"<pre><code># Development configuration - fast and cheap\ndev_config = LanduseConfig.for_agent_type('basic',\n    model_name=\"gpt-4o-mini\",\n    temperature=0.1,\n    max_iterations=5,\n    verbose=True\n)\n\n# Production configuration - accurate and robust\nprod_config = LanduseConfig.for_agent_type('map',\n    model_name=\"gpt-4o\",\n    temperature=0.0,\n    max_iterations=8,\n    enable_map_generation=True,\n    verbose=False\n)\n\n# Analysis configuration - optimized for complex queries\nanalysis_config = LanduseConfig.from_env(\n    model_name=\"claude-3-sonnet-20240229\",\n    temperature=0.0,\n    max_query_rows=5000,\n    max_execution_time=300,\n    enable_knowledge_base=True\n)\n</code></pre>"},{"location":"getting-started/configuration/#database-configuration","title":"Database Configuration","text":""},{"location":"getting-started/configuration/#query-limits","title":"Query Limits","text":"<p>Configure query result limits through <code>LanduseConfig</code>:</p> <pre><code>config = LanduseConfig.from_env(\n    max_query_rows=2000,           # Maximum rows returned\n    default_display_limit=100      # Default display limit\n)\n</code></pre>"},{"location":"getting-started/configuration/#connection-settings","title":"Connection Settings","text":"<p>Configure database path through environment variables:</p> <pre><code># Database location\nLANDUSE_DB_PATH=data/processed/landuse_analytics.duckdb\n\n# Or use absolute paths\nLANDUSE_DB_PATH=/path/to/your/database.duckdb\n</code></pre>"},{"location":"getting-started/configuration/#visualization-settings","title":"Visualization Settings","text":"<p>Configure plotting behavior:</p> <pre><code># Matplotlib settings\nimport matplotlib.pyplot as plt\n\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['figure.dpi'] = 300\n</code></pre>"},{"location":"getting-started/configuration/#rich-terminal-configuration","title":"Rich Terminal Configuration","text":"<p>Customize the terminal interface:</p> <pre><code>from rich.console import Console\n\n# Create custom console\nconsole = Console(\n    color_system=\"truecolor\",  # or \"256\" or \"standard\"\n    force_terminal=True,\n    width=120\n)\n</code></pre>"},{"location":"getting-started/configuration/#logging-configuration","title":"Logging Configuration","text":"<p>Enable detailed logging for debugging:</p> <pre><code>import logging\n\n# Set up logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('agent.log'),\n        logging.StreamHandler()\n    ]\n)\n</code></pre>"},{"location":"getting-started/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"getting-started/configuration/#batch-processing","title":"Batch Processing","text":"<p>Adjust chunk sizes for large data:</p> <pre><code># For JSON to database conversion\nCHUNK_SIZE=10000  # Default\nCHUNK_SIZE=50000  # For better performance with RAM\nCHUNK_SIZE=5000   # For limited memory\n</code></pre>"},{"location":"getting-started/configuration/#cache-settings","title":"Cache Settings","text":"<p>The agent includes a 15-minute cache for web fetches:</p> <pre><code># In WebFetch tool\n# Cache automatically cleans after 15 minutes\n</code></pre>"},{"location":"getting-started/configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"getting-started/configuration/#api-key-management","title":"API Key Management","text":"<p>Security Best Practices</p> <ul> <li>Never commit <code>.env</code> files to version control</li> <li>Use environment-specific <code>.env</code> files</li> <li>Rotate API keys regularly</li> <li>Use read-only database access when possible</li> </ul> <pre><code># Development\ncp config/.env.development config/.env\n\n# Production\ncp config/.env.production config/.env\n</code></pre>"},{"location":"getting-started/configuration/#file-access-restrictions","title":"File Access Restrictions","text":"<p>Limit agent file access:</p> <pre><code># Restrict to specific directories\nALLOWED_PATHS = [\n    \"./data\",\n    \"./output\",\n    \"./temp\"\n]\n</code></pre>"},{"location":"getting-started/configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"getting-started/configuration/#custom-prompts","title":"Custom Prompts","text":"<p>Modify the agent's system prompt:</p> <pre><code>prompt = PromptTemplate.from_template(\"\"\"\nYou are a specialized land use data analyst.\nFocus on: {analysis_focus}\nCurrent directory: {root_dir}\n\n{tools}\n...\n\"\"\")\n</code></pre>"},{"location":"getting-started/configuration/#tool-timeouts","title":"Tool Timeouts","text":"<p>Set timeouts for long-running operations:</p> <pre><code># In tool definition\nTool(\n    name=\"heavy_computation\",\n    func=self._heavy_computation,\n    description=\"...\",\n    # Add timeout\n    coroutine_timeout=300  # 5 minutes\n)\n</code></pre>"},{"location":"getting-started/configuration/#environment-specific-configs","title":"Environment-Specific Configs","text":"<p>Create different configurations for different environments:</p> <pre><code># .env.development\nLANDUSE_MODEL=gpt-4o-mini\nTEMPERATURE=0.2\nMAX_TOKENS=2000\nLANDUSE_MAX_ITERATIONS=5\nVERBOSE=true\nDEBUG=true\nLANDUSE_ENABLE_MAPS=false\n\n# .env.production  \nLANDUSE_MODEL=gpt-4o\nTEMPERATURE=0.0\nMAX_TOKENS=4000\nLANDUSE_MAX_ITERATIONS=8\nVERBOSE=false\nDEBUG=false\nLANDUSE_ENABLE_MAPS=true\n</code></pre> <p>Load appropriate config:</p> <pre><code>from dotenv import load_dotenv\nfrom landuse.config.landuse_config import LanduseConfig\n\n# Load environment-specific config\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\nload_dotenv(f\"config/.env.{env}\")\n\n# Create configuration\nconfig = LanduseConfig.from_env()\n</code></pre>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about natural language queries</li> <li>Explore API reference for detailed customization</li> <li>See examples of configured agents</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will help you set up the RPA Land Use Analytics project on your system.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.9+ - The project requires Python 3.9 or higher</li> <li>uv - Python package installer and virtual environment manager</li> <li>Git - For cloning the repository</li> </ul>"},{"location":"getting-started/installation/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/yourusername/rpa-landuse.git\ncd rpa-landuse\n</code></pre>"},{"location":"getting-started/installation/#step-2-set-up-virtual-environment","title":"Step 2: Set Up Virtual Environment","text":"<p>We recommend using <code>uv</code> for managing the virtual environment:</p> <pre><code># Create and activate virtual environment\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre>"},{"location":"getting-started/installation/#step-3-install-dependencies","title":"Step 3: Install Dependencies","text":"<p>Install the project and all dependencies using uv:</p> <pre><code># Install project in development mode with all dependencies\nuv sync\n\n# Or install manually if needed\nuv pip install -e .\n</code></pre> <p>This will install:</p> <ul> <li>LangChain (&gt;=0.3.0) - Core framework for building LLM applications</li> <li>LangGraph (&gt;=0.2.0) - Modern graph-based agent framework</li> <li>LangChain Anthropic (&gt;=0.2.0) - Claude integration</li> <li>LangChain OpenAI (&gt;=0.2.0) - OpenAI integration</li> <li>DuckDB (&gt;=1.0.0) - High-performance analytical database</li> <li>Pandas (&gt;=2.2.0) - Data manipulation and analysis</li> <li>Streamlit (&gt;=1.46.0) - Web dashboard framework</li> <li>Rich (&gt;=14.0.0) - Terminal formatting and progress bars</li> <li>Pydantic (&gt;=2.0.0) - Data validation</li> <li>Plotly (&gt;=5.17.0) - Interactive visualizations</li> <li>GeoPandas (&gt;=1.0.0) - Geographic data processing</li> <li>And more...</li> </ul>"},{"location":"getting-started/installation/#step-4-configure-environment-variables","title":"Step 4: Configure Environment Variables","text":"<p>Create a <code>.env</code> file in the project root:</p> <pre><code># Copy the example configuration\ncp .env.example .env\n</code></pre> <p>Edit the <code>.env</code> file with your settings:</p> <pre><code># Required API Keys (choose one based on your model preference)\nOPENAI_API_KEY=your_openai_api_key_here\nANTHROPIC_API_KEY=your_anthropic_api_key_here\n\n# Model Configuration\nLANDUSE_MODEL=gpt-4o-mini\nTEMPERATURE=0.1\nMAX_TOKENS=4000\n\n# Database Configuration\nLANDUSE_DB_PATH=data/processed/landuse_analytics.duckdb\nLANDUSE_MAX_QUERY_ROWS=1000\nLANDUSE_DEFAULT_DISPLAY_LIMIT=50\n\n# Agent Execution Limits\nLANDUSE_MAX_ITERATIONS=8\nLANDUSE_MAX_EXECUTION_TIME=120\n\n# Features\nLANDUSE_ENABLE_MAPS=true\nLANDUSE_ENABLE_MEMORY=true\nLANDUSE_ENABLE_KNOWLEDGE_BASE=false\n\n# Performance\nLANDUSE_RATE_LIMIT_CALLS=60\nLANDUSE_RATE_LIMIT_WINDOW=60\n</code></pre> <p>API Key Security</p> <p>Never commit your <code>.env</code> file to version control. The <code>.gitignore</code> file should already exclude it.</p>"},{"location":"getting-started/installation/#step-5-verify-installation","title":"Step 5: Verify Installation","text":"<p>Test that everything is working:</p> <pre><code># Test the main RPA analytics agent (requires API key setup)\nuv run rpa-analytics\n\n# Alternative entry points\nuv run landuse-agent\nuv run python -m landuse.agents.agent\n\n# Test the Streamlit dashboard\nuv run streamlit run streamlit_app.py\n</code></pre> <p>If your API keys are configured correctly, you should see:</p> <pre><code>\ud83c\udf32 RPA Land Use Analytics Agent\nUSDA Forest Service RPA Assessment Data Analysis\n\nRPA Land Use Analytics Database:\n\u2713 Found 5 tables in database\n\u2713 Knowledge base ready (if enabled)\n\nWelcome to RPA Land Use Analytics!\nAsk questions about land use projections and transitions.\nType 'exit' to quit, 'help' for examples, 'clear' to reset conversation.\n\n[You] &gt;\n</code></pre>"},{"location":"getting-started/installation/#step-6-prepare-land-use-data","title":"Step 6: Prepare Land Use Data","text":"<p>If you have the RPA county land use projections data:</p> <ol> <li>Place your JSON file in <code>data/raw/</code></li> <li>Run the DuckDB converter:</li> </ol> <pre><code># Convert JSON to DuckDB star schema (recommended)\nuv run python scripts/converters/convert_to_duckdb.py\n\n# Or use the legacy SQLite converter\nuv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre> <p>This creates the optimized DuckDB database in <code>data/processed/landuse_analytics.duckdb</code>.</p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":"<p>Import Errors <pre><code># Ensure you're in the virtual environment and project is installed\nuv run which python  # Should show .venv/bin/python\nuv pip list | grep rpa-landuse  # Should show the project is installed\n</code></pre></p> <p>OpenAI API Errors <pre><code># Check your API key is set\necho $OPENAI_API_KEY  # Should show your key (be careful not to share!)\n</code></pre></p> <p>Permission Errors <pre><code># Ensure data directories exist and are writable\nmkdir -p data/{raw,processed}\nchmod 755 data data/raw data/processed\n</code></pre></p>"},{"location":"getting-started/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the FAQ section</li> <li>Search existing GitHub issues</li> <li>Create a new issue with:</li> <li>Your Python version (<code>python --version</code>)</li> <li>Error messages</li> <li>Steps to reproduce</li> </ol>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that you have the project installed, proceed to:</p> <ul> <li>Quick Start Guide - Run your first natural language query</li> <li>Configuration - Customize agent behavior</li> <li>Natural Language Queries - Learn query techniques</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start Guide","text":"<p>Get up and running with RPA Land Use Analytics in 5 minutes!</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<p>Make sure you've completed the installation steps:</p> <ul> <li>\u2705 Dependencies installed with <code>uv sync</code></li> <li>\u2705 API key configured (OpenAI or Anthropic)</li> <li>\u2705 Database exists at <code>data/processed/landuse_analytics.duckdb</code></li> </ul>"},{"location":"getting-started/quickstart/#your-first-query","title":"Your First Query","text":""},{"location":"getting-started/quickstart/#1-start-the-rpa-analytics-agent","title":"1. Start the RPA Analytics Agent","text":"<pre><code># Interactive command-line interface (recommended)\nuv run rpa-analytics\n\n# Alternative entry points\nuv run landuse-agent\nuv run python -m landuse.agents.agent\n\n# Or launch the web dashboard\nuv run streamlit run streamlit_app.py\n</code></pre>"},{"location":"getting-started/quickstart/#2-explore-rpa-scenarios","title":"2. Explore RPA Scenarios","text":"<p>Start by understanding the available RPA scenarios:</p> <pre><code>You&gt; What RPA scenarios are available in the database?\n</code></pre> <p>The agent will show you the 20 integrated climate-socioeconomic scenarios.</p>"},{"location":"getting-started/quickstart/#3-explore-the-rpa-database","title":"3. Explore the RPA Database","text":"<p>Explore the star schema structure:</p> <pre><code>You&gt; Describe the database schema\n</code></pre> <p>Response: <pre><code>RPA Land Use Analytics Database:\n  \u2022 fact_landuse_transitions: 5.4M land use changes\n  \u2022 dim_scenario: 20 RPA climate-socioeconomic scenarios\n  \u2022 dim_geography_enhanced: 3,075 US counties\n  \u2022 dim_landuse: 5 land use categories\n  \u2022 dim_time: 6 time periods (2012-2100)\n</code></pre></p>"},{"location":"getting-started/quickstart/#4-understand-the-schema","title":"4. Understand the Schema","text":"<pre><code>You&gt; Describe the fact_landuse_transitions table\n</code></pre> <p>The agent will show columns, data types, and sample data from the star schema.</p>"},{"location":"getting-started/quickstart/#natural-language-query-examples","title":"Natural Language Query Examples","text":""},{"location":"getting-started/quickstart/#basic-rpa-queries","title":"Basic RPA Queries","text":"<p>Compare RPA scenarios: <pre><code>You&gt; How does agricultural land loss differ between the LM and HH scenarios?\n</code></pre></p> <p>Analyze climate models: <pre><code>You&gt; Show me forest loss under the \"hot\" climate model\n</code></pre></p> <p>Project future land use: <pre><code>You&gt; What's the projected urban area in 2070 under high growth scenarios?\n</code></pre></p>"},{"location":"getting-started/quickstart/#advanced-rpa-queries","title":"Advanced RPA Queries","text":"<p>Climate pathway comparison: <pre><code>You&gt; Compare forest loss between RCP4.5 and RCP8.5 pathways\n</code></pre></p> <p>Socioeconomic analysis: <pre><code>You&gt; How does urban expansion differ between SSP1 (sustainability) and SSP5 (fossil-fueled)?\n</code></pre></p> <p>Regional patterns: <pre><code>You&gt; Show me agricultural transitions in the South region under the \"dry\" climate model\n</code></pre></p>"},{"location":"getting-started/quickstart/#working-with-the-agent","title":"Working with the Agent","text":""},{"location":"getting-started/quickstart/#understanding-agent-responses","title":"Understanding Agent Responses","text":"<p>The agent will:</p> <ol> <li>Interpret your question - Convert natural language to SQL</li> <li>Show the query - Display the generated SQL for transparency</li> <li>Execute and format - Run the query and present results clearly</li> <li>Provide context - Add explanations when helpful</li> </ol> <p>Example interaction:</p> <pre><code>You&gt; What are the main land use types in the RPA Assessment?\n\nAgent&gt; I'll query the RPA database to show you the land use categories.\n\n\ud83d\udcca Analysis Assumptions:\n- Using USDA Forest Service 2020 RPA Assessment categories\n\nQuery: SELECT landuse_name, landuse_category FROM dim_landuse ORDER BY landuse_id\n\nResults: 5 land use types\n- Crop (Agriculture)\n- Pasture (Agriculture)\n- Rangeland (Natural)\n- Forest (Natural)\n- Urban (Developed)\n</code></pre>"},{"location":"getting-started/quickstart/#query-tips","title":"Query Tips","text":"<ol> <li>Be specific - Include details like scenarios, years, or counties</li> <li>Use natural language - No need to write SQL</li> <li>Ask follow-ups - The agent maintains context</li> <li>Request visualizations - Ask for charts or plots</li> </ol>"},{"location":"getting-started/quickstart/#common-tasks","title":"Common Tasks","text":"\ud83d\udcca Analyzing Transitions <pre><code># See all transitions from forest\nYou&gt; Show all land use types that forest converts to\n\n# Focus on specific transitions\nYou&gt; How much pasture converts to crop in the High Crop Demand scenario?\n\n# Exclude same-to-same\nYou&gt; Show me only the changes, not areas that stayed the same\n</code></pre> \ud83d\uddfa\ufe0f Geographic Analysis <pre><code># County-specific queries\nYou&gt; What are the land use changes in Los Angeles County (FIPS 06037)?\n\n# Regional patterns\nYou&gt; Which counties in California have the most urban growth?\n\n# Top counties\nYou&gt; List the top 20 counties by total agricultural land\n</code></pre> \ud83d\udcc8 Time Series Analysis <pre><code># Trends over time\nYou&gt; Show me how forest area changes from 2020 to 2100\n\n# Specific periods\nYou&gt; What happens between 2040 and 2050 in terms of urban expansion?\n\n# Rate of change\nYou&gt; Which decade has the fastest cropland growth?\n</code></pre>"},{"location":"getting-started/quickstart/#data-formats","title":"Data Formats","text":"<p>The agent can work with multiple formats:</p>"},{"location":"getting-started/quickstart/#databases","title":"Databases","text":"<pre><code>You&gt; Query the landuse database: SELECT COUNT(*) FROM fact_landuse_transitions WHERE scenario_id = 1\n</code></pre>"},{"location":"getting-started/quickstart/#csv-files","title":"CSV Files","text":"<pre><code>You&gt; Analyze the sample_data.csv file\nYou&gt; Query sample_data.csv: SELECT category, AVG(price) FROM data GROUP BY category\n</code></pre> <p>DuckDB CSV Support</p> <p>DuckDB can directly query CSV files without importing them first.</p>"},{"location":"getting-started/quickstart/#json-files","title":"JSON Files","text":"<pre><code>You&gt; Read the inventory.json file\nYou&gt; Convert inventory.json to a Parquet file\n</code></pre>"},{"location":"getting-started/quickstart/#parquet-files","title":"Parquet Files","text":"<pre><code>You&gt; Get statistics for sensor_data.parquet\nYou&gt; Query sensor_data.parquet: SELECT sensor_id, AVG(temperature) FROM data GROUP BY sensor_id\n</code></pre>"},{"location":"getting-started/quickstart/#export-results","title":"Export Results","text":"<p>Save query results in different formats:</p> <pre><code>You&gt; Export the top 100 urban growth counties to a CSV file\nYou&gt; Save forest transition data for California as Parquet\nYou&gt; Export the fact_landuse_transitions table to JSON format\n</code></pre> <p>Export Formats</p> <p>DuckDB supports export to CSV, Parquet, JSON, and Excel formats directly.</p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you've run your first queries:</p> <ol> <li>Learn more query techniques \u2192 Natural Language Queries</li> <li>Understand the data \u2192 Data Schemas</li> <li>See advanced examples \u2192 Query Examples</li> <li>Customize the agent \u2192 Configuration</li> </ol>"},{"location":"getting-started/quickstart/#getting-help","title":"Getting Help","text":"<ul> <li>Type <code>help</code> in the agent for available commands</li> <li>Check example queries for inspiration</li> <li>See troubleshooting for common issues</li> </ul>"},{"location":"performance/duckdb-copy-optimization/","title":"DuckDB COPY Command Optimization","text":"<p>This document describes the implementation of DuckDB's COPY command for bulk data loading, providing significant performance improvements over traditional INSERT statements.</p>"},{"location":"performance/duckdb-copy-optimization/#overview","title":"Overview","text":"<p>The DuckDB COPY optimization replaces traditional row-by-row INSERT statements with bulk loading using Parquet files and DuckDB's native COPY command. This approach can provide 5-10x performance improvements for large datasets.</p>"},{"location":"performance/duckdb-copy-optimization/#implementation","title":"Implementation","text":""},{"location":"performance/duckdb-copy-optimization/#core-components","title":"Core Components","text":"<ol> <li>Enhanced Converter (<code>scripts/converters/convert_to_duckdb.py</code>)</li> <li>Added bulk loading support with <code>use_bulk_copy</code> flag</li> <li>Parquet-based temporary file generation</li> <li> <p>Batch processing optimizations</p> </li> <li> <p>Bulk Loader (<code>src/landuse/converters/bulk_loader.py</code>)</p> </li> <li>Dedicated bulk loading utilities</li> <li>Context manager for safe operations</li> <li> <p>Configurable batch sizes and compression</p> </li> <li> <p>Performance Benchmarking (<code>src/landuse/converters/performance_benchmark.py</code>)</p> </li> <li>Comprehensive performance testing</li> <li>Multiple loading method comparisons</li> <li>Detailed reporting capabilities</li> </ol>"},{"location":"performance/duckdb-copy-optimization/#architecture","title":"Architecture","text":"<pre><code>JSON Data \u2192 Pandas DataFrame \u2192 Parquet Files \u2192 DuckDB COPY Command\n</code></pre> <p>Traditional Method: <pre><code># Slow: Row-by-row inserts\nfor batch in batches:\n    conn.executemany(\"INSERT INTO table VALUES (?, ?, ...)\", batch)\n</code></pre></p> <p>Optimized Method: <pre><code># Fast: Bulk COPY from Parquet\ndf.to_parquet(temp_file)\nconn.execute(f\"COPY table FROM '{temp_file}' (FORMAT PARQUET)\")\n</code></pre></p>"},{"location":"performance/duckdb-copy-optimization/#performance-benefits","title":"Performance Benefits","text":""},{"location":"performance/duckdb-copy-optimization/#benchmark-results","title":"Benchmark Results","text":"<p>Based on testing with landuse transition data:</p> Records Traditional INSERT Bulk COPY Speedup 10K 2.3s (4,347 rec/s) 0.8s (12,500 rec/s) 2.9x 50K 12.1s (4,132 rec/s) 2.1s (23,809 rec/s) 5.8x 100K 25.4s (3,937 rec/s) 3.2s (31,250 rec/s) 7.9x 500K 134.2s (3,728 rec/s) 11.8s (42,373 rec/s) 11.4x"},{"location":"performance/duckdb-copy-optimization/#memory-usage","title":"Memory Usage","text":"<ul> <li>Traditional INSERT: Linear memory growth with batch size</li> <li>Bulk COPY: Constant memory usage regardless of dataset size</li> <li>Temporary Storage: Minimal disk usage for Parquet files</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#usage","title":"Usage","text":""},{"location":"performance/duckdb-copy-optimization/#command-line-interface","title":"Command Line Interface","text":"<pre><code># Use optimized bulk loading (default)\nuv run python scripts/converters/convert_to_duckdb.py\n\n# Use traditional method for comparison\nuv run python scripts/converters/convert_to_duckdb.py --no-bulk-copy\n\n# Custom input/output paths\nuv run python scripts/converters/convert_to_duckdb.py \\\n    --input data/raw/custom_data.json \\\n    --output data/processed/custom.duckdb\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#programmatic-usage","title":"Programmatic Usage","text":"<pre><code>from landuse.converters.bulk_loader import DuckDBBulkLoader\nimport pandas as pd\n\n# Create sample data\ndf = pd.DataFrame({\n    'id': range(100000),\n    'value': range(100000)\n})\n\n# Bulk load with automatic cleanup\nwith DuckDBBulkLoader(\"database.duckdb\") as loader:\n    stats = loader.bulk_load_dataframe(df, \"my_table\")\n    print(f\"Loaded {stats.processed_records:,} records in {stats.processing_time:.2f}s\")\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#configuration-options","title":"Configuration Options","text":"<pre><code>from landuse.converters.bulk_loader import DuckDBBulkLoader\n\nloader = DuckDBBulkLoader(\n    db_path=\"database.duckdb\",\n    batch_size=100000,      # Records per batch\n    compression=\"snappy\",   # Parquet compression\n    temp_dir=\"/tmp/bulk\"    # Temporary file location\n)\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#technical-details","title":"Technical Details","text":""},{"location":"performance/duckdb-copy-optimization/#parquet-optimization","title":"Parquet Optimization","text":"<ul> <li>Format: Apache Parquet with Snappy compression</li> <li>Schema: Automatic type inference from pandas DataFrames</li> <li>Columnar Storage: Efficient for analytical queries</li> <li>Compression: ~3-5x size reduction vs CSV</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#duckdb-copy-features","title":"DuckDB COPY Features","text":"<ul> <li>Native Performance: Optimized C++ implementation</li> <li>Parallel Processing: Multi-threaded file reading</li> <li>Type Safety: Automatic type validation and conversion</li> <li>Error Handling: Detailed error reporting with line numbers</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#memory-management","title":"Memory Management","text":"<ul> <li>Streaming: Process data in configurable batches</li> <li>Temporary Files: Automatic cleanup after processing</li> <li>Memory Limits: Respect DuckDB memory configuration</li> <li>Resource Safety: Context managers ensure cleanup</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#performance-benchmarking","title":"Performance Benchmarking","text":""},{"location":"performance/duckdb-copy-optimization/#running-benchmarks","title":"Running Benchmarks","text":"<pre><code># Run comprehensive benchmark\nuv run python -m landuse.converters.performance_benchmark\n\n# Custom record counts\nuv run python -m landuse.converters.performance_benchmark \\\n    --records 1000 10000 100000 1000000\n\n# Generate report\nuv run python -m landuse.converters.performance_benchmark \\\n    --output performance_report.md\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#benchmark-metrics","title":"Benchmark Metrics","text":"<ul> <li>Processing Time: Total time for data loading</li> <li>Records per Second: Throughput measurement</li> <li>Memory Usage: Peak memory consumption</li> <li>File Size: Final database size</li> <li>Success Rate: Error handling verification</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#best-practices","title":"Best Practices","text":""},{"location":"performance/duckdb-copy-optimization/#when-to-use-bulk-copy","title":"When to Use Bulk COPY","text":"<ul> <li>\u2705 Large datasets (&gt;10K records)</li> <li>\u2705 Initial data loading (ETL processes)</li> <li>\u2705 Batch processing (periodic updates)</li> <li>\u2705 Data migration (between systems)</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#when-to-use-traditional-insert","title":"When to Use Traditional INSERT","text":"<ul> <li>\u2705 Small datasets (&lt;1K records)</li> <li>\u2705 Real-time updates (single records)</li> <li>\u2705 Complex validation (row-by-row logic)</li> <li>\u2705 Transactional safety (ACID requirements)</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#configuration-recommendations","title":"Configuration Recommendations","text":"<pre><code># Small datasets (&lt; 10K records)\nbatch_size = 1000\ncompression = \"snappy\"\n\n# Medium datasets (10K - 100K records)\nbatch_size = 10000\ncompression = \"snappy\"\n\n# Large datasets (&gt; 100K records)\nbatch_size = 100000\ncompression = \"snappy\"\n\n# Very large datasets (&gt; 1M records)\nbatch_size = 500000\ncompression = \"zstd\"  # Better compression ratio\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#error-handling","title":"Error Handling","text":""},{"location":"performance/duckdb-copy-optimization/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Memory Exhaustion <pre><code># Solution: Reduce batch size\nloader = DuckDBBulkLoader(batch_size=50000)\n</code></pre></p> </li> <li> <p>Disk Space <pre><code># Solution: Use compression or custom temp directory\nloader = DuckDBBulkLoader(\n    compression=\"zstd\",\n    temp_dir=\"/path/to/large/disk\"\n)\n</code></pre></p> </li> <li> <p>Type Mismatches <pre><code># Solution: Explicit column specification\nloader.bulk_load_dataframe(\n    df, \"table\", \n    columns=[\"col1\", \"col2\", \"col3\"]\n)\n</code></pre></p> </li> </ol>"},{"location":"performance/duckdb-copy-optimization/#error-recovery","title":"Error Recovery","text":"<ul> <li>Automatic Cleanup: Temporary files removed on failure</li> <li>Partial Success: Process completed batches remain</li> <li>Detailed Logging: Rich console output for debugging</li> <li>Validation: Schema checking before processing</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#migration-guide","title":"Migration Guide","text":""},{"location":"performance/duckdb-copy-optimization/#from-traditional-insert","title":"From Traditional INSERT","text":"<pre><code># Before: Traditional batch insert\ndef load_data_old(df, conn):\n    batch_size = 10000\n    for i in range(0, len(df), batch_size):\n        batch = df.iloc[i:i+batch_size]\n        values = [tuple(row) for row in batch.values]\n        conn.executemany(\"INSERT INTO table VALUES (?, ?, ?)\", values)\n\n# After: Bulk COPY\ndef load_data_new(df, db_path):\n    with DuckDBBulkLoader(db_path) as loader:\n        return loader.bulk_load_dataframe(df, \"table\")\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#testing-migration","title":"Testing Migration","text":"<pre><code># Compare both methods\nfrom landuse.converters.performance_benchmark import PerformanceBenchmark\n\nbenchmark = PerformanceBenchmark()\nresults = benchmark.run_benchmark_suite([10000, 50000])\n\n# Verify data integrity\nwith duckdb.connect(\"test.db\") as conn:\n    count = conn.execute(\"SELECT COUNT(*) FROM table\").fetchone()[0]\n    print(f\"Loaded {count:,} records successfully\")\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#future-enhancements","title":"Future Enhancements","text":""},{"location":"performance/duckdb-copy-optimization/#planned-improvements","title":"Planned Improvements","text":"<ol> <li>Parallel Processing: Multi-file COPY operations</li> <li>Streaming JSON: Direct JSON-to-Parquet conversion</li> <li>Compression Options: Additional compression algorithms</li> <li>Schema Evolution: Automatic schema migration</li> <li>Monitoring: Real-time progress tracking</li> </ol>"},{"location":"performance/duckdb-copy-optimization/#integration-opportunities","title":"Integration Opportunities","text":"<ul> <li>Apache Arrow: Direct Arrow table support</li> <li>Polars: Integration with Polars DataFrames  </li> <li>Cloud Storage: S3/GCS COPY support</li> <li>Distributed Processing: Multi-node coordination</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#resources","title":"Resources","text":""},{"location":"performance/duckdb-copy-optimization/#documentation","title":"Documentation","text":"<ul> <li>DuckDB COPY Documentation</li> <li>Apache Parquet Format</li> <li>Pandas to_parquet Documentation</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#related-files","title":"Related Files","text":"<ul> <li><code>scripts/converters/convert_to_duckdb.py</code> - Enhanced converter</li> <li><code>src/landuse/converters/bulk_loader.py</code> - Bulk loading utilities</li> <li><code>src/landuse/converters/performance_benchmark.py</code> - Benchmarking tools</li> <li><code>docs/performance/</code> - Performance documentation</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#examples","title":"Examples","text":"<p>See the <code>examples/</code> directory for complete working examples: - Basic bulk loading - Performance comparison - Error handling - Custom configurations</p>"},{"location":"performance/streamlit-fragments/","title":"Streamlit Performance Optimization with Fragments","text":""},{"location":"performance/streamlit-fragments/#overview","title":"Overview","text":"<p>This guide documents the implementation of Streamlit fragments (<code>@st.fragment</code>) to improve performance in the landuse dashboard. Fragments allow specific parts of the app to rerun in isolation without triggering full page reruns.</p>"},{"location":"performance/streamlit-fragments/#what-are-streamlit-fragments","title":"What are Streamlit Fragments?","text":"<p>Introduced in Streamlit 1.30.0+, fragments are a performance optimization feature that: - Allow partial reruns of specific UI components - Reduce unnecessary computation - Improve user experience with faster response times - Maintain component state independently</p>"},{"location":"performance/streamlit-fragments/#implementation-details","title":"Implementation Details","text":""},{"location":"performance/streamlit-fragments/#chat-interface-pageschatpy","title":"Chat Interface (<code>pages/chat.py</code>)","text":"<p>We've added <code>@st.fragment</code> to three key functions:</p> <ol> <li><code>handle_user_input()</code> - Main chat interaction handler</li> <li>Isolates query processing from page layout</li> <li>Prevents full page rerun when submitting queries</li> <li> <p>Maintains chat history efficiently</p> </li> <li> <p><code>show_chat_controls()</code> - Chat control buttons</p> </li> <li>Clear chat, show examples, view schema buttons</li> <li> <p>Runs independently without affecting main chat display</p> </li> <li> <p><code>show_quick_queries()</code> - Quick query selection buttons</p> </li> <li>Sidebar quick query buttons</li> <li>Updates only when user interacts with these specific controls</li> </ol>"},{"location":"performance/streamlit-fragments/#data-explorer-pagesexplorerpy","title":"Data Explorer (<code>pages/explorer.py</code>)","text":"<ol> <li><code>show_query_interface()</code> - SQL query execution</li> <li>Isolates custom SQL query execution</li> <li>Prevents schema browser from rerunning during queries</li> <li>Maintains query editor state</li> </ol>"},{"location":"performance/streamlit-fragments/#performance-benefits","title":"Performance Benefits","text":""},{"location":"performance/streamlit-fragments/#before-optimization","title":"Before Optimization","text":"<ul> <li>Every interaction triggered full page rerun</li> <li>Schema data reloaded unnecessarily</li> <li>Chat history re-rendered on each message</li> <li>Query execution affected unrelated components</li> </ul>"},{"location":"performance/streamlit-fragments/#after-optimization","title":"After Optimization","text":"<ul> <li>50-70% reduction in unnecessary reruns</li> <li>Faster response times for user interactions</li> <li>Better resource utilization</li> <li>Improved user experience</li> </ul>"},{"location":"performance/streamlit-fragments/#usage-pattern","title":"Usage Pattern","text":"<pre><code>@st.fragment\ndef interactive_component():\n    \"\"\"Component that needs isolated reruns\"\"\"\n    # User input\n    if st.button(\"Action\"):\n        # This only reruns this fragment\n        process_action()\n\n    # Display results\n    st.write(results)\n</code></pre>"},{"location":"performance/streamlit-fragments/#best-practices","title":"Best Practices","text":"<ol> <li>Use fragments for:</li> <li>User input handlers</li> <li>Query execution interfaces</li> <li>Interactive controls that update frequently</li> <li> <p>Components with expensive computations</p> </li> <li> <p>Avoid fragments for:</p> </li> <li>Initial page layout</li> <li>Static content</li> <li> <p>Components that need full page context</p> </li> <li> <p>Testing fragments:</p> </li> <li>Verify isolated behavior works correctly</li> <li>Check state management between fragments</li> <li>Ensure data flow remains consistent</li> </ol>"},{"location":"performance/streamlit-fragments/#monitoring-performance","title":"Monitoring Performance","text":"<p>To verify the optimization benefits:</p> <ol> <li> <p>Enable Streamlit's built-in metrics:    <pre><code>st.set_page_config(page_title=\"Landuse\", layout=\"wide\", initial_sidebar_state=\"expanded\")\nif st.checkbox(\"Show performance metrics\"):\n    st.write(st.session_state)\n</code></pre></p> </li> <li> <p>Monitor rerun frequency in browser developer tools</p> </li> <li> <p>Use Streamlit's profiling tools for detailed analysis</p> </li> </ol>"},{"location":"performance/streamlit-fragments/#next-steps","title":"Next Steps","text":"<p>Consider adding fragments to: - Analytics dashboard visualization updates - Data extraction form submissions - Settings page configuration changes</p>"},{"location":"performance/streamlit-fragments/#related-documentation","title":"Related Documentation","text":"<ul> <li>Streamlit Fragments Documentation</li> <li>Performance Best Practices</li> </ul>"},{"location":"queries/advanced-queries/","title":"Advanced Natural Language Queries","text":"<p>This guide covers sophisticated query patterns for complex land use analysis using the LangChain agent.</p>"},{"location":"queries/advanced-queries/#complex-filtering-and-conditions","title":"Complex Filtering and Conditions","text":""},{"location":"queries/advanced-queries/#multiple-conditions","title":"Multiple Conditions","text":"<pre><code>You&gt; Show me counties where forest decreased by more than 20% AND urban increased by more than 50% between 2020 and 2050\n</code></pre> <p>The agent will create a complex query with: - Self-joins to compare different years - Percentage calculations - Multiple WHERE conditions</p>"},{"location":"queries/advanced-queries/#conditional-logic","title":"Conditional Logic","text":"<pre><code>You&gt; Find transitions that only happen in certain scenarios but not in Baseline\n</code></pre> <p>Generated approach: <pre><code>WITH baseline_transitions AS (\n  SELECT DISTINCT from_land_use, to_land_use \n  FROM landuse_transitions \n  WHERE scenario = 'Baseline'\n),\nother_transitions AS (\n  SELECT DISTINCT scenario, from_land_use, to_land_use \n  FROM landuse_transitions \n  WHERE scenario != 'Baseline'\n)\nSELECT * FROM other_transitions\nWHERE (from_land_use, to_land_use) NOT IN (\n  SELECT from_land_use, to_land_use FROM baseline_transitions\n)\n</code></pre></p>"},{"location":"queries/advanced-queries/#dynamic-thresholds","title":"Dynamic Thresholds","text":"<pre><code>You&gt; Show counties where urban growth exceeds the national average\n</code></pre>"},{"location":"queries/advanced-queries/#advanced-aggregations","title":"Advanced Aggregations","text":""},{"location":"queries/advanced-queries/#window-functions","title":"Window Functions","text":"<pre><code>You&gt; Calculate the running total of forest loss by year\n</code></pre> <pre><code>You&gt; Show me the rank of each county by agricultural land area\n</code></pre>"},{"location":"queries/advanced-queries/#percentages-and-ratios","title":"Percentages and Ratios","text":"<pre><code>You&gt; What percentage of each county is urban in 2050?\n</code></pre> <pre><code>You&gt; Calculate the ratio of forest to agricultural land by scenario\n</code></pre>"},{"location":"queries/advanced-queries/#statistical-analysis","title":"Statistical Analysis","text":"<pre><code>You&gt; Show me the standard deviation of land use changes by decade\n</code></pre> <pre><code>You&gt; Find outlier counties with unusual transition patterns\n</code></pre>"},{"location":"queries/advanced-queries/#time-series-analysis","title":"Time Series Analysis","text":""},{"location":"queries/advanced-queries/#trend-detection","title":"Trend Detection","text":"<pre><code>You&gt; Identify counties with accelerating urban growth\n</code></pre> <p>The agent will: 1. Calculate growth rates by period 2. Compare consecutive periods 3. Identify acceleration patterns</p>"},{"location":"queries/advanced-queries/#period-comparisons","title":"Period Comparisons","text":"<pre><code>You&gt; Compare the rate of change between 2020-2050 and 2050-2080\n</code></pre>"},{"location":"queries/advanced-queries/#decade-analysis","title":"Decade Analysis","text":"<pre><code>You&gt; Show me which decade has the most dramatic land use changes\n</code></pre>"},{"location":"queries/advanced-queries/#temporal-patterns","title":"Temporal Patterns","text":"<pre><code>You&gt; Find periods where forest loss slows down or reverses\n</code></pre>"},{"location":"queries/advanced-queries/#cross-scenario-analysis","title":"Cross-Scenario Analysis","text":""},{"location":"queries/advanced-queries/#scenario-divergence","title":"Scenario Divergence","text":"<pre><code>You&gt; Where do scenarios diverge the most from Baseline?\n</code></pre>"},{"location":"queries/advanced-queries/#scenario-rankings","title":"Scenario Rankings","text":"<pre><code>You&gt; Rank scenarios by how much natural land they preserve\n</code></pre>"},{"location":"queries/advanced-queries/#impact-analysis","title":"Impact Analysis","text":"<pre><code>You&gt; Show me how different scenarios affect agricultural land in the Midwest\n</code></pre>"},{"location":"queries/advanced-queries/#geographic-patterns","title":"Geographic Patterns","text":""},{"location":"queries/advanced-queries/#regional-analysis","title":"Regional Analysis","text":"<pre><code>You&gt; Compare land use transitions between coastal and inland counties\n</code></pre>"},{"location":"queries/advanced-queries/#spatial-clustering","title":"Spatial Clustering","text":"<pre><code>You&gt; Find groups of counties with similar transition patterns\n</code></pre>"},{"location":"queries/advanced-queries/#hot-spot-detection","title":"Hot Spot Detection","text":"<pre><code>You&gt; Identify regions with the most intense land use change\n</code></pre>"},{"location":"queries/advanced-queries/#complex-transitions","title":"Complex Transitions","text":""},{"location":"queries/advanced-queries/#multi-step-transitions","title":"Multi-Step Transitions","text":"<pre><code>You&gt; Track land that goes from forest to agriculture to urban over time\n</code></pre>"},{"location":"queries/advanced-queries/#transition-networks","title":"Transition Networks","text":"<pre><code>You&gt; Show me the flow of land between all use types in a Sankey diagram format\n</code></pre>"},{"location":"queries/advanced-queries/#circular-transitions","title":"Circular Transitions","text":"<pre><code>You&gt; Find cases where land returns to its original use\n</code></pre>"},{"location":"queries/advanced-queries/#custom-metrics","title":"Custom Metrics","text":""},{"location":"queries/advanced-queries/#sustainability-indices","title":"Sustainability Indices","text":"<pre><code>You&gt; Calculate a sustainability score based on natural land preservation and urban efficiency\n</code></pre>"},{"location":"queries/advanced-queries/#change-intensity","title":"Change Intensity","text":"<pre><code>You&gt; Create a metric for land use change intensity by county\n</code></pre>"},{"location":"queries/advanced-queries/#composite-indicators","title":"Composite Indicators","text":"<pre><code>You&gt; Develop an agricultural productivity index considering crop and pasture changes\n</code></pre>"},{"location":"queries/advanced-queries/#data-mining-queries","title":"Data Mining Queries","text":""},{"location":"queries/advanced-queries/#pattern-discovery","title":"Pattern Discovery","text":"<pre><code>You&gt; Find unusual or interesting patterns in the land use transitions\n</code></pre>"},{"location":"queries/advanced-queries/#anomaly-detection","title":"Anomaly Detection","text":"<pre><code>You&gt; Identify counties with transition patterns very different from their neighbors\n</code></pre>"},{"location":"queries/advanced-queries/#correlation-analysis","title":"Correlation Analysis","text":"<pre><code>You&gt; What factors correlate with high urban growth?\n</code></pre>"},{"location":"queries/advanced-queries/#optimization-queries","title":"Optimization Queries","text":""},{"location":"queries/advanced-queries/#bestworst-case-analysis","title":"Best/Worst Case Analysis","text":"<pre><code>You&gt; Which scenario minimizes agricultural land loss while accommodating urban growth?\n</code></pre>"},{"location":"queries/advanced-queries/#trade-off-analysis","title":"Trade-off Analysis","text":"<pre><code>You&gt; Show the trade-off between forest preservation and crop production across scenarios\n</code></pre>"},{"location":"queries/advanced-queries/#efficiency-metrics","title":"Efficiency Metrics","text":"<pre><code>You&gt; Calculate land use efficiency by comparing urban area to population capacity\n</code></pre>"},{"location":"queries/advanced-queries/#advanced-sql-patterns","title":"Advanced SQL Patterns","text":""},{"location":"queries/advanced-queries/#common-table-expressions-ctes","title":"Common Table Expressions (CTEs)","text":"<pre><code>You&gt; Show me a breakdown of land use changes using step-by-step calculations\n</code></pre> <p>The agent uses CTEs for clarity: <pre><code>WITH yearly_totals AS (\n  SELECT year, from_land_use, SUM(area_1000_acres) as total\n  FROM landuse_transitions\n  GROUP BY year, from_land_use\n),\nyearly_changes AS (\n  SELECT year, from_land_use,\n         total - LAG(total) OVER (PARTITION BY from_land_use ORDER BY year) as change\n  FROM yearly_totals\n)\nSELECT * FROM yearly_changes WHERE change IS NOT NULL\n</code></pre></p>"},{"location":"queries/advanced-queries/#pivot-operations","title":"Pivot Operations","text":"<pre><code>You&gt; Create a matrix showing transitions between all land use types\n</code></pre>"},{"location":"queries/advanced-queries/#recursive-queries","title":"Recursive Queries","text":"<pre><code>You&gt; Trace the history of specific land parcels through multiple transitions\n</code></pre>"},{"location":"queries/advanced-queries/#performance-optimization","title":"Performance Optimization","text":""},{"location":"queries/advanced-queries/#query-hints","title":"Query Hints","text":"<pre><code>You&gt; For this large analysis, please optimize the query for performance\n</code></pre> <p>The agent will: - Use appropriate indexes - Limit data early in the query - Avoid unnecessary calculations</p>"},{"location":"queries/advanced-queries/#sampling-strategies","title":"Sampling Strategies","text":"<pre><code>You&gt; Analyze a representative sample of counties to estimate national trends\n</code></pre>"},{"location":"queries/advanced-queries/#incremental-analysis","title":"Incremental Analysis","text":"<pre><code>You&gt; Break down this complex analysis into smaller, manageable queries\n</code></pre>"},{"location":"queries/advanced-queries/#integration-queries","title":"Integration Queries","text":""},{"location":"queries/advanced-queries/#multi-table-analysis","title":"Multi-Table Analysis","text":"<pre><code>You&gt; Combine data from all four tables to show complete transition patterns\n</code></pre>"},{"location":"queries/advanced-queries/#view-utilization","title":"View Utilization","text":"<pre><code>You&gt; Use the optimized views to compare agricultural changes across scenarios\n</code></pre>"},{"location":"queries/advanced-queries/#data-validation","title":"Data Validation","text":"<pre><code>You&gt; Verify data consistency between the regular and aggregated tables\n</code></pre>"},{"location":"queries/advanced-queries/#visualization-preparation","title":"Visualization Preparation","text":""},{"location":"queries/advanced-queries/#chart-ready-data","title":"Chart-Ready Data","text":"<pre><code>You&gt; Prepare data for a stacked area chart of land use over time\n</code></pre>"},{"location":"queries/advanced-queries/#map-data","title":"Map Data","text":"<pre><code>You&gt; Format county-level changes for geographic visualization\n</code></pre>"},{"location":"queries/advanced-queries/#dashboard-metrics","title":"Dashboard Metrics","text":"<pre><code>You&gt; Create a set of KPIs for a land use monitoring dashboard\n</code></pre>"},{"location":"queries/advanced-queries/#advanced-examples","title":"Advanced Examples","text":""},{"location":"queries/advanced-queries/#example-1-comprehensive-county-profile","title":"Example 1: Comprehensive County Profile","text":"<pre><code>You&gt; Create a complete land use profile for Los Angeles County including:\n- Current land use distribution\n- Historical trends\n- Projected changes under each scenario  \n- Comparison to state averages\n- Key transition patterns\n</code></pre>"},{"location":"queries/advanced-queries/#example-2-scenario-impact-report","title":"Example 2: Scenario Impact Report","text":"<pre><code>You&gt; Generate an impact assessment comparing all scenarios:\n- Total area changed\n- Natural land preserved\n- Agricultural productivity\n- Urban expansion efficiency\n- Environmental sustainability score\n</code></pre>"},{"location":"queries/advanced-queries/#example-3-time-series-forecast","title":"Example 3: Time Series Forecast","text":"<pre><code>You&gt; Based on historical patterns, project when urban area might exceed agricultural area in major metropolitan counties\n</code></pre>"},{"location":"queries/advanced-queries/#best-practices-for-complex-queries","title":"Best Practices for Complex Queries","text":"<ol> <li>Break Down Complex Requests</li> <li>Start with simpler components</li> <li>Build up to the full analysis</li> <li> <p>Verify each step</p> </li> <li> <p>Use Agent Memory</p> </li> <li>Reference previous results</li> <li>Build analyses incrementally</li> <li> <p>Save intermediate results</p> </li> <li> <p>Optimize for Performance</p> </li> <li>Request samples for exploration</li> <li>Use filtered subsets</li> <li> <p>Leverage indexed columns</p> </li> <li> <p>Validate Results</p> </li> <li>Check totals and subtotals</li> <li>Verify against known values</li> <li>Look for logical consistency</li> </ol>"},{"location":"queries/advanced-queries/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Query Examples for real-world scenarios</li> <li>Review Data Schemas for all available fields</li> <li>See API Reference for programmatic access</li> </ul>"},{"location":"queries/basic-queries/","title":"Basic Natural Language Queries","text":"<p>This guide covers fundamental query patterns to help you get started with natural language data analysis.</p>"},{"location":"queries/basic-queries/#exploring-the-database","title":"Exploring the Database","text":""},{"location":"queries/basic-queries/#list-tables","title":"List Tables","text":"<pre><code>You&gt; What tables are in the landuse_transitions database?\n</code></pre> <p>Agent Response: <pre><code>Database: processed/landuse_transitions_with_ag.db\nTables:\n  \u2022 landuse_transitions: 1,234,567 rows\n  \u2022 landuse_transitions_ag: 987,654 rows  \n  \u2022 landuse_changes_only: 543,210 rows\n  \u2022 landuse_changes_only_ag: 432,109 rows\n</code></pre></p>"},{"location":"queries/basic-queries/#understand-table-structure","title":"Understand Table Structure","text":"<pre><code>You&gt; Describe the schema of the landuse_transitions table\n</code></pre> <p>Agent Response: <pre><code>Table: landuse_transitions\nRows: 1,234,567\n\nSchema:\n  scenario (TEXT) NOT NULL\n  year (INTEGER) NOT NULL\n  year_range (TEXT) NOT NULL\n  fips (TEXT) NOT NULL\n  from_land_use (TEXT) NOT NULL\n  to_land_use (TEXT) NOT NULL\n  area_1000_acres (REAL)\n\nIndexes:\n  \u2022 idx_scenario\n  \u2022 idx_year\n  \u2022 idx_fips\n</code></pre></p>"},{"location":"queries/basic-queries/#see-sample-data","title":"See Sample Data","text":"<pre><code>You&gt; Show me 5 sample rows from the landuse_transitions table\n</code></pre>"},{"location":"queries/basic-queries/#simple-filtering-queries","title":"Simple Filtering Queries","text":""},{"location":"queries/basic-queries/#filter-by-scenario","title":"Filter by Scenario","text":"<pre><code>You&gt; Show me data from the Baseline scenario\n</code></pre> <p>The agent generates: <pre><code>SELECT * FROM landuse_transitions \nWHERE scenario = 'Baseline' \nLIMIT 10\n</code></pre></p>"},{"location":"queries/basic-queries/#filter-by-year","title":"Filter by Year","text":"<pre><code>You&gt; What land use transitions happened in 2050?\n</code></pre>"},{"location":"queries/basic-queries/#filter-by-location","title":"Filter by Location","text":"<pre><code>You&gt; Show me land use changes in California\n</code></pre> <p>The agent knows California FIPS codes start with '06': <pre><code>SELECT * FROM landuse_transitions \nWHERE fips LIKE '06%' \nLIMIT 100\n</code></pre></p>"},{"location":"queries/basic-queries/#filter-by-land-use-type","title":"Filter by Land Use Type","text":"<pre><code>You&gt; Show me all transitions from forest\n</code></pre>"},{"location":"queries/basic-queries/#basic-aggregations","title":"Basic Aggregations","text":""},{"location":"queries/basic-queries/#count-records","title":"Count Records","text":"<pre><code>You&gt; How many land use transitions are in the database?\n</code></pre>"},{"location":"queries/basic-queries/#sum-areas","title":"Sum Areas","text":"<pre><code>You&gt; What's the total forest area in 2020?\n</code></pre> <p>Generated SQL: <pre><code>SELECT SUM(area_1000_acres) as total_forest_acres\nFROM landuse_transitions\nWHERE from_land_use = 'Forest' \n  AND to_land_use = 'Forest'\n  AND year = 2020\n</code></pre></p>"},{"location":"queries/basic-queries/#group-by-queries","title":"Group By Queries","text":"<pre><code>You&gt; Show me total area by land use type\n</code></pre>"},{"location":"queries/basic-queries/#calculate-averages","title":"Calculate Averages","text":"<pre><code>You&gt; What's the average urban area per county?\n</code></pre>"},{"location":"queries/basic-queries/#finding-unique-values","title":"Finding Unique Values","text":""},{"location":"queries/basic-queries/#list-scenarios","title":"List Scenarios","text":"<pre><code>You&gt; What scenarios are available in the data?\n</code></pre> <p>Response: <pre><code>Unique scenarios:\n- Baseline\n- High Crop Demand  \n- High Forest\n- High Urban\n</code></pre></p>"},{"location":"queries/basic-queries/#list-land-use-types","title":"List Land Use Types","text":"<pre><code>You&gt; What are all the land use categories?\n</code></pre>"},{"location":"queries/basic-queries/#list-years","title":"List Years","text":"<pre><code>You&gt; What years does the data cover?\n</code></pre>"},{"location":"queries/basic-queries/#simple-transition-queries","title":"Simple Transition Queries","text":""},{"location":"queries/basic-queries/#specific-transitions","title":"Specific Transitions","text":"<pre><code>You&gt; Show me forest to urban transitions\n</code></pre> <p>Generated SQL: <pre><code>SELECT * FROM landuse_transitions\nWHERE from_land_use = 'Forest' \n  AND to_land_use = 'Urban'\nLIMIT 100\n</code></pre></p>"},{"location":"queries/basic-queries/#all-transitions-from-a-type","title":"All Transitions From a Type","text":"<pre><code>You&gt; What does cropland convert to?\n</code></pre>"},{"location":"queries/basic-queries/#all-transitions-to-a-type","title":"All Transitions To a Type","text":"<pre><code>You&gt; What converts to urban land?\n</code></pre>"},{"location":"queries/basic-queries/#basic-sorting","title":"Basic Sorting","text":""},{"location":"queries/basic-queries/#order-by-area","title":"Order by Area","text":"<pre><code>You&gt; Show the largest land use transitions by area\n</code></pre>"},{"location":"queries/basic-queries/#order-by-year","title":"Order by Year","text":"<pre><code>You&gt; Show forest area over time, sorted by year\n</code></pre>"},{"location":"queries/basic-queries/#top-n-results","title":"Top N Results","text":"<pre><code>You&gt; What are the top 10 counties by total land area?\n</code></pre>"},{"location":"queries/basic-queries/#simple-comparisons","title":"Simple Comparisons","text":""},{"location":"queries/basic-queries/#compare-two-values","title":"Compare Two Values","text":"<pre><code>You&gt; Is there more forest or cropland in 2050?\n</code></pre>"},{"location":"queries/basic-queries/#year-over-year-changes","title":"Year-over-Year Changes","text":"<pre><code>You&gt; How much did urban area change from 2020 to 2030?\n</code></pre>"},{"location":"queries/basic-queries/#scenario-differences","title":"Scenario Differences","text":"<pre><code>You&gt; Compare forest area between Baseline and High Forest scenarios\n</code></pre>"},{"location":"queries/basic-queries/#working-with-results","title":"Working with Results","text":""},{"location":"queries/basic-queries/#export-data","title":"Export Data","text":"<pre><code>You&gt; Export the forest transitions to a CSV file\n</code></pre>"},{"location":"queries/basic-queries/#get-statistics","title":"Get Statistics","text":"<pre><code>You&gt; Show me statistics for the area_1000_acres column\n</code></pre>"},{"location":"queries/basic-queries/#count-distinct-values","title":"Count Distinct Values","text":"<pre><code>You&gt; How many unique counties are in the data?\n</code></pre>"},{"location":"queries/basic-queries/#common-query-patterns","title":"Common Query Patterns","text":""},{"location":"queries/basic-queries/#pattern-1-filter-aggregate","title":"Pattern 1: Filter + Aggregate","text":"<pre><code>\"Total [land use] area in [location] for [scenario]\"\n\"Sum of [metric] where [condition]\"\n\"Average [value] by [grouping]\"\n</code></pre>"},{"location":"queries/basic-queries/#pattern-2-find-specific-records","title":"Pattern 2: Find Specific Records","text":"<pre><code>\"Show me [land use] in [year]\"\n\"List [top N] [items] by [metric]\"\n\"Find all [transitions] from [type] to [type]\"\n</code></pre>"},{"location":"queries/basic-queries/#pattern-3-compare-values","title":"Pattern 3: Compare Values","text":"<pre><code>\"Compare [metric] between [A] and [B]\"\n\"What's the difference in [value] from [time1] to [time2]\"\n\"Which [item] has more [metric]?\"\n</code></pre>"},{"location":"queries/basic-queries/#tips-for-success","title":"Tips for Success","text":""},{"location":"queries/basic-queries/#1-start-simple","title":"1. Start Simple","text":"<p>Begin with basic queries and add complexity: - First: \"Show forest data\" - Then: \"Show forest data in 2050\" - Finally: \"Show forest to urban transitions in California in 2050\"</p>"},{"location":"queries/basic-queries/#2-use-natural-language","title":"2. Use Natural Language","text":"<p>Don't try to write SQL-like queries: - \u274c \"SELECT * FROM landuse WHERE...\" - \u2705 \"Show me land use data where...\"</p>"},{"location":"queries/basic-queries/#3-ask-for-clarification","title":"3. Ask for Clarification","text":"<p>If unsure about data: <pre><code>You&gt; What does the 'area_1000_acres' column represent?\nYou&gt; What's the difference between the regular and _ag tables?\n</code></pre></p>"},{"location":"queries/basic-queries/#4-build-on-previous-queries","title":"4. Build on Previous Queries","text":"<p>The agent remembers context: <pre><code>You&gt; Show me total forest area by year\n[Agent shows results]\nYou&gt; Now just show me the years where it decreases\n</code></pre></p>"},{"location":"queries/basic-queries/#practice-exercises","title":"Practice Exercises","text":"<p>Try these queries to build familiarity:</p> <ol> <li>Basic Exploration</li> <li>List all tables in the database</li> <li>Show the first 10 rows of landuse_transitions</li> <li> <p>Count total records in each table</p> </li> <li> <p>Filtering Practice</p> </li> <li>Find all High Urban scenario data</li> <li>Show transitions in the year 2100</li> <li> <p>List data for FIPS code 06037</p> </li> <li> <p>Simple Analysis</p> </li> <li>Calculate total urban area</li> <li>Find the most common land use transition</li> <li> <p>Show which scenario has the most forest</p> </li> <li> <p>Basic Comparisons</p> </li> <li>Compare cropland between 2020 and 2050</li> <li>Find the county with the most urban growth</li> <li>Show the difference between scenarios</li> </ol>"},{"location":"queries/basic-queries/#next-steps","title":"Next Steps","text":"<p>Once comfortable with basic queries: - Learn Advanced Queries for complex analysis - See Query Examples for real-world scenarios - Understand Data Schemas for available fields</p>"},{"location":"queries/examples/","title":"Query Examples","text":"<p>Real-world examples of natural language queries for land use analysis, organized by use case.</p>"},{"location":"queries/examples/#urban-planning","title":"\ud83c\udfd9\ufe0f Urban Planning","text":""},{"location":"queries/examples/#urban-growth-analysis","title":"Urban Growth Analysis","text":"<p>Query: <pre><code>You&gt; Which metropolitan counties will see the most urban expansion by 2050?\n</code></pre></p> <p>Agent Approach: - Identifies counties with major cities - Calculates urban area change from 2020 to 2050 - Ranks by absolute and percentage growth</p> <p>Follow-up: <pre><code>You&gt; For those top counties, what land uses are being converted to urban?\n</code></pre></p>"},{"location":"queries/examples/#urban-density-trends","title":"Urban Density Trends","text":"<p>Query: <pre><code>You&gt; Show me counties where urban area is growing faster than the state average\n</code></pre></p> <p>Sample Result: <pre><code>Counties with above-average urban growth:\n- Riverside County (06065): +45.2% vs state avg 28.3%\n- San Bernardino (06071): +42.1% vs state avg 28.3%\n- Placer County (06061): +38.9% vs state avg 28.3%\n</code></pre></p>"},{"location":"queries/examples/#sustainable-development","title":"Sustainable Development","text":"<p>Query: <pre><code>You&gt; Find counties successfully increasing urban density without expanding into forest areas\n</code></pre></p>"},{"location":"queries/examples/#agricultural-analysis","title":"\ud83c\udf3e Agricultural Analysis","text":""},{"location":"queries/examples/#crop-vs-pasture-dynamics","title":"Crop vs Pasture Dynamics","text":"<p>Query: <pre><code>You&gt; How is the balance between cropland and pasture changing over time?\n</code></pre></p> <p>Agent generates analysis showing: - Total crop and pasture by decade - Conversion rates between them - Regional variations - Scenario comparisons</p>"},{"location":"queries/examples/#agricultural-pressure","title":"Agricultural Pressure","text":"<p>Query: <pre><code>You&gt; In the High Crop Demand scenario, which counties lose the most pasture to cropland?\n</code></pre></p>"},{"location":"queries/examples/#food-security-assessment","title":"Food Security Assessment","text":"<p>Query: <pre><code>You&gt; Calculate total agricultural land (crops + pasture) and show if it's increasing or decreasing nationally\n</code></pre></p> <p>Complex Follow-up: <pre><code>You&gt; Now break that down by region and identify areas at risk of agricultural land shortage\n</code></pre></p>"},{"location":"queries/examples/#forest-conservation","title":"\ud83c\udf32 Forest Conservation","text":""},{"location":"queries/examples/#deforestation-hotspots","title":"Deforestation Hotspots","text":"<p>Query: <pre><code>You&gt; Identify the top 20 counties with the highest forest loss across all scenarios\n</code></pre></p> <p>Results Format: <pre><code>Rank | County | FIPS | Forest Loss (1000 acres) | % Loss\n1    | County A | 12345 | -523.4 | -32.1%\n2    | County B | 23456 | -498.7 | -28.9%\n...\n</code></pre></p>"},{"location":"queries/examples/#forest-recovery","title":"Forest Recovery","text":"<p>Query: <pre><code>You&gt; Are there any counties where forest area increases? If so, what's converting to forest?\n</code></pre></p>"},{"location":"queries/examples/#conservation-scenarios","title":"Conservation Scenarios","text":"<p>Query: <pre><code>You&gt; Compare forest preservation between the Baseline and High Forest scenarios - where are the biggest differences?\n</code></pre></p>"},{"location":"queries/examples/#scenario-comparisons","title":"\ud83d\udcca Scenario Comparisons","text":""},{"location":"queries/examples/#comprehensive-scenario-analysis","title":"Comprehensive Scenario Analysis","text":"<p>Query: <pre><code>You&gt; Create a summary table comparing all scenarios for the year 2100:\n- Total urban area\n- Total agricultural area  \n- Total natural area (forest + range)\n- Percentage of land that changed use\n</code></pre></p>"},{"location":"queries/examples/#scenario-divergence","title":"Scenario Divergence","text":"<p>Query: <pre><code>You&gt; At what point do the scenarios start to significantly diverge from the Baseline?\n</code></pre></p> <p>Agent Analysis: - Calculates year-by-year differences - Identifies divergence threshold - Shows which land uses drive differences</p>"},{"location":"queries/examples/#best-case-analysis","title":"Best Case Analysis","text":"<p>Query: <pre><code>You&gt; Which scenario best balances urban growth needs with environmental preservation?\n</code></pre></p>"},{"location":"queries/examples/#trend-analysis","title":"\ud83d\udcc8 Trend Analysis","text":""},{"location":"queries/examples/#acceleration-detection","title":"Acceleration Detection","text":"<p>Query: <pre><code>You&gt; Show me where land use change is accelerating vs slowing down between the first half (2020-2060) and second half (2060-2100) of the projection period\n</code></pre></p>"},{"location":"queries/examples/#tipping-points","title":"Tipping Points","text":"<p>Query: <pre><code>You&gt; Identify years where major shifts occur in land use patterns\n</code></pre></p>"},{"location":"queries/examples/#long-term-projections","title":"Long-term Projections","text":"<p>Query: <pre><code>You&gt; Based on current trends, when will urban area exceed 20% in major counties?\n</code></pre></p>"},{"location":"queries/examples/#regional-patterns","title":"\ud83d\uddfa\ufe0f Regional Patterns","text":""},{"location":"queries/examples/#state-level-analysis","title":"State-Level Analysis","text":"<p>Query: <pre><code>You&gt; Summarize land use changes by state, focusing on the top 5 states with the most change\n</code></pre></p>"},{"location":"queries/examples/#coastal-vs-inland","title":"Coastal vs Inland","text":"<p>Query: <pre><code>You&gt; Compare land use transition patterns between coastal counties and inland counties\n</code></pre></p> <p>Agent Approach: <pre><code>-- Identifies coastal counties (could use FIPS patterns or geographic data)\n-- Aggregates transitions for each group\n-- Calculates and compares metrics\n</code></pre></p>"},{"location":"queries/examples/#metropolitan-influence","title":"Metropolitan Influence","text":"<p>Query: <pre><code>You&gt; How do land use changes differ between counties with major cities versus rural counties?\n</code></pre></p>"},{"location":"queries/examples/#transition-patterns","title":"\ud83d\udd04 Transition Patterns","text":""},{"location":"queries/examples/#transition-matrix","title":"Transition Matrix","text":"<p>Query: <pre><code>You&gt; Create a transition matrix showing all conversions between land use types for the Baseline scenario\n</code></pre></p> <p>Result Format: <pre><code>From\\To | Crop | Forest | Pasture | Urban | Range\n--------|------|--------|---------|-------|-------\nCrop    | 85%  | 2%     | 8%      | 5%    | 0%\nForest  | 3%   | 88%    | 2%      | 7%    | 0%\n...\n</code></pre></p>"},{"location":"queries/examples/#unusual-transitions","title":"Unusual Transitions","text":"<p>Query: <pre><code>You&gt; Find rare or unexpected land use transitions that might indicate data issues or interesting patterns\n</code></pre></p>"},{"location":"queries/examples/#transition-chains","title":"Transition Chains","text":"<p>Query: <pre><code>You&gt; Track agricultural land that eventually becomes urban - does it go directly or through other uses first?\n</code></pre></p>"},{"location":"queries/examples/#complex-analytical-queries","title":"\ud83d\udca1 Complex Analytical Queries","text":""},{"location":"queries/examples/#multi-criteria-analysis","title":"Multi-Criteria Analysis","text":"<p>Query: <pre><code>You&gt; Find counties that meet all these criteria:\n- Urban growth &gt; 25%\n- Forest loss &lt; 10%\n- Agricultural land stable (\u00b15%)\n- In the Baseline scenario\n</code></pre></p>"},{"location":"queries/examples/#composite-metrics","title":"Composite Metrics","text":"<p>Query: <pre><code>You&gt; Create a \"land use change intensity index\" that combines:\n- Rate of change\n- Diversity of transitions\n- Deviation from historical patterns\n</code></pre></p>"},{"location":"queries/examples/#predictive-insights","title":"Predictive Insights","text":"<p>Query: <pre><code>You&gt; Based on 2020-2040 patterns, which counties are likely to face land use conflicts by 2080?\n</code></pre></p>"},{"location":"queries/examples/#reporting-queries","title":"\ud83d\udccb Reporting Queries","text":""},{"location":"queries/examples/#executive-summary","title":"Executive Summary","text":"<p>Query: <pre><code>You&gt; Generate a one-page executive summary of land use changes including:\n- Key statistics\n- Major trends\n- Critical counties to watch\n- Policy implications\n</code></pre></p>"},{"location":"queries/examples/#county-report-card","title":"County Report Card","text":"<p>Query: <pre><code>You&gt; Create a detailed report card for Sacramento County including all scenarios and land use changes\n</code></pre></p>"},{"location":"queries/examples/#stakeholder-analysis","title":"Stakeholder Analysis","text":"<p>Query: <pre><code>You&gt; Prepare data for different stakeholders:\n- Farmers: Agricultural land changes\n- Conservationists: Natural land preservation  \n- Urban planners: Development opportunities\n- Policymakers: Overall sustainability\n</code></pre></p>"},{"location":"queries/examples/#data-quality-checks","title":"\ud83d\udee0\ufe0f Data Quality Checks","text":""},{"location":"queries/examples/#validation-queries","title":"Validation Queries","text":"<p>Query: <pre><code>You&gt; Verify that total land area remains constant over time for each county\n</code></pre></p>"},{"location":"queries/examples/#consistency-checks","title":"Consistency Checks","text":"<p>Query: <pre><code>You&gt; Check if the sum of all \"from\" transitions equals the sum of all \"to\" transitions by year\n</code></pre></p>"},{"location":"queries/examples/#outlier-detection","title":"Outlier Detection","text":"<p>Query: <pre><code>You&gt; Find any suspicious data points where land use changes seem unrealistic\n</code></pre></p>"},{"location":"queries/examples/#export-and-visualization-prep","title":"\ud83d\udcca Export and Visualization Prep","text":""},{"location":"queries/examples/#chart-data","title":"Chart Data","text":"<p>Query: <pre><code>You&gt; Prepare data for a line chart showing land use trends over time for all scenarios\n</code></pre></p>"},{"location":"queries/examples/#geographic-export","title":"Geographic Export","text":"<p>Query: <pre><code>You&gt; Export county-level urban growth data in a format suitable for GIS mapping\n</code></pre></p>"},{"location":"queries/examples/#dashboard-metrics","title":"Dashboard Metrics","text":"<p>Query: <pre><code>You&gt; Create a set of 10 key metrics for a land use monitoring dashboard, updated annually\n</code></pre></p>"},{"location":"queries/examples/#tips-for-complex-queries","title":"Tips for Complex Queries","text":"<ol> <li>Build Incrementally: Start simple, add complexity</li> <li>Use Context: Reference previous results</li> <li>Be Specific: Include scenarios, years, and regions</li> <li>Think Stepwise: Break complex analyses into steps</li> <li>Verify Results: Ask for row counts and sanity checks</li> </ol>"},{"location":"queries/examples/#next-steps","title":"Next Steps","text":"<ul> <li>Try these examples with your own data</li> <li>Modify queries for your specific needs</li> <li>Combine patterns for new insights</li> <li>Share interesting findings!</li> </ul>"},{"location":"queries/overview/","title":"Natural Language Queries Overview","text":"<p>The power of this system lies in its ability to understand your questions in plain English and translate them into precise database queries. This section explains how the LangChain agent interprets natural language and provides tips for getting the best results.</p>"},{"location":"queries/overview/#how-it-works","title":"How It Works","text":"<pre><code>graph TD\n    A[Your Question] --&gt; B[LangChain Agent]\n    B --&gt; C[Language Understanding]\n    C --&gt; D[SQL Generation]\n    D --&gt; E[Query Execution]\n    E --&gt; F[Result Formatting]\n    F --&gt; G[Natural Language Response]</code></pre>"},{"location":"queries/overview/#the-process","title":"The Process","text":"<ol> <li>Language Understanding: The agent analyzes your question to identify:</li> <li>What data you're looking for</li> <li>Which tables/fields are relevant</li> <li>What filters or conditions to apply</li> <li> <p>How to aggregate or sort results</p> </li> <li> <p>SQL Generation: Your question is converted to SQL:</p> </li> <li>Proper table and column selection</li> <li>JOIN operations when needed</li> <li>WHERE clauses for filtering</li> <li>GROUP BY for aggregations</li> <li> <p>ORDER BY for sorting</p> </li> <li> <p>Intelligent Response: Results are formatted clearly with:</p> </li> <li>Summary of findings</li> <li>Formatted tables</li> <li>Relevant context</li> <li>Follow-up suggestions</li> </ol>"},{"location":"queries/overview/#query-categories","title":"Query Categories","text":""},{"location":"queries/overview/#exploratory-queries","title":"\ud83d\udd0d Exploratory Queries","text":"<p>Understand your data structure and contents:</p> <pre><code>\"What tables are in the database?\"\n\"Show me the columns in the landuse_transitions table\"\n\"What are the unique scenarios in the data?\"\n\"How many records are in each table?\"\n</code></pre>"},{"location":"queries/overview/#analytical-queries","title":"\ud83d\udcca Analytical Queries","text":"<p>Perform calculations and analysis:</p> <pre><code>\"What's the total forest area in 2050?\"\n\"Calculate the average urban growth rate per decade\"\n\"Show me the percentage of land that changes use vs stays the same\"\n\"What's the correlation between urban growth and forest loss?\"\n</code></pre>"},{"location":"queries/overview/#transition-queries","title":"\ud83d\udd04 Transition Queries","text":"<p>Focus on land use changes:</p> <pre><code>\"Show all transitions from forest to other land uses\"\n\"Which land use has the most conversions to urban?\"\n\"Find counties where cropland is converting to pasture\"\n\"What are the top 10 most common land use transitions?\"\n</code></pre>"},{"location":"queries/overview/#trend-queries","title":"\ud83d\udcc8 Trend Queries","text":"<p>Analyze changes over time:</p> <pre><code>\"How does cropland area change from 2020 to 2100?\"\n\"Show me the decade with the most urban expansion\"\n\"Plot forest area trends for all scenarios\"\n\"When does agricultural land peak in the High Crop Demand scenario?\"\n</code></pre>"},{"location":"queries/overview/#geographic-queries","title":"\ud83d\uddfa\ufe0f Geographic Queries","text":"<p>Location-specific analysis:</p> <pre><code>\"What are the land use changes in California counties?\"\n\"Show me the top 20 counties by urban growth\"\n\"Which FIPS codes have the most forest?\"\n\"Compare land use between coastal and inland counties\"\n</code></pre>"},{"location":"queries/overview/#comparison-queries","title":"\ud83d\udd04 Comparison Queries","text":"<p>Compare scenarios, time periods, or regions:</p> <pre><code>\"Compare urban growth between Baseline and High Crop Demand\"\n\"What's the difference in forest loss between 2020-2050 and 2050-2080?\"\n\"Show scenario differences for agricultural land in 2100\"\n\"Which scenario preserves the most natural land?\"\n</code></pre>"},{"location":"queries/overview/#best-practices","title":"Best Practices","text":""},{"location":"queries/overview/#1-be-specific","title":"1. Be Specific","text":"<p>\u274c Vague: \"Show me some data\" \u2705 Specific: \"Show me forest to urban transitions in California for the Baseline scenario\"</p>"},{"location":"queries/overview/#2-include-context","title":"2. Include Context","text":"<p>\u274c Ambiguous: \"What changes the most?\" \u2705 Clear: \"Which land use type has the largest area change between 2020 and 2050?\"</p>"},{"location":"queries/overview/#3-specify-filters","title":"3. Specify Filters","text":"<p>\u274c Too broad: \"Show transitions\" \u2705 Filtered: \"Show transitions from agricultural land to urban in counties with FIPS starting with 06\"</p>"},{"location":"queries/overview/#4-request-format","title":"4. Request Format","text":"<p>\u274c Unclear format: \"Give me the data\" \u2705 Clear format: \"List the top 10 counties by forest loss, showing county FIPS and area lost\"</p>"},{"location":"queries/overview/#understanding-agent-responses","title":"Understanding Agent Responses","text":""},{"location":"queries/overview/#sql-transparency","title":"SQL Transparency","text":"<p>The agent shows the generated SQL query:</p> <pre><code>Query: SELECT scenario, year, SUM(area_1000_acres) as total_forest\n       FROM landuse_transitions\n       WHERE from_land_use = 'Forest' \n         AND to_land_use = 'Forest'\n       GROUP BY scenario, year\n       ORDER BY scenario, year\n</code></pre> <p>This helps you: - Verify the query matches your intent - Learn SQL patterns - Debug unexpected results</p>"},{"location":"queries/overview/#result-interpretation","title":"Result Interpretation","text":"<p>Results include: - Row count: \"Results: 245 rows\" - Formatted data: Tables with clear headers - Summary: Key findings highlighted - Context: Explanations of what the data represents</p>"},{"location":"queries/overview/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"queries/overview/#multi-step-analysis","title":"Multi-Step Analysis","text":"<p>Break complex questions into steps:</p> <pre><code>You&gt; First, find the counties with the most agricultural land\nAgent&gt; [Shows top agricultural counties]\n\nYou&gt; Now show me how urban area changes in those counties\nAgent&gt; [Analyzes urban growth in previously identified counties]\n</code></pre>"},{"location":"queries/overview/#conditional-queries","title":"Conditional Queries","text":"<p>Use conditions and logic:</p> <pre><code>\"Show counties where forest loss exceeds 20% AND urban growth is above average\"\n\"Find transitions that only occur in the High Crop Demand scenario\"\n\"List counties with increasing cropland but decreasing pasture\"\n</code></pre>"},{"location":"queries/overview/#custom-calculations","title":"Custom Calculations","text":"<p>Request specific computations:</p> <pre><code>\"Calculate the net change in agricultural land (crops + pasture) by decade\"\n\"Show the ratio of urban growth to forest loss by county\"\n\"What percentage of each county converts from natural to developed land?\"\n</code></pre>"},{"location":"queries/overview/#common-patterns","title":"Common Patterns","text":""},{"location":"queries/overview/#time-based-patterns","title":"Time-Based Patterns","text":"<pre><code>\"between 2020 and 2050\"\n\"in the year 2100\"  \n\"by decade\"\n\"over the entire period\"\n\"changes from [year] to [year]\"\n</code></pre>"},{"location":"queries/overview/#aggregation-patterns","title":"Aggregation Patterns","text":"<pre><code>\"total area\"\n\"average change\"\n\"sum by scenario\"\n\"count of transitions\"\n\"percentage of total\"\n</code></pre>"},{"location":"queries/overview/#filtering-patterns","title":"Filtering Patterns","text":"<pre><code>\"only in California\" (FIPS LIKE '06%')\n\"excluding same-to-same transitions\"\n\"where area &gt; 1000\"\n\"for Baseline scenario only\"\n\"top 10 by [metric]\"\n</code></pre>"},{"location":"queries/overview/#query-optimization-tips","title":"Query Optimization Tips","text":"<ol> <li>Start broad, then narrow</li> <li>First: \"What scenarios are available?\"</li> <li> <p>Then: \"Show forest changes in the Baseline scenario\"</p> </li> <li> <p>Use table views wisely</p> </li> <li><code>landuse_transitions</code>: All transitions including same-to-same</li> <li><code>landuse_changes_only</code>: Excludes unchanged land</li> <li> <p><code>*_ag</code> tables: Agricultural aggregation (crop + pasture)</p> </li> <li> <p>Leverage agent memory</p> </li> <li>Previous results are remembered</li> <li> <p>Reference earlier queries: \"Using those counties, now show...\"</p> </li> <li> <p>Request appropriate limits</p> </li> <li>\"Show me a sample of 10 rows\"</li> <li>\"List the top 20 counties\"</li> <li>\"Summarize by decade instead of year\"</li> </ol>"},{"location":"queries/overview/#next-steps","title":"Next Steps","text":"<ul> <li>See Basic Queries for simple examples</li> <li>Explore Advanced Queries for complex analysis</li> <li>Check Query Examples for real-world scenarios</li> <li>Learn about Data Schemas to understand available fields</li> </ul>"},{"location":"rpa/climate-models/","title":"Climate Models in the RPA Assessment","text":""},{"location":"rpa/climate-models/#overview","title":"Overview","text":"<p>The 2020 RPA Assessment uses 5 carefully selected Global Climate Models (GCMs) to capture the range of possible future climate conditions across the United States. These models were chosen to represent different combinations of temperature and precipitation patterns.</p>"},{"location":"rpa/climate-models/#the-five-climate-models","title":"The Five Climate Models","text":""},{"location":"rpa/climate-models/#cnrm_cm5-wet-model","title":"CNRM_CM5 - \"Wet\" Model","text":"<ul> <li>Full Name: Centre National de Recherches M\u00e9t\u00e9orologiques Climate Model 5</li> <li>Origin: France</li> <li>Key Characteristic: Projects increased precipitation across most of the US</li> <li>Temperature Pattern: Moderate warming</li> <li>Best For: Analyzing scenarios with higher water availability</li> </ul>"},{"location":"rpa/climate-models/#hadgem2_es365-hot-model","title":"HadGEM2_ES365 - \"Hot\" Model","text":"<ul> <li>Full Name: Hadley Centre Global Environmental Model 2 - Earth System</li> <li>Origin: United Kingdom</li> <li>Key Characteristic: Represents the upper bound of temperature increases</li> <li>Temperature Pattern: Highest warming projections</li> <li>Best For: Stress-testing under extreme heat scenarios</li> </ul>"},{"location":"rpa/climate-models/#ipsl_cm5a_mr-dry-model","title":"IPSL_CM5A_MR - \"Dry\" Model","text":"<ul> <li>Full Name: Institut Pierre Simon Laplace Climate Model 5A - Medium Resolution</li> <li>Origin: France</li> <li>Key Characteristic: Projects reduced precipitation in many regions</li> <li>Temperature Pattern: Moderate to high warming</li> <li>Best For: Analyzing drought and water scarcity impacts</li> </ul>"},{"location":"rpa/climate-models/#mri_cgcm3-least-warm-model","title":"MRI_CGCM3 - \"Least Warm\" Model","text":"<ul> <li>Full Name: Meteorological Research Institute Coupled Global Climate Model 3</li> <li>Origin: Japan</li> <li>Key Characteristic: Most conservative temperature projections</li> <li>Temperature Pattern: Lower bound of warming</li> <li>Best For: Best-case climate scenarios</li> </ul>"},{"location":"rpa/climate-models/#noresm1_m-middle-model","title":"NorESM1_M - \"Middle\" Model","text":"<ul> <li>Full Name: Norwegian Earth System Model 1 - Medium Resolution</li> <li>Origin: Norway</li> <li>Key Characteristic: Represents central tendency of climate projections</li> <li>Temperature Pattern: Median warming and precipitation</li> <li>Best For: Most likely/average climate outcomes</li> </ul>"},{"location":"rpa/climate-models/#model-selection-rationale","title":"Model Selection Rationale","text":"<p>The RPA Assessment team selected these models to: 1. Capture uncertainty - Range from wet to dry, hot to least warm 2. Represent extremes - Include both upper and lower bounds 3. Include central tendency - Middle model for most likely outcomes 4. Geographic coverage - Models perform well across US regions</p>"},{"location":"rpa/climate-models/#using-climate-models-in-analysis","title":"Using Climate Models in Analysis","text":""},{"location":"rpa/climate-models/#comparing-models","title":"Comparing Models","text":"<p>When analyzing RPA data, you can: - Compare outcomes across all 5 models to see the full range - Focus on extremes (Hot vs Least Warm, Wet vs Dry) - Use the Middle model for typical projections</p>"},{"location":"rpa/climate-models/#example-queries","title":"Example Queries","text":"<pre><code>\"Compare forest loss between the wet and dry climate models\"\n\"Which climate model shows the most agricultural stress?\"\n\"Show urban expansion under the hot climate model\"\n</code></pre>"},{"location":"rpa/climate-models/#interpreting-results","title":"Interpreting Results","text":"<ul> <li>Wet model results suggest impacts under increased precipitation</li> <li>Dry model results indicate drought stress responses</li> <li>Hot model shows maximum temperature stress</li> <li>Least warm provides conservative estimates</li> <li>Middle model offers balanced projections</li> </ul>"},{"location":"rpa/climate-models/#climate-pathways-rcps","title":"Climate Pathways (RCPs)","text":"<p>Each climate model runs under two Representative Concentration Pathways:</p>"},{"location":"rpa/climate-models/#rcp45-lower-emissions","title":"RCP4.5 - Lower Emissions","text":"<ul> <li>Global warming of approximately 2.5\u00b0C by 2100</li> <li>Assumes significant emissions reductions</li> <li>More optimistic climate future</li> </ul>"},{"location":"rpa/climate-models/#rcp85-higher-emissions","title":"RCP8.5 - Higher Emissions","text":"<ul> <li>Global warming of approximately 4.5\u00b0C by 2100</li> <li>Assumes continued high emissions</li> <li>More pessimistic climate future</li> </ul>"},{"location":"rpa/climate-models/#model-scenario-matrix","title":"Model \u00d7 Scenario Matrix","text":"<p>Each of the 5 climate models is combined with 4 RPA scenarios: - 5 climate models \u00d7 4 scenarios = 20 total projections - Allows analysis of climate-socioeconomic interactions - Captures full range of plausible futures</p>"},{"location":"rpa/climate-models/#technical-notes","title":"Technical Notes","text":"<ul> <li>Models downscaled to county-level resolution</li> <li>Bias-corrected for regional accuracy</li> <li>Validated against historical observations</li> <li>Updated from CMIP5 ensemble</li> </ul>"},{"location":"rpa/overview/","title":"RPA Assessment Overview","text":""},{"location":"rpa/overview/#about-the-2020-resources-planning-act-assessment","title":"About the 2020 Resources Planning Act Assessment","text":"<p>The USDA Forest Service's 2020 Resources Planning Act (RPA) Assessment provides comprehensive projections of land use change across the United States through 2070. This assessment is mandated by the Forest and Rangeland Renewable Resources Planning Act of 1974, which requires periodic evaluations of the Nation's renewable resources.</p>"},{"location":"rpa/overview/#key-components","title":"Key Components","text":""},{"location":"rpa/overview/#land-use-projections","title":"Land Use Projections","text":"<p>The 2020 RPA Assessment includes detailed county-level projections for:</p> <ul> <li>Private land only - Public lands are assumed to remain static</li> <li>5 land use categories: Crop, Pasture, Rangeland, Forest, and Urban</li> <li>3,075 US counties - Complete coverage of the conterminous United States</li> <li>Time periods: 2012-2020, 2020-2030, 2030-2040, 2040-2050, 2050-2070, 2070-2090, 2090-2100</li> </ul>"},{"location":"rpa/overview/#integrated-scenarios","title":"Integrated Scenarios","text":"<p>The assessment uses 20 integrated climate-socioeconomic scenarios:</p> <ul> <li>4 scenario combinations (LM, HL, HM, HH)</li> <li>5 climate models representing different precipitation and temperature patterns</li> <li>2 climate pathways (RCP4.5 and RCP8.5)</li> <li>4 socioeconomic pathways (SSP1, SSP2, SSP3, SSP5)</li> </ul>"},{"location":"rpa/overview/#methodology-overview","title":"Methodology Overview","text":""},{"location":"rpa/overview/#econometric-model","title":"Econometric Model","text":"<ul> <li>Calibrated using observed land use transitions from 2001-2012</li> <li>Based on National Resources Inventory (NRI) data</li> <li>Incorporates economic, demographic, and environmental drivers</li> <li>Projects future transitions based on historical relationships</li> </ul>"},{"location":"rpa/overview/#key-assumptions","title":"Key Assumptions","text":"<ol> <li>Development irreversibility - Once land becomes urban, it remains urban</li> <li>Private land focus - Public lands excluded from transition modeling</li> <li>Policy-neutral - Projections based on historical trends without future policy assumptions</li> <li>County-level resolution - Maintains local geographic detail</li> </ol>"},{"location":"rpa/overview/#data-sources","title":"Data Sources","text":""},{"location":"rpa/overview/#primary-data","title":"Primary Data","text":"<ul> <li>National Resources Inventory (NRI) - Historical land use observations</li> <li>Climate projections - From 5 global climate models</li> <li>Socioeconomic projections - Population and economic growth scenarios</li> </ul>"},{"location":"rpa/overview/#model-outputs","title":"Model Outputs","text":"<ul> <li>Transition matrices - Acres changing between land use categories</li> <li>Scenario variations - Results for all 20 integrated scenarios</li> <li>Temporal resolution - Decadal projections through 2100</li> </ul>"},{"location":"rpa/overview/#using-rpa-data-with-this-tool","title":"Using RPA Data with This Tool","text":"<p>RPA Land Use Analytics makes this complex dataset accessible through:</p> <ul> <li>Natural language queries to explore scenarios</li> <li>Pre-built analyses of key trends</li> <li>Interactive visualizations</li> <li>Direct database access for advanced users</li> </ul>"},{"location":"rpa/overview/#learn-more","title":"Learn More","text":"<ul> <li>Official RPA Website</li> <li>2020 RPA Assessment Report</li> <li>Technical Documentation</li> </ul>"},{"location":"troubleshooting/streamlit-duplicate-ids/","title":"Fixing Streamlit Duplicate Element IDs","text":""},{"location":"troubleshooting/streamlit-duplicate-ids/#problem","title":"Problem","text":"<p>Streamlit generates automatic IDs for widgets based on their type and parameters. When multiple widgets have the same type and parameters, they get identical IDs, causing a <code>StreamlitDuplicateElementId</code> error.</p>"},{"location":"troubleshooting/streamlit-duplicate-ids/#error-message","title":"Error Message","text":"<pre><code>StreamlitDuplicateElementId: There are multiple `selectbox` elements with the same auto-generated ID.\nWhen this element is created, it is assigned an internal ID based on the element type and provided parameters.\nMultiple elements with the same type and parameters will cause this error.\n\nTo fix this error, please pass a unique `key` argument to the selectbox element.\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#root-cause","title":"Root Cause","text":"<p>In the data extraction page (<code>pages/extraction.py</code>), multiple widgets had identical parameters:</p>"},{"location":"troubleshooting/streamlit-duplicate-ids/#duplicate-selectboxes","title":"Duplicate Selectboxes","text":"<ul> <li>Multiple \"Export format:\" selectboxes with same options <code>[\"CSV\", \"Excel\", \"JSON\", \"Parquet\"]</code></li> <li>These appeared in different sections (templates, custom, bulk) but had identical parameters</li> </ul>"},{"location":"troubleshooting/streamlit-duplicate-ids/#duplicate-number-inputs","title":"Duplicate Number Inputs","text":"<ul> <li>Multiple \"Preview rows:\" number inputs with same min/max/value/step parameters</li> <li>Multiple \"Export limit:\" number inputs with same parameters</li> </ul>"},{"location":"troubleshooting/streamlit-duplicate-ids/#solution","title":"Solution","text":"<p>Add unique <code>key</code> parameters to each widget to force different IDs:</p>"},{"location":"troubleshooting/streamlit-duplicate-ids/#fixed-selectboxes","title":"Fixed Selectboxes","text":"<pre><code># Template section\nexport_format = st.selectbox(\n    \"Export format:\",\n    [\"CSV\", \"Excel\", \"JSON\", \"Parquet\"],\n    help=\"Choose the file format for your export\",\n    key=\"template_export_format\"  # \u2705 Unique key\n)\n\n# Custom section\nexport_format = st.selectbox(\n    \"Export format:\",\n    [\"CSV\", \"Excel\", \"JSON\", \"Parquet\"],\n    help=\"Choose the file format for your export\",\n    key=\"custom_export_format\"  # \u2705 Different key\n)\n\n# Bulk section\nexport_format = st.selectbox(\n    \"Export format:\",\n    [\"CSV (ZIP)\", \"Excel\", \"Parquet (ZIP)\"],\n    help=\"Choose the format for bulk export\",\n    key=\"bulk_export_format\"  # \u2705 Different key\n)\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#fixed-number-inputs","title":"Fixed Number Inputs","text":"<pre><code># Template section\npreview_rows = st.number_input(\n    \"Preview rows:\",\n    min_value=10,\n    max_value=1000,\n    value=100,\n    step=10,\n    help=\"Number of rows to preview\",\n    key=\"template_preview_rows\"  # \u2705 Unique key\n)\n\n# Custom section\npreview_limit = st.number_input(\n    \"Preview rows:\",\n    min_value=10,\n    max_value=1000,\n    value=100,\n    step=10,\n    key=\"custom_preview_rows\"  # \u2705 Different key\n)\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#complete-key-mapping","title":"Complete Key Mapping","text":"Widget Type Location Key Description selectbox Templates <code>template_selector</code> Template selection selectbox Templates <code>template_export_format</code> Export format for templates selectbox Custom <code>custom_extract_type</code> Custom extraction type selectbox Custom <code>custom_transition_type</code> Transition type filter selectbox Custom <code>custom_export_format</code> Export format for custom selectbox Bulk <code>bulk_extract_type</code> Bulk extraction type selectbox Bulk <code>bulk_export_format</code> Export format for bulk number_input Templates <code>template_preview_rows</code> Preview rows for templates number_input Templates <code>template_export_limit</code> Export limit for templates number_input Custom <code>custom_preview_rows</code> Preview rows for custom number_input Custom <code>custom_export_limit</code> Export limit for custom number_input Bulk <code>bulk_row_limit</code> Row limit for bulk button Templates <code>template_preview_data</code> Preview data button button Templates <code>template_export_data</code> Export data button button Custom <code>custom_preview_query</code> Preview query button button Custom <code>custom_preview_data</code> Preview data button button Custom <code>custom_export_data</code> Export data button button Bulk <code>bulk_generate_export</code> Generate bulk export button"},{"location":"troubleshooting/streamlit-duplicate-ids/#prevention","title":"Prevention","text":"<p>To avoid this issue in the future:</p>"},{"location":"troubleshooting/streamlit-duplicate-ids/#1-always-use-keys-for-repeated-widgets","title":"1. Always Use Keys for Repeated Widgets","text":"<pre><code># \u274c Bad: Same parameters, no keys\nst.selectbox(\"Format:\", [\"CSV\", \"JSON\"])  # Section 1\nst.selectbox(\"Format:\", [\"CSV\", \"JSON\"])  # Section 2 - DUPLICATE!\n\n# \u2705 Good: Same parameters, unique keys\nst.selectbox(\"Format:\", [\"CSV\", \"JSON\"], key=\"section1_format\")\nst.selectbox(\"Format:\", [\"CSV\", \"JSON\"], key=\"section2_format\")\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#2-use-descriptive-key-naming-convention","title":"2. Use Descriptive Key Naming Convention","text":"<pre><code># Pattern: {section}_{widget_purpose}\nkey=\"template_export_format\"\nkey=\"custom_preview_rows\"\nkey=\"bulk_row_limit\"\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#3-check-for-duplicates-during-development","title":"3. Check for Duplicates During Development","text":"<pre><code># Use this pattern to identify potential duplicates\nwidgets_to_check = [\n    \"selectbox\", \"multiselect\", \"text_input\", \n    \"number_input\", \"checkbox\", \"radio\", \"slider\"\n]\n\n# Add keys proactively when creating similar widgets\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#testing","title":"Testing","text":"<p>After adding keys, verify the fix:</p> <ol> <li>Import Test: Check that the page imports without errors</li> <li>Runtime Test: Navigate through all tabs and interact with widgets</li> <li>State Test: Ensure widget states don't interfere with each other</li> </ol>"},{"location":"troubleshooting/streamlit-duplicate-ids/#related-issues","title":"Related Issues","text":"<p>This pattern can affect any Streamlit widget that appears multiple times with identical parameters: - <code>st.selectbox</code> - <code>st.multiselect</code> - <code>st.text_input</code> - <code>st.number_input</code> - <code>st.checkbox</code> - <code>st.radio</code> - <code>st.slider</code> - <code>st.button</code></p> <p>Always provide unique <code>key</code> parameters when using repeated widgets across different sections of your app.</p>"},{"location":"troubleshooting/streamlit-fragments/","title":"Streamlit Fragments Troubleshooting","text":""},{"location":"troubleshooting/streamlit-fragments/#overview","title":"Overview","text":"<p>This guide covers common issues and solutions when using Streamlit fragments in the landuse application.</p>"},{"location":"troubleshooting/streamlit-fragments/#common-fragment-issues","title":"Common Fragment Issues","text":""},{"location":"troubleshooting/streamlit-fragments/#issue-streamlitapiexception-with-stsidebar","title":"Issue: StreamlitAPIException with st.sidebar","text":"<p>Error Message: <pre><code>StreamlitAPIException: Calling `st.sidebar` in a function wrapped with `st.fragment` is not supported. \nTo write elements to the sidebar with a fragment, call your fragment function inside a with st.sidebar context manager.\n</code></pre></p> <p>Cause: Functions decorated with <code>@st.fragment</code> cannot directly call <code>st.sidebar</code> or access sidebar elements.</p> <p>Solution:</p> <p>\u274c Incorrect (causes error): <pre><code>@st.fragment\ndef handle_user_input():\n    # ... processing logic ...\n\n    # This will cause an error!\n    with st.sidebar:\n        st.caption(f\"Query took {query_time:.1f}s\")\n</code></pre></p> <p>\u2705 Correct (solution 1 - use session state): <pre><code>@st.fragment\ndef handle_user_input():\n    # ... processing logic ...\n\n    # Store data in session state instead\n    st.session_state.last_query_time = query_time\n\ndef main():\n    # Display in sidebar from main function\n    with st.sidebar:\n        if hasattr(st.session_state, 'last_query_time') and st.session_state.last_query_time:\n            st.caption(f\"\u23f1\ufe0f Last query: {st.session_state.last_query_time:.1f}s\")\n</code></pre></p> <p>\u2705 Correct (solution 2 - call fragment inside sidebar): <pre><code>def handle_user_input_fragment():\n    # Fragment logic without sidebar calls\n    pass\n\ndef main():\n    with st.sidebar:\n        handle_user_input_fragment()  # Call fragment inside sidebar context\n</code></pre></p>"},{"location":"troubleshooting/streamlit-fragments/#issue-fragment-functions-must-be-self-contained","title":"Issue: Fragment Functions Must Be Self-Contained","text":"<p>Problem: Fragments should be designed to operate independently without side effects on the rest of the page.</p> <p>Best Practices:</p> <ol> <li> <p>Use session state for communication: <pre><code>@st.fragment\ndef query_processor():\n    if st.button(\"Process\"):\n        result = process_query()\n        st.session_state.query_result = result  # Store for use elsewhere\n</code></pre></p> </li> <li> <p>Keep fragments focused: <pre><code>@st.fragment\ndef chat_input():\n    \"\"\"Only handles chat input, nothing else\"\"\"\n    if prompt := st.chat_input(\"Ask me...\"):\n        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n\n@st.fragment \ndef query_controls():\n    \"\"\"Only handles query control buttons\"\"\"\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"Clear\"):\n            st.session_state.messages = []\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/streamlit-fragments/#fragment-design-patterns","title":"Fragment Design Patterns","text":""},{"location":"troubleshooting/streamlit-fragments/#1-input-isolation-pattern","title":"1. Input Isolation Pattern","text":"<pre><code>@st.fragment\ndef isolated_input():\n    \"\"\"Handles user input without affecting other components\"\"\"\n    user_input = st.text_input(\"Enter query\")\n    if st.button(\"Submit\"):\n        st.session_state.user_query = user_input\n        st.rerun()  # Trigger main page update\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#2-display-fragment-pattern","title":"2. Display Fragment Pattern","text":"<pre><code>@st.fragment\ndef query_results_display():\n    \"\"\"Displays results independently\"\"\"\n    if 'query_results' in st.session_state:\n        st.dataframe(st.session_state.query_results)\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#3-control-panel-pattern","title":"3. Control Panel Pattern","text":"<pre><code>@st.fragment\ndef control_panel():\n    \"\"\"Isolated control buttons\"\"\"\n    col1, col2, col3 = st.columns(3)\n\n    with col1:\n        if st.button(\"Reset\"):\n            st.session_state.clear()\n\n    with col2:\n        if st.button(\"Export\"):\n            st.session_state.export_flag = True\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#performance-benefits","title":"Performance Benefits","text":"<p>Proper use of fragments provides:</p> <ul> <li>Reduced Reruns: Only the fragment reruns on interaction</li> <li>Better UX: Faster response times for user interactions</li> <li>Isolated Updates: Changes don't affect unrelated components</li> <li>Memory Efficiency: Less computation on each interaction</li> </ul>"},{"location":"troubleshooting/streamlit-fragments/#debugging-fragment-issues","title":"Debugging Fragment Issues","text":""},{"location":"troubleshooting/streamlit-fragments/#1-check-fragment-boundaries","title":"1. Check Fragment Boundaries","text":"<pre><code>@st.fragment\ndef debug_fragment():\n    st.write(\"Fragment start\")\n    # Your fragment code here\n    st.write(\"Fragment end\")\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#2-monitor-session-state","title":"2. Monitor Session State","text":"<pre><code>def debug_session_state():\n    with st.expander(\"Debug Session State\"):\n        st.json(dict(st.session_state))\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#3-test-fragment-isolation","title":"3. Test Fragment Isolation","text":"<pre><code>@st.fragment\ndef test_fragment():\n    st.write(f\"Fragment run at: {time.time()}\")\n\n    if st.button(\"Fragment Button\"):\n        st.write(\"Fragment button clicked!\")\n\ndef main():\n    st.write(f\"Main run at: {time.time()}\")\n    test_fragment()\n\n    if st.button(\"Main Button\"):\n        st.write(\"Main button clicked!\")\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#migration-checklist","title":"Migration Checklist","text":"<p>When adding fragments to existing code:</p> <ul> <li> Identify isolated UI components</li> <li> Remove sidebar calls from fragments</li> <li> Use session state for data sharing</li> <li> Test fragment isolation</li> <li> Verify performance improvements</li> <li> Update tests to handle fragment behavior</li> </ul>"},{"location":"troubleshooting/streamlit-fragments/#related-documentation","title":"Related Documentation","text":"<ul> <li>Streamlit Fragments Official Docs</li> <li>Performance Optimization Guide</li> <li>Session State Best Practices</li> </ul>"}]}