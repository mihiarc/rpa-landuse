{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RPA Land Use Analytics","text":"<p>Welcome to the RPA Land Use Analytics documentation! This AI-powered analytics tool enables natural language exploration of USDA Forest Service 2020 Resources Planning Act (RPA) Assessment land use projections.</p> <pre>\n    ____  ____  ___       __                   __   __  __         \n   / __ \\/ __ \\/   |     / /   ____ _____  ____/ /  / / / /_______  \n  / /_/ / /_/ / /| |    / /   / __ `/ __ \\/ __  /  / / / / ___/ _ \\ \n / _, _/ ____/ ___ |   / /___/ /_/ / / / / /_/ /  / /_/ (__  )  __/ \n/_/ |_/_/   /_/  |_|  /_____/\\__,_/_/ /_/\\__,_/   \\____/____/\\___/  \n                    ___                __      __  _          \n                   /   |  ____  ____ _/ /_  __/ /_(_)_________\n                  / /| | / __ \\/ __ `/ / / / / __/ / ___/ ___/\n                 / ___ |/ / / / /_/ / / /_/ / /_/ / /__(__  ) \n                /_/  |_/_/ /_/\\__,_/_/\\__, /\\__/_/\\___/____/  \n                                     /____/                    \n</pre>"},{"location":"#what-is-rpa-land-use-analytics","title":"\ud83c\udf32 What is RPA Land Use Analytics?","text":"<p>RPA Land Use Analytics transforms the USDA Forest Service's 2020 Resources Planning Act Assessment data into actionable insights through:</p> <ul> <li>Natural Language Queries - Ask questions in plain English about land use transitions</li> <li>20 Integrated Scenarios - Explore projections across climate and socioeconomic pathways</li> <li>County-Level Detail - Analyze 3,075 US counties from 2012-2070</li> <li>AI-Powered Analysis - Modern agents understand context and provide intelligent insights</li> </ul>"},{"location":"#key-features","title":"\ud83c\udfaf Key Features","text":""},{"location":"#advanced-natural-language-interface","title":"Advanced Natural Language Interface","text":"<p>Powered by LangGraph and Claude/GPT-4, ask complex questions and get meaningful answers:</p> <pre><code>You&gt; Which RPA scenarios show the most agricultural land loss by 2070?\n\nAgent&gt; I'll analyze agricultural land transitions across all 20 RPA scenarios...\n\n\ud83d\udcca Analysis Assumptions:\n- Scenarios: Comparing all 20 climate-socioeconomic combinations\n- Time Period: Full projection period 2012-2070\n- Geographic Scope: All US counties\n</code></pre>"},{"location":"#comprehensive-rpa-scenario-analysis","title":"Comprehensive RPA Scenario Analysis","text":"<ul> <li>4 Integrated Scenarios: LM, HL, HM, HH combining climate and socioeconomic pathways</li> <li>5 Climate Models: Wet, Hot, Dry, Least warm, Middle projections</li> <li>Private Land Focus: Based on econometric model calibrated to 2001-2012 observations</li> <li>Development Irreversibility: Once urban, always urban assumption</li> </ul>"},{"location":"#interactive-streamlit-dashboard","title":"Interactive Streamlit Dashboard","text":"<ul> <li>Modern web interface with natural language chat</li> <li>Pre-built visualizations for key insights</li> <li>SQL query interface for advanced users</li> <li>Data export in multiple formats</li> </ul>"},{"location":"#example-rpa-queries","title":"\ud83d\udcca Example RPA Queries","text":"<p>Explore the 2020 RPA Assessment data with queries like:</p> <p>RPA-Specific Natural Language Queries</p> <ul> <li>\"Compare forest loss between the sustainability (LM) and fossil-fueled (HH) scenarios\"</li> <li>\"Which climate model shows the most urban expansion - hot or dry?\"</li> <li>\"How does agricultural land change differ between RCP4.5 and RCP8.5?\"</li> <li>\"Show me land use transitions in the South region under high growth scenarios\"</li> <li>\"What's the impact of the 'wet' climate model on crop to pasture transitions?\"</li> </ul>"},{"location":"#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<pre><code>graph LR\n    A[RPA JSON Data&lt;br/&gt;20M+ lines] --&gt; B[DuckDB Converter&lt;br/&gt;Star Schema]\n    B --&gt; C[Analytics Database&lt;br/&gt;5.4M transitions]\n    C --&gt; D[LangGraph Agent&lt;br/&gt;Natural Language]\n    D --&gt; E[Streamlit Dashboard&lt;br/&gt;Web Interface]\n    E --&gt; F[User Insights]\n    F --&gt; E</code></pre>"},{"location":"#quick-start","title":"\ud83d\udea6 Quick Start","text":"<p>Get started analyzing RPA land use projections:</p> <ol> <li> <p>Clone and install <pre><code>git clone https://github.com/mihiarc/langchain-landuse\ncd langchain-landuse\nuv sync\n</code></pre></p> </li> <li> <p>Run guided setup <pre><code>uv run python setup_agents.py\n</code></pre></p> </li> <li> <p>Launch the dashboard <pre><code>uv run streamlit run streamlit_app.py\n</code></pre></p> </li> <li> <p>Start exploring! <pre><code>\ud83d\udcac Try: \"How much forest is projected to be lost under the high warming scenarios?\"\n</code></pre></p> </li> </ol>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":""},{"location":"#rpa-assessment-background","title":"RPA Assessment Background","text":"<ul> <li>RPA Overview - Understanding the 2020 Assessment</li> <li>RPA Scenarios - Detailed scenario definitions</li> <li>Land Use Methodology - Econometric model details</li> <li>Climate Models - 5 climate model characteristics</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation - Set up the project</li> <li>Quick Start - Run your first RPA queries</li> <li>Configuration - Customize for your needs</li> </ul>"},{"location":"#natural-language-queries","title":"Natural Language Queries","text":"<ul> <li>Overview - How the AI understands RPA questions</li> <li>Basic Queries - Simple RPA query patterns</li> <li>Advanced Queries - Complex scenario comparisons</li> <li>Examples - Real RPA analysis examples</li> </ul>"},{"location":"#data-schemas","title":"Data &amp; Schemas","text":"<ul> <li>Data Sources - RPA Assessment data structure</li> <li>Database Schema - Star schema design</li> <li>Land Use Categories - Crop, Forest, Urban definitions</li> <li>Processing Pipeline - JSON to DuckDB transformation</li> </ul>"},{"location":"#api-reference","title":"API Reference","text":"<ul> <li>LangGraph Agent - Modern graph-based agent</li> <li>Traditional Agent - Legacy LangChain agent</li> <li>Converters - Data transformation tools</li> <li>Tools - Available agent capabilities</li> </ul>"},{"location":"#rpa-scenarios-quick-reference","title":"\ud83c\udf1f RPA Scenarios Quick Reference","text":"Scenario Climate Socioeconomic Key Theme LM RCP4.5 (~2.5\u00b0C) SSP1 Sustainability focus, lower warming HL RCP8.5 (~4.5\u00b0C) SSP3 Regional rivalry, high warming HM RCP8.5 (~4.5\u00b0C) SSP2 Middle of the road, high warming HH RCP8.5 (~4.5\u00b0C) SSP5 Fossil-fueled growth, high warming"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>We welcome contributions! Check out our contributing guide and branding strategy.</p>"},{"location":"#data-attribution","title":"\ud83d\udcc4 Data Attribution","text":"<p>This project analyzes data from the USDA Forest Service 2020 Resources Planning Act Assessment.</p> RPA Land Use Analytics Transforming America's land use data into actionable insights \ud83c\udf32 Powered by USDA Forest Service RPA Assessment \ud83c\udf32"},{"location":"CLAUDE.local/","title":"Local Configuration","text":""},{"location":"CLAUDE.local/#best-practices","title":"Best Practices","text":"<ul> <li>Refer to the langchain documentation before every task.</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/","title":"GitHub Pages Documentation Setup","text":""},{"location":"GITHUB_PAGES_SETUP/#overview","title":"Overview","text":"<p>The RPA Land Use Analytics documentation is now configured for deployment to GitHub Pages using MkDocs with the Material theme.</p>"},{"location":"GITHUB_PAGES_SETUP/#configuration-updates","title":"Configuration Updates","text":""},{"location":"GITHUB_PAGES_SETUP/#1-mkdocs-configuration-mkdocsyml","title":"1. MkDocs Configuration (<code>mkdocs.yml</code>)","text":"<ul> <li>\u2705 Updated site name to \"RPA Land Use Analytics\"</li> <li>\u2705 Updated site description with RPA Assessment context</li> <li>\u2705 Changed repository URLs to mihiarc/langchain-landuse</li> <li>\u2705 Updated theme colors to forest green (#2E7D32)</li> <li>\u2705 Added RPA Assessment section to navigation</li> <li>\u2705 Updated copyright with RPA attribution</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#2-documentation-structure","title":"2. Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                    # Updated with RPA branding\n\u251c\u2500\u2500 rpa/                        # New RPA-specific section\n\u2502   \u251c\u2500\u2500 overview.md            # 2020 RPA Assessment overview\n\u2502   \u2514\u2500\u2500 climate-models.md      # 5 climate model details\n\u251c\u2500\u2500 RPA_SCENARIOS.md           # Detailed scenario documentation\n\u251c\u2500\u2500 LAND_USE_METHODOLOGY.md    # Econometric model methodology\n\u251c\u2500\u2500 api/\n\u2502   \u2514\u2500\u2500 langgraph-agent.md     # New LangGraph agent documentation\n\u2514\u2500\u2500 development/\n    \u2514\u2500\u2500 BRANDING_STRATEGY.md   # RPA branding guidelines\n</code></pre>"},{"location":"GITHUB_PAGES_SETUP/#3-github-actions-workflow","title":"3. GitHub Actions Workflow","text":"<p>Created <code>.github/workflows/deploy-docs.yml</code> for automatic deployment: - Triggers on push to main branch - Builds documentation with strict mode - Deploys to GitHub Pages</p>"},{"location":"GITHUB_PAGES_SETUP/#local-development","title":"Local Development","text":""},{"location":"GITHUB_PAGES_SETUP/#build-documentation","title":"Build Documentation","text":"<pre><code># Build the site\nuv run mkdocs build\n\n# Build with strict mode (catches all warnings)\nuv run mkdocs build --strict\n</code></pre>"},{"location":"GITHUB_PAGES_SETUP/#serve-locally","title":"Serve Locally","text":"<pre><code># Using mkdocs directly\nuv run mkdocs serve\n\n# Using the helper script\nuv run python scripts/serve_docs.py\n</code></pre> <p>Documentation will be available at http://localhost:8000</p>"},{"location":"GITHUB_PAGES_SETUP/#deployment","title":"Deployment","text":""},{"location":"GITHUB_PAGES_SETUP/#initial-setup-one-time","title":"Initial Setup (One-time)","text":"<ol> <li>Go to repository Settings \u2192 Pages</li> <li>Source: Deploy from a branch</li> <li>Branch: gh-pages / (root)</li> <li>Save the settings</li> </ol>"},{"location":"GITHUB_PAGES_SETUP/#automatic-deployment","title":"Automatic Deployment","text":"<p>Documentation automatically deploys when: - Documentation files are changed and pushed to main branch - The deploy-docs workflow is manually triggered - Uses <code>mkdocs gh-deploy</code> to build and push to gh-pages branch</p>"},{"location":"GITHUB_PAGES_SETUP/#manual-deployment","title":"Manual Deployment","text":"<pre><code># Using the helper script\nuv run python scripts/deploy_docs.py\n\n# Or using mkdocs directly\nuv run mkdocs gh-deploy --force\n</code></pre>"},{"location":"GITHUB_PAGES_SETUP/#key-updates-made","title":"Key Updates Made","text":""},{"location":"GITHUB_PAGES_SETUP/#content-updates","title":"Content Updates","text":"<ul> <li>Home page now features RPA branding and scenarios</li> <li>Quick start guide updated with RPA-specific examples</li> <li>Added comprehensive RPA Assessment documentation</li> <li>Created climate model reference guide</li> <li>Updated all examples to use RPA terminology</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#visual-updates","title":"Visual Updates","text":"<ul> <li>Forest green color scheme throughout</li> <li>RPA ASCII logo on home page</li> <li>Consistent branding across all pages</li> <li>USDA Forest Service attribution</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#technical-updates","title":"Technical Updates","text":"<ul> <li>Modern navigation with RPA sections</li> <li>Cross-referenced RPA documentation</li> <li>Updated API documentation for agents</li> <li>Fixed broken links and references</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#urls","title":"URLs","text":"<ul> <li>Live Documentation: https://mihiarc.github.io/langchain-landuse</li> <li>Repository: https://github.com/mihiarc/langchain-landuse</li> <li>RPA Assessment: https://www.fs.usda.gov/research/rpa</li> </ul>"},{"location":"GITHUB_PAGES_SETUP/#next-steps","title":"Next Steps","text":"<ol> <li>Enable GitHub Pages in repository settings</li> <li>Monitor first deployment via Actions tab</li> <li>Update README with documentation link</li> <li>Add documentation badge to repository</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/","title":"RPA Land Use Change Methodology","text":""},{"location":"LAND_USE_METHODOLOGY/#overview","title":"Overview","text":"<p>The land use projections in the RPA Assessment database are based on a sophisticated econometric model that projects county-level land use transitions from 2020 to 2070. This document explains the methodology, key assumptions, and how to interpret the data.</p>"},{"location":"LAND_USE_METHODOLOGY/#model-characteristics","title":"Model Characteristics","text":""},{"location":"LAND_USE_METHODOLOGY/#core-features","title":"Core Features","text":"<ul> <li>Spatial Resolution: County-level (3,075 counties in conterminous U.S.)</li> <li>Temporal Coverage: 2020-2070 projections</li> <li>Land Ownership: Private land only</li> <li>Scenarios: 20 integrated climate-socioeconomic futures</li> <li>Policy Approach: Policy-neutral projections</li> </ul>"},{"location":"LAND_USE_METHODOLOGY/#key-assumptions","title":"Key Assumptions","text":"<ol> <li>Development is Irreversible: Once land converts to developed use, it doesn't revert</li> <li>Private Land Focus: All transitions occur on privately owned land</li> <li>Historical Basis: Model calibrated on observed transitions from 2001-2012</li> <li>Policy Neutral: No assumptions about future conservation policies</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#land-use-classes","title":"Land Use Classes","text":"<p>The model tracks five major land use categories:</p> Code Land Use Category Description cr Crop Agriculture Agricultural cropland ps Pasture Agriculture Livestock grazing land fr Forest Natural Forested areas ur Urban Developed Built/developed areas rg Rangeland Natural Natural grasslands"},{"location":"LAND_USE_METHODOLOGY/#historical-context","title":"Historical Context","text":""},{"location":"LAND_USE_METHODOLOGY/#development-trends","title":"Development Trends","text":"<p>The model was calibrated during a period of changing development patterns: - 1980s: ~1.2 million acres/year converted to developed - 1992-1997: Peak at ~2.0 million acres/year - After 2000: Declining rate (reflected in projections)</p>"},{"location":"LAND_USE_METHODOLOGY/#observed-transitions-2001-2012","title":"Observed Transitions (2001-2012)","text":"<ul> <li>Most active transitions between crop \u2194 pasture (agricultural rotation)</li> <li>Forest \u2192 Developed: Primary urbanization pathway</li> <li>Agricultural \u2192 Developed: Secondary urbanization pathway</li> </ul>"},{"location":"LAND_USE_METHODOLOGY/#projection-methodology","title":"Projection Methodology","text":""},{"location":"LAND_USE_METHODOLOGY/#model-structure","title":"Model Structure","text":"<ol> <li>Econometric Foundation: Based on empirical analysis of NRI data</li> <li>Climate Integration: Incorporates temperature and precipitation projections</li> <li>Socioeconomic Drivers: Population and GDP growth from SSPs</li> <li>Spatial Constraints: Respects county boundaries and land availability</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#scenario-integration","title":"Scenario Integration","text":"<p>Each of the 20 scenarios combines: - Climate Model (5 options): Hot, Wet, Dry, Least warm, Middle - RCP Pathway (2 options): RCP 4.5 or RCP 8.5 - SSP Pathway (4 options): SSP1, SSP2, SSP3, or SSP5</p>"},{"location":"LAND_USE_METHODOLOGY/#projection-process","title":"Projection Process","text":"<ol> <li>Calculate transition probabilities based on:</li> <li>Historical land use patterns</li> <li>Projected climate conditions</li> <li>Socioeconomic growth rates</li> <li> <p>Land quality factors</p> </li> <li> <p>Apply constraints:</p> </li> <li>Total county area must be conserved</li> <li>Development cannot revert</li> <li> <p>Transitions follow observed patterns</p> </li> <li> <p>Generate projections for six time periods:</p> </li> <li>2012-2020, 2020-2030, 2030-2040, 2040-2050, 2050-2070, 2070-2100</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#key-projections-2020-2070","title":"Key Projections (2020-2070)","text":""},{"location":"LAND_USE_METHODOLOGY/#national-level","title":"National Level","text":"<ul> <li>Developed Land: +41.3 to +57.0 million acres</li> <li>Forest Land: -7.6 to -15.0 million acres</li> <li>Agricultural Land: Variable by scenario</li> <li>Primary Conversion: ~46% of new developed land from forest</li> </ul>"},{"location":"LAND_USE_METHODOLOGY/#regional-patterns","title":"Regional Patterns","text":"<p>Highest Development Pressure: 1. South Region: 18.4-25.0 million acres 2. North Region: 10.6-14.0 million acres 3. Rocky Mountain: 6.4-8.9 million acres 4. Pacific Coast: 5.9-9.9 million acres</p> <p>Forest Loss Patterns: - Largest losses: South Region (4.6-9.2 million acres) - Moderate losses: Pacific Coast, North - Smallest losses: Rocky Mountain Region</p>"},{"location":"LAND_USE_METHODOLOGY/#scenario-effects","title":"Scenario Effects","text":""},{"location":"LAND_USE_METHODOLOGY/#climate-impact-rcp-45-vs-rcp-85","title":"Climate Impact (RCP 4.5 vs RCP 8.5)","text":"<p>Higher warming (RCP 8.5) results in: - 2.4% less developed land expansion - 1.2 million acres more forest retention - Climate stress reduces development attractiveness</p>"},{"location":"LAND_USE_METHODOLOGY/#socioeconomic-impact-low-vs-high-growth","title":"Socioeconomic Impact (Low vs High Growth)","text":"<p>Higher growth (SSP5 vs SSP3) results in: - 9.4% more developed land expansion - 3.5 million acres less forest - Economic pressure drives conversion</p>"},{"location":"LAND_USE_METHODOLOGY/#data-structure-in-database","title":"Data Structure in Database","text":""},{"location":"LAND_USE_METHODOLOGY/#fact-table-fact_landuse_transitions","title":"Fact Table: <code>fact_landuse_transitions</code>","text":"<p>Each record represents a land use transition for a specific: - County (geography_id) - Time period (time_id) - Scenario (scenario_id) - Transition type (from_landuse_id \u2192 to_landuse_id)</p>"},{"location":"LAND_USE_METHODOLOGY/#key-fields","title":"Key Fields","text":"<ul> <li>acres: Area undergoing this specific transition</li> <li>transition_type: 'change' (actual transition) or 'same' (no change)</li> </ul>"},{"location":"LAND_USE_METHODOLOGY/#aggregation-patterns","title":"Aggregation Patterns","text":"<p>Common aggregations in analysis: - By Scenario: Compare climate/socioeconomic pathways - By Time: Track temporal trends - By Geography: State or regional patterns - By Transition: Focus on specific conversions (e.g., forest loss)</p>"},{"location":"LAND_USE_METHODOLOGY/#important-considerations","title":"Important Considerations","text":""},{"location":"LAND_USE_METHODOLOGY/#when-analyzing-data","title":"When Analyzing Data","text":"<ol> <li>Default to Averages: When not comparing scenarios, average across all 20</li> <li>Focus on Changes: Use transition_type = 'change' for actual transitions</li> <li>Consider Scale: National patterns may differ from local trends</li> <li>Remember Constraints: Development is irreversible in projections</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#common-analysis-patterns","title":"Common Analysis Patterns","text":"<pre><code>-- Total agricultural loss (averaged across scenarios)\nSELECT AVG(acres) as avg_loss_per_scenario\nFROM fact_landuse_transitions\nWHERE from_landuse_id IN (SELECT landuse_id FROM dim_landuse WHERE landuse_category = 'Agriculture')\n  AND to_landuse_id NOT IN (SELECT landuse_id FROM dim_landuse WHERE landuse_category = 'Agriculture')\n  AND transition_type = 'change';\n\n-- Urbanization by source\nSELECT fl.landuse_name as source, SUM(acres) as total_converted\nFROM fact_landuse_transitions f\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE tl.landuse_code = 'ur' AND f.transition_type = 'change'\nGROUP BY fl.landuse_name;\n</code></pre>"},{"location":"LAND_USE_METHODOLOGY/#limitations","title":"Limitations","text":"<ol> <li>Private Land Only: Public lands assumed static</li> <li>Policy Neutral: Doesn't account for future conservation efforts</li> <li>County Level: Sub-county patterns not captured</li> <li>Historical Basis: Assumes past relationships continue</li> </ol>"},{"location":"LAND_USE_METHODOLOGY/#references","title":"References","text":"<ul> <li>Mihiar, C.J.; Lewis, D.J.; Coulston, J.W. 2023. Land use projections for the 2020 RPA Assessment. https://doi.org/10.2737/RDS-2023-0026</li> <li>Chapter 4: Land Resources. In: Future of America's Forest and Rangelands: Forest Service 2020 Resources Planning Act Assessment. Gen. Tech. Rep. WO-102.</li> </ul>"},{"location":"RPA_SCENARIOS/","title":"RPA Assessment Scenarios Reference Guide","text":""},{"location":"RPA_SCENARIOS/#overview","title":"Overview","text":"<p>The 2020 RPA Assessment uses four integrated scenarios to explore alternative futures and provide a framework for evaluating a plausible range of natural resource outcomes through 2070. These scenarios combine climate pathways (RCPs) with socioeconomic pathways (SSPs) to create comprehensive projections.</p>"},{"location":"RPA_SCENARIOS/#the-four-rpa-scenarios","title":"The Four RPA Scenarios","text":""},{"location":"RPA_SCENARIOS/#quick-reference-table","title":"Quick Reference Table","text":"Scenario Code Climate Socioeconomic Description Lower-Moderate LM RCP 4.5 SSP1 Lower warming, moderate U.S. growth, sustainable development High-Low HL RCP 8.5 SSP3 High warming, low U.S. growth, regional rivalry High-Moderate HM RCP 8.5 SSP2 High warming, moderate U.S. growth, middle of the road High-High HH RCP 8.5 SSP5 High warming, high U.S. growth, fossil-fueled development"},{"location":"RPA_SCENARIOS/#detailed-scenario-descriptions","title":"Detailed Scenario Descriptions","text":""},{"location":"RPA_SCENARIOS/#scenario-lm-lower-warming-moderate-us-growth-rcp-45-ssp1","title":"Scenario LM: Lower warming-moderate U.S. growth (RCP 4.5-SSP1)","text":"<ul> <li>Theme: \"Taking the Green Road\"</li> <li>Climate: Lower emissions with moderate warming (~2.5\u00b0C by 2100)</li> <li>Society: Strong international cooperation, sustainable practices</li> <li>U.S. Economy: 3.0X GDP growth by 2070</li> <li>U.S. Population: 1.5X growth to ~470 million by 2070</li> <li>Key Features: Environmental protection prioritized, renewable energy transition</li> </ul>"},{"location":"RPA_SCENARIOS/#scenario-hl-high-warming-low-us-growth-rcp-85-ssp3","title":"Scenario HL: High warming-low U.S. growth (RCP 8.5-SSP3)","text":"<ul> <li>Theme: \"A Rocky Road\"</li> <li>Climate: High emissions with significant warming (~4.5\u00b0C by 2100)</li> <li>Society: Nationalism, regional conflicts, security concerns</li> <li>U.S. Economy: 1.9X GDP growth by 2070 (slowest)</li> <li>U.S. Population: 1.0X (no net growth, ~330 million by 2070)</li> <li>Key Features: Trade barriers, resource competition, adaptation challenges</li> </ul>"},{"location":"RPA_SCENARIOS/#scenario-hm-high-warming-moderate-us-growth-rcp-85-ssp2","title":"Scenario HM: High warming-moderate U.S. growth (RCP 8.5-SSP2)","text":"<ul> <li>Theme: \"Middle of the Road\"</li> <li>Climate: High emissions with significant warming (~4.5\u00b0C by 2100)</li> <li>Society: Historical trends continue, slow progress</li> <li>U.S. Economy: 2.8X GDP growth by 2070</li> <li>U.S. Population: 1.4X growth to ~450 million by 2070</li> <li>Key Features: Uneven development, moderate challenges and progress</li> </ul>"},{"location":"RPA_SCENARIOS/#scenario-hh-high-warming-high-us-growth-rcp-85-ssp5","title":"Scenario HH: High warming-high U.S. growth (RCP 8.5-SSP5)","text":"<ul> <li>Theme: \"Taking the Highway\"</li> <li>Climate: High emissions with significant warming (~4.5\u00b0C by 2100)</li> <li>Society: Rapid development, technology-focused, fossil fuel reliant</li> <li>U.S. Economy: 4.7X GDP growth by 2070 (highest)</li> <li>U.S. Population: 1.9X growth to ~580 million by 2070</li> <li>Key Features: High consumption, technological solutions, urbanization</li> </ul>"},{"location":"RPA_SCENARIOS/#climate-models-used","title":"Climate Models Used","text":"<p>The RPA Assessment uses five climate models to capture different aspects of climate change:</p>"},{"location":"RPA_SCENARIOS/#the-five-core-climate-projections","title":"The Five Core Climate Projections","text":"Model Type Climate Model Institution Key Characteristic Least warm MRI-CGCM3 Meteorological Research Institute, Japan Lower bound of warming Hot HadGEM2-ES Met Office Hadley Centre, UK Upper bound of warming Dry IPSL-CM5A-MR Institut Pierre Simon Laplace, France Reduced precipitation Wet CNRM-CM5 National Centre of Meteorological Research, France Increased precipitation Middle NorESM1-M Norwegian Climate Center, Norway Central tendency"},{"location":"RPA_SCENARIOS/#understanding-rcps-and-ssps","title":"Understanding RCPs and SSPs","text":""},{"location":"RPA_SCENARIOS/#representative-concentration-pathways-rcps","title":"Representative Concentration Pathways (RCPs)","text":"<ul> <li>RCP 4.5: Medium forcing scenario with emissions peaking around 2040</li> <li>Assumes implementation of climate policies</li> <li>~2.5\u00b0C global warming by 2100</li> <li> <p>Used in scenario LM</p> </li> <li> <p>RCP 8.5: High forcing scenario with continued emissions growth</p> </li> <li>Assumes limited climate action</li> <li>~4.5\u00b0C global warming by 2100</li> <li>Used in scenarios HL, HM, and HH</li> </ul>"},{"location":"RPA_SCENARIOS/#shared-socioeconomic-pathways-ssps","title":"Shared Socioeconomic Pathways (SSPs)","text":"<ul> <li>SSP1 - Sustainability: Green growth, reduced inequality, international cooperation</li> <li>SSP2 - Middle of the Road: Historical trends continue, slow progress</li> <li>SSP3 - Regional Rivalry: Nationalism, security concerns, material-intensive consumption</li> <li>SSP5 - Fossil-fueled Development: Rapid growth, technological solutions, high energy use</li> </ul>"},{"location":"RPA_SCENARIOS/#land-use-implications-by-scenario","title":"Land Use Implications by Scenario","text":""},{"location":"RPA_SCENARIOS/#development-pressure","title":"Development Pressure","text":"<ul> <li>Highest: Scenario HH (high growth, urbanization)</li> <li>Moderate: Scenarios LM and HM (balanced growth)</li> <li>Lowest: Scenario HL (low growth, limited expansion)</li> </ul>"},{"location":"RPA_SCENARIOS/#agricultural-land-loss","title":"Agricultural Land Loss","text":"<ul> <li>Most Severe: Scenarios with high population/economic growth (HH)</li> <li>Moderate: Middle scenarios (LM, HM)</li> <li>Least Severe: Low growth scenario (HL)</li> </ul>"},{"location":"RPA_SCENARIOS/#forest-conservation","title":"Forest Conservation","text":"<ul> <li>Best Outcomes: Scenario LM (sustainability focus)</li> <li>Worst Outcomes: Scenario HH (development pressure)</li> <li>Variable: Scenarios HL and HM (depends on regional factors)</li> </ul>"},{"location":"RPA_SCENARIOS/#using-scenarios-in-analysis","title":"Using Scenarios in Analysis","text":""},{"location":"RPA_SCENARIOS/#time-horizons","title":"Time Horizons","text":"<ul> <li>Near-term (2020-2030): Limited divergence between scenarios</li> <li>Mid-term (2030-2050): Increasing differentiation</li> <li>Long-term (2050-2070): Maximum scenario divergence</li> </ul>"},{"location":"RPA_SCENARIOS/#best-practices","title":"Best Practices","text":"<ol> <li>Always specify the scenario when presenting results</li> <li>Compare across scenarios to show uncertainty range</li> <li>Use scenario names consistently (LM, HL, HM, HH)</li> <li>Include climate model when relevant (e.g., \"HH-Hot\" or \"LM-Wet\")</li> <li>Consider averaging across all scenarios for general trends</li> </ol>"},{"location":"RPA_SCENARIOS/#common-analysis-patterns","title":"Common Analysis Patterns","text":""},{"location":"RPA_SCENARIOS/#for-climate-impact-studies","title":"For Climate Impact Studies","text":"<ul> <li>Compare RCP 4.5 (scenario LM) vs RCP 8.5 (scenarios HL, HM, HH)</li> <li>Use all five climate models to capture precipitation uncertainty</li> </ul>"},{"location":"RPA_SCENARIOS/#for-socioeconomic-analysis","title":"For Socioeconomic Analysis","text":"<ul> <li>Compare high growth (HH) vs low growth (HL) scenarios</li> <li>Use middle scenarios (LM, HM) for moderate projections</li> </ul>"},{"location":"RPA_SCENARIOS/#for-integrated-assessment","title":"For Integrated Assessment","text":"<ul> <li>Present all four scenarios to show full uncertainty range</li> <li>Highlight scenario LM as \"best case\" and HL as \"challenging case\"</li> </ul>"},{"location":"RPA_SCENARIOS/#data-structure-in-database","title":"Data Structure in Database","text":"<p>In our DuckDB database, scenarios are structured as:</p> <pre><code>-- Scenario naming convention\n-- Format: {ClimateModel}_{RCP}_ssp{SSP}\n-- Example: CNRM_CM5_rcp45_ssp1 (Wet climate, lower warming, sustainability)\n\n-- The 20 scenarios in our database combine:\n-- 5 climate models \u00d7 2 RCPs \u00d7 variable SSPs = 20 total scenarios\n\n-- Scenario components:\n-- Climate models: CNRM_CM5, HadGEM2_ES365, IPSL_CM5A_MR, MRI_CGCM3, NorESM1_M\n-- RCPs: rcp45, rcp85\n-- SSPs: ssp1, ssp2, ssp3, ssp5\n</code></pre>"},{"location":"RPA_SCENARIOS/#references","title":"References","text":"<ul> <li>U.S. Department of Agriculture, Forest Service. 2023. Future Scenarios. Chapter 3 in: Future of America's Forest and Rangelands: Forest Service 2020 Resources Planning Act Assessment. Gen. Tech. Rep. WO-102. Washington, DC.</li> <li>O'Dea, C.B.; Langner, L.L.; Joyce, L.A.; Prestemon, J.P.; Wear, D.N. 2023. Future Scenarios. https://doi.org/10.2737/WO-GTR-102-Chap3</li> </ul>"},{"location":"SECURITY/","title":"Security Guide","text":"<p>This document outlines the security features and best practices implemented in the Langchain Landuse Analysis System.</p>"},{"location":"SECURITY/#overview","title":"Overview","text":"<p>The system implements multiple layers of security to protect against common vulnerabilities and ensure safe operation when processing natural language queries and database operations.</p>"},{"location":"SECURITY/#security-features","title":"Security Features","text":""},{"location":"SECURITY/#1-sql-injection-prevention","title":"1. SQL Injection Prevention","text":"<p>All user-generated queries are validated before execution:</p> <ul> <li>Query Validation: Only SELECT statements are allowed</li> <li>Keyword Blocking: Dangerous SQL keywords (DROP, DELETE, etc.) are blocked</li> <li>Comment Stripping: SQL comments are removed to prevent comment-based attacks</li> <li>Single Statement Enforcement: Multiple SQL statements are not allowed</li> </ul> <p>Example of blocked queries: <pre><code>-- These will be rejected:\nDROP TABLE dim_scenario;\nSELECT * FROM users; DELETE FROM users;\nSELECT * FROM users WHERE id = 1 OR '1'='1'--\n</code></pre></p>"},{"location":"SECURITY/#2-input-validation","title":"2. Input Validation","text":"<p>All user inputs are validated and sanitized:</p> <ul> <li>File Path Validation: Prevents directory traversal attacks</li> <li>Identifier Sanitization: Database identifiers are validated against safe patterns</li> <li>Parameter Validation: Query parameters are type-checked and range-validated</li> </ul>"},{"location":"SECURITY/#3-api-key-security","title":"3. API Key Security","text":"<p>API keys are handled securely throughout the system:</p> <ul> <li>Secure Storage: Keys stored in <code>.env</code> files (gitignored)</li> <li>Format Validation: Keys are validated against expected patterns</li> <li>Masking: Keys are masked in logs and UI output</li> <li>No Hardcoding: Code is scanned to prevent hardcoded secrets</li> </ul>"},{"location":"SECURITY/#4-rate-limiting","title":"4. Rate Limiting","text":"<p>Protection against API abuse:</p> <ul> <li>Default Limit: 60 queries per minute per user</li> <li>Configurable: Limits can be adjusted based on needs</li> <li>Graceful Handling: Clear error messages with retry information</li> </ul>"},{"location":"SECURITY/#5-database-security","title":"5. Database Security","text":"<p>Database access is restricted and monitored:</p> <ul> <li>Read-Only Access: Agents connect with read-only permissions</li> <li>Query Limits: Automatic LIMIT clauses prevent data exfiltration</li> <li>Connection Security: Connections are properly closed after use</li> </ul>"},{"location":"SECURITY/#6-logging-and-auditing","title":"6. Logging and Auditing","text":"<p>Comprehensive security logging:</p> <ul> <li>Query Logging: All queries are logged with status</li> <li>Access Logging: Resource access attempts are tracked</li> <li>Security Events: Failed validations and rate limits are logged</li> <li>No Sensitive Data: Logs exclude full API keys and query results</li> </ul>"},{"location":"SECURITY/#configuration","title":"Configuration","text":""},{"location":"SECURITY/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>config/.env</code> file with:</p> <pre><code># Required (at least one)\nOPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-ant-...\n\n# Security Settings\nDEFAULT_QUERY_LIMIT=1000    # Max rows returned\nLOG_LEVEL=INFO              # Logging verbosity\nENABLE_LOGGING=true         # Enable security logging\n</code></pre>"},{"location":"SECURITY/#file-permissions","title":"File Permissions","text":"<p>On Unix-like systems, ensure proper file permissions:</p> <pre><code>chmod 600 config/.env       # Only owner can read/write\nchmod 755 scripts/*.py      # Scripts are executable\n</code></pre>"},{"location":"SECURITY/#usage","title":"Usage","text":""},{"location":"SECURITY/#running-the-secure-agent","title":"Running the Secure Agent","text":"<pre><code># Run the secure setup wizard first\nuv run python setup_secure_agents.py\n\n# Then run the secure agent\nuv run python scripts/agents/secure_landuse_query_agent.py\n</code></pre>"},{"location":"SECURITY/#security-features-in-action","title":"Security Features in Action","text":"<p>When you run the secure agent, you'll see:</p> <ol> <li>API Key Validation: Keys are validated on startup</li> <li>Query Validation: Each query is checked before execution</li> <li>Rate Limiting: Prevents excessive API usage</li> <li>Audit Logging: All actions are logged</li> </ol>"},{"location":"SECURITY/#best-practices-for-users","title":"Best Practices for Users","text":"<ol> <li>Protect Your API Keys</li> <li>Never share your <code>.env</code> file</li> <li>Don't commit API keys to version control</li> <li> <p>Rotate keys regularly</p> </li> <li> <p>Use Appropriate Queries</p> </li> <li>Stick to analytical queries</li> <li>Avoid trying to modify data</li> <li> <p>Report any security issues</p> </li> <li> <p>Monitor Usage</p> </li> <li>Check logs regularly</li> <li>Watch for unusual patterns</li> <li>Stay within rate limits</li> </ol>"},{"location":"SECURITY/#security-architecture","title":"Security Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   User Input    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n    \u2502Validation\u2502  \u2190 Rate Limiting\n    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518     Input Sanitization\n         \u2502          SQL Validation\n    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n    \u2502  Agent  \u2502  \u2190 Secure Config\n    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518     API Key Validation\n         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n    \u2502 Database \u2502  \u2190 Read-Only Access\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     Query Limits\n</code></pre>"},{"location":"SECURITY/#logging","title":"Logging","text":"<p>Security logs are stored in <code>logs/security.log</code> and include:</p> <ul> <li>Query attempts (successful and blocked)</li> <li>Rate limit violations</li> <li>Invalid input attempts</li> <li>Configuration errors</li> </ul> <p>Example log entry: <pre><code>2024-01-15 10:23:45 - security - INFO - Query attempt - User: user123, Status: success, Error: None\n2024-01-15 10:24:12 - security - WARNING - Blocked query from user123: DROP TABLE...\n</code></pre></p>"},{"location":"SECURITY/#troubleshooting","title":"Troubleshooting","text":""},{"location":"SECURITY/#common-security-issues","title":"Common Security Issues","text":"<ol> <li>\"Invalid API key format\"</li> <li>Ensure your API key matches the expected pattern</li> <li>OpenAI: <code>sk-</code> followed by 48 characters</li> <li> <p>Anthropic: <code>sk-ant-</code> followed by 95 characters</p> </li> <li> <p>\"Rate limit exceeded\"</p> </li> <li>Wait for the specified retry time</li> <li> <p>Consider upgrading limits if needed frequently</p> </li> <li> <p>\"Query validation failed\"</p> </li> <li>Ensure you're only using SELECT statements</li> <li>Remove any data modification keywords</li> <li>Check for SQL injection patterns</li> </ol>"},{"location":"SECURITY/#getting-help","title":"Getting Help","text":"<p>If you encounter security issues:</p> <ol> <li>Check the security logs</li> <li>Review this documentation</li> <li>Report issues (without including sensitive data)</li> </ol>"},{"location":"SECURITY/#updates-and-maintenance","title":"Updates and Maintenance","text":"<p>Keep your security features up to date:</p> <pre><code># Update dependencies\nuv sync\n\n# Re-run security setup\nuv run python setup_secure_agents.py\n\n# Test security features\nuv run python scripts/utilities/security.py\n</code></pre>"},{"location":"SECURITY/#compliance","title":"Compliance","text":"<p>This system implements security best practices aligned with:</p> <ul> <li>OWASP Top 10 recommendations</li> <li>SQL injection prevention guidelines</li> <li>API security best practices</li> <li>Data protection principles</li> </ul> <p>Remember: Security is a shared responsibility. Always follow best practices and report any concerns.</p>"},{"location":"TESTING/","title":"Testing Guide","text":"<p>This guide covers the testing infrastructure and best practices for the Langchain Landuse project.</p>"},{"location":"TESTING/#overview","title":"Overview","text":"<p>The project uses pytest as the testing framework with comprehensive unit and integration tests for all major components.</p>"},{"location":"TESTING/#quick-start","title":"Quick Start","text":"<pre><code># Install dependencies (including test dependencies)\nuv sync\n\n# Run all tests\nuv run python run_tests.py\n\n# Run specific test suites\nuv run python run_tests.py unit        # Unit tests only\nuv run python run_tests.py integration # Integration tests only\nuv run python run_tests.py security    # Security tests only\nuv run python run_tests.py coverage    # Generate coverage report\n</code></pre>"},{"location":"TESTING/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py          # Shared fixtures and configuration\n\u251c\u2500\u2500 unit/                # Unit tests (fast, isolated)\n\u2502   \u251c\u2500\u2500 test_security.py # Security utilities tests\n\u2502   \u2514\u2500\u2500 test_converters.py # Data converter tests\n\u251c\u2500\u2500 integration/         # Integration tests\n\u2502   \u2514\u2500\u2500 test_secure_agent.py # Agent integration tests\n\u2514\u2500\u2500 fixtures/           # Test data files\n</code></pre>"},{"location":"TESTING/#running-tests","title":"Running Tests","text":""},{"location":"TESTING/#using-the-test-runner","title":"Using the Test Runner","text":"<p>The <code>run_tests.py</code> script provides convenient commands:</p> <pre><code># Run all tests with coverage\nuv run python run_tests.py all\n\n# Run only failed tests from last run\nuv run python run_tests.py failed\n\n# Run tests in parallel (faster)\nuv run python run_tests.py parallel\n\n# List available test markers\nuv run python run_tests.py markers\n</code></pre>"},{"location":"TESTING/#using-pytest-directly","title":"Using pytest Directly","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=scripts --cov-report=html\n\n# Run specific test file\nuv run pytest tests/unit/test_security.py\n\n# Run specific test function\nuv run pytest tests/unit/test_security.py::TestSQLQueryValidator::test_valid_queries\n\n# Run tests matching pattern\nuv run pytest -k \"security\"\n\n# Run tests with specific marker\nuv run pytest -m \"unit\"\nuv run pytest -m \"integration\"\nuv run pytest -m \"security\"\n\n# Stop on first failure\nuv run pytest -x\n\n# Drop into debugger on failure\nuv run pytest --pdb\n\n# Verbose output\nuv run pytest -v\n</code></pre>"},{"location":"TESTING/#test-markers","title":"Test Markers","text":"<p>Tests are organized with markers for easy filtering:</p> <ul> <li><code>@pytest.mark.unit</code> - Fast, isolated unit tests</li> <li><code>@pytest.mark.integration</code> - Tests requiring database or external resources</li> <li><code>@pytest.mark.security</code> - Security-specific tests</li> <li><code>@pytest.mark.slow</code> - Tests taking &gt;5 seconds</li> <li><code>@pytest.mark.requires_api</code> - Tests needing real API keys</li> <li><code>@pytest.mark.requires_db</code> - Tests needing the production database</li> </ul> <p>Example usage: <pre><code>@pytest.mark.unit\ndef test_sql_validation():\n    \"\"\"This is a unit test\"\"\"\n    pass\n\n@pytest.mark.integration\n@pytest.mark.requires_db\ndef test_database_query():\n    \"\"\"This test requires a database\"\"\"\n    pass\n</code></pre></p>"},{"location":"TESTING/#writing-tests","title":"Writing Tests","text":""},{"location":"TESTING/#unit-tests","title":"Unit Tests","text":"<p>Unit tests should be fast and isolated:</p> <pre><code># tests/unit/test_example.py\nimport pytest\nfrom scripts.utilities.security import SQLQueryValidator\n\nclass TestSQLQueryValidator:\n    def test_valid_query(self):\n        validator = SQLQueryValidator()\n        is_valid, error = validator.validate_query(\"SELECT * FROM table\")\n        assert is_valid\n        assert error is None\n\n    def test_invalid_query(self):\n        validator = SQLQueryValidator()\n        is_valid, error = validator.validate_query(\"DROP TABLE users\")\n        assert not is_valid\n        assert \"DROP\" in error\n</code></pre>"},{"location":"TESTING/#integration-tests","title":"Integration Tests","text":"<p>Integration tests can use the test database:</p> <pre><code># tests/integration/test_agent.py\nimport pytest\n\n@pytest.mark.integration\ndef test_agent_query(test_database):\n    \"\"\"Test agent with test database\"\"\"\n    from scripts.agents.secure_landuse_query_agent import SecureLanduseQueryAgent\n\n    agent = SecureLanduseQueryAgent()\n    result = agent.query(\"How many scenarios exist?\")\n    assert \"scenarios\" in result.lower()\n</code></pre>"},{"location":"TESTING/#using-fixtures","title":"Using Fixtures","text":"<p>Common fixtures are defined in <code>conftest.py</code>:</p> <pre><code>def test_with_database(test_database):\n    \"\"\"test_database fixture provides a test DuckDB instance\"\"\"\n    conn = duckdb.connect(str(test_database))\n    result = conn.execute(\"SELECT COUNT(*) FROM dim_scenario\").fetchone()\n    assert result[0] &gt; 0\n\ndef test_with_config(test_config_file):\n    \"\"\"test_config_file provides a test .env file\"\"\"\n    config = SecureConfig.from_env(test_config_file)\n    assert config.openai_api_key.startswith(\"sk-\")\n\ndef test_malicious_queries(malicious_queries):\n    \"\"\"malicious_queries provides SQL injection test cases\"\"\"\n    validator = SQLQueryValidator()\n    for query in malicious_queries:\n        is_valid, _ = validator.validate_query(query)\n        assert not is_valid\n</code></pre>"},{"location":"TESTING/#test-coverage","title":"Test Coverage","text":""},{"location":"TESTING/#viewing-coverage","title":"Viewing Coverage","text":"<pre><code># Generate coverage report\nuv run pytest --cov=scripts --cov-report=html\n\n# Open HTML report\nopen htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\nstart htmlcov/index.html  # Windows\n</code></pre>"},{"location":"TESTING/#coverage-requirements","title":"Coverage Requirements","text":"<ul> <li>Minimum coverage: 70% (configured in pytest.ini)</li> <li>Target coverage: 85%+</li> <li>Critical modules (security, agents): 90%+</li> </ul>"},{"location":"TESTING/#excluding-code-from-coverage","title":"Excluding Code from Coverage","text":"<pre><code>def debug_function():  # pragma: no cover\n    \"\"\"This function is excluded from coverage\"\"\"\n    pass\n\nif __name__ == \"__main__\":  # pragma: no cover\n    main()\n</code></pre>"},{"location":"TESTING/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"TESTING/#1-test-naming","title":"1. Test Naming","text":"<p>Use descriptive test names: <pre><code># Good\ndef test_sql_injection_with_drop_table_is_blocked():\n    pass\n\n# Bad\ndef test_1():\n    pass\n</code></pre></p>"},{"location":"TESTING/#2-test-organization","title":"2. Test Organization","text":"<p>Group related tests in classes: <pre><code>class TestSQLValidation:\n    def test_valid_queries(self):\n        pass\n\n    def test_invalid_queries(self):\n        pass\n</code></pre></p>"},{"location":"TESTING/#3-use-fixtures","title":"3. Use Fixtures","text":"<p>Don't repeat setup code: <pre><code># Good\ndef test_agent(test_database, mock_llm):\n    agent = SecureLanduseQueryAgent()\n    # ... test code\n\n# Bad\ndef test_agent():\n    db = create_test_database()\n    llm = create_mock_llm()\n    agent = SecureLanduseQueryAgent()\n    # ... test code\n    cleanup_database(db)\n</code></pre></p>"},{"location":"TESTING/#4-test-error-cases","title":"4. Test Error Cases","text":"<p>Always test error conditions: <pre><code>def test_invalid_input():\n    with pytest.raises(ValueError, match=\"Invalid FIPS code\"):\n        validate_fips_code(\"invalid\")\n</code></pre></p>"},{"location":"TESTING/#5-use-mocks-appropriately","title":"5. Use Mocks Appropriately","text":"<p>Mock external dependencies: <pre><code>@patch('requests.post')\ndef test_api_call(mock_post):\n    mock_post.return_value.json.return_value = {\"result\": \"success\"}\n    result = make_api_call()\n    assert result == \"success\"\n</code></pre></p>"},{"location":"TESTING/#continuous-integration","title":"Continuous Integration","text":"<p>Tests run automatically on: - Pull requests - Commits to main branch - Nightly schedule</p> <p>See <code>.github/workflows/tests.yml</code> for CI configuration.</p>"},{"location":"TESTING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"TESTING/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Import errors <pre><code># Ensure project is in Python path\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\n</code></pre></p> </li> <li> <p>Missing dependencies <pre><code># Install all dependencies including test deps\nuv sync\n</code></pre></p> </li> <li> <p>Database not found <pre><code># Tests use a test database, not production\n# This is created automatically by fixtures\n</code></pre></p> </li> <li> <p>API key errors <pre><code># Tests use mock API keys by default\n# For integration tests with real APIs:\nexport REAL_OPENAI_API_KEY=your-key\n</code></pre></p> </li> </ol>"},{"location":"TESTING/#debugging-tests","title":"Debugging Tests","text":"<pre><code># Drop into debugger on failure\nuv run pytest --pdb\n\n# Show print statements\nuv run pytest -s\n\n# Very verbose output\nuv run pytest -vv\n\n# Show local variables on failure\nuv run pytest -l\n</code></pre>"},{"location":"TESTING/#adding-new-tests","title":"Adding New Tests","text":"<ol> <li>Create test file in appropriate directory:</li> <li><code>tests/unit/</code> for unit tests</li> <li> <p><code>tests/integration/</code> for integration tests</p> </li> <li> <p>Import necessary modules and fixtures</p> </li> <li> <p>Write test functions with descriptive names</p> </li> <li> <p>Use appropriate markers</p> </li> <li> <p>Run tests to ensure they pass</p> </li> <li> <p>Check coverage hasn't decreased</p> </li> </ol> <p>Example: <pre><code># tests/unit/test_new_feature.py\nimport pytest\nfrom scripts.new_module import NewFeature\n\n@pytest.mark.unit\nclass TestNewFeature:\n    def test_feature_initialization(self):\n        feature = NewFeature()\n        assert feature is not None\n\n    def test_feature_process(self):\n        feature = NewFeature()\n        result = feature.process(\"input\")\n        assert result == \"expected output\"\n\n    def test_feature_error_handling(self):\n        feature = NewFeature()\n        with pytest.raises(ValueError):\n            feature.process(None)\n</code></pre></p> <p>Remember: Well-tested code is maintainable code!</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Common questions about the LangChain Land Use Analysis system.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-this-project","title":"What is this project?","text":"<p>The LangChain Land Use Analysis system allows you to query and analyze county-level land use projections using natural language. Instead of writing SQL, you can ask questions like \"Show me forest loss in California\" and get meaningful results.</p>"},{"location":"faq/#what-data-does-it-analyze","title":"What data does it analyze?","text":"<p>The system analyzes USDA Forest Service RPA (Resources Planning Act) land use projections: - Coverage: All US counties - Time Period: 2020-2100 - Scenarios: Baseline, High Crop Demand, High Forest, High Urban - Land Types: Crop, Pasture, Forest, Urban, Range</p>"},{"location":"faq/#do-i-need-to-know-sql","title":"Do I need to know SQL?","text":"<p>No! The agent converts your natural language questions into SQL automatically. You can ask questions in plain English like: - \"What counties have the most urban growth?\" - \"Show me forest to cropland transitions\" - \"Compare scenarios for agricultural land\"</p>"},{"location":"faq/#setup-questions","title":"Setup Questions","text":""},{"location":"faq/#what-are-the-system-requirements","title":"What are the system requirements?","text":"<ul> <li>Python: 3.8 or higher</li> <li>Memory: 4GB RAM minimum (8GB recommended)</li> <li>Disk Space: 2GB for data and dependencies</li> <li>OS: Windows, macOS, or Linux</li> <li>API Key: OpenAI API key required</li> </ul>"},{"location":"faq/#how-do-i-get-an-openai-api-key","title":"How do I get an OpenAI API key?","text":"<ol> <li>Visit https://platform.openai.com/signup</li> <li>Create an account</li> <li>Go to API keys section</li> <li>Create new secret key</li> <li>Add to your <code>.env</code> file</li> </ol>"},{"location":"faq/#which-openai-model-should-i-use","title":"Which OpenAI model should I use?","text":"<pre><code># Recommended (best accuracy)\nAGENT_MODEL=gpt-4-turbo-preview\n\n# Budget option (faster, less accurate)\nAGENT_MODEL=gpt-3.5-turbo\n\n# High accuracy (more expensive)\nAGENT_MODEL=gpt-4\n</code></pre>"},{"location":"faq/#can-i-use-it-offline","title":"Can I use it offline?","text":"<p>The data processing and queries work offline, but the natural language interpretation requires an internet connection to reach OpenAI's API.</p>"},{"location":"faq/#data-questions","title":"Data Questions","text":""},{"location":"faq/#what-do-the-land-use-categories-mean","title":"What do the land use categories mean?","text":"<ul> <li>Crop: Agricultural land for growing crops</li> <li>Pasture: Land for livestock grazing</li> <li>Forest: Wooded areas (natural and managed)</li> <li>Urban: Developed areas (cities, towns, infrastructure)</li> <li>Range: Natural grasslands and shrublands</li> </ul>"},{"location":"faq/#whats-the-difference-between-the-tables","title":"What's the difference between the tables?","text":"Table Description Use Case <code>landuse_transitions</code> All transitions including same-to-same Complete analysis <code>landuse_transitions_ag</code> Crop+Pasture combined as Agriculture Simplified agricultural analysis <code>landuse_changes_only</code> Excludes unchanged land Focus on actual changes <code>landuse_changes_only_ag</code> Changes with agricultural aggregation Simplified change analysis"},{"location":"faq/#what-scenarios-are-available","title":"What scenarios are available?","text":"<ol> <li>Baseline: Most likely future based on current trends</li> <li>High Crop Demand: Increased agricultural pressure</li> <li>High Forest: Strong forest conservation</li> <li>High Urban: Accelerated urbanization</li> </ol>"},{"location":"faq/#why-are-areas-in-1000-acres","title":"Why are areas in \"1000 acres\"?","text":"<p>This unit makes large numbers more manageable. To convert: - Acres: multiply by 1,000 - Square miles: multiply by 1.5625 - Hectares: multiply by 404.686</p>"},{"location":"faq/#usage-questions","title":"Usage Questions","text":""},{"location":"faq/#how-do-i-start-a-query","title":"How do I start a query?","text":"<p>Simply run the agent and type your question: <pre><code>uv run python scripts/agents/test_agent.py\n\nYou&gt; Show me urban growth in Texas counties\n</code></pre></p>"},{"location":"faq/#can-i-export-results","title":"Can I export results?","text":"<p>Yes! Ask the agent to export: <pre><code>You&gt; Export the results to urban_growth_texas.csv\n</code></pre></p> <p>Supported formats: CSV, JSON, Parquet</p>"},{"location":"faq/#how-do-i-query-specific-years","title":"How do I query specific years?","text":"<p>Include the year in your question: <pre><code>You&gt; Show me forest area in 2050\nYou&gt; Compare urban growth between 2030 and 2080\nYou&gt; What changes happen in the 2040-2050 decade?\n</code></pre></p>"},{"location":"faq/#can-i-compare-scenarios","title":"Can I compare scenarios?","text":"<p>Yes! Ask comparison questions: <pre><code>You&gt; Compare forest area between all scenarios in 2100\nYou&gt; Which scenario has the most agricultural land?\nYou&gt; Show the difference between Baseline and High Urban\n</code></pre></p>"},{"location":"faq/#how-do-i-focus-on-specific-counties","title":"How do I focus on specific counties?","text":"<p>Use FIPS codes or descriptions: <pre><code>You&gt; Show data for FIPS 06037 (Los Angeles)\nYou&gt; Analyze California counties (FIPS starting with 06)\nYou&gt; Focus on Midwest agricultural counties\n</code></pre></p>"},{"location":"faq/#technical-questions","title":"Technical Questions","text":""},{"location":"faq/#how-does-the-natural-language-processing-work","title":"How does the natural language processing work?","text":"<ol> <li>Your question \u2192 LangChain agent</li> <li>Agent uses GPT model to understand intent</li> <li>Generates appropriate SQL query</li> <li>Executes query on database</li> <li>Formats results in natural language</li> </ol>"},{"location":"faq/#can-i-see-the-generated-sql","title":"Can I see the generated SQL?","text":"<p>Yes, the agent shows the SQL it generates: <pre><code>Query: SELECT * FROM landuse_transitions WHERE ...\nResults: 123 rows\n[Table of results]\n</code></pre></p>"},{"location":"faq/#how-accurate-is-the-sql-generation","title":"How accurate is the SQL generation?","text":"<p>The GPT-4 models are very accurate for: - Basic queries (&gt;95% accuracy) - Complex queries (&gt;85% accuracy) - Domain-specific terms (understands \"forest loss\", \"urban growth\", etc.)</p>"},{"location":"faq/#can-i-write-sql-directly","title":"Can I write SQL directly?","text":"<p>Yes! Use this format: <pre><code>You&gt; Query database.db: SELECT * FROM table WHERE condition\n</code></pre></p>"},{"location":"faq/#is-the-data-real-time","title":"Is the data real-time?","text":"<p>No, this is projection data created by USDA models. It represents scenarios of possible futures, not real-time monitoring.</p>"},{"location":"faq/#performance-questions","title":"Performance Questions","text":""},{"location":"faq/#why-is-my-query-slow","title":"Why is my query slow?","text":"<p>Common causes: 1. Large result sets - add limits 2. Complex aggregations - simplify query 3. Missing indexes - use indexed columns (scenario, year, fips)</p>"},{"location":"faq/#how-can-i-make-queries-faster","title":"How can I make queries faster?","text":"<ol> <li>Use filtered tables (<code>_changes_only</code>)</li> <li>Add LIMIT clauses</li> <li>Filter by indexed columns first</li> <li>Query specific years instead of all years</li> </ol>"},{"location":"faq/#whats-the-maximum-file-size-i-can-process","title":"What's the maximum file size I can process?","text":"<p>Default limit is 100MB (configurable): <pre><code>MAX_FILE_SIZE_MB=200  # Increase limit\n</code></pre></p> <p>Large files are automatically sampled for preview.</p>"},{"location":"faq/#troubleshooting-questions","title":"Troubleshooting Questions","text":""},{"location":"faq/#why-does-it-say-database-not-found","title":"Why does it say \"Database not found\"?","text":"<p>Run the data conversion first: <pre><code>uv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre></p>"},{"location":"faq/#why-am-i-getting-api-key-errors","title":"Why am I getting API key errors?","text":"<ol> <li>Check <code>.env</code> file exists in <code>config/</code></li> <li>Verify key starts with <code>sk-</code></li> <li>Ensure no extra quotes or spaces</li> <li>Check API key is active on OpenAI</li> </ol>"},{"location":"faq/#can-i-use-a-different-llm-provider","title":"Can I use a different LLM provider?","text":"<p>Currently supports OpenAI. The architecture allows for other providers (Claude, local models) with code modifications.</p>"},{"location":"faq/#how-do-i-update-the-data","title":"How do I update the data?","text":"<p>Place new JSON data in <code>data/raw/</code> and run: <pre><code>uv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre></p>"},{"location":"faq/#advanced-questions","title":"Advanced Questions","text":""},{"location":"faq/#can-i-add-custom-tools","title":"Can I add custom tools?","text":"<p>Yes! See the Contributing Guide for instructions on adding tools to the agent.</p>"},{"location":"faq/#can-i-modify-the-land-use-categories","title":"Can I modify the land use categories?","text":"<p>Yes, edit the <code>LAND_USE_MAP</code> in the converter scripts: <pre><code>LAND_USE_MAP = {\n    'cr': 'Cropland',  # Change naming\n    'new': 'NewCategory'  # Add categories\n}\n</code></pre></p>"},{"location":"faq/#can-i-integrate-this-with-other-systems","title":"Can I integrate this with other systems?","text":"<p>Yes! Options include: - Python API for programmatic access - Export functions for data pipelines - Web service wrapper possible - Jupyter notebook integration</p>"},{"location":"faq/#can-i-use-my-own-projections","title":"Can I use my own projections?","text":"<p>Yes, if your data follows the same JSON structure. See Data Processing for format requirements.</p>"},{"location":"faq/#best-practices-questions","title":"Best Practices Questions","text":""},{"location":"faq/#what-makes-a-good-query","title":"What makes a good query?","text":"<p>Good queries are: - Specific: \"Show forest loss in California between 2020-2050\" - Clear: Use standard terms (urban, forest, crop) - Focused: One question at a time</p> <p>Avoid: - Vague: \"Show me some data\" - Complex: Multiple unrelated questions - Ambiguous: \"What changes?\" (which changes?)</p>"},{"location":"faq/#how-should-i-explore-the-data","title":"How should I explore the data?","text":"<ol> <li>Start broad: \"What tables are available?\"</li> <li>Understand structure: \"Describe the main table\"</li> <li>Look at samples: \"Show me 10 example rows\"</li> <li>Focus analysis: \"Now show me specific patterns\"</li> </ol>"},{"location":"faq/#when-should-i-use-each-table","title":"When should I use each table?","text":"<ul> <li>Full analysis: Use base <code>landuse_transitions</code></li> <li>Change focus: Use <code>landuse_changes_only</code></li> <li>Agricultural studies: Use <code>_ag</code> tables</li> <li>Performance critical: Use filtered views</li> </ul>"},{"location":"faq/#getting-more-help","title":"Getting More Help","text":""},{"location":"faq/#where-can-i-find-more-examples","title":"Where can I find more examples?","text":"<ul> <li>Query Examples - Extensive query patterns</li> <li>Workflows - Step-by-step guides</li> <li>Notebooks - Interactive examples</li> </ul>"},{"location":"faq/#how-do-i-report-issues","title":"How do I report issues?","text":"<ol> <li>Check Troubleshooting Guide</li> <li>Search existing GitHub issues</li> <li>Create new issue with:</li> <li>Error message</li> <li>Steps to reproduce</li> <li>System information</li> </ol>"},{"location":"faq/#can-i-contribute","title":"Can I contribute?","text":"<p>Yes! See Contributing Guide for: - Code contributions - Documentation improvements - Bug reports - Feature requests</p>"},{"location":"faq/#where-can-i-learn-more","title":"Where can I learn more?","text":"<ul> <li>LangChain: https://python.langchain.com/</li> <li>OpenAI API: https://platform.openai.com/docs</li> <li>SQLite: https://www.sqlite.org/docs.html</li> <li>Project GitHub: Link to your repository</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues and solutions when using the LangChain Land Use Analysis system.</p>"},{"location":"troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"troubleshooting/#python-version-error","title":"Python Version Error","text":"<p>Problem: <code>ERROR: This project requires Python 3.8+</code></p> <p>Solution: <pre><code># Check Python version\npython --version\n\n# Install Python 3.8+ if needed\n# macOS: brew install python@3.11\n# Ubuntu: sudo apt install python3.11\n# Windows: Download from python.org\n</code></pre></p>"},{"location":"troubleshooting/#uv-installation-failed","title":"uv Installation Failed","text":"<p>Problem: <code>uv: command not found</code></p> <p>Solution: <pre><code># Install uv\npip install uv\n\n# Or with pipx\npipx install uv\n\n# Verify installation\nuv --version\n</code></pre></p>"},{"location":"troubleshooting/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>Problem: <code>ERROR: pip's dependency resolver found conflicts</code></p> <p>Solution: <pre><code># Clean install in fresh environment\nrm -rf .venv\nuv venv\nsource .venv/bin/activate\nuv pip install -r config/requirements.txt\n</code></pre></p>"},{"location":"troubleshooting/#api-key-issues","title":"API Key Issues","text":""},{"location":"troubleshooting/#missing-api-key","title":"Missing API Key","text":"<p>Problem: <code>Error: OPENAI_API_KEY not found</code></p> <p>Solution: 1. Create <code>.env</code> file in <code>config/</code> directory:    <pre><code>cd config\ncp .env.example .env\n</code></pre></p> <ol> <li> <p>Add your API key:    <pre><code>OPENAI_API_KEY=sk-...your-key-here...\n</code></pre></p> </li> <li> <p>Verify it's loaded:    <pre><code>import os\nprint(os.getenv(\"OPENAI_API_KEY\"))\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#invalid-api-key","title":"Invalid API Key","text":"<p>Problem: <code>Error: Incorrect API key provided</code></p> <p>Solution: - Verify key at https://platform.openai.com/api-keys - Ensure no extra spaces or quotes - Check API key permissions - Verify billing is active</p>"},{"location":"troubleshooting/#rate-limiting","title":"Rate Limiting","text":"<p>Problem: <code>Error: Rate limit exceeded</code></p> <p>Solution: <pre><code># Add retry logic\nimport time\n\ndef retry_query(agent, query, max_retries=3):\n    for i in range(max_retries):\n        try:\n            return agent.run(query)\n        except RateLimitError:\n            time.sleep(2 ** i)  # Exponential backoff\n    raise Exception(\"Max retries exceeded\")\n</code></pre></p>"},{"location":"troubleshooting/#database-issues","title":"Database Issues","text":""},{"location":"troubleshooting/#database-not-found","title":"Database Not Found","text":"<p>Problem: <code>Error: Database file not found: landuse_transitions.db</code></p> <p>Solution: 1. Check if database exists:    <pre><code>ls data/processed/\n</code></pre></p> <ol> <li>If missing, create it:    <pre><code>uv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre></li> </ol>"},{"location":"troubleshooting/#database-locked","title":"Database Locked","text":"<p>Problem: <code>sqlite3.OperationalError: database is locked</code></p> <p>Solution: <pre><code># Close any open connections\nconn.close()\n\n# Or use context manager\nwith sqlite3.connect('database.db') as conn:\n    # Operations here\n    pass  # Connection closes automatically\n</code></pre></p>"},{"location":"troubleshooting/#query-errors","title":"Query Errors","text":"<p>Problem: <code>Error executing query: no such column</code></p> <p>Solution: 1. Check table schema:    <pre><code>You&gt; Describe the landuse_transitions table\n</code></pre></p> <ol> <li>Verify column names:    <pre><code>-- Correct column names\nfrom_land_use (not from_landuse)\narea_1000_acres (not area)\n</code></pre></li> </ol>"},{"location":"troubleshooting/#agentlangchain-issues","title":"Agent/LangChain Issues","text":""},{"location":"troubleshooting/#agent-import-error","title":"Agent Import Error","text":"<p>Problem: <code>ImportError: cannot import name 'DataEngineeringAgent'</code></p> <p>Solution: <pre><code># Ensure you're in project root\ncd /path/to/langchain-landuse\n\n# Add to Python path\nexport PYTHONPATH=\"${PYTHONPATH}:${PWD}\"\n\n# Or in Python\nimport sys\nsys.path.append('/path/to/langchain-landuse')\n</code></pre></p>"},{"location":"troubleshooting/#tool-execution-failed","title":"Tool Execution Failed","text":"<p>Problem: <code>Error: Tool execution failed</code></p> <p>Solution: 1. Check tool parameters:    <pre><code># Ensure correct format\nparams = {\n    \"file_path\": \"data.csv\",\n    \"query\": \"SELECT * FROM data\"\n}\n</code></pre></p> <ol> <li>Verify file permissions:    <pre><code>ls -la data/\nchmod 644 data/*.csv\n</code></pre></li> </ol>"},{"location":"troubleshooting/#memorycontext-issues","title":"Memory/Context Issues","text":"<p>Problem: Agent doesn't remember previous queries</p> <p>Solution: <pre><code># Ensure using same agent instance\nagent = DataEngineeringAgent()\n\n# First query\nresult1 = agent.run(\"Show tables\")\n\n# Follow-up uses same agent\nresult2 = agent.run(\"Describe the first table\")  # Uses context\n</code></pre></p>"},{"location":"troubleshooting/#file-operation-issues","title":"File Operation Issues","text":""},{"location":"troubleshooting/#file-not-found","title":"File Not Found","text":"<p>Problem: <code>Error reading file: [Errno 2] No such file or directory</code></p> <p>Solution: 1. Check file path:    <pre><code>from pathlib import Path\n\nfile_path = Path(\"data/sample.csv\")\nif file_path.exists():\n    agent.run(f\"Read {file_path}\")\nelse:\n    print(f\"File not found: {file_path.absolute()}\")\n</code></pre></p> <ol> <li>Use correct relative path:    <pre><code>You&gt; Read data/sample.csv  # Correct\nYou&gt; Read sample.csv       # May fail if not in data/\n</code></pre></li> </ol>"},{"location":"troubleshooting/#large-file-handling","title":"Large File Handling","text":"<p>Problem: <code>MemoryError</code> when processing large files</p> <p>Solution: <pre><code># Set file size limit\nos.environ['MAX_FILE_SIZE_MB'] = '200'\n\n# Or use streaming\nagent.run(\"Convert large_file.json to database format\")\n</code></pre></p>"},{"location":"troubleshooting/#permission-denied","title":"Permission Denied","text":"<p>Problem: <code>PermissionError: [Errno 13] Permission denied</code></p> <p>Solution: <pre><code># Check permissions\nls -la data/\n\n# Fix permissions\nchmod 755 data/\nchmod 644 data/*\n\n# For write operations\nchmod 766 data/output/\n</code></pre></p>"},{"location":"troubleshooting/#query-issues","title":"Query Issues","text":""},{"location":"troubleshooting/#natural-language-not-understood","title":"Natural Language Not Understood","text":"<p>Problem: Agent doesn't understand the query</p> <p>Solution: 1. Be more specific:    <pre><code>\u274c \"Show stuff\"\n\u2705 \"Show me all tables in the landuse database\"\n</code></pre></p> <ol> <li> <p>Use keywords:    <pre><code>\u2705 \"forest\", \"urban\", \"transition\", \"scenario\"\n</code></pre></p> </li> <li> <p>Break complex queries:    <pre><code># Instead of one complex query\n# Break into steps\nagent.run(\"First, show me all scenarios\")\nagent.run(\"Now compare forest area between them\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#sql-syntax-errors","title":"SQL Syntax Errors","text":"<p>Problem: <code>Error executing query: near \"FORM\": syntax error</code></p> <p>Solution: <pre><code>-- Common SQL fixes\nFROM not FORM\nWHERE not WERE  \nSELECT not SELCT\n\n-- Use agent's natural language instead\nYou&gt; Show me forest transitions\n# Instead of writing SQL directly\n</code></pre></p>"},{"location":"troubleshooting/#no-results-returned","title":"No Results Returned","text":"<p>Problem: Query returns empty results</p> <p>Solution: 1. Check filters:    <pre><code>You&gt; Remove the WHERE clause and try again\n</code></pre></p> <ol> <li> <p>Verify data exists:    <pre><code>You&gt; Count total rows in the table\n</code></pre></p> </li> <li> <p>Check case sensitivity:    <pre><code>-- Land use values are capitalized\nWHERE from_land_use = 'Forest'  -- Correct\nWHERE from_land_use = 'forest'  -- Wrong\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"troubleshooting/#slow-queries","title":"Slow Queries","text":"<p>Problem: Queries take too long to execute</p> <p>Solution: 1. Add LIMIT:    <pre><code>You&gt; Show me the first 100 forest transitions\n</code></pre></p> <ol> <li> <p>Use indexed columns:    <pre><code>You&gt; Filter by scenario, year, and fips first\n</code></pre></p> </li> <li> <p>Use filtered views:    <pre><code>You&gt; Query landuse_changes_only instead of landuse_transitions\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#memory-usage","title":"Memory Usage","text":"<p>Problem: High memory usage during processing</p> <p>Solution: <pre><code># Monitor memory\nimport psutil\n\nprocess = psutil.Process()\nprint(f\"Memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n\n# Clear large objects\ndel large_dataframe\nimport gc\ngc.collect()\n</code></pre></p>"},{"location":"troubleshooting/#environment-issues","title":"Environment Issues","text":""},{"location":"troubleshooting/#mkdocs-port-already-in-use","title":"MkDocs Port Already in Use","text":"<p>Problem: <code>OSError: [Errno 48] Address already in use</code></p> <p>Solution: <pre><code># Find process using port\nlsof -i :8000\n\n# Kill process\nkill -9 &lt;PID&gt;\n\n# Or use different port\nmkdocs serve -a localhost:8001\n</code></pre></p>"},{"location":"troubleshooting/#virtual-environment-not-activated","title":"Virtual Environment Not Activated","text":"<p>Problem: Packages not found despite installation</p> <p>Solution: <pre><code># Check if in virtual environment\nwhich python\n# Should show .venv/bin/python\n\n# Activate if needed\nsource .venv/bin/activate\n\n# Verify activation\necho $VIRTUAL_ENV\n</code></pre></p>"},{"location":"troubleshooting/#common-error-messages","title":"Common Error Messages","text":""},{"location":"troubleshooting/#error-reference-table","title":"Error Reference Table","text":"Error Message Likely Cause Quick Fix <code>KeyError: 'OPENAI_API_KEY'</code> Missing API key Add to .env file <code>FileNotFoundError</code> Wrong file path Check path exists <code>sqlite3.OperationalError</code> Database issue Check DB exists <code>JSONDecodeError</code> Invalid JSON Validate JSON format <code>AttributeError</code> Wrong method name Check API docs <code>ConnectionError</code> Network issue Check internet <code>TimeoutError</code> Slow operation Increase timeout"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"troubleshooting/#debugging-steps","title":"Debugging Steps","text":"<ol> <li> <p>Enable verbose output: <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre></p> </li> <li> <p>Check agent state: <pre><code>print(f\"Root dir: {agent.root_dir}\")\nprint(f\"Tools: {[t.name for t in agent.tools]}\")\n</code></pre></p> </li> <li> <p>Test components individually: <pre><code># Test file reading\nresult = agent._read_csv(\"test.csv\")\n\n# Test database connection\nimport sqlite3\nconn = sqlite3.connect(\"test.db\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#resources","title":"Resources","text":"<ul> <li>GitHub Issues: Report bugs and get help</li> <li>Documentation: Check docs for examples</li> <li>Community: Discord/Slack channels</li> <li>Stack Overflow: Tag with <code>langchain</code></li> </ul>"},{"location":"troubleshooting/#creating-bug-reports","title":"Creating Bug Reports","text":"<p>Include: 1. Python version 2. Package versions (<code>pip freeze</code>) 3. Error message and traceback 4. Minimal code to reproduce 5. Expected vs actual behavior</p> <p>Example: <pre><code>**Environment:**\n- Python 3.11.0\n- langchain==0.3.0\n- OS: macOS 14.0\n\n**Error:**\n</code></pre> FileNotFoundError: data.csv <pre><code>**Code to reproduce:**\n```python\nagent = DataEngineeringAgent()\nagent.run(\"Read data.csv\")\n</code></pre></p> <p>Expected: File should be read Actual: Error thrown ```</p>"},{"location":"api/agent/","title":"SQL Query Agents API","text":"<p>Complete API reference for our specialized SQL agents and their natural language interfaces.</p>"},{"location":"api/agent/#overview","title":"Overview","text":"<p>We provide two specialized agents for different data analysis needs:</p>"},{"location":"api/agent/#landuse-natural-language-query-agent","title":"\ud83c\udf3e Landuse Natural Language Query Agent","text":"<p>Specialized for landuse transition analysis - converts natural language questions into optimized DuckDB SQL queries.</p> <p>\ud83d\udcd6 Complete Documentation \u2192</p> <pre><code>from scripts.agents.landuse_query_agent import LanduseQueryAgent\n\n# Initialize the specialized landuse agent\nagent = LanduseQueryAgent()\n\n# Ask natural language questions\nresult = agent.query(\"Which scenarios show the most agricultural land loss?\")\n</code></pre>"},{"location":"api/agent/#general-sql-query-agent","title":"\ud83d\udd0d General SQL Query Agent","text":"<p>Multi-database support for SQLite, DuckDB, CSV, JSON, and Parquet files.</p> <pre><code>from scripts.agents.sql_query_agent import SQLQueryAgent\n\n# Initialize the general SQL agent\nagent = SQLQueryAgent(root_dir=\"./data\")\n\n# Run SQL queries on various data sources\nresult = agent.run(\"Show me the tables in landuse_transitions.db\")\n</code></pre>"},{"location":"api/agent/#general-sql-query-agent-legacy","title":"General SQL Query Agent (Legacy)","text":"<p>The <code>SQLQueryAgent</code> is the original component that interprets natural language queries and performs data operations on various databases and files.</p> <pre><code>from scripts.agents.data_engineering_agent import DataEngineeringAgent\n\n# Initialize the agent\nagent = DataEngineeringAgent(root_dir=\"./data\")\n\n# Run a query\nresult = agent.run(\"Show me the tables in landuse_transitions.db\")\n</code></pre>"},{"location":"api/agent/#class-dataengineeringagent","title":"Class: DataEngineeringAgent","text":""},{"location":"api/agent/#constructor","title":"Constructor","text":"<pre><code>DataEngineeringAgent(root_dir: str = None)\n</code></pre> <p>Parameters: - <code>root_dir</code> (str, optional): Root directory for file operations. Defaults to <code>PROJECT_ROOT_DIR</code> from environment or <code>\"./data\"</code></p> <p>Example: <pre><code># Use default directory\nagent = DataEngineeringAgent()\n\n# Specify custom directory\nagent = DataEngineeringAgent(root_dir=\"/path/to/data\")\n</code></pre></p>"},{"location":"api/agent/#methods","title":"Methods","text":""},{"location":"api/agent/#runquery-str-str","title":"run(query: str) -&gt; str","text":"<p>Execute a natural language query and return results.</p> <p>Parameters: - <code>query</code> (str): Natural language query to execute</p> <p>Returns: - <code>str</code>: Query results formatted as text</p> <p>Example: <pre><code>result = agent.run(\"What are the top 5 counties by urban growth?\")\nprint(result)\n</code></pre></p>"},{"location":"api/agent/#chat","title":"chat()","text":"<p>Start an interactive chat session with rich terminal formatting.</p> <p>Example: <pre><code># Start interactive mode\nagent.chat()\n# Type 'exit' to quit\n</code></pre></p>"},{"location":"api/agent/#available-tools","title":"Available Tools","text":"<p>The agent has access to numerous tools for data operations:</p>"},{"location":"api/agent/#file-management-tools","title":"File Management Tools","text":"Tool Description Example Query <code>list_files</code> List files in directory \"Show me all files in the data folder\" <code>read_file</code> Read file contents \"Read the README file\" <code>write_file</code> Create/update files \"Save these results to output.txt\" <code>copy_file</code> Copy files \"Copy the database to backup folder\""},{"location":"api/agent/#data-analysis-tools","title":"Data Analysis Tools","text":"Tool Description Example Query <code>read_csv</code> Load CSV files \"Analyze the sample_data.csv file\" <code>read_parquet</code> Load Parquet files \"Show me the sensor_data.parquet contents\" <code>analyze_dataframe</code> Get detailed statistics \"Analyze the land use data in detail\" <code>query_data</code> SQL queries on files \"Query the CSV: SELECT * FROM data WHERE value &gt; 100\""},{"location":"api/agent/#database-tools","title":"Database Tools","text":"Tool Description Example Query <code>list_database_tables</code> Show all tables \"What tables are in the database?\" <code>describe_database_table</code> Get schema info \"Describe the landuse_transitions table\" <code>query_database</code> Execute SQL \"Query the database: SELECT COUNT(*) FROM transitions\" <code>export_database_table</code> Export to file \"Export the results to CSV\""},{"location":"api/agent/#transformation-tools","title":"Transformation Tools","text":"Tool Description Example Query <code>transform_data</code> Convert formats \"Convert the JSON file to Parquet\" <code>optimize_storage</code> Suggest optimal format \"What's the best format for this data?\" <code>json_to_database</code> Convert large JSON \"Convert the JSON to a SQLite database\""},{"location":"api/agent/#query-patterns","title":"Query Patterns","text":""},{"location":"api/agent/#basic-information-queries","title":"Basic Information Queries","text":"<pre><code># List available data\nagent.run(\"Show me all data files\")\n\n# Get table information  \nagent.run(\"What tables are in landuse_transitions.db?\")\n\n# View sample data\nagent.run(\"Show me 5 rows from the landuse_transitions table\")\n</code></pre>"},{"location":"api/agent/#analysis-queries","title":"Analysis Queries","text":"<pre><code># Aggregations\nagent.run(\"What's the total urban area in 2050?\")\n\n# Comparisons\nagent.run(\"Compare forest area between scenarios\")\n\n# Trends\nagent.run(\"Show me urban growth trends by decade\")\n</code></pre>"},{"location":"api/agent/#complex-queries","title":"Complex Queries","text":"<pre><code># Multi-step analysis\nagent.run(\"\"\"\nFind counties with the most forest loss, \nthen show what that forest is converting to\n\"\"\")\n\n# Custom calculations\nagent.run(\"\"\"\nCalculate the percentage of land that changes use \nvs stays the same for each scenario\n\"\"\")\n</code></pre>"},{"location":"api/agent/#response-format","title":"Response Format","text":"<p>The agent returns responses in a structured format:</p> <pre><code>Query: [Generated SQL or operation]\nResults: [Number of rows]\n\n[Formatted data table or results]\n\n[Additional context or explanations]\n</code></pre>"},{"location":"api/agent/#error-handling","title":"Error Handling","text":"<p>The agent handles various error conditions gracefully:</p> <pre><code># File not found\nresult = agent.run(\"Read nonexistent.csv\")\n# Returns: \"Error reading CSV: [Errno 2] No such file or directory\"\n\n# Invalid SQL\nresult = agent.run(\"Query with invalid SQL syntax\")\n# Returns: \"Error executing query: [SQL error details]\"\n\n# Type mismatches\nresult = agent.run(\"Calculate the average of text columns\")\n# Returns: \"No numeric columns found for calculation\"\n</code></pre>"},{"location":"api/agent/#memory-and-context","title":"Memory and Context","text":"<p>The agent maintains conversation context:</p> <pre><code># First query establishes context\nagent.run(\"Show me counties in California\")\n\n# Follow-up query uses context\nagent.run(\"Now show me just the ones with high urban growth\")\n# Agent remembers we're looking at California counties\n</code></pre>"},{"location":"api/agent/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/agent/#query-optimization","title":"Query Optimization","text":"<p>The agent automatically optimizes queries: - Adds appropriate LIMIT clauses - Uses indexes when available - Filters early in query execution</p>"},{"location":"api/agent/#large-file-handling","title":"Large File Handling","text":"<p>For files over <code>MAX_FILE_SIZE_MB</code>: - Automatic sampling for preview - Streaming processing for conversions - Progress indicators for long operations</p>"},{"location":"api/agent/#configuration","title":"Configuration","text":"<p>The agent respects environment variables:</p> <pre><code>import os\n\n# Set configuration\nos.environ['AGENT_MODEL'] = 'gpt-4-turbo-preview'\nos.environ['TEMPERATURE'] = '0.1'\nos.environ['MAX_TOKENS'] = '4000'\n\n# Initialize with configuration\nagent = DataEngineeringAgent()\n</code></pre>"},{"location":"api/agent/#integration-examples","title":"Integration Examples","text":""},{"location":"api/agent/#programmatic-usage","title":"Programmatic Usage","text":"<pre><code># Batch processing\nqueries = [\n    \"List all tables\",\n    \"Count total records\",\n    \"Show summary statistics\"\n]\n\nresults = {}\nfor query in queries:\n    results[query] = agent.run(query)\n</code></pre>"},{"location":"api/agent/#pipeline-integration","title":"Pipeline Integration","text":"<pre><code># Data processing pipeline\ndef analyze_county(fips_code):\n    agent = DataEngineeringAgent()\n\n    # Get county profile\n    profile = agent.run(f\"Show land use for FIPS {fips_code}\")\n\n    # Calculate changes\n    changes = agent.run(f\"Calculate land use changes for FIPS {fips_code}\")\n\n    # Export results\n    agent.run(f\"Export analysis for FIPS {fips_code} to CSV\")\n\n    return profile, changes\n</code></pre>"},{"location":"api/agent/#web-service-integration","title":"Web Service Integration","text":"<pre><code>from flask import Flask, request, jsonify\n\napp = Flask(__name__)\nagent = DataEngineeringAgent()\n\n@app.route('/query', methods=['POST'])\ndef query():\n    user_query = request.json.get('query')\n    result = agent.run(user_query)\n    return jsonify({'result': result})\n</code></pre>"},{"location":"api/agent/#advanced-features","title":"Advanced Features","text":""},{"location":"api/agent/#custom-tools","title":"Custom Tools","text":"<p>Add custom analysis tools:</p> <pre><code>class CustomAgent(DataEngineeringAgent):\n    def _create_tools(self):\n        tools = super()._create_tools()\n\n        # Add custom tool\n        tools.append(Tool(\n            name=\"custom_metric\",\n            func=self._calculate_custom_metric,\n            description=\"Calculate custom sustainability metric\"\n        ))\n\n        return tools\n\n    def _calculate_custom_metric(self, params):\n        # Custom implementation\n        pass\n</code></pre>"},{"location":"api/agent/#extending-functionality","title":"Extending Functionality","text":"<pre><code># Add visualization capabilities\nagent.run(\"Create a chart showing urban growth trends\")\n\n# Add geographic analysis\nagent.run(\"Show me a map of land use changes\")\n\n# Add statistical modeling\nagent.run(\"Predict future land use based on trends\")\n</code></pre>"},{"location":"api/agent/#best-practices","title":"Best Practices","text":"<ol> <li>Clear Queries: Be specific about what you want</li> <li>Iterative Refinement: Start broad, then narrow down</li> <li>Use Context: Leverage the agent's memory for complex analyses</li> <li>Error Recovery: Check for errors and refine queries as needed</li> <li>Performance: Use appropriate limits and filters for large datasets</li> </ol>"},{"location":"api/agent/#next-steps","title":"Next Steps","text":"<ul> <li>See Query Examples for more patterns</li> <li>Review Converters API for data processing</li> <li>Check Tools Reference for detailed tool documentation</li> </ul>"},{"location":"api/converters/","title":"Converters API Reference","text":"<p>Documentation for the data conversion scripts that transform raw JSON data into queryable SQLite databases.</p>"},{"location":"api/converters/#overview","title":"Overview","text":"<p>The converters module contains scripts for processing land use projection data:</p> <pre><code>scripts/converters/\n\u251c\u2500\u2500 convert_json_to_parquet.py\n\u251c\u2500\u2500 convert_landuse_to_db.py\n\u251c\u2500\u2500 convert_landuse_transitions.py\n\u251c\u2500\u2500 convert_landuse_with_agriculture.py\n\u251c\u2500\u2500 convert_landuse_nested.py\n\u2514\u2500\u2500 add_change_views.py\n</code></pre>"},{"location":"api/converters/#core-converters","title":"Core Converters","text":""},{"location":"api/converters/#convert_landuse_to_dbpy","title":"convert_landuse_to_db.py","text":"<p>Converts raw JSON land use projections to SQLite database format.</p> <pre><code># Basic usage\nuv run python scripts/converters/convert_landuse_to_db.py\n</code></pre> <p>Key Functions:</p> <pre><code>def process_matrix_data(matrix_data, scenario, year, year_range, fips):\n    \"\"\"Convert transition matrix to normalized records.\n\n    Args:\n        matrix_data: List of transition matrix rows\n        scenario: Scenario name (e.g., 'Baseline')\n        year: End year of transition period\n        year_range: Period string (e.g., '2020-2030')\n        fips: County FIPS code\n\n    Returns:\n        List of transition dictionaries\n    \"\"\"\n</code></pre> <p>Output: - Creates <code>landuse_transitions.db</code> - Table: <code>landuse_transitions</code> - ~1.2 million transition records</p>"},{"location":"api/converters/#convert_landuse_with_agriculturepy","title":"convert_landuse_with_agriculture.py","text":"<p>Enhanced converter that includes agricultural aggregation views.</p> <pre><code># Usage with agricultural aggregation\nuv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre> <p>Features: - Creates base transition table - Adds agricultural aggregation (Crop + Pasture) - Creates filtered views (changes only) - Adds performance indexes</p> <p>Output Tables: 1. <code>landuse_transitions</code> - All transitions 2. <code>landuse_transitions_ag</code> - With agricultural aggregation 3. <code>landuse_changes_only</code> - Excluding same-to-same 4. <code>landuse_changes_only_ag</code> - Changes with ag aggregation</p>"},{"location":"api/converters/#add_change_viewspy","title":"add_change_views.py","text":"<p>Adds filtered views to existing database.</p> <pre><code># Add views to existing database\nuv run python scripts/converters/add_change_views.py\n</code></pre> <p>Creates Views: <pre><code>-- Changes only view\nCREATE VIEW landuse_changes_only AS\nSELECT * FROM landuse_transitions\nWHERE from_land_use != to_land_use\n  AND from_land_use != 'Total'\n  AND to_land_use != 'Total';\n</code></pre></p>"},{"location":"api/converters/#utility-functions","title":"Utility Functions","text":""},{"location":"api/converters/#land-use-mapping","title":"Land Use Mapping","text":"<pre><code>LAND_USE_MAP = {\n    'cr': 'Crop',\n    'ps': 'Pasture',\n    'rg': 'Range',\n    'fr': 'Forest',\n    'ur': 'Urban',\n    't1': 'Total',  # Row sum\n    't2': 'Total'   # Column sum\n}\n</code></pre>"},{"location":"api/converters/#year-extraction","title":"Year Extraction","text":"<pre><code>def extract_end_year(year_range):\n    \"\"\"Extract end year from range string.\n\n    Args:\n        year_range: String like '2020-2030'\n\n    Returns:\n        int: End year (2030)\n    \"\"\"\n    return int(year_range.split('-')[1])\n</code></pre>"},{"location":"api/converters/#value-conversion","title":"Value Conversion","text":"<pre><code>def convert_value(value):\n    \"\"\"Convert Decimal/numeric to float.\n\n    Handles various numeric types safely.\n    \"\"\"\n    if isinstance(value, Decimal):\n        return float(value)\n    return float(value) if value is not None else 0.0\n</code></pre>"},{"location":"api/converters/#processing-large-files","title":"Processing Large Files","text":""},{"location":"api/converters/#streaming-json-processing","title":"Streaming JSON Processing","text":"<p>For large JSON files, use streaming:</p> <pre><code>import ijson\n\ndef process_large_json(json_path):\n    \"\"\"Stream process large JSON files.\"\"\"\n    with open(json_path, 'rb') as file:\n        parser = ijson.items(file, 'item')\n\n        batch = []\n        for item in parser:\n            batch.append(process_item(item))\n\n            if len(batch) &gt;= 10000:\n                insert_batch(batch)\n                batch = []\n</code></pre>"},{"location":"api/converters/#progress-tracking","title":"Progress Tracking","text":"<p>Using Rich for progress display:</p> <pre><code>from rich.progress import Progress\n\nwith Progress() as progress:\n    task = progress.add_task(\"Converting...\", total=county_count)\n\n    for county in counties:\n        process_county(county)\n        progress.update(task, advance=1)\n</code></pre>"},{"location":"api/converters/#database-schema-creation","title":"Database Schema Creation","text":""},{"location":"api/converters/#main-table","title":"Main Table","text":"<pre><code>CREATE TABLE landuse_transitions (\n    scenario TEXT NOT NULL,\n    year INTEGER NOT NULL,\n    year_range TEXT NOT NULL,\n    fips TEXT NOT NULL,\n    from_land_use TEXT NOT NULL,\n    to_land_use TEXT NOT NULL,\n    area_1000_acres REAL\n);\n</code></pre>"},{"location":"api/converters/#indexes","title":"Indexes","text":"<pre><code>-- Performance indexes\nCREATE INDEX idx_scenario ON landuse_transitions(scenario);\nCREATE INDEX idx_year ON landuse_transitions(year);\nCREATE INDEX idx_fips ON landuse_transitions(fips);\nCREATE INDEX idx_from_to ON landuse_transitions(from_land_use, to_land_use);\n</code></pre>"},{"location":"api/converters/#error-handling","title":"Error Handling","text":""},{"location":"api/converters/#validation","title":"Validation","text":"<pre><code>def validate_transitions(transitions, fips, year):\n    \"\"\"Validate data integrity.\"\"\"\n    # Check total area consistency\n    total_from = sum(t['area'] for t in transitions if t['from'] != 'Total')\n    total_to = sum(t['area'] for t in transitions if t['to'] != 'Total')\n\n    if abs(total_from - total_to) &gt; 0.01:\n        raise ValueError(f\"Area mismatch for {fips} in {year}\")\n</code></pre>"},{"location":"api/converters/#error-recovery","title":"Error Recovery","text":"<pre><code>try:\n    process_county(county_data)\nexcept Exception as e:\n    logger.error(f\"Error processing {county_id}: {e}\")\n    failed_counties.append(county_id)\n    continue\n</code></pre>"},{"location":"api/converters/#custom-converters","title":"Custom Converters","text":""},{"location":"api/converters/#creating-custom-aggregations","title":"Creating Custom Aggregations","text":"<pre><code>def create_custom_aggregation(db_path, aggregation_map):\n    \"\"\"Create custom land use aggregations.\n\n    Args:\n        db_path: Database file path\n        aggregation_map: Dict mapping original to new categories\n    \"\"\"\n    conn = sqlite3.connect(db_path)\n\n    # Example: Urban + Infrastructure\n    aggregation_map = {\n        'Urban': 'Developed',\n        'Infrastructure': 'Developed',\n        'Forest': 'Natural',\n        'Range': 'Natural'\n    }\n</code></pre>"},{"location":"api/converters/#adding-calculated-fields","title":"Adding Calculated Fields","text":"<pre><code>def add_calculated_fields(db_path):\n    \"\"\"Add derived columns to database.\"\"\"\n    conn = sqlite3.connect(db_path)\n\n    # Add percentage column\n    conn.execute(\"\"\"\n        ALTER TABLE landuse_transitions \n        ADD COLUMN percent_of_county REAL\n    \"\"\")\n\n    # Calculate percentages\n    conn.execute(\"\"\"\n        UPDATE landuse_transitions\n        SET percent_of_county = \n            area_1000_acres / (\n                SELECT SUM(area_1000_acres) \n                FROM landuse_transitions t2 \n                WHERE t2.fips = landuse_transitions.fips\n                  AND t2.year = landuse_transitions.year\n            ) * 100\n    \"\"\")\n</code></pre>"},{"location":"api/converters/#performance-optimization","title":"Performance Optimization","text":""},{"location":"api/converters/#batch-operations","title":"Batch Operations","text":"<pre><code># Batch inserts\nconn.executemany(\n    \"INSERT INTO landuse_transitions VALUES (?,?,?,?,?,?,?)\",\n    batch_data\n)\n\n# Transaction wrapping\nconn.execute(\"BEGIN TRANSACTION\")\n# ... bulk operations ...\nconn.execute(\"COMMIT\")\n</code></pre>"},{"location":"api/converters/#memory-management","title":"Memory Management","text":"<pre><code># Process in chunks\nCHUNK_SIZE = 50000\n\nfor i in range(0, len(data), CHUNK_SIZE):\n    chunk = data[i:i + CHUNK_SIZE]\n    process_chunk(chunk)\n\n    # Explicit garbage collection if needed\n    if i % (CHUNK_SIZE * 10) == 0:\n        import gc\n        gc.collect()\n</code></pre>"},{"location":"api/converters/#usage-examples","title":"Usage Examples","text":""},{"location":"api/converters/#basic-conversion","title":"Basic Conversion","text":"<pre><code># Convert JSON to database\nuv run python scripts/converters/convert_landuse_to_db.py\n\n# Output\nProcessing county_landuse_projections_RPA.json...\nCreated 1,234,567 transition records\nDatabase saved to: landuse_transitions.db\n</code></pre>"},{"location":"api/converters/#full-pipeline","title":"Full Pipeline","text":"<pre><code># Complete processing pipeline\n# 1. Basic conversion\nuv run python scripts/converters/convert_landuse_to_db.py\n\n# 2. Add agricultural aggregation\nuv run python scripts/converters/convert_landuse_with_agriculture.py\n\n# 3. Add filtered views\nuv run python scripts/converters/add_change_views.py\n</code></pre>"},{"location":"api/converters/#custom-processing","title":"Custom Processing","text":"<pre><code>from scripts.converters.convert_landuse_to_db import process_matrix_data\n\n# Custom processing example\ndef process_custom_scenario(json_data, scenario_name):\n    \"\"\"Process only specific scenario.\"\"\"\n    transitions = []\n\n    for county in json_data:\n        if scenario_name in county['scenarios']:\n            scenario_data = county['scenarios'][scenario_name]\n            # Process this scenario\n\n    return transitions\n</code></pre>"},{"location":"api/converters/#next-steps","title":"Next Steps","text":"<ul> <li>See Data Processing for detailed pipeline</li> <li>Check Database Schema for table structure</li> <li>Review Agent API for querying converted data</li> </ul>"},{"location":"api/landuse-query-agent/","title":"Landuse Natural Language Query Agent","text":""},{"location":"api/landuse-query-agent/#overview","title":"Overview","text":"<p>The Landuse Natural Language Query Agent is a specialized AI-powered tool that converts natural language questions into optimized DuckDB SQL queries for analyzing landuse transition data. This agent understands the star schema structure of your landuse database and can generate complex analytical queries from simple English questions.</p>"},{"location":"api/landuse-query-agent/#features","title":"Features","text":""},{"location":"api/landuse-query-agent/#natural-language-processing","title":"\ud83e\udd16 Natural Language Processing","text":"<ul> <li>Converts English questions to SQL queries</li> <li>Understands landuse domain terminology</li> <li>Handles complex analytical requirements</li> <li>Provides business context for results</li> </ul>"},{"location":"api/landuse-query-agent/#duckdb-optimization","title":"\ud83e\udd86 DuckDB Optimization","text":"<ul> <li>Generates efficient star schema joins</li> <li>Uses appropriate aggregations and filters</li> <li>Includes performance optimizations</li> <li>Leverages DuckDB's analytical capabilities</li> </ul>"},{"location":"api/landuse-query-agent/#rich-analytics","title":"\ud83d\udcca Rich Analytics","text":"<ul> <li>Automatic summary statistics</li> <li>Formatted result tables</li> <li>Business interpretation of findings</li> <li>Suggested follow-up analyses</li> </ul>"},{"location":"api/landuse-query-agent/#beautiful-interface","title":"\ud83c\udfa8 Beautiful Interface","text":"<ul> <li>Rich terminal interface with colors</li> <li>Markdown-formatted responses</li> <li>Interactive chat mode</li> <li>Example queries and help system</li> </ul>"},{"location":"api/landuse-query-agent/#quick-start","title":"Quick Start","text":""},{"location":"api/landuse-query-agent/#basic-usage","title":"Basic Usage","text":"<pre><code># Interactive chat mode\nuv run python scripts/agents/landuse_query_agent.py\n\n# Test with sample queries\nuv run python scripts/agents/test_landuse_agent.py\n</code></pre>"},{"location":"api/landuse-query-agent/#programmatic-usage","title":"Programmatic Usage","text":"<pre><code>from scripts.agents.landuse_query_agent import LanduseQueryAgent\n\n# Initialize agent\nagent = LanduseQueryAgent()\n\n# Ask natural language questions\nresponse = agent.query(\"Which scenarios show the most agricultural land loss?\")\nprint(response)\n</code></pre>"},{"location":"api/landuse-query-agent/#example-queries","title":"Example Queries","text":""},{"location":"api/landuse-query-agent/#agricultural-analysis","title":"\ud83c\udf3e Agricultural Analysis","text":"<p>Question: \"Which scenarios show the most agricultural land loss?\"</p> <p>Generated SQL: <pre><code>SELECT \n    s.scenario_name,\n    SUM(f.acres) as acres_lost\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_category = 'Agriculture' \n  AND tl.landuse_category != 'Agriculture'\n  AND f.transition_type = 'change'\nGROUP BY s.scenario_name\nORDER BY acres_lost DESC;\n</code></pre></p> <p>Question: \"How much farmland is being converted to urban areas?\"</p> <p>Generated SQL: <pre><code>SELECT \n    fl.landuse_name as from_landuse,\n    SUM(f.acres) as acres_urbanized,\n    COUNT(*) as transition_count\nFROM fact_landuse_transitions f\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_category = 'Agriculture'\n  AND tl.landuse_name = 'Urban'\n  AND f.transition_type = 'change'\nGROUP BY fl.landuse_name\nORDER BY acres_urbanized DESC;\n</code></pre></p>"},{"location":"api/landuse-query-agent/#climate-environment","title":"\ud83c\udf0d Climate &amp; Environment","text":"<p>Question: \"Compare forest loss between RCP45 and RCP85 scenarios\"</p> <p>Generated SQL: <pre><code>SELECT \n    s.rcp_scenario,\n    tl.landuse_name as to_landuse,\n    SUM(f.acres) as forest_lost\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_name = 'Forest'\n  AND tl.landuse_name != 'Forest'\n  AND s.rcp_scenario IN ('rcp45', 'rcp85')\n  AND f.transition_type = 'change'\nGROUP BY s.rcp_scenario, tl.landuse_name\nORDER BY forest_lost DESC;\n</code></pre></p>"},{"location":"api/landuse-query-agent/#geographic-patterns","title":"\ud83c\udfd8\ufe0f Geographic Patterns","text":"<p>Question: \"Which states have the most urban expansion?\"</p> <p>Generated SQL: <pre><code>SELECT \n    g.state_code,\n    fl.landuse_name as from_landuse,\n    SUM(f.acres) as acres_urbanized\nFROM fact_landuse_transitions f\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE tl.landuse_name = 'Urban'\n  AND f.transition_type = 'change'\nGROUP BY g.state_code, fl.landuse_name\nORDER BY acres_urbanized DESC;\n</code></pre></p>"},{"location":"api/landuse-query-agent/#scenario-analysis","title":"\ud83c\udf21\ufe0f Scenario Analysis","text":"<p>Question: \"Compare SSP1 vs SSP5 development patterns\"</p> <p>Generated SQL: <pre><code>SELECT \n    s.ssp_scenario,\n    fl.landuse_name as from_landuse,\n    tl.landuse_name as to_landuse,\n    SUM(f.acres) as total_acres,\n    COUNT(*) as transition_count\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE s.ssp_scenario IN ('ssp1', 'ssp5')\n  AND f.transition_type = 'change'\nGROUP BY s.ssp_scenario, fl.landuse_name, tl.landuse_name\nORDER BY total_acres DESC;\n</code></pre></p>"},{"location":"api/landuse-query-agent/#interactive-commands","title":"Interactive Commands","text":""},{"location":"api/landuse-query-agent/#chat-mode-commands","title":"Chat Mode Commands","text":"<ul> <li><code>help</code>: Show example questions</li> <li><code>schema</code>: Display database schema information</li> <li><code>exit</code>: Quit the agent</li> </ul>"},{"location":"api/landuse-query-agent/#example-session","title":"Example Session","text":"<pre><code>\ud83c\udf3e Ask&gt; Which scenarios show the most agricultural land loss?\n\n\ud83e\udd16 Converting to SQL and executing...\n\n\ud83d\udd0d Analysis Results\n\ud83e\udd86 DuckDB Query Results (20 rows)\nSQL: SELECT s.scenario_name, SUM(f.acres) as acres_lost ...\n\nResults:\nscenario_name                    acres_lost\nCNRM_CM5_rcp85_ssp5             2648344.3885\nMRI_CGCM3_rcp85_ssp5            2643260.7336\n...\n\n\ud83d\udcca Summary Statistics:\n       acres_lost\ncount    20.000000\nmean     2500000.00\nstd      150000.00\n...\n\n\ud83c\udf3e Ask&gt; Show me which states are losing the most farmland\n\n\ud83e\udd16 Converting to SQL and executing...\n</code></pre>"},{"location":"api/landuse-query-agent/#architecture","title":"Architecture","text":""},{"location":"api/landuse-query-agent/#core-components","title":"Core Components","text":"<ol> <li>LanduseQueryAgent: Main agent class</li> <li>Schema Information: Dynamic database schema discovery</li> <li>Natural Language Processing: GPT-4 powered query understanding</li> <li>SQL Generation: Star schema optimized query creation</li> <li>Result Formatting: Rich terminal output with statistics</li> </ol>"},{"location":"api/landuse-query-agent/#agent-tools","title":"Agent Tools","text":"<ul> <li><code>execute_landuse_query</code>: Execute SQL on DuckDB</li> <li><code>get_schema_info</code>: Retrieve database schema</li> <li><code>suggest_query_examples</code>: Show example queries</li> <li><code>explain_query_results</code>: Interpret results in business context</li> </ul>"},{"location":"api/landuse-query-agent/#prompt-engineering","title":"Prompt Engineering","text":"<p>The agent uses a specialized prompt that includes: - Database schema information - Common query patterns - Business context understanding - SQL optimization guidelines</p>"},{"location":"api/landuse-query-agent/#advanced-features","title":"Advanced Features","text":""},{"location":"api/landuse-query-agent/#automatic-query-optimization","title":"Automatic Query Optimization","text":"<ul> <li>Adds LIMIT clauses for safety</li> <li>Uses efficient star schema joins</li> <li>Includes appropriate indexes</li> <li>Optimizes for DuckDB's columnar storage</li> </ul>"},{"location":"api/landuse-query-agent/#business-context","title":"Business Context","text":"<ul> <li>Interprets agricultural vs environmental impacts</li> <li>Explains climate scenario differences</li> <li>Provides geographic context</li> <li>Suggests follow-up analyses</li> </ul>"},{"location":"api/landuse-query-agent/#error-handling","title":"Error Handling","text":"<ul> <li>Graceful SQL error recovery</li> <li>Helpful error messages</li> <li>Query suggestion on failures</li> <li>Database connection management</li> </ul>"},{"location":"api/landuse-query-agent/#configuration","title":"Configuration","text":""},{"location":"api/landuse-query-agent/#environment-variables","title":"Environment Variables","text":"<pre><code># Required: OpenAI API key\nOPENAI_API_KEY=your_api_key_here\n\n# Optional: Custom database path\nLANDUSE_DB_PATH=data/processed/landuse_analytics.duckdb\n</code></pre>"},{"location":"api/landuse-query-agent/#customization","title":"Customization","text":"<pre><code># Custom database path\nagent = LanduseQueryAgent(db_path=\"custom/path/to/database.duckdb\")\n\n# Custom LLM settings\nagent.llm = ChatOpenAI(\n    model=\"gpt-4-turbo-preview\",\n    temperature=0.1,\n    max_tokens=2000\n)\n</code></pre>"},{"location":"api/landuse-query-agent/#performance","title":"Performance","text":""},{"location":"api/landuse-query-agent/#query-speed","title":"Query Speed","text":"<ul> <li>Simple queries: &lt; 1 second</li> <li>Complex aggregations: 1-5 seconds</li> <li>Large result sets: 5-15 seconds</li> </ul>"},{"location":"api/landuse-query-agent/#accuracy","title":"Accuracy","text":"<ul> <li>Schema understanding: 95%+ accuracy</li> <li>Query generation: 90%+ correct SQL</li> <li>Business interpretation: High contextual relevance</li> </ul>"},{"location":"api/landuse-query-agent/#best-practices","title":"Best Practices","text":""},{"location":"api/landuse-query-agent/#question-formatting","title":"Question Formatting","text":"<ul> <li>Good: \"Which scenarios show the most agricultural land loss?\"</li> <li>Good: \"Compare forest loss between RCP45 and RCP85\"</li> <li>Avoid: \"Show me data\" (too vague)</li> <li>Avoid: \"SQL query for transitions\" (ask for insights, not SQL)</li> </ul>"},{"location":"api/landuse-query-agent/#analysis-workflow","title":"Analysis Workflow","text":"<ol> <li>Start with broad questions about scenarios or states</li> <li>Drill down into specific land use transitions</li> <li>Compare across time periods or geographies</li> <li>Use follow-up questions to explore patterns</li> </ol>"},{"location":"api/landuse-query-agent/#performance-tips","title":"Performance Tips","text":"<ul> <li>Ask for top N results rather than all data</li> <li>Specify time periods or geographies to filter results</li> <li>Use aggregated views for summary statistics</li> </ul>"},{"location":"api/landuse-query-agent/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api/landuse-query-agent/#common-issues","title":"Common Issues","text":"<p>\"Database file not found\" - Ensure the DuckDB database has been created - Check the database path configuration</p> <p>\"No results returned\" - Try broader queries first - Check if filters are too restrictive - Verify scenario or geography names</p> <p>\"SQL Error\" - The agent will suggest corrections - Try rephrasing the question - Use the <code>help</code> command for examples</p>"},{"location":"api/landuse-query-agent/#getting-help","title":"Getting Help","text":"<ul> <li>Use <code>help</code> command for examples</li> <li>Use <code>schema</code> command to understand data structure</li> <li>Check the test script for working examples</li> <li>Review the generated SQL for understanding</li> </ul>"},{"location":"api/landuse-query-agent/#integration","title":"Integration","text":""},{"location":"api/landuse-query-agent/#with-other-tools","title":"With Other Tools","text":"<pre><code># Use with visualization libraries\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nagent = LanduseQueryAgent()\nresponse = agent.query(\"Agricultural land loss by scenario\")\n# Parse response and create visualizations\n</code></pre>"},{"location":"api/landuse-query-agent/#api-integration","title":"API Integration","text":"<pre><code># Create a simple API endpoint\nfrom flask import Flask, request, jsonify\n\napp = Flask(__name__)\nagent = LanduseQueryAgent()\n\n@app.route('/query', methods=['POST'])\ndef query_landuse():\n    question = request.json['question']\n    result = agent.query(question)\n    return jsonify({'result': result})\n</code></pre>"},{"location":"api/landuse-query-agent/#future-enhancements","title":"Future Enhancements","text":""},{"location":"api/landuse-query-agent/#planned-features","title":"Planned Features","text":"<ul> <li>Visualization generation: Automatic chart creation</li> <li>Export capabilities: CSV/Excel export of results</li> <li>Saved queries: Store and reuse common analyses</li> <li>Multi-database support: Query multiple databases</li> <li>Advanced analytics: Time series forecasting</li> </ul>"},{"location":"api/landuse-query-agent/#contributing","title":"Contributing","text":"<ul> <li>Add new query patterns to the examples</li> <li>Improve business context explanations</li> <li>Enhance error handling and recovery</li> <li>Optimize SQL generation patterns</li> </ul> <p>This agent represents the cutting edge of natural language data analysis, making complex landuse analytics accessible through simple English questions! </p>"},{"location":"api/langgraph-agent/","title":"LangGraph Agent API Reference","text":""},{"location":"api/langgraph-agent/#overview","title":"Overview","text":"<p>The LangGraph Agent is the modern, graph-based natural language agent for RPA Land Use Analytics. It provides enhanced state management, conversation memory, and streaming capabilities compared to the traditional LangChain agent.</p>"},{"location":"api/langgraph-agent/#key-features","title":"Key Features","text":"<ul> <li>Graph-based Architecture: Uses LangGraph for complex workflow orchestration</li> <li>Conversation Memory: Built-in checkpointing for session continuity</li> <li>Streaming Support: Real-time response streaming</li> <li>Enhanced Error Handling: Graceful recovery from failures</li> <li>RPA Context Aware: Specialized for 2020 RPA Assessment data</li> </ul>"},{"location":"api/langgraph-agent/#usage","title":"Usage","text":""},{"location":"api/langgraph-agent/#command-line-interface","title":"Command Line Interface","text":"<pre><code># Start the interactive agent\nuv run python -m landuse.agents.langgraph_agent\n\n# Or use the CLI shortcut\nuv run rpa-analytics\n</code></pre>"},{"location":"api/langgraph-agent/#python-api","title":"Python API","text":"<pre><code>from landuse.agents.langgraph_agent import LanduseLangGraphAgent\n\n# Initialize the agent\nagent = LanduseLangGraphAgent(\n    db_path=\"data/processed/landuse_analytics.duckdb\",\n    model_name=\"claude-3-5-sonnet-20241022\",  # or \"gpt-4o-mini\"\n    temperature=0.1\n)\n\n# Query the agent\nresult = await agent.aquery(\"Which RPA scenarios show the most forest loss?\")\nprint(result)\n\n# Or use synchronous API\nresult = agent.query(\"Compare urban expansion between LM and HH scenarios\")\nprint(result)\n</code></pre>"},{"location":"api/langgraph-agent/#configuration","title":"Configuration","text":""},{"location":"api/langgraph-agent/#environment-variables","title":"Environment Variables","text":"<pre><code># Model selection (optional)\nLANDUSE_MODEL=claude-3-5-sonnet-20241022  # Default\n\n# API Keys (one required)\nANTHROPIC_API_KEY=your_key\nOPENAI_API_KEY=your_key\n\n# Database path (optional)\nLANDUSE_DB_PATH=data/processed/landuse_analytics.duckdb\n\n# Execution limits (optional)\nLANDUSE_MAX_ITERATIONS=5\nLANDUSE_MAX_EXECUTION_TIME=120\nLANDUSE_MAX_QUERY_ROWS=1000\n</code></pre>"},{"location":"api/langgraph-agent/#agent-state","title":"Agent State","text":"<p>The agent maintains state using TypedDict:</p> <pre><code>class AgentState(TypedDict):\n    messages: Annotated[list[BaseMessage], add_messages]\n    query: str\n    results: Optional[str]\n    error: Optional[str]\n    iterations: int\n    max_iterations: int\n</code></pre>"},{"location":"api/langgraph-agent/#available-tools","title":"Available Tools","text":""},{"location":"api/langgraph-agent/#execute_landuse_query","title":"execute_landuse_query","text":"<p>Executes DuckDB SQL queries on the RPA database.</p> <pre><code># Example usage\n\"Execute SQL: SELECT * FROM dim_scenario WHERE rcp_scenario = 'rcp85'\"\n</code></pre>"},{"location":"api/langgraph-agent/#get_schema_info","title":"get_schema_info","text":"<p>Returns detailed schema information about the RPA database.</p> <pre><code># Returns star schema structure with RPA context\n\"Get database schema information\"\n</code></pre>"},{"location":"api/langgraph-agent/#suggest_query_examples","title":"suggest_query_examples","text":"<p>Provides example queries for common RPA analysis patterns.</p> <pre><code># Categories: agricultural_loss, urbanization, climate_comparison, time_series\n\"Suggest query examples for climate_comparison\"\n</code></pre>"},{"location":"api/langgraph-agent/#explain_query_results","title":"explain_query_results","text":"<p>Interprets query results in RPA business context.</p> <pre><code>\"Explain these results: [query results]\"\n</code></pre>"},{"location":"api/langgraph-agent/#get_default_assumptions","title":"get_default_assumptions","text":"<p>Shows default assumptions for scenarios, time periods, and geography.</p> <pre><code>\"What are the default analysis assumptions?\"\n</code></pre>"},{"location":"api/langgraph-agent/#get_state_code","title":"get_state_code","text":"<p>Converts state names to FIPS codes.</p> <pre><code>\"Get state code for California\"\n</code></pre>"},{"location":"api/langgraph-agent/#example-queries","title":"Example Queries","text":""},{"location":"api/langgraph-agent/#basic-rpa-analysis","title":"Basic RPA Analysis","text":"<pre><code># Agricultural land loss\nresult = agent.query(\"How much agricultural land is projected to be lost by 2070?\")\n\n# Climate model comparison\nresult = agent.query(\"Compare forest loss between wet and dry climate models\")\n\n# Scenario analysis\nresult = agent.query(\"Which RPA scenario has the most urban expansion?\")\n</code></pre>"},{"location":"api/langgraph-agent/#advanced-analysis","title":"Advanced Analysis","text":"<pre><code># Time series with specific scenario\nresult = agent.query(\"\"\"\n    Show me annual forest loss rates under the HH scenario \n    (high warming, high growth) from 2020 to 2070\n\"\"\")\n\n# Regional comparison\nresult = agent.query(\"\"\"\n    Compare agricultural transitions between the South and \n    Midwest regions under the sustainability scenario (LM)\n\"\"\")\n\n# Climate pathway analysis\nresult = agent.query(\"\"\"\n    What's the difference in total land use change between \n    RCP4.5 and RCP8.5 pathways across all socioeconomic scenarios?\n\"\"\")\n</code></pre>"},{"location":"api/langgraph-agent/#error-handling","title":"Error Handling","text":"<p>The agent includes comprehensive error handling:</p> <pre><code>try:\n    result = agent.query(\"Invalid query\")\nexcept Exception as e:\n    print(f\"Query failed: {e}\")\n    # Agent provides helpful error messages and suggestions\n</code></pre>"},{"location":"api/langgraph-agent/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Query Optimization: Agent automatically adds appropriate filters and limits</li> <li>Memory Management: Conversation history is pruned to maintain performance</li> <li>Concurrent Queries: Thread-safe for multiple simultaneous queries</li> <li>Response Streaming: Use async methods for real-time updates</li> </ul>"},{"location":"api/langgraph-agent/#integration-with-streamlit","title":"Integration with Streamlit","text":"<p>The LangGraph agent powers the Streamlit chat interface:</p> <pre><code># In Streamlit app\nimport streamlit as st\nfrom landuse.agents.langgraph_agent import LanduseLangGraphAgent\n\nagent = LanduseLangGraphAgent()\n\n# Stream responses\nfor chunk in agent.stream(user_query):\n    st.write(chunk)\n</code></pre>"},{"location":"api/langgraph-agent/#comparison-with-traditional-agent","title":"Comparison with Traditional Agent","text":"Feature LangGraph Agent Traditional Agent Architecture Graph-based Linear REACT State Management Built-in checkpointing Session-based Streaming Native support Not supported Error Recovery Advanced retry logic Basic error handling Memory Conversation history Single query Performance Optimized iteration Standard execution"},{"location":"api/langgraph-agent/#api-methods","title":"API Methods","text":""},{"location":"api/langgraph-agent/#queryquestion-str-str","title":"query(question: str) -&gt; str","text":"<p>Synchronous query method for simple interactions.</p>"},{"location":"api/langgraph-agent/#aqueryquestion-str-str","title":"aquery(question: str) -&gt; str","text":"<p>Asynchronous query method for better performance.</p>"},{"location":"api/langgraph-agent/#streamquestion-str-iteratorstr","title":"stream(question: str) -&gt; Iterator[str]","text":"<p>Streaming method for real-time responses.</p>"},{"location":"api/langgraph-agent/#astreamquestion-str-asynciteratorstr","title":"astream(question: str) -&gt; AsyncIterator[str]","text":"<p>Asynchronous streaming for web applications.</p>"},{"location":"api/langgraph-agent/#clear_memory","title":"clear_memory()","text":"<p>Clears conversation history and resets state.</p>"},{"location":"api/langgraph-agent/#best-practices","title":"Best Practices","text":"<ol> <li>Use specific RPA terminology: Reference scenarios (LM, HL, HM, HH) and models by name</li> <li>Leverage defaults: Agent uses intelligent defaults when parameters aren't specified</li> <li>Ask follow-up questions: Agent maintains context across queries</li> <li>Handle streaming: Use async methods for better user experience</li> <li>Monitor iterations: Set appropriate limits for complex queries</li> </ol>"},{"location":"api/tools/","title":"Tools API Reference","text":"<p>Detailed documentation of all tools available to the LangChain Data Engineering Agent.</p>"},{"location":"api/tools/#overview","title":"Overview","text":"<p>The agent uses a collection of specialized tools for file operations, data analysis, and database queries. Each tool is designed to handle specific tasks while maintaining consistency and error handling.</p>"},{"location":"api/tools/#tool-categories","title":"Tool Categories","text":""},{"location":"api/tools/#file-management-tools","title":"\ud83d\udcc1 File Management Tools","text":"<p>Tools inherited from LangChain's <code>FileManagementToolkit</code>:</p> Tool Function Parameters Example <code>list_directory</code> List files in directory <code>dir_path: str</code> \"List files in data/\" <code>read_file</code> Read file contents <code>file_path: str</code> \"Read config.json\" <code>write_file</code> Write to file <code>file_path: str, text: str</code> \"Save results to output.txt\" <code>copy_file</code> Copy file <code>source: str, destination: str</code> \"Copy data.csv to backup/\" <code>move_file</code> Move/rename file <code>source: str, destination: str</code> \"Move temp.csv to processed/\" <code>delete_file</code> Delete file <code>file_path: str</code> \"Delete temporary.txt\""},{"location":"api/tools/#data-reading-tools","title":"\ud83d\udcca Data Reading Tools","text":"<p>Specialized tools for reading different data formats:</p>"},{"location":"api/tools/#read_csv","title":"read_csv","text":"<pre><code>def _read_csv(self, file_path: str) -&gt; str\n</code></pre> <p>Purpose: Read CSV files and return basic information</p> <p>Returns: - Shape, columns, data types - Missing values summary - Memory usage - First 5 rows - Basic statistics</p> <p>Example: <pre><code>agent.run(\"Read the sample_data.csv file\")\n</code></pre></p>"},{"location":"api/tools/#read_parquet","title":"read_parquet","text":"<pre><code>def _read_parquet(self, file_path: str) -&gt; str\n</code></pre> <p>Purpose: Read Parquet files efficiently</p> <p>Features: - Columnar format support - Compression handling - Metadata extraction</p>"},{"location":"api/tools/#read_json","title":"read_json","text":"<pre><code>def _read_json(self, file_path: str) -&gt; str\n</code></pre> <p>Purpose: Read JSON files with large file support</p> <p>Special Handling: - Files &gt; MAX_FILE_SIZE_MB use streaming - Automatic structure detection - Sample extraction for large files</p>"},{"location":"api/tools/#data-analysis-tools","title":"\ud83d\udd0d Data Analysis Tools","text":""},{"location":"api/tools/#analyze_dataframe","title":"analyze_dataframe","text":"<pre><code>def _analyze_dataframe(self, file_path: str) -&gt; str\n</code></pre> <p>Purpose: Perform detailed analysis on any supported file format</p> <p>Analysis Includes: - Shape and memory usage - Duplicate row detection - Column-wise analysis:   - Data types   - Null counts and percentages   - Unique values   - Cardinality   - Numeric statistics</p> <p>Output Format: <pre><code>{\n  \"shape\": [rows, cols],\n  \"memory_usage_mb\": 12.5,\n  \"duplicate_rows\": 0,\n  \"column_analysis\": {\n    \"column_name\": {\n      \"dtype\": \"float64\",\n      \"null_count\": 5,\n      \"null_percentage\": 0.5,\n      \"unique_values\": 100,\n      \"mean\": 50.2,\n      \"std\": 10.5\n    }\n  }\n}\n</code></pre></p>"},{"location":"api/tools/#query_data","title":"query_data","text":"<pre><code>def _query_data(self, params: Union[Dict[str, str], str]) -&gt; str\n</code></pre> <p>Purpose: Execute SQL queries on any file format using DuckDB</p> <p>Parameters: <pre><code>{\n  \"file_path\": \"data.csv\",\n  \"query\": \"SELECT * FROM data WHERE value &gt; 100\"\n}\n</code></pre></p> <p>Features: - Automatic table creation - SQL syntax support - Cross-format queries - Spatial support for GeoParquet</p>"},{"location":"api/tools/#data-transformation-tools","title":"\ud83d\udd04 Data Transformation Tools","text":""},{"location":"api/tools/#transform_data","title":"transform_data","text":"<pre><code>def _transform_data(self, params: Union[Dict[str, str], str]) -&gt; str\n</code></pre> <p>Purpose: Convert between data formats</p> <p>Parameters: <pre><code>{\n  \"input_path\": \"data.json\",\n  \"output_path\": \"data.parquet\",\n  \"output_format\": \"parquet\",\n  \"compression\": \"snappy\"  # optional\n}\n</code></pre></p> <p>Supported Formats: - CSV \u2194 Parquet - JSON \u2194 Parquet - Excel \u2194 CSV - Any format to GeoParquet (if geometry present)</p>"},{"location":"api/tools/#optimize_storage","title":"optimize_storage","text":"<pre><code>def _optimize_storage(self, file_path: str) -&gt; str\n</code></pre> <p>Purpose: Analyze data and suggest optimal storage format</p> <p>Analysis Factors: - Current format and size - Data characteristics - Column types distribution - Compression potential</p> <p>Recommendations Include: - Suggested format - Reason for recommendation - Estimated size reduction</p>"},{"location":"api/tools/#database-tools","title":"\ud83d\uddc4\ufe0f Database Tools","text":""},{"location":"api/tools/#list_database_tables","title":"list_database_tables","text":"<pre><code>def _list_database_tables(self, db_path: str) -&gt; str\n</code></pre> <p>Purpose: List all tables in a SQLite database</p> <p>Output: <pre><code>Database: landuse.db\nTables:\n  \u2022 landuse_transitions: 1,234,567 rows\n  \u2022 landuse_changes: 543,210 rows\n</code></pre></p>"},{"location":"api/tools/#describe_database_table","title":"describe_database_table","text":"<pre><code>def _describe_database_table(self, params: Dict[str, str]) -&gt; str\n</code></pre> <p>Purpose: Get detailed table information</p> <p>Parameters: <pre><code>{\n  \"db_path\": \"database.db\",\n  \"table_name\": \"landuse_transitions\"\n}\n</code></pre></p> <p>Returns: - Row count - Column schema - Data types - Constraints - Indexes - Sample data</p>"},{"location":"api/tools/#query_database","title":"query_database","text":"<pre><code>def _query_database(self, params: Dict[str, str]) -&gt; str\n</code></pre> <p>Purpose: Execute SQL queries on SQLite databases</p> <p>Parameters: <pre><code>{\n  \"db_path\": \"database.db\",\n  \"query\": \"SELECT COUNT(*) FROM table\",\n  \"limit\": 1000  # optional, default 1000\n}\n</code></pre></p> <p>Features: - Automatic LIMIT addition - Result formatting - Error handling - Performance optimization</p>"},{"location":"api/tools/#export_database_table","title":"export_database_table","text":"<pre><code>def _export_database_table(self, params: Dict[str, str]) -&gt; str\n</code></pre> <p>Purpose: Export database tables to files</p> <p>Parameters: <pre><code>{\n  \"db_path\": \"database.db\",\n  \"table_name\": \"results\",\n  \"output_path\": \"export.csv\",\n  \"output_format\": \"csv\",  # csv, json, parquet\n  \"where_clause\": \"year &gt; 2020\",  # optional\n  \"limit\": 10000  # optional\n}\n</code></pre></p>"},{"location":"api/tools/#visualization-tools","title":"\ud83d\udcc8 Visualization Tools","text":""},{"location":"api/tools/#data_visualization","title":"data_visualization","text":"<pre><code>def _create_visualization(self, params: Dict[str, str]) -&gt; str\n</code></pre> <p>Purpose: Create data visualizations</p> <p>Parameters: <pre><code>{\n  \"file_path\": \"data.csv\",\n  \"plot_type\": \"scatter\",  # scatter, line, histogram, correlation\n  \"x\": \"column1\",  # optional\n  \"y\": \"column2\"   # optional\n}\n</code></pre></p> <p>Plot Types: - Scatter plots - Line charts - Histograms - Correlation heatmaps</p> <p>Output: Saves plot as PNG file</p>"},{"location":"api/tools/#advanced-tools","title":"\ud83d\ude80 Advanced Tools","text":""},{"location":"api/tools/#json_to_database","title":"json_to_database","text":"<pre><code>def _json_to_database(self, params: Dict[str, Any]) -&gt; str\n</code></pre> <p>Purpose: Convert large JSON files to SQLite efficiently</p> <p>Parameters: <pre><code>{\n  \"json_path\": \"large_data.json\",\n  \"db_path\": \"output.db\",\n  \"table_name\": \"data\",\n  \"chunk_size\": 10000\n}\n</code></pre></p> <p>Features: - Streaming processing - Automatic schema detection - Progress tracking - Index creation - Batch insertion</p>"},{"location":"api/tools/#database_statistics","title":"database_statistics","text":"<pre><code>def _database_statistics(self, db_path: str) -&gt; str\n</code></pre> <p>Purpose: Get comprehensive database statistics</p> <p>Returns: - File size - Table count - Row counts per table - Index information - Schema version</p>"},{"location":"api/tools/#tool-integration","title":"Tool Integration","text":""},{"location":"api/tools/#creating-custom-tools","title":"Creating Custom Tools","text":"<pre><code>from langchain_core.tools import Tool\n\ndef create_custom_tool():\n    return Tool(\n        name=\"custom_analysis\",\n        func=custom_analysis_function,\n        description=\"Perform custom analysis on data\"\n    )\n</code></pre>"},{"location":"api/tools/#tool-parameters","title":"Tool Parameters","text":"<p>Tools accept parameters in multiple formats:</p> <ol> <li> <p>String parameters: <pre><code>agent.run(\"Read file.csv\")\n</code></pre></p> </li> <li> <p>Dictionary parameters: <pre><code>params = {\"file_path\": \"data.csv\", \"query\": \"SELECT * FROM data\"}\nagent.run(f\"Query data with parameters: {json.dumps(params)}\")\n</code></pre></p> </li> <li> <p>Structured parameters: <pre><code>from pydantic import BaseModel\n\nclass QueryParams(BaseModel):\n    file_path: str\n    query: str\n    limit: Optional[int] = 1000\n</code></pre></p> </li> </ol>"},{"location":"api/tools/#error-handling","title":"Error Handling","text":"<p>All tools implement consistent error handling:</p> <pre><code>try:\n    # Tool operation\n    result = perform_operation()\n    return format_success(result)\nexcept FileNotFoundError:\n    return f\"Error: File not found: {file_path}\"\nexcept ValueError as e:\n    return f\"Error: Invalid value: {str(e)}\"\nexcept Exception as e:\n    return f\"Error: {str(e)}\"\n</code></pre>"},{"location":"api/tools/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/tools/#file-size-handling","title":"File Size Handling","text":"<ul> <li>Files &gt; MAX_FILE_SIZE_MB trigger special handling</li> <li>Large files use streaming/sampling</li> <li>Progress indicators for long operations</li> </ul>"},{"location":"api/tools/#query-optimization","title":"Query Optimization","text":"<ul> <li>Automatic LIMIT clauses</li> <li>Index usage</li> <li>Batch processing</li> <li>Connection pooling</li> </ul>"},{"location":"api/tools/#memory-management","title":"Memory Management","text":"<ul> <li>Chunked processing for large datasets</li> <li>Explicit garbage collection when needed</li> <li>Streaming for JSON/CSV processing</li> </ul>"},{"location":"api/tools/#usage-examples","title":"Usage Examples","text":""},{"location":"api/tools/#basic-file-analysis","title":"Basic File Analysis","text":"<pre><code># Analyze a CSV file\nresult = agent.run(\"Analyze the sales_data.csv file\")\n\n# Get specific statistics\nresult = agent.run(\"Show me statistics for the revenue column in sales_data.csv\")\n</code></pre>"},{"location":"api/tools/#complex-queries","title":"Complex Queries","text":"<pre><code># Multi-step analysis\nagent.run(\"\"\"\n1. Read the customer_data.csv file\n2. Query it to find top customers by revenue\n3. Export results to top_customers.parquet\n\"\"\")\n</code></pre>"},{"location":"api/tools/#database-operations","title":"Database Operations","text":"<pre><code># Explore database\nagent.run(\"Show all tables in analytics.db\")\n\n# Complex query\nagent.run(\"\"\"\nQuery analytics.db: \nSELECT category, SUM(sales) as total_sales \nFROM transactions \nWHERE date &gt;= '2024-01-01' \nGROUP BY category \nORDER BY total_sales DESC\n\"\"\")\n</code></pre>"},{"location":"api/tools/#best-practices","title":"Best Practices","text":"<ol> <li>Use appropriate tools for the task</li> <li>File reading for exploration</li> <li>Query tools for analysis</li> <li> <p>Export tools for results</p> </li> <li> <p>Handle errors gracefully</p> </li> <li>Check file existence</li> <li>Validate parameters</li> <li> <p>Provide helpful error messages</p> </li> <li> <p>Optimize for performance</p> </li> <li>Use appropriate chunk sizes</li> <li>Leverage indexes</li> <li> <p>Stream large files</p> </li> <li> <p>Maintain data integrity</p> </li> <li>Validate transformations</li> <li>Preserve data types</li> <li>Handle nulls appropriately</li> </ol>"},{"location":"api/tools/#next-steps","title":"Next Steps","text":"<ul> <li>See Agent API for using tools programmatically</li> <li>Review Query Examples for tool usage patterns</li> <li>Check Data Processing for data pipeline tools</li> </ul>"},{"location":"data/categories/","title":"Land Use Categories","text":"<p>Detailed explanation of each land use category in the database and how they relate to real-world land classification systems.</p>"},{"location":"data/categories/#overview","title":"Overview","text":"<p>The land use classification system used in this project is based on standard USDA and land cover categories, simplified into six main types for analysis.</p> <pre><code>graph TD\n    A[Total Land Area] --&gt; B[Crop]\n    A --&gt; C[Pasture]\n    A --&gt; D[Forest]\n    A --&gt; E[Urban]\n    A --&gt; F[Range]\n\n    B --&gt; G[Agriculture]\n    C --&gt; G\n\n    style G fill:#f9f,stroke:#333,stroke-width:2px</code></pre>"},{"location":"data/categories/#primary-categories","title":"Primary Categories","text":""},{"location":"data/categories/#crop-cropland","title":"\ud83c\udf3e Crop (Cropland)","text":"<p>Definition: Land used for the production of adapted crops for harvest.</p> <p>Includes: - Annual crops (corn, soybeans, wheat, etc.) - Perennial crops (orchards, vineyards) - Cultivated lands - Crop rotation areas - Fallow cropland</p> <p>Characteristics: - Actively managed for agricultural production - Regular planting and harvesting cycles - May include irrigation infrastructure - Subject to agricultural policies and subsidies</p> <p>Typical Transitions: - To Urban: Agricultural land near cities under development pressure - To Pasture: Crop-livestock integration or economic shifts - To Forest: Abandoned farmland or conservation programs - From Pasture: Intensification of agricultural use</p>"},{"location":"data/categories/#pasture","title":"\ud83d\udc04 Pasture","text":"<p>Definition: Land used primarily for grazing of livestock.</p> <p>Includes: - Improved pastures with planted grasses - Grazing lands in rotation with crops - Permanent pastures - Hayfields</p> <p>Characteristics: - Managed grasslands for livestock - May be fertilized or irrigated - Often near crop areas (mixed farming) - Can be converted relatively easily</p> <p>Typical Transitions: - To Crop: Agricultural intensification - To Urban: Development in rural-urban fringe - To Forest: Natural succession or tree planting - From Crop: Shift to livestock farming</p>"},{"location":"data/categories/#forest","title":"\ud83c\udf32 Forest","text":"<p>Definition: Land dominated by trees and woody vegetation.</p> <p>Includes: - Natural forests - Managed forests for timber - Forest plantations - Wooded wetlands - Young forest regeneration</p> <p>Characteristics: - Tree canopy coverage &gt;10% - May be managed or unmanaged - Provides ecosystem services - Subject to conservation policies</p> <p>Typical Transitions: - To Urban: Deforestation for development - To Crop: Agricultural expansion - To Pasture: Clearing for grazing - From Range: Natural succession or afforestation</p>"},{"location":"data/categories/#urban","title":"\ud83c\udfe2 Urban","text":"<p>Definition: Developed land with constructed materials and infrastructure.</p> <p>Includes: - Cities and towns - Residential areas - Commercial and industrial zones - Transportation infrastructure - Urban green spaces (parks)</p> <p>Characteristics: - Permanent land use change - High economic value - Rarely converts to other uses - Expanding in most scenarios</p> <p>Typical Transitions: - From Forest: Suburban expansion - From Crop: Agricultural land conversion - From Pasture: Rural development - To Urban: Essentially none (permanent)</p>"},{"location":"data/categories/#range-rangeland","title":"\ud83c\udf3f Range (Rangeland)","text":"<p>Definition: Natural grasslands and shrublands, typically in arid/semi-arid regions.</p> <p>Includes: - Native grasslands - Shrublands - Desert vegetation - Non-improved grazing lands - Prairie ecosystems</p> <p>Characteristics: - Natural vegetation - Minimal management - Often used for extensive grazing - Climate-limited productivity</p> <p>Typical Transitions: - To Pasture: Improvement for livestock - To Crop: Irrigation development - To Forest: Succession in wetter areas - To Urban: Limited (usually near cities)</p>"},{"location":"data/categories/#total","title":"\ud83d\udcca Total","text":"<p>Definition: Sum of all land use categories for validation.</p> <p>Purpose: - Data quality check - Ensures accounting completeness - Not a real land use category</p> <p>Usage in Queries: <pre><code>-- Always exclude Total from analyses\nWHERE from_land_use != 'Total' \n  AND to_land_use != 'Total'\n</code></pre></p>"},{"location":"data/categories/#agricultural-aggregation","title":"Agricultural Aggregation","text":"<p>In the <code>*_ag</code> tables, agricultural land is combined:</p>"},{"location":"data/categories/#agriculture-combined","title":"\ud83d\ude9c Agriculture (Combined)","text":"<p>Definition: Crop + Pasture combined into a single category.</p> <p>Rationale: - Simplifies agricultural analysis - Both are managed for food production - Often intermixed on farms - Similar policy implications</p> <p>When to Use: - Analyzing total agricultural land - Food security assessments - Comparing agricultural vs. natural land - Policy scenario analysis</p>"},{"location":"data/categories/#understanding-transitions","title":"Understanding Transitions","text":""},{"location":"data/categories/#natural-progressions","title":"Natural Progressions","text":"<p>Some transitions follow natural succession patterns:</p> <pre><code>Range \u2192 Forest (increasing precipitation)\nPasture \u2192 Forest (abandonment)\nCrop \u2192 Pasture \u2192 Forest (land retirement)\n</code></pre>"},{"location":"data/categories/#economic-drivers","title":"Economic Drivers","text":"<p>Market forces drive many transitions:</p> <pre><code>Forest \u2192 Crop (commodity prices high)\nPasture \u2192 Crop (intensification)\nRange \u2192 Pasture (livestock expansion)\nAll \u2192 Urban (development pressure)\n</code></pre>"},{"location":"data/categories/#policy-influences","title":"Policy Influences","text":"<p>Conservation and development policies affect transitions:</p> <pre><code>Crop \u2192 Forest (conservation programs)\nForest \u2192 Forest (protection policies)\nPasture \u2192 Urban (zoning changes)\n</code></pre>"},{"location":"data/categories/#regional-variations","title":"Regional Variations","text":""},{"location":"data/categories/#eastern-us","title":"Eastern US","text":"<ul> <li>More Forest \u2194 Crop transitions</li> <li>Higher Forest \u2192 Urban pressure</li> <li>Limited rangeland</li> </ul>"},{"location":"data/categories/#western-us","title":"Western US","text":"<ul> <li>Extensive rangelands</li> <li>Range \u2194 Pasture transitions</li> <li>Water-limited crop expansion</li> </ul>"},{"location":"data/categories/#midwest","title":"Midwest","text":"<ul> <li>Crop \u2194 Pasture rotations</li> <li>Stable agricultural land</li> <li>Urban expansion into farmland</li> </ul>"},{"location":"data/categories/#coastal-areas","title":"Coastal Areas","text":"<ul> <li>High Urban expansion pressure</li> <li>Forest \u2192 Urban common</li> <li>Agricultural land loss</li> </ul>"},{"location":"data/categories/#query-examples-by-category","title":"Query Examples by Category","text":""},{"location":"data/categories/#cropland-analysis","title":"Cropland Analysis","text":"<pre><code>You&gt; Show me counties with the most cropland expansion\nYou&gt; What's converting to cropland in the High Crop Demand scenario?\nYou&gt; Track cropland changes in Iowa counties\n</code></pre>"},{"location":"data/categories/#forest-conservation","title":"Forest Conservation","text":"<pre><code>You&gt; Which counties maintain the most forest cover through 2100?\nYou&gt; Show forest to urban conversion rates by decade\nYou&gt; Compare forest outcomes across scenarios\n</code></pre>"},{"location":"data/categories/#urban-growth","title":"Urban Growth","text":"<pre><code>You&gt; Calculate urban expansion rates for major metropolitan areas\nYou&gt; What land uses are consumed by urban growth?\nYou&gt; Project when urban area will double from 2020 levels\n</code></pre>"},{"location":"data/categories/#agricultural-trends","title":"Agricultural Trends","text":"<pre><code>You&gt; Show the balance between crop and pasture over time\nYou&gt; Which scenario maximizes agricultural productivity?\nYou&gt; Find counties shifting from crops to livestock\n</code></pre>"},{"location":"data/categories/#rangeland-changes","title":"Rangeland Changes","text":"<pre><code>You&gt; How much rangeland converts to other uses?\nYou&gt; Show rangeland preservation by scenario\nYou&gt; Identify counties with significant range to pasture conversion\n</code></pre>"},{"location":"data/categories/#data-quality-considerations","title":"Data Quality Considerations","text":""},{"location":"data/categories/#classification-accuracy","title":"Classification Accuracy","text":"<ul> <li>Based on remote sensing and surveys</li> <li>Some mixed land uses simplified</li> <li>Urban includes various developed types</li> </ul>"},{"location":"data/categories/#temporal-consistency","title":"Temporal Consistency","text":"<ul> <li>Categories stable across time periods</li> <li>Same definitions used throughout</li> <li>Allows valid historical comparisons</li> </ul>"},{"location":"data/categories/#spatial-resolution","title":"Spatial Resolution","text":"<ul> <li>County-level aggregation</li> <li>Sub-county variations not captured</li> <li>Edge effects at county boundaries</li> </ul>"},{"location":"data/categories/#best-practices","title":"Best Practices","text":"<ol> <li>Consider Regional Context</li> <li>Land use meanings vary by region</li> <li>Climate affects transition likelihood</li> <li> <p>Local policies matter</p> </li> <li> <p>Aggregate Thoughtfully</p> </li> <li>Use agricultural aggregation for food analysis</li> <li>Keep separate for detailed studies</li> <li> <p>Remember Total is for validation only</p> </li> <li> <p>Interpret Transitions</p> </li> <li>Some transitions are rare/unlikely</li> <li>Consider economic feasibility</li> <li>Account for policy constraints</li> </ol>"},{"location":"data/categories/#next-steps","title":"Next Steps","text":"<ul> <li>Review Database Schema for technical details</li> <li>Explore Data Sources for methodology</li> <li>See Query Examples for category-specific analyses</li> </ul>"},{"location":"data/duckdb-schema/","title":"DuckDB Schema Design","text":""},{"location":"data/duckdb-schema/#overview","title":"Overview","text":"<p>The landuse database has been redesigned from a single denormalized table to a star schema optimized for analytical queries. This follows modern data warehousing best practices and significantly improves query performance.</p>"},{"location":"data/duckdb-schema/#schema-architecture","title":"Schema Architecture","text":""},{"location":"data/duckdb-schema/#star-schema-design","title":"Star Schema Design","text":"<pre><code>erDiagram\n    fact_landuse_transitions {\n        bigint transition_id PK\n        int scenario_id FK\n        int time_id FK\n        int geography_id FK\n        int from_landuse_id FK\n        int to_landuse_id FK\n        decimal acres\n        varchar transition_type\n        timestamp created_at\n    }\n\n    dim_scenario {\n        int scenario_id PK\n        varchar scenario_name\n        varchar climate_model\n        varchar rcp_scenario\n        varchar ssp_scenario\n        timestamp created_at\n    }\n\n    dim_time {\n        int time_id PK\n        varchar year_range\n        int start_year\n        int end_year\n        int period_length\n        timestamp created_at\n    }\n\n    dim_geography {\n        int geography_id PK\n        varchar fips_code\n        varchar county_name\n        varchar state_code\n        varchar state_name\n        varchar region\n        timestamp created_at\n    }\n\n    dim_landuse {\n        int landuse_id PK\n        varchar landuse_code\n        varchar landuse_name\n        varchar landuse_category\n        text description\n        timestamp created_at\n    }\n\n    fact_landuse_transitions ||--|| dim_scenario : scenario_id\n    fact_landuse_transitions ||--|| dim_time : time_id\n    fact_landuse_transitions ||--|| dim_geography : geography_id\n    fact_landuse_transitions ||--|| dim_landuse : from_landuse_id\n    fact_landuse_transitions ||--|| dim_landuse : to_landuse_id</code></pre>"},{"location":"data/duckdb-schema/#tables","title":"Tables","text":""},{"location":"data/duckdb-schema/#dimension-tables","title":"Dimension Tables","text":""},{"location":"data/duckdb-schema/#dim_scenario","title":"<code>dim_scenario</code>","text":"<p>Climate and socioeconomic scenarios - scenario_id: Primary key - scenario_name: Full scenario name (e.g., \"CNRM_CM5_rcp45_ssp1\") - climate_model: Climate model used (e.g., \"CNRM_CM5\") - rcp_scenario: Representative Concentration Pathway (e.g., \"rcp45\") - ssp_scenario: Shared Socioeconomic Pathway (e.g., \"ssp1\")</p>"},{"location":"data/duckdb-schema/#dim_time","title":"<code>dim_time</code>","text":"<p>Time periods and ranges - time_id: Primary key - year_range: Year range string (e.g., \"2012-2020\") - start_year: Starting year - end_year: Ending year - period_length: Duration in years</p>"},{"location":"data/duckdb-schema/#dim_geography","title":"<code>dim_geography</code>","text":"<p>Geographic locations - geography_id: Primary key - fips_code: 5-digit FIPS county code - county_name: County name (to be populated) - state_code: 2-digit state code - state_name: State name (to be populated) - region: Geographic region (to be populated)</p>"},{"location":"data/duckdb-schema/#dim_landuse","title":"<code>dim_landuse</code>","text":"<p>Land use types and categories - landuse_id: Primary key - landuse_code: Short code (cr, ps, rg, fr, ur) - landuse_name: Full name (Crop, Pasture, Rangeland, Forest, Urban) - landuse_category: Category (Agriculture, Natural, Developed) - description: Detailed description</p>"},{"location":"data/duckdb-schema/#fact-table","title":"Fact Table","text":""},{"location":"data/duckdb-schema/#fact_landuse_transitions","title":"<code>fact_landuse_transitions</code>","text":"<p>Main fact table containing all land use transitions - transition_id: Primary key - scenario_id: Foreign key to dim_scenario - time_id: Foreign key to dim_time - geography_id: Foreign key to dim_geography - from_landuse_id: Foreign key to dim_landuse (source) - to_landuse_id: Foreign key to dim_landuse (destination) - acres: Area in acres for this transition - transition_type: 'same' or 'change'</p>"},{"location":"data/duckdb-schema/#analytical-views","title":"Analytical Views","text":""},{"location":"data/duckdb-schema/#v_agriculture_transitions","title":"<code>v_agriculture_transitions</code>","text":"<p>Pre-filtered view for agricultural transitions <pre><code>SELECT \n    s.scenario_name,\n    t.year_range,\n    g.fips_code,\n    g.state_code,\n    fl.landuse_name as from_landuse,\n    tl.landuse_name as to_landuse,\n    f.acres,\n    f.transition_type\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_time t ON f.time_id = t.time_id\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_category = 'Agriculture' OR tl.landuse_category = 'Agriculture'\n</code></pre></p>"},{"location":"data/duckdb-schema/#v_scenario_summary","title":"<code>v_scenario_summary</code>","text":"<p>Aggregated summary by scenario <pre><code>SELECT \n    s.scenario_name,\n    t.year_range,\n    fl.landuse_name as from_landuse,\n    tl.landuse_name as to_landuse,\n    COUNT(*) as transition_count,\n    SUM(f.acres) as total_acres,\n    AVG(f.acres) as avg_acres\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_time t ON f.time_id = t.time_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nGROUP BY s.scenario_name, t.year_range, fl.landuse_name, tl.landuse_name\n</code></pre></p>"},{"location":"data/duckdb-schema/#v_total_land_area","title":"<code>v_total_land_area</code>","text":"<p>Total land area calculations for percentage-based analysis <pre><code>WITH land_totals AS (\n    SELECT \n        g.geography_id,\n        g.fips_code,\n        g.state_code,\n        SUM(f.acres) as total_land_acres\n    FROM fact_landuse_transitions f\n    JOIN dim_geography g ON f.geography_id = g.geography_id\n    JOIN dim_time t ON f.time_id = t.time_id\n    JOIN dim_scenario s ON f.scenario_id = s.scenario_id\n    WHERE t.start_year = (SELECT MIN(start_year) FROM dim_time)\n      AND s.scenario_name = (SELECT MIN(scenario_name) FROM dim_scenario)\n    GROUP BY g.geography_id, g.fips_code, g.state_code\n),\nstate_totals AS (\n    SELECT \n        state_code,\n        SUM(total_land_acres) as state_total_acres,\n        COUNT(*) as counties_in_state\n    FROM land_totals\n    GROUP BY state_code\n)\nSELECT \n    lt.geography_id,\n    lt.fips_code,\n    lt.state_code,\n    lt.total_land_acres as county_total_acres,\n    st.state_total_acres,\n    st.counties_in_state,\n    ROUND((lt.total_land_acres / st.state_total_acres) * 100, 2) as pct_of_state\nFROM land_totals lt\nJOIN state_totals st ON lt.state_code = st.state_code\n</code></pre></p> <p>Key Features: - Baseline Consistency: Uses earliest time period and first scenario for consistent totals - County Level: Total acres for each county - State Level: Total acres for each state - Percentage Calculations: County as percentage of state - Use Cases:    - \"Rank states by percentage of forest loss\"   - \"Counties with highest percentage of agricultural land\"   - \"Urban expansion as percentage of total land area\"</p>"},{"location":"data/duckdb-schema/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"data/duckdb-schema/#indexes","title":"Indexes","text":"<ul> <li>Primary keys on all dimension tables</li> <li>Foreign key indexes on fact table</li> <li>Composite index on (scenario_id, time_id, geography_id)</li> <li>Individual indexes on commonly queried columns</li> </ul>"},{"location":"data/duckdb-schema/#query-patterns","title":"Query Patterns","text":"<p>The star schema is optimized for: - Aggregation queries: Sum acres by scenario, time, geography - Filtering: Fast filtering by any dimension - Joins: Efficient joins between fact and dimension tables - Time series analysis: Easy querying across time periods - Geographic analysis: Fast geographic filtering and grouping</p>"},{"location":"data/duckdb-schema/#benefits-over-previous-design","title":"Benefits Over Previous Design","text":""},{"location":"data/duckdb-schema/#before-single-table","title":"Before (Single Table)","text":"<ul> <li>\u274c 8.6M rows with repeated dimension data</li> <li>\u274c No referential integrity</li> <li>\u274c Inefficient storage due to string repetition</li> <li>\u274c Slow aggregation queries</li> <li>\u274c No clear separation of concerns</li> </ul>"},{"location":"data/duckdb-schema/#after-star-schema","title":"After (Star Schema)","text":"<ul> <li>\u2705 Normalized dimension tables with referential integrity</li> <li>\u2705 Efficient storage through integer foreign keys</li> <li>\u2705 Fast analytical queries optimized for DuckDB</li> <li>\u2705 Clear separation between facts and dimensions</li> <li>\u2705 Extensible design for adding new dimensions</li> <li>\u2705 Better data quality through constraints</li> </ul>"},{"location":"data/duckdb-schema/#usage-examples","title":"Usage Examples","text":""},{"location":"data/duckdb-schema/#basic-queries","title":"Basic Queries","text":"<pre><code>-- Get all scenarios\nSELECT * FROM dim_scenario;\n\n-- Get landuse categories\nSELECT landuse_category, COUNT(*) \nFROM dim_landuse \nGROUP BY landuse_category;\n\n-- Total acres by scenario\nSELECT s.scenario_name, SUM(f.acres) as total_acres\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nGROUP BY s.scenario_name;\n</code></pre>"},{"location":"data/duckdb-schema/#advanced-analytics","title":"Advanced Analytics","text":"<pre><code>-- Agricultural land loss by state and scenario\nSELECT \n    s.scenario_name,\n    g.state_code,\n    SUM(f.acres) as acres_lost\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_category = 'Agriculture' \n  AND tl.landuse_category != 'Agriculture'\n  AND f.transition_type = 'change'\nGROUP BY s.scenario_name, g.state_code\nORDER BY acres_lost DESC;\n</code></pre>"},{"location":"data/duckdb-schema/#file-location","title":"File Location","text":"<ul> <li>Database: <code>data/processed/landuse_analytics.duckdb</code></li> <li>Size: Optimized for analytical workloads</li> <li>Format: DuckDB (columnar storage, optimized for analytics)</li> </ul>"},{"location":"data/duckdb-schema/#tools-integration","title":"Tools Integration","text":"<ul> <li>SQL Query Agent: Full support for DuckDB queries</li> <li>DuckDB CLI: Direct database access</li> <li>Python: pandas integration via DuckDB</li> <li>BI Tools: Compatible with most analytics tools </li> </ul>"},{"location":"data/processing/","title":"Data Processing","text":"<p>Detailed explanation of how raw land use projection data is transformed into the queryable database format.</p>"},{"location":"data/processing/#processing-pipeline-overview","title":"Processing Pipeline Overview","text":"<pre><code>graph TD\n    A[Raw JSON Data] --&gt; B[Parse &amp; Validate]\n    B --&gt; C[Transform to Long Format]\n    C --&gt; D[Create Base Tables]\n    D --&gt; E[Add Agricultural Aggregation]\n    E --&gt; F[Create Filtered Views]\n    F --&gt; G[Add Indexes]\n    G --&gt; H[Final Database]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style H fill:#9f9,stroke:#333,stroke-width:2px</code></pre>"},{"location":"data/processing/#step-1-raw-data-structure","title":"Step 1: Raw Data Structure","text":""},{"location":"data/processing/#input-format","title":"Input Format","text":"<p>The raw JSON file (<code>county_landuse_projections_RPA.json</code>) has a nested structure:</p> <pre><code>{\n  \"06037\": {  // FIPS code\n    \"county_name\": \"Los Angeles\",\n    \"state\": \"CA\",\n    \"scenarios\": {\n      \"Baseline\": {\n        \"2012-2020\": {\n          \"transition_matrix\": [\n            {\"_row\": \"cr\", \"cr\": 100.5, \"ps\": 2.3, \"ur\": 5.7, ...},\n            {\"_row\": \"ps\", \"cr\": 1.2, \"ps\": 89.4, \"ur\": 3.1, ...},\n            ...\n          ]\n        },\n        \"2020-2030\": {...}\n      },\n      \"High Crop Demand\": {...}\n    }\n  }\n}\n</code></pre>"},{"location":"data/processing/#matrix-interpretation","title":"Matrix Interpretation","text":"<p>Each transition matrix represents land use changes: - Rows: Original land use (from) - Columns: New land use (to) - Values: Area in 1000 acres</p>"},{"location":"data/processing/#step-2-conversion-scripts","title":"Step 2: Conversion Scripts","text":""},{"location":"data/processing/#main-converter","title":"Main Converter","text":"<p><code>convert_landuse_to_db.py</code> performs the initial conversion:</p> <pre><code>def process_matrix_data(matrix_data, scenario, year, year_range, fips):\n    \"\"\"Convert matrix format to transition records.\"\"\"\n    transitions = []\n\n    for row in matrix_data:\n        from_type = LAND_USE_MAP.get(row.get('_row', ''), row.get('_row', ''))\n\n        if from_type != 'Total':  # Skip total row\n            for col, value in row.items():\n                if col not in ['_row', 't1'] and col in LAND_USE_MAP:\n                    to_type = LAND_USE_MAP[col]\n\n                    if to_type != 'Total':  # Skip total column\n                        transitions.append({\n                            'scenario': scenario,\n                            'year': year,\n                            'year_range': year_range,\n                            'fips': fips,\n                            'from_land_use': from_type,\n                            'to_land_use': to_type,\n                            'area_1000_acres': float(value)\n                        })\n\n    return transitions\n</code></pre>"},{"location":"data/processing/#processing-large-files","title":"Processing Large Files","text":"<p>For large JSON files, streaming processing is used:</p> <pre><code>import ijson\n\ndef process_large_json(json_path):\n    \"\"\"Stream process large JSON files.\"\"\"\n    with open(json_path, 'rb') as file:\n        parser = ijson.items(file, 'item')\n\n        for county_data in parser:\n            process_county(county_data)\n\n            # Batch insert for efficiency\n            if len(batch) &gt;= 10000:\n                insert_batch(batch)\n                batch = []\n</code></pre>"},{"location":"data/processing/#step-3-agricultural-aggregation","title":"Step 3: Agricultural Aggregation","text":""},{"location":"data/processing/#creating-combined-agriculture","title":"Creating Combined Agriculture","text":"<p><code>convert_landuse_with_agriculture.py</code> adds agricultural aggregation:</p> <pre><code>def aggregate_agriculture(transitions):\n    \"\"\"Combine Crop and Pasture into Agriculture.\"\"\"\n    ag_transitions = []\n\n    for t in transitions:\n        # Map individual categories to aggregated\n        from_ag = 'Agriculture' if t['from_land_use'] in ['Crop', 'Pasture'] else t['from_land_use']\n        to_ag = 'Agriculture' if t['to_land_use'] in ['Crop', 'Pasture'] else t['to_land_use']\n\n        # Find or create aggregated transition\n        key = (t['scenario'], t['year'], t['fips'], from_ag, to_ag)\n        # Sum areas for same aggregated transition\n</code></pre>"},{"location":"data/processing/#aggregation-logic","title":"Aggregation Logic","text":"<pre><code>-- Example: Combining crop and pasture transitions\n-- Original: Crop\u2192Urban (10) + Pasture\u2192Urban (5)\n-- Becomes: Agriculture\u2192Urban (15)\n\nINSERT INTO landuse_transitions_ag\nSELECT \n    scenario, year, year_range, fips,\n    CASE \n        WHEN from_land_use IN ('Crop', 'Pasture') THEN 'Agriculture'\n        ELSE from_land_use \n    END as from_land_use,\n    CASE \n        WHEN to_land_use IN ('Crop', 'Pasture') THEN 'Agriculture'\n        ELSE to_land_use \n    END as to_land_use,\n    SUM(area_1000_acres) as area_1000_acres\nFROM landuse_transitions\nGROUP BY scenario, year, year_range, fips, from_land_use, to_land_use;\n</code></pre>"},{"location":"data/processing/#step-4-creating-filtered-views","title":"Step 4: Creating Filtered Views","text":""},{"location":"data/processing/#change-only-views","title":"Change-Only Views","text":"<p><code>add_change_views.py</code> creates views excluding unchanged land:</p> <pre><code>CREATE VIEW landuse_changes_only AS\nSELECT * FROM landuse_transitions\nWHERE from_land_use != to_land_use\n  AND from_land_use != 'Total'\n  AND to_land_use != 'Total';\n\nCREATE VIEW landuse_changes_only_ag AS\nSELECT * FROM landuse_transitions_ag\nWHERE from_land_use != to_land_use\n  AND from_land_use != 'Total'\n  AND to_land_use != 'Total';\n</code></pre>"},{"location":"data/processing/#benefits-of-views","title":"Benefits of Views","text":"<ol> <li>Smaller datasets - Fewer rows to process</li> <li>Focused analysis - Only actual changes</li> <li>Better performance - Less data to scan</li> <li>Cleaner results - No diagonal values</li> </ol>"},{"location":"data/processing/#step-5-database-optimization","title":"Step 5: Database Optimization","text":""},{"location":"data/processing/#index-creation","title":"Index Creation","text":"<pre><code>-- Optimize common query patterns\nCREATE INDEX idx_scenario ON landuse_transitions(scenario);\nCREATE INDEX idx_year ON landuse_transitions(year);\nCREATE INDEX idx_fips ON landuse_transitions(fips);\nCREATE INDEX idx_from_to ON landuse_transitions(from_land_use, to_land_use);\n\n-- Composite indexes for complex queries\nCREATE INDEX idx_scenario_year_fips ON landuse_transitions(scenario, year, fips);\n</code></pre>"},{"location":"data/processing/#performance-statistics","title":"Performance Statistics","text":"<pre><code>-- Analyze table for query optimization\nANALYZE landuse_transitions;\n\n-- Check index usage\nEXPLAIN QUERY PLAN\nSELECT * FROM landuse_transitions\nWHERE scenario = 'Baseline' AND year = 2050;\n</code></pre>"},{"location":"data/processing/#quality-control","title":"Quality Control","text":""},{"location":"data/processing/#data-validation","title":"Data Validation","text":"<p>During processing, several checks ensure data quality:</p> <pre><code>def validate_transitions(transitions, fips, year):\n    \"\"\"Validate transition data integrity.\"\"\"\n\n    # Check 1: Total area should be consistent\n    total_from = sum(t['area'] for t in transitions if t['from'] != 'Total')\n    total_to = sum(t['area'] for t in transitions if t['to'] != 'Total')\n    assert abs(total_from - total_to) &lt; 0.01, f\"Area mismatch for {fips} in {year}\"\n\n    # Check 2: No negative areas\n    assert all(t['area'] &gt;= 0 for t in transitions), \"Negative area found\"\n\n    # Check 3: Valid land use categories\n    valid_categories = {'Crop', 'Pasture', 'Forest', 'Urban', 'Range', 'Total'}\n    assert all(t['from'] in valid_categories for t in transitions), \"Invalid category\"\n</code></pre>"},{"location":"data/processing/#error-handling","title":"Error Handling","text":"<pre><code>def process_county_safe(county_data):\n    \"\"\"Process with error handling.\"\"\"\n    try:\n        transitions = process_county(county_data)\n        validate_transitions(transitions)\n        return transitions\n    except Exception as e:\n        logger.error(f\"Error processing county {county_data.get('fips')}: {e}\")\n        return []\n</code></pre>"},{"location":"data/processing/#processing-performance","title":"Processing Performance","text":""},{"location":"data/processing/#optimization-techniques","title":"Optimization Techniques","text":"<ol> <li> <p>Batch Processing <pre><code># Insert in batches instead of one-by-one\ncursor.executemany(\n    \"INSERT INTO landuse_transitions VALUES (?,?,?,?,?,?,?)\",\n    batch_data\n)\n</code></pre></p> </li> <li> <p>Transaction Management <pre><code>conn.execute(\"BEGIN TRANSACTION\")\n# ... bulk inserts ...\nconn.execute(\"COMMIT\")\n</code></pre></p> </li> <li> <p>Memory Management <pre><code># Process in chunks for large files\nfor chunk in pd.read_json(file_path, chunksize=10000):\n    process_chunk(chunk)\n</code></pre></p> </li> </ol>"},{"location":"data/processing/#processing-statistics","title":"Processing Statistics","text":"<p>Typical processing performance: - Raw JSON size: ~500 MB - Processing time: 2-5 minutes - Final database size: ~200 MB - Row count: ~1.2 million transitions</p>"},{"location":"data/processing/#running-the-processors","title":"Running the Processors","text":""},{"location":"data/processing/#basic-conversion","title":"Basic Conversion","text":"<pre><code># Convert JSON to basic SQLite database\nuv run python scripts/converters/convert_landuse_to_db.py\n</code></pre>"},{"location":"data/processing/#with-agricultural-aggregation","title":"With Agricultural Aggregation","text":"<pre><code># Create database with ag aggregation\nuv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre>"},{"location":"data/processing/#add-views-to-existing-database","title":"Add Views to Existing Database","text":"<pre><code># Add filtered views\nuv run python scripts/converters/add_change_views.py\n</code></pre>"},{"location":"data/processing/#full-pipeline","title":"Full Pipeline","text":"<pre><code># Run complete processing pipeline\n./scripts/process_all.sh\n</code></pre>"},{"location":"data/processing/#customization-options","title":"Customization Options","text":""},{"location":"data/processing/#modifying-land-use-categories","title":"Modifying Land Use Categories","text":"<p>Edit the mapping in converter scripts:</p> <pre><code>LAND_USE_MAP = {\n    'cr': 'Cropland',      # Change names\n    'ps': 'Pasture',\n    'rg': 'Rangeland',     # Alternative naming\n    'fr': 'Forest',\n    'ur': 'Developed',     # Different term\n    'wt': 'Wetland'        # Add new category\n}\n</code></pre>"},{"location":"data/processing/#custom-aggregations","title":"Custom Aggregations","text":"<p>Create your own groupings:</p> <pre><code># Example: Natural vs Developed\nNATURAL_LANDS = ['Forest', 'Range', 'Wetland']\nDEVELOPED_LANDS = ['Urban', 'Infrastructure']\nAGRICULTURAL_LANDS = ['Crop', 'Pasture']\n</code></pre>"},{"location":"data/processing/#additional-processing","title":"Additional Processing","text":"<p>Add custom calculations during conversion:</p> <pre><code># Calculate net change during processing\nnet_change = area_new - area_original\n\n# Add percentage calculations\npercent_change = (net_change / area_original) * 100 if area_original &gt; 0 else 0\n</code></pre>"},{"location":"data/processing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"data/processing/#common-issues","title":"Common Issues","text":"<ol> <li>Memory Errors</li> <li>Use streaming processing</li> <li>Increase chunk size</li> <li> <p>Process by scenario</p> </li> <li> <p>Data Inconsistencies</p> </li> <li>Check total validations</li> <li>Review error logs</li> <li> <p>Verify source data</p> </li> <li> <p>Performance Problems</p> </li> <li>Add appropriate indexes</li> <li>Use batch operations</li> <li>Consider partitioning</li> </ol>"},{"location":"data/processing/#debugging-tools","title":"Debugging Tools","text":"<pre><code>-- Check for data issues\nSELECT fips, year, \n       SUM(area_1000_acres) as total,\n       COUNT(*) as transitions\nFROM landuse_transitions\nGROUP BY fips, year\nHAVING total &lt; 100  -- Suspiciously small counties\n    OR transitions &lt; 25;  -- Missing transitions\n</code></pre>"},{"location":"data/processing/#next-steps","title":"Next Steps","text":"<ul> <li>Understand the Database Schema</li> <li>Learn about Land Use Categories</li> <li>Start Querying the Data</li> <li>Explore API Documentation</li> </ul>"},{"location":"data/rpa-model-diagram/","title":"RPA Land Use Model Diagram","text":"<pre><code>graph LR\n    %% Data nodes (yellow ovals)\n    PRISM[\"PRISM Historical&lt;br/&gt;Climate\"]:::data\n    NetReturns[\"Net Returns to Land&lt;br/&gt;Production\"]:::data\n    SoilQuality[\"Soil Quality (NRI)\"]:::data\n    MACA[\"MACA Climate&lt;br/&gt;Projections\"]:::data\n    SSP[\"Downscaled SSP&lt;br/&gt;Projections\"]:::data\n\n    %% Ricardian Climate Functions box\n    subgraph RCF[\"Ricardian Climate Functions\"]\n        Forest[\"Forest\"]:::process\n        Crop[\"Crop\"]:::process\n        Urban[\"Urban\"]:::process\n    end\n\n    %% Process nodes (gray rectangles)\n    LandUseModel[\"Land-use&lt;br/&gt;Change Model\"]:::process\n\n    %% Output nodes (red hexagons)\n    ClimateParam[\"Climate&lt;br/&gt;Parameterized&lt;br/&gt;Net Returns\"]:::output\n    Transition[\"Transition&lt;br/&gt;Probability as&lt;br/&gt;Function of&lt;br/&gt;Climate / SSP\"]:::output\n    SimulatedChange[\"Simulated Land&lt;br/&gt;Area Change&lt;br/&gt;(Gross &amp; Net)\"]:::output\n\n    %% Simplified connections to the RCF box\n    PRISM --&gt; RCF\n    NetReturns --&gt; RCF\n    SoilQuality --&gt; RCF\n\n    %% Connections from RCF components to other nodes\n    Forest --&gt; ClimateParam\n    Crop --&gt; ClimateParam\n    Urban --&gt; ClimateParam\n\n    ClimateParam --&gt; LandUseModel\n    LandUseModel --&gt; Transition\n    MACA --&gt; Transition\n    SSP --&gt; Transition\n\n    Transition --&gt; SimulatedChange\n\n    %% Styling\n    classDef data fill:#ffecb3,stroke:#333,stroke-width:2px\n    classDef process fill:#e0e0e0,stroke:#333,stroke-width:2px\n    classDef output fill:#ffcdd2,stroke:#333,stroke-width:2px,shape:hexagon\n    style RCF fill:#fff5e6,stroke:#be9b3e,stroke-width:3px</code></pre> <p>This diagram represents the RPA Land Use Model's data flow and components, showing how various inputs like climate data and soil quality flow through the Ricardian Climate Functions and ultimately produce simulated land area changes. </p>"},{"location":"data/schema/","title":"Database Schema","text":"<p>This page documents the structure of the land use transitions database, including all tables, columns, and relationships.</p>"},{"location":"data/schema/#database-overview","title":"Database Overview","text":"<p>The SQLite database (<code>landuse_transitions_with_ag.db</code>) contains four main tables:</p> <pre><code>erDiagram\n    landuse_transitions {\n        TEXT scenario\n        INTEGER year\n        TEXT year_range\n        TEXT fips\n        TEXT from_land_use\n        TEXT to_land_use\n        REAL area_1000_acres\n    }\n\n    landuse_transitions_ag {\n        TEXT scenario\n        INTEGER year\n        TEXT year_range\n        TEXT fips\n        TEXT from_land_use\n        TEXT to_land_use\n        REAL area_1000_acres\n    }\n\n    landuse_changes_only {\n        TEXT scenario\n        INTEGER year\n        TEXT year_range\n        TEXT fips\n        TEXT from_land_use\n        TEXT to_land_use\n        REAL area_1000_acres\n    }\n\n    landuse_changes_only_ag {\n        TEXT scenario\n        INTEGER year\n        TEXT year_range\n        TEXT fips\n        TEXT from_land_use\n        TEXT to_land_use\n        REAL area_1000_acres\n    }</code></pre>"},{"location":"data/schema/#table-descriptions","title":"Table Descriptions","text":""},{"location":"data/schema/#1-landuse_transitions","title":"1. <code>landuse_transitions</code>","text":"<p>The main table containing all land use transitions, including same-to-same transitions (land that doesn't change use).</p> <p>Purpose: Complete transition matrix for all land uses</p> <p>Key Features: - Includes unchanged land (e.g., Forest \u2192 Forest) - Separates Crop and Pasture as distinct categories - Contains \"Total\" rows for validation</p>"},{"location":"data/schema/#2-landuse_transitions_ag","title":"2. <code>landuse_transitions_ag</code>","text":"<p>Same as <code>landuse_transitions</code> but with agricultural aggregation.</p> <p>Purpose: Simplified view with combined agricultural land</p> <p>Key Features: - Combines Crop + Pasture into \"Agriculture\" - Reduces complexity for agricultural analysis - Maintains all other land use categories</p>"},{"location":"data/schema/#3-landuse_changes_only","title":"3. <code>landuse_changes_only</code>","text":"<p>Filtered view excluding same-to-same transitions.</p> <p>Purpose: Focus on actual land use changes</p> <p>Key Features: - Excludes unchanged land (e.g., no Forest \u2192 Forest) - Smaller dataset for change analysis - Same schema as main table</p>"},{"location":"data/schema/#4-landuse_changes_only_ag","title":"4. <code>landuse_changes_only_ag</code>","text":"<p>Combines agricultural aggregation with change-only filtering.</p> <p>Purpose: Simplified change analysis with agricultural grouping</p> <p>Key Features: - Only actual changes - Agricultural land combined - Most focused view for policy analysis</p>"},{"location":"data/schema/#column-definitions","title":"Column Definitions","text":""},{"location":"data/schema/#core-columns-all-tables","title":"Core Columns (All Tables)","text":"Column Type Description Example <code>scenario</code> TEXT Projection scenario name \"Baseline\", \"High Crop Demand\" <code>year</code> INTEGER End year of the period 2050 <code>year_range</code> TEXT Time period of transition \"2040-2050\" <code>fips</code> TEXT County FIPS code \"06037\" (Los Angeles) <code>from_land_use</code> TEXT Original land use \"Forest\" <code>to_land_use</code> TEXT New land use \"Urban\" <code>area_1000_acres</code> REAL Area in thousands of acres 123.45"},{"location":"data/schema/#indexes","title":"Indexes","text":"<p>All tables have indexes on: - <code>scenario</code> - Fast filtering by scenario - <code>year</code> - Efficient time-based queries - <code>fips</code> - Quick county lookups</p>"},{"location":"data/schema/#data-relationships","title":"Data Relationships","text":""},{"location":"data/schema/#scenario-values","title":"Scenario Values","text":"<pre><code>-- Available scenarios\nSELECT DISTINCT scenario FROM landuse_transitions;\n</code></pre> <p>Common scenarios: - Baseline - Standard projections - High Crop Demand - Increased agricultural pressure - High Forest - Forest conservation emphasis - High Urban - Accelerated urbanization</p>"},{"location":"data/schema/#year-ranges","title":"Year Ranges","text":"<p>The data uses decade intervals:</p> year_range year (end) 2012-2020 2020 2020-2030 2030 2030-2040 2040 ... ... 2090-2100 2100"},{"location":"data/schema/#fips-code-structure","title":"FIPS Code Structure","text":"<p>FIPS codes identify counties: - First 2 digits: State (e.g., \"06\" = California) - Next 3 digits: County (e.g., \"037\" = Los Angeles) - Full code: \"06037\"</p>"},{"location":"data/schema/#land-use-categories","title":"Land Use Categories","text":""},{"location":"data/schema/#standard-categories","title":"Standard Categories","text":"Code Land Use Description Crop Cropland Agricultural land for crops Pasture Pasture Grazing land for livestock Forest Forest Forested areas Urban Urban Developed/built areas Range Range Rangeland/grassland Total Total Sum row/column (validation)"},{"location":"data/schema/#agricultural-aggregation","title":"Agricultural Aggregation","text":"<p>In <code>*_ag</code> tables: - Agriculture = Crop + Pasture - Reduces 6 categories to 5 - Simplifies agricultural analysis</p>"},{"location":"data/schema/#area-calculations","title":"Area Calculations","text":""},{"location":"data/schema/#understanding-area_1000_acres","title":"Understanding area_1000_acres","text":"<pre><code>-- Convert to acres\nactual_acres = area_1000_acres * 1000\n\n-- Convert to square miles  \nsquare_miles = area_1000_acres * 1000 / 640\n\n-- Convert to hectares\nhectares = area_1000_acres * 1000 * 0.404686\n</code></pre>"},{"location":"data/schema/#validation-queries","title":"Validation Queries","text":"<pre><code>-- Check total area consistency\nSELECT year, fips, SUM(area_1000_acres) as total_area\nFROM landuse_transitions\nWHERE from_land_use != 'Total'\n  AND to_land_use != 'Total'\nGROUP BY year, fips;\n\n-- Verify transitions balance\nSELECT year, \n       SUM(CASE WHEN from_land_use = 'Forest' THEN area_1000_acres ELSE 0 END) as forest_from,\n       SUM(CASE WHEN to_land_use = 'Forest' THEN area_1000_acres ELSE 0 END) as forest_to\nFROM landuse_transitions\nWHERE from_land_use != 'Total' AND to_land_use != 'Total'\nGROUP BY year;\n</code></pre>"},{"location":"data/schema/#query-patterns","title":"Query Patterns","text":""},{"location":"data/schema/#basic-transition-query","title":"Basic Transition Query","text":"<pre><code>-- Find specific transitions\nSELECT * FROM landuse_transitions\nWHERE from_land_use = 'Forest' \n  AND to_land_use = 'Urban'\n  AND scenario = 'Baseline';\n</code></pre>"},{"location":"data/schema/#aggregation-query","title":"Aggregation Query","text":"<pre><code>-- Total area by land use and year\nSELECT year, to_land_use, SUM(area_1000_acres) as total_area\nFROM landuse_transitions  \nWHERE from_land_use = to_land_use  -- Only unchanged land\n  AND to_land_use != 'Total'\nGROUP BY year, to_land_use;\n</code></pre>"},{"location":"data/schema/#change-analysis-query","title":"Change Analysis Query","text":"<pre><code>-- Net change in forest area\nSELECT year, \n       SUM(CASE WHEN to_land_use = 'Forest' THEN area_1000_acres \n                WHEN from_land_use = 'Forest' THEN -area_1000_acres \n                ELSE 0 END) as net_forest_change\nFROM landuse_changes_only\nGROUP BY year;\n</code></pre>"},{"location":"data/schema/#cross-scenario-comparison","title":"Cross-Scenario Comparison","text":"<pre><code>-- Compare scenarios\nSELECT scenario, SUM(area_1000_acres) as total_urban\nFROM landuse_transitions\nWHERE to_land_use = 'Urban' \n  AND from_land_use = to_land_use\n  AND year = 2050\nGROUP BY scenario;\n</code></pre>"},{"location":"data/schema/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use Appropriate Tables</li> <li>Full analysis: <code>landuse_transitions</code></li> <li>Change focus: <code>landuse_changes_only</code></li> <li> <p>Agricultural studies: <code>*_ag</code> tables</p> </li> <li> <p>Leverage Indexes</p> </li> <li>Filter by indexed columns first</li> <li> <p>Use scenario, year, fips in WHERE clauses</p> </li> <li> <p>Aggregate Wisely</p> </li> <li>Sum areas before calculating percentages</li> <li> <p>Group by fewer columns when possible</p> </li> <li> <p>Exclude Totals</p> </li> <li>Always exclude 'Total' land use in calculations</li> <li>Use <code>WHERE from_land_use != 'Total'</code></li> </ol>"},{"location":"data/schema/#data-quality-notes","title":"Data Quality Notes","text":"<ul> <li>Consistency: Total area per county should remain constant</li> <li>Completeness: All counties have data for all years/scenarios</li> <li>Validation: 'Total' rows/columns for cross-checking</li> <li>Precision: Areas in 1000-acre units for manageable numbers</li> </ul>"},{"location":"data/schema/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Land Use Categories in detail</li> <li>See Data Sources for data provenance</li> <li>Review Processing Steps for data pipeline</li> </ul>"},{"location":"data/sources/","title":"Data Sources","text":"<p>Understanding the origin, methodology, and reliability of the land use projection data.</p>"},{"location":"data/sources/#primary-data-source","title":"Primary Data Source","text":""},{"location":"data/sources/#rpa-land-use-projections","title":"RPA Land Use Projections","text":"<p>The data comes from the USDA Forest Service Resources Planning Act (RPA) Assessment, which provides long-term projections of land use change in the United States.</p> <p>Key Features: - County-level projections - Multiple scenarios - 2020-2100 timeframe - Decade intervals - All US counties included</p> <p>Citation: <pre><code>USDA Forest Service. (2024). Resources Planning Act (RPA) \nLand Use Projections. Fort Collins, CO: Rocky Mountain \nResearch Station.\n</code></pre></p>"},{"location":"data/sources/#projection-methodology","title":"Projection Methodology","text":""},{"location":"data/sources/#modeling-approach","title":"Modeling Approach","text":"<p>The RPA projections use an integrated assessment model that combines:</p> <ol> <li>Economic Drivers</li> <li>Population growth</li> <li>Income changes</li> <li>Commodity prices</li> <li> <p>Land values</p> </li> <li> <p>Policy Assumptions</p> </li> <li>Conservation programs</li> <li>Zoning regulations</li> <li>Agricultural subsidies</li> <li> <p>Environmental protections</p> </li> <li> <p>Biophysical Constraints</p> </li> <li>Soil quality</li> <li>Water availability</li> <li>Climate conditions</li> <li>Topography</li> </ol>"},{"location":"data/sources/#model-components","title":"Model Components","text":"<pre><code>graph LR\n    A[Economic Module] --&gt; D[Land Use Change Model]\n    B[Demographic Module] --&gt; D\n    C[Climate Module] --&gt; D\n    D --&gt; E[County Projections]\n    E --&gt; F[Scenario Outputs]</code></pre>"},{"location":"data/sources/#scenario-descriptions","title":"Scenario Descriptions","text":""},{"location":"data/sources/#baseline-scenario","title":"Baseline Scenario","text":"<p>Assumptions: - Moderate population growth - Historical economic trends continue - Current policies maintained - Average climate change impacts</p> <p>Key Characteristics: - Most likely future pathway - Balanced land use changes - Reference for comparisons</p>"},{"location":"data/sources/#high-crop-demand","title":"High Crop Demand","text":"<p>Assumptions: - Increased global food demand - Higher commodity prices - Agricultural expansion incentivized - Biofuel demand growth</p> <p>Expected Outcomes: - More forest/range \u2192 cropland - Pasture \u2192 crop conversion - Reduced natural lands</p>"},{"location":"data/sources/#high-forest","title":"High Forest","text":"<p>Assumptions: - Strong conservation policies - Carbon sequestration valued - Reduced deforestation - Afforestation programs</p> <p>Expected Outcomes: - Forest area maintained/increased - Limited agricultural expansion - More sustainable land use</p>"},{"location":"data/sources/#high-urban","title":"High Urban","text":"<p>Assumptions: - Accelerated population growth - Concentrated in metro areas - Higher development rates - Sprawl patterns continue</p> <p>Expected Outcomes: - Rapid urban expansion - Agricultural land loss - Forest fragmentation - Infrastructure demands</p>"},{"location":"data/sources/#data-processing-pipeline","title":"Data Processing Pipeline","text":""},{"location":"data/sources/#1-original-format","title":"1. Original Format","text":"<p>Raw data structure: <pre><code>{\n  \"county\": {\n    \"fips\": \"06037\",\n    \"name\": \"Los Angeles\",\n    \"scenarios\": {\n      \"Baseline\": {\n        \"2020-2030\": {\n          \"transitions\": [\n            {\"from\": \"cr\", \"to\": \"ur\", \"area\": 12.5},\n            ...\n          ]\n        }\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"data/sources/#2-conversion-process","title":"2. Conversion Process","text":"<p>The conversion scripts (<code>scripts/converters/</code>) transform this into:</p> <pre><code>-- Normalized relational format\nINSERT INTO landuse_transitions VALUES\n('Baseline', 2030, '2020-2030', '06037', 'Crop', 'Urban', 12.5);\n</code></pre>"},{"location":"data/sources/#3-data-enhancements","title":"3. Data Enhancements","text":"<p>Additional processing creates: - Agricultural aggregation views - Change-only filtered tables - Indexed columns for performance - Validation totals</p>"},{"location":"data/sources/#data-quality-and-limitations","title":"Data Quality and Limitations","text":""},{"location":"data/sources/#strengths","title":"Strengths","text":"<p>\u2705 Comprehensive Coverage - All US counties included - Consistent methodology - Multiple scenarios - Long time horizon</p> <p>\u2705 Scientific Basis - Peer-reviewed methods - Validated against historical data - Uncertainty quantified - Regular updates</p> <p>\u2705 Policy Relevance - Used for federal planning - Informs resource management - Scenario analysis capability</p>"},{"location":"data/sources/#limitations","title":"Limitations","text":"<p>\u26a0\ufe0f Spatial Resolution - County-level only - Sub-county variation lost - Edge effects possible - Urban detail limited</p> <p>\u26a0\ufe0f Temporal Resolution - Decade intervals - Annual variation smoothed - Sudden changes averaged - No seasonal data</p> <p>\u26a0\ufe0f Uncertainty - Future projections inherently uncertain - Economic assumptions may not hold - Climate impacts simplified - Policy changes unpredictable</p>"},{"location":"data/sources/#known-issues","title":"Known Issues","text":"<ol> <li>Urban Definition</li> <li>Includes all developed land</li> <li>Mixed-use areas simplified</li> <li> <p>Green space within cities included</p> </li> <li> <p>Agricultural Categories</p> </li> <li>Crop/pasture distinction sometimes blurred</li> <li>Rotation systems simplified</li> <li> <p>Specialty crops aggregated</p> </li> <li> <p>Edge Counties</p> </li> <li>Small counties may have rounding effects</li> <li>Cross-border influences not captured</li> <li>Island counties special cases</li> </ol>"},{"location":"data/sources/#validation-methods","title":"Validation Methods","text":""},{"location":"data/sources/#historical-validation","title":"Historical Validation","text":"<p>The model was validated against: - USDA Census of Agriculture - National Land Cover Database (NLCD) - Forest Inventory and Analysis (FIA) - Economic census data</p>"},{"location":"data/sources/#cross-validation","title":"Cross-Validation","text":"<pre><code>-- Check total area consistency\nSELECT fips, year, \n       SUM(area_1000_acres) as total_area,\n       COUNT(*) as transition_count\nFROM landuse_transitions\nWHERE from_land_use != 'Total'\nGROUP BY fips, year\nHAVING COUNT(DISTINCT total_area) &gt; 1;\n</code></pre>"},{"location":"data/sources/#scenario-consistency","title":"Scenario Consistency","text":"<pre><code>-- Verify scenario relationships\nSELECT scenario,\n       SUM(CASE WHEN to_land_use = 'Urban' THEN area_1000_acres END) as urban_total\nFROM landuse_transitions\nWHERE year = 2050\nGROUP BY scenario\nORDER BY urban_total;\n-- High Urban should have highest value\n</code></pre>"},{"location":"data/sources/#updates-and-versions","title":"Updates and Versions","text":""},{"location":"data/sources/#current-version","title":"Current Version","text":"<ul> <li>Data version: 2024 RPA Assessment</li> <li>Processing date: 2024</li> <li>Database format: SQLite 3</li> </ul>"},{"location":"data/sources/#update-cycle","title":"Update Cycle","text":"<ul> <li>RPA assessments every 10 years</li> <li>Interim updates for major changes</li> <li>Methodology improvements ongoing</li> </ul>"},{"location":"data/sources/#version-control","title":"Version Control","text":"<pre><code># Check data version\nSELECT * FROM metadata WHERE key = 'data_version';\n\n# Processing timestamp\nSELECT * FROM metadata WHERE key = 'processed_date';\n</code></pre>"},{"location":"data/sources/#related-datasets","title":"Related Datasets","text":""},{"location":"data/sources/#complementary-data-sources","title":"Complementary Data Sources","text":"<ol> <li>National Land Cover Database (NLCD)</li> <li>30m resolution land cover</li> <li>Historical validation</li> <li> <p>Urban detail</p> </li> <li> <p>Census of Agriculture</p> </li> <li>Farm-level data</li> <li>Crop specifics</li> <li> <p>Economic variables</p> </li> <li> <p>Forest Inventory Analysis (FIA)</p> </li> <li>Detailed forest data</li> <li>Species composition</li> <li>Management practices</li> </ol>"},{"location":"data/sources/#integration-opportunities","title":"Integration Opportunities","text":"<pre><code># Example: Combining with other data\nimport geopandas as gpd\n\n# Load county boundaries\ncounties = gpd.read_file('counties.shp')\n\n# Join with land use projections\nlanduse_2050 = query_database(\n    \"SELECT fips, SUM(area_1000_acres) as urban_area \"\n    \"FROM landuse_transitions \"\n    \"WHERE to_land_use = 'Urban' AND year = 2050 \"\n    \"GROUP BY fips\"\n)\n\n# Spatial analysis\ncounties_with_landuse = counties.merge(\n    landuse_2050, \n    left_on='GEOID', \n    right_on='fips'\n)\n</code></pre>"},{"location":"data/sources/#usage-rights-and-citation","title":"Usage Rights and Citation","text":""},{"location":"data/sources/#license","title":"License","text":"<ul> <li>Public domain data</li> <li>No usage restrictions</li> <li>Attribution appreciated</li> </ul>"},{"location":"data/sources/#recommended-citation","title":"Recommended Citation","text":"<pre><code>When using this data, please cite:\n\n[Your Project Name]. (2025). Land Use Transition Analysis \nusing RPA Projections. Based on USDA Forest Service RPA \nAssessment data.\n\nOriginal data: USDA Forest Service. (2024). 2020 RPA \nAssessment. Fort Collins, CO: RMRS.\n</code></pre>"},{"location":"data/sources/#acknowledgments","title":"Acknowledgments","text":"<p>This project builds upon the extensive work of: - USDA Forest Service researchers - RPA Assessment team - Land use modeling community</p>"},{"location":"data/sources/#data-access","title":"Data Access","text":""},{"location":"data/sources/#raw-data-location","title":"Raw Data Location","text":"<pre><code>data/raw/county_landuse_projections_RPA.json\n</code></pre>"},{"location":"data/sources/#processed-databases","title":"Processed Databases","text":"<pre><code>data/processed/landuse_transitions.db\ndata/processed/landuse_transitions_with_ag.db\n</code></pre>"},{"location":"data/sources/#query-access","title":"Query Access","text":"<pre><code># Direct database access\nimport sqlite3\nconn = sqlite3.connect('data/processed/landuse_transitions_with_ag.db')\n\n# Through the agent\nagent.run(\"Query the landuse database...\")\n</code></pre>"},{"location":"data/sources/#next-steps","title":"Next Steps","text":"<ul> <li>Review Database Schema for structure</li> <li>Understand Land Use Categories</li> <li>Learn about Processing Steps</li> <li>Start Querying Data</li> </ul>"},{"location":"data/variable-descriptions/","title":"Variable Descriptions","text":"<p>The following variables are found in the county land use projections data files.</p>"},{"location":"data/variable-descriptions/#rpa-scenario","title":"RPA Scenario","text":"<ul> <li>File: county_landuse_projections_RPA.*</li> <li>Units: Not applicable</li> <li>Precision: Not applicable</li> </ul> <p>RPA Scenarios are defined by Global Climate Model (GCM), Representative Concentration Pathway (RCP), and Shared Socioeconomic Pathway (SSP).</p>"},{"location":"data/variable-descriptions/#climate-models","title":"Climate Models:","text":"<ul> <li>CNRM_CM5: \"wet\" climate model</li> <li>HadGEM2_ES365: \"hot\" climate model</li> <li>IPSL_CM5A_MR: \"dry\" climate model</li> <li>MRI_CGCM3: \"least warm\" climate model</li> <li>NorESM1_M: \"middle\" climate model</li> </ul>"},{"location":"data/variable-descriptions/#rpa-scenario-combinations","title":"RPA Scenario Combinations:","text":"<ul> <li>rcp45_ssp1: Low emissions forcing, medium growth</li> <li>rcp85_ssp2: High emissions forcing, medium growth</li> <li>rcp85_ssp3: High emissions forcing, low growth</li> <li>rcp85_ssp5: High emissions forcing, high growth</li> </ul>"},{"location":"data/variable-descriptions/#time-step","title":"Time Step","text":"<ul> <li>File: county_landuse_projections_RPA.*</li> <li>Units: Years</li> <li>Precision: Integer</li> </ul> <p>Projections are made in 10-year time steps from 2020-2070. For completeness we have included an additional time step (2012-2020) that was used to calibrate the projections for use in subsequent modeling efforts as part of the 2020 RPA Assessment.</p>"},{"location":"data/variable-descriptions/#us-county-identifier","title":"U.S. County Identifier","text":"<ul> <li>File: county_landuse_projections_RPA.*</li> <li>Units: Not applicable</li> <li>Precision: Integer</li> </ul> <p>5 Digit FIPS (Federal Information Processing Standards) code.</p>"},{"location":"data/variable-descriptions/#6-x-6-transition-table","title":"[6 x 6 transition table]","text":"<ul> <li>File: county_landuse_projections_RPA.*</li> <li>Units: 100s of acres</li> <li>Precision: Double-Precision Floating-Point</li> </ul> <p>Area of land transitioned between land use categories: - cr: cropland - ps: pasture land - rg: rangeland - fr: forest land - ur: urban developed land - t1: total area of land in use category at starting year - t2: total area of land in use category at ending year </p>"},{"location":"development/BRANDING_STRATEGY/","title":"RPA Land Use Analytics - Branding Strategy","text":""},{"location":"development/BRANDING_STRATEGY/#project-name","title":"Project Name","text":"<p>RPA Land Use Analytics An AI-powered analysis tool for USDA Forest Service RPA Assessment data</p>"},{"location":"development/BRANDING_STRATEGY/#branding-elements","title":"Branding Elements","text":""},{"location":"development/BRANDING_STRATEGY/#primary-name-options","title":"Primary Name Options","text":"<ol> <li>RPA Land Use Analytics (Recommended)</li> <li>Clear connection to RPA Assessment</li> <li>Descriptive of functionality</li> <li> <p>Professional and government-appropriate</p> </li> <li> <p>RPA Assessment Explorer</p> </li> <li>Emphasizes exploration capabilities</li> <li> <p>Direct tie to source data</p> </li> <li> <p>Forest &amp; Rangeland Analytics</p> </li> <li>Broader appeal</li> <li>Matches RPA Assessment subtitle</li> </ol>"},{"location":"development/BRANDING_STRATEGY/#tagline","title":"Tagline","text":"<p>\"Transforming America's land use data into actionable insights\"</p>"},{"location":"development/BRANDING_STRATEGY/#visual-identity","title":"Visual Identity","text":""},{"location":"development/BRANDING_STRATEGY/#color-palette","title":"Color Palette","text":"<p>Based on USDA Forest Service branding: - Primary Green: #2E7D32 (Forest green) - Secondary Blue: #1976D2 (Sky blue for water resources) - Accent Brown: #6D4C41 (Earth/soil tone) - Neutral Gray: #424242 (Text and UI elements) - Background: #FAFAFA (Light gray/white)</p>"},{"location":"development/BRANDING_STRATEGY/#typography","title":"Typography","text":"<ul> <li>Headers: Inter or Roboto (clean, modern, accessible)</li> <li>Body: Open Sans or Source Sans Pro</li> <li>Monospace: Fira Code or JetBrains Mono (for code/queries)</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#logo-concept","title":"Logo Concept","text":"<ul> <li>Simple tree/forest icon combined with data visualization elements</li> <li>Could incorporate chart bars growing like trees</li> <li>Keep it minimal and professional for government context</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#implementation-areas","title":"Implementation Areas","text":""},{"location":"development/BRANDING_STRATEGY/#1-streamlit-dashboard","title":"1. Streamlit Dashboard","text":"<ul> <li>Custom theme with brand colors</li> <li>Header with logo and project name</li> <li>Consistent color use in charts (Plotly)</li> <li>Professional sidebar styling</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#2-command-line-interface","title":"2. Command Line Interface","text":"<ul> <li>ASCII art logo for terminal</li> <li>Colored output matching brand palette (using Rich)</li> <li>Consistent header/footer branding</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#3-documentation","title":"3. Documentation","text":"<ul> <li>README with branded header</li> <li>Consistent use of project name</li> <li>Professional screenshots with branding visible</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#4-code-structure","title":"4. Code Structure","text":"<ul> <li>Update package name from <code>landuse</code> to <code>rpa_landuse</code></li> <li>Consistent module naming</li> <li>Clear attribution to USDA Forest Service data</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#key-messages","title":"Key Messages","text":""},{"location":"development/BRANDING_STRATEGY/#for-users","title":"For Users","text":"<ul> <li>\"Official analytics tool for RPA Assessment data\"</li> <li>\"Ask questions in plain English, get data-driven answers\"</li> <li>\"Explore 50-year projections across climate scenarios\"</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#technical-positioning","title":"Technical Positioning","text":"<ul> <li>Built on modern data stack (DuckDB, LangChain)</li> <li>AI-powered natural language interface</li> <li>Open source and extensible</li> </ul>"},{"location":"development/BRANDING_STRATEGY/#attribution-requirements","title":"Attribution Requirements","text":"<p>Always include: - \"Data source: USDA Forest Service 2020 RPA Assessment\" - Link to official RPA Assessment: https://www.fs.usda.gov/research/rpa - Proper citations per RPA documentation</p>"},{"location":"development/BRANDING_STRATEGY/#next-steps","title":"Next Steps","text":"<ol> <li>Update pyproject.toml with new name</li> <li>Create logo assets</li> <li>Implement Streamlit custom theme</li> <li>Update CLI with Rich formatting</li> <li>Revise all documentation</li> </ol>"},{"location":"development/architecture/","title":"System Architecture","text":"<p>Understanding the technical architecture of the LangChain Land Use Analysis system.</p>"},{"location":"development/architecture/#overview","title":"Overview","text":"<p>The system follows a modular architecture that separates data processing, storage, and natural language interaction into distinct layers.</p> <pre><code>graph TB\n    subgraph \"User Interface\"\n        CLI[CLI Interface]\n        API[Python API]\n    end\n\n    subgraph \"LangChain Layer\"\n        Agent[Data Engineering Agent]\n        Memory[Conversation Memory]\n        Tools[Tool Collection]\n    end\n\n    subgraph \"Processing Layer\"\n        Converters[Data Converters]\n        Validators[Data Validators]\n        Optimizers[Query Optimizers]\n    end\n\n    subgraph \"Data Layer\"\n        JSON[JSON Files]\n        SQLite[SQLite Databases]\n        Parquet[Parquet Files]\n    end\n\n    CLI --&gt; Agent\n    API --&gt; Agent\n    Agent --&gt; Memory\n    Agent --&gt; Tools\n    Tools --&gt; Converters\n    Tools --&gt; Validators\n    Tools --&gt; Optimizers\n    Converters --&gt; JSON\n    Converters --&gt; SQLite\n    Tools --&gt; SQLite\n    Tools --&gt; Parquet</code></pre>"},{"location":"development/architecture/#component-architecture","title":"Component Architecture","text":""},{"location":"development/architecture/#1-user-interface-layer","title":"1. User Interface Layer","text":"<p>CLI Interface (<code>test_agent.py</code>) - Rich terminal UI - Interactive chat loop - Progress indicators - Syntax highlighting</p> <p>Python API - Programmatic access - Batch processing - Integration points</p>"},{"location":"development/architecture/#2-langchain-layer","title":"2. LangChain Layer","text":"<p>Data Engineering Agent <pre><code>class DataEngineeringAgent:\n    def __init__(self, root_dir: str = None):\n        self.llm = ChatOpenAI(...)\n        self.memory = MemorySaver()\n        self.tools = self._create_tools()\n        self.agent = self._create_agent()\n</code></pre></p> <p>Key Components: - LLM Integration: OpenAI GPT models - Memory System: Conversation context retention - Tool Registry: Dynamic tool loading - Prompt Engineering: Structured prompts</p>"},{"location":"development/architecture/#3-tool-system","title":"3. Tool System","text":"<p>Tool Architecture: <pre><code>Tool(\n    name=\"tool_name\",\n    func=implementation_function,\n    description=\"Natural language description\",\n    args_schema=PydanticModel  # Optional\n)\n</code></pre></p> <p>Tool Categories: - File Operations - Data Analysis - SQL Execution - Format Conversion - Visualization</p>"},{"location":"development/architecture/#4-data-processing-layer","title":"4. Data Processing Layer","text":"<p>Converter Pipeline: <pre><code>Raw JSON \u2192 Parser \u2192 Transformer \u2192 Validator \u2192 Database\n</code></pre></p> <p>Processing Steps: 1. Parsing: Extract nested JSON structure 2. Transformation: Normalize to relational format 3. Aggregation: Create derived views 4. Optimization: Add indexes and statistics</p>"},{"location":"development/architecture/#5-storage-layer","title":"5. Storage Layer","text":"<p>Database Design: <pre><code>-- Core tables\nlanduse_transitions\nlanduse_transitions_ag\n\n-- Filtered views\nlanduse_changes_only\nlanduse_changes_only_ag\n\n-- Indexes for performance\nidx_scenario, idx_year, idx_fips\n</code></pre></p>"},{"location":"development/architecture/#data-flow-architecture","title":"Data Flow Architecture","text":""},{"location":"development/architecture/#query-processing-flow","title":"Query Processing Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Agent\n    participant LLM\n    participant Tools\n    participant Database\n\n    User-&gt;&gt;Agent: Natural language query\n    Agent-&gt;&gt;LLM: Parse intent\n    LLM-&gt;&gt;Agent: Structured request\n    Agent-&gt;&gt;Tools: Execute tool\n    Tools-&gt;&gt;Database: SQL query\n    Database-&gt;&gt;Tools: Results\n    Tools-&gt;&gt;Agent: Formatted data\n    Agent-&gt;&gt;User: Natural language response</code></pre>"},{"location":"development/architecture/#memory-architecture","title":"Memory Architecture","text":"<p>The agent uses LangGraph's MemorySaver for context:</p> <pre><code># Memory stores:\n- Conversation history\n- Previous query results\n- User preferences\n- Context markers\n</code></pre>"},{"location":"development/architecture/#technical-stack","title":"Technical Stack","text":""},{"location":"development/architecture/#core-dependencies","title":"Core Dependencies","text":"Component Technology Purpose LLM Framework LangChain 0.3+ Agent orchestration LLM Provider OpenAI GPT-4 Natural language understanding Database SQLite 3 Local data storage Query Engine DuckDB SQL on files Data Processing Pandas 2.2+ Data manipulation CLI Rich 14+ Terminal interface Validation Pydantic 2+ Data validation"},{"location":"development/architecture/#file-processing-stack","title":"File Processing Stack","text":"<pre><code># JSON Processing\n- ijson: Streaming large files\n- json: Standard library\n\n# Tabular Data\n- pandas: DataFrames\n- pyarrow: Parquet support\n- openpyxl: Excel files\n\n# Geospatial\n- geopandas: Spatial data\n- Parquet: GeoParquet format\n</code></pre>"},{"location":"development/architecture/#security-architecture","title":"Security Architecture","text":""},{"location":"development/architecture/#api-key-management","title":"API Key Management","text":"<pre><code># Environment-based configuration\nload_dotenv(dotenv_path=\"config/.env\")\n\n# Never in code\napi_key = os.getenv(\"OPENAI_API_KEY\")\n</code></pre>"},{"location":"development/architecture/#file-access-control","title":"File Access Control","text":"<pre><code># Restricted to root directory\nself.root_dir = root_dir or \"./data\"\n\n# Path validation\nfull_path = Path(self.root_dir) / file_path\nif not full_path.resolve().is_relative_to(self.root_dir):\n    raise SecurityError(\"Path traversal detected\")\n</code></pre>"},{"location":"development/architecture/#query-safety","title":"Query Safety","text":"<ul> <li>SQL injection prevention via parameterization</li> <li>File path sanitization</li> <li>Size limits on operations</li> </ul>"},{"location":"development/architecture/#performance-architecture","title":"Performance Architecture","text":""},{"location":"development/architecture/#optimization-strategies","title":"Optimization Strategies","text":"<ol> <li>Query Optimization</li> <li>Index usage</li> <li>Query plan analysis</li> <li> <p>Result limiting</p> </li> <li> <p>Memory Management</p> </li> <li>Streaming for large files</li> <li>Chunk processing</li> <li> <p>Garbage collection</p> </li> <li> <p>Caching</p> </li> <li>15-minute web fetch cache</li> <li>Query result caching</li> <li>Schema caching</li> </ol>"},{"location":"development/architecture/#scalability-considerations","title":"Scalability Considerations","text":"<pre><code># Chunked processing\nCHUNK_SIZE = 10000\n\n# Parallel processing potential\nfrom concurrent.futures import ThreadPoolExecutor\n\n# Database partitioning\n# Could partition by year or scenario\n</code></pre>"},{"location":"development/architecture/#extension-architecture","title":"Extension Architecture","text":""},{"location":"development/architecture/#adding-new-tools","title":"Adding New Tools","text":"<pre><code>class CustomAgent(DataEngineeringAgent):\n    def _create_tools(self):\n        tools = super()._create_tools()\n        tools.append(self._create_custom_tool())\n        return tools\n\n    def _create_custom_tool(self):\n        return Tool(\n            name=\"custom_tool\",\n            func=self._custom_implementation,\n            description=\"Custom functionality\"\n        )\n</code></pre>"},{"location":"development/architecture/#plugin-system-potential","title":"Plugin System Potential","text":"<pre><code># Future: Dynamic tool loading\ndef load_tools_from_plugins():\n    plugin_dir = Path(\"plugins\")\n    for plugin_file in plugin_dir.glob(\"*.py\"):\n        module = import_module(plugin_file.stem)\n        if hasattr(module, \"create_tools\"):\n            tools.extend(module.create_tools())\n</code></pre>"},{"location":"development/architecture/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"development/architecture/#local-deployment","title":"Local Deployment","text":"<pre><code># Current: Single-user local\npython scripts/agents/test_agent.py\n</code></pre>"},{"location":"development/architecture/#server-deployment-potential","title":"Server Deployment Potential","text":"<pre><code># Future: Multi-user server\nfrom fastapi import FastAPI\nfrom celery import Celery\n\napp = FastAPI()\ncelery = Celery()\n\n@app.post(\"/query\")\nasync def query(request: QueryRequest):\n    task = celery.send_task(\"process_query\", args=[request])\n    return {\"task_id\": task.id}\n</code></pre>"},{"location":"development/architecture/#container-architecture","title":"Container Architecture","text":"<pre><code># Potential Dockerfile\nFROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY . .\nCMD [\"python\", \"scripts/agents/test_agent.py\"]\n</code></pre>"},{"location":"development/architecture/#monitoring-architecture","title":"Monitoring Architecture","text":""},{"location":"development/architecture/#logging-structure","title":"Logging Structure","text":"<pre><code>import logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('agent.log'),\n        logging.StreamHandler()\n    ]\n)\n</code></pre>"},{"location":"development/architecture/#metrics-collection","title":"Metrics Collection","text":"<pre><code># Future: Metrics tracking\nmetrics = {\n    \"queries_processed\": Counter(),\n    \"query_duration\": Histogram(),\n    \"tool_usage\": Counter(),\n    \"error_rate\": Rate()\n}\n</code></pre>"},{"location":"development/architecture/#health-checks","title":"Health Checks","text":"<pre><code>def health_check():\n    checks = {\n        \"database\": check_database_connection(),\n        \"llm\": check_llm_availability(),\n        \"disk_space\": check_disk_space(),\n        \"memory\": check_memory_usage()\n    }\n    return all(checks.values())\n</code></pre>"},{"location":"development/architecture/#error-handling-architecture","title":"Error Handling Architecture","text":""},{"location":"development/architecture/#layered-error-handling","title":"Layered Error Handling","text":"<pre><code># Level 1: Tool-level errors\ntry:\n    result = execute_tool()\nexcept SpecificError as e:\n    return handle_specific_error(e)\n\n# Level 2: Agent-level errors\ntry:\n    response = agent.run(query)\nexcept AgentError as e:\n    return fallback_response(e)\n\n# Level 3: System-level errors\ntry:\n    start_system()\nexcept SystemError as e:\n    log_and_alert(e)\n</code></pre>"},{"location":"development/architecture/#testing-architecture","title":"Testing Architecture","text":""},{"location":"development/architecture/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/\n\u2502   \u251c\u2500\u2500 test_converters.py\n\u2502   \u251c\u2500\u2500 test_tools.py\n\u2502   \u2514\u2500\u2500 test_agent.py\n\u251c\u2500\u2500 integration/\n\u2502   \u251c\u2500\u2500 test_database_queries.py\n\u2502   \u2514\u2500\u2500 test_full_pipeline.py\n\u2514\u2500\u2500 e2e/\n    \u2514\u2500\u2500 test_user_workflows.py\n</code></pre>"},{"location":"development/architecture/#test-data-management","title":"Test Data Management","text":"<pre><code># Fixtures for testing\n@pytest.fixture\ndef sample_database():\n    # Create test database\n    return test_db_path\n\n@pytest.fixture\ndef mock_llm():\n    # Mock LLM responses\n    return MockLLM()\n</code></pre>"},{"location":"development/architecture/#future-architecture-considerations","title":"Future Architecture Considerations","text":""},{"location":"development/architecture/#microservices-potential","title":"Microservices Potential","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Query     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Agent     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502    Data     \u2502\n\u2502  Service    \u2502     \u2502  Service    \u2502     \u2502  Service    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"development/architecture/#event-driven-architecture","title":"Event-Driven Architecture","text":"<pre><code># Future: Event-based processing\nclass EventBus:\n    def publish(self, event: Event):\n        for handler in self.handlers[event.type]:\n            handler.handle(event)\n\n# Query events, completion events, error events\n</code></pre>"},{"location":"development/architecture/#multi-model-support","title":"Multi-Model Support","text":"<pre><code># Future: Multiple LLM providers\nclass ModelRouter:\n    def route_query(self, query):\n        if is_complex_sql(query):\n            return self.gpt4_model\n        else:\n            return self.gpt35_model\n</code></pre>"},{"location":"development/architecture/#best-practices","title":"Best Practices","text":"<ol> <li>Separation of Concerns</li> <li>Keep data processing separate from UI</li> <li>Isolate LLM interactions</li> <li> <p>Modular tool design</p> </li> <li> <p>Error Boundaries</p> </li> <li>Handle errors at appropriate levels</li> <li>Provide meaningful feedback</li> <li> <p>Graceful degradation</p> </li> <li> <p>Performance First</p> </li> <li>Design for large datasets</li> <li>Optimize critical paths</li> <li> <p>Monitor resource usage</p> </li> <li> <p>Extensibility</p> </li> <li>Plugin-friendly architecture</li> <li>Clear extension points</li> <li>Documented interfaces</li> </ol>"},{"location":"development/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Review Contributing Guide for development</li> <li>See Testing Guide for quality assurance</li> <li>Check API Reference for implementation details</li> </ul>"},{"location":"development/ci-cd-pipeline/","title":"CI/CD Pipeline Documentation","text":"<p>This document describes the comprehensive CI/CD pipeline implemented for the landuse project using GitHub Actions.</p>"},{"location":"development/ci-cd-pipeline/#overview","title":"Overview","text":"<p>The CI/CD pipeline provides automated testing, security scanning, performance monitoring, documentation building, and release management. It ensures code quality, security, and reliability while enabling rapid development and deployment.</p>"},{"location":"development/ci-cd-pipeline/#pipeline-components","title":"Pipeline Components","text":""},{"location":"development/ci-cd-pipeline/#1-continuous-integration-ciyml","title":"1. Continuous Integration (<code>ci.yml</code>)","text":"<p>Triggers: - Push to <code>main</code> or <code>develop</code> branches - Pull requests to <code>main</code> or <code>develop</code> branches</p> <p>Matrix Testing: - Python 3.11 and 3.12 - Ubuntu Linux environment</p> <p>Steps: 1. Environment Setup    - Checkout code    - Install Python and uv    - Cache dependencies for faster builds    - Install project dependencies</p> <ol> <li>Code Quality Checks</li> <li>Linting: <code>ruff check</code> for code style and potential issues</li> <li> <p>Type Checking: <code>mypy</code> for static type analysis</p> </li> <li> <p>Testing</p> </li> <li>Unit and integration tests with <code>pytest</code></li> <li>Code coverage analysis with minimum 50% threshold</li> <li> <p>Test result artifacts and coverage reports</p> </li> <li> <p>Artifacts</p> </li> <li>Coverage reports (HTML and XML)</li> <li>Security scan results</li> <li>Test artifacts</li> </ol>"},{"location":"development/ci-cd-pipeline/#2-security-scanning-securityyml","title":"2. Security Scanning (<code>security.yml</code>)","text":"<p>Triggers: - Push to <code>main</code> or <code>develop</code> branches - Pull requests to <code>main</code> or <code>develop</code> branches - Daily scheduled scans at 2 AM UTC</p> <p>Security Checks:</p>"},{"location":"development/ci-cd-pipeline/#dependency-scanning","title":"Dependency Scanning","text":"<ul> <li>Safety: Check for known vulnerabilities in dependencies</li> <li>pip-audit: Additional vulnerability scanning</li> <li>Reports generated in JSON format</li> </ul>"},{"location":"development/ci-cd-pipeline/#code-analysis","title":"Code Analysis","text":"<ul> <li>Bandit: Python security linter for common security issues</li> <li>Semgrep: Advanced static analysis with security rules</li> <li>SARIF output for GitHub Security tab integration</li> </ul>"},{"location":"development/ci-cd-pipeline/#secrets-detection","title":"Secrets Detection","text":"<ul> <li>TruffleHog: Scan for committed secrets and credentials</li> <li>Verified secrets detection only</li> </ul>"},{"location":"development/ci-cd-pipeline/#license-compliance","title":"License Compliance","text":"<ul> <li>pip-licenses: Check dependency licenses</li> <li>Alert on GPL licenses that might conflict with MIT</li> <li>Generate license compatibility reports</li> </ul>"},{"location":"development/ci-cd-pipeline/#3-performance-testing-performanceyml","title":"3. Performance Testing (<code>performance.yml</code>)","text":"<p>Triggers: - Push to <code>main</code> or <code>develop</code> branches - Pull requests to <code>main</code> or <code>develop</code> branches - Weekly scheduled runs on Sundays at 3 AM UTC</p> <p>Performance Tests:</p>"},{"location":"development/ci-cd-pipeline/#duckdb-benchmarking","title":"DuckDB Benchmarking","text":"<ul> <li>Bulk loading performance tests</li> <li>Traditional INSERT vs COPY command comparison</li> <li>Performance regression detection</li> <li>Detailed timing and throughput metrics</li> </ul>"},{"location":"development/ci-cd-pipeline/#memory-profiling","title":"Memory Profiling","text":"<ul> <li>Memory usage analysis with <code>memory-profiler</code></li> <li>Bulk loading memory consumption</li> <li>Connection pooling memory efficiency</li> </ul>"},{"location":"development/ci-cd-pipeline/#load-testing","title":"Load Testing","text":"<ul> <li>Concurrent query simulation</li> <li>Response time analysis</li> <li>Performance threshold monitoring</li> <li>Regression detection and alerting</li> </ul>"},{"location":"development/ci-cd-pipeline/#4-documentation-documentationyml","title":"4. Documentation (<code>documentation.yml</code>)","text":"<p>Triggers: - Push to <code>main</code> branch (docs changes) - Pull requests affecting documentation - Changes to <code>docs/</code>, <code>mkdocs.yml</code>, <code>README.md</code>, or <code>CLAUDE.md</code></p> <p>Documentation Workflow:</p>"},{"location":"development/ci-cd-pipeline/#build-and-deploy","title":"Build and Deploy","text":"<ul> <li>MkDocs Build: Generate static documentation site</li> <li>Link Checking: Validate internal and external links</li> <li>GitHub Pages: Automatic deployment to GitHub Pages</li> </ul>"},{"location":"development/ci-cd-pipeline/#quality-assessment","title":"Quality Assessment","text":"<ul> <li>Readability Analysis: Flesch reading ease scores</li> <li>Writing Quality: Grammar and style checking</li> <li>Issue Detection: Find TODO items and broken links</li> <li>PR Comments: Automated quality reports on pull requests</li> </ul>"},{"location":"development/ci-cd-pipeline/#5-release-management-releaseyml","title":"5. Release Management (<code>release.yml</code>)","text":"<p>Triggers: - Git tags starting with <code>v</code> (e.g., <code>v1.0.0</code>) - Manual workflow dispatch with version input</p> <p>Release Process:</p>"},{"location":"development/ci-cd-pipeline/#pre-release-testing","title":"Pre-Release Testing","text":"<ul> <li>Full test suite execution</li> <li>Minimum 70% code coverage requirement</li> <li>All quality checks must pass</li> </ul>"},{"location":"development/ci-cd-pipeline/#build-artifacts","title":"Build Artifacts","text":"<ul> <li>Python Package: Build wheel and source distribution</li> <li>Documentation: Generate complete documentation site</li> <li>Artifacts: Upload all build outputs</li> </ul>"},{"location":"development/ci-cd-pipeline/#release-creation","title":"Release Creation","text":"<ul> <li>GitHub Release: Automatic release creation</li> <li>Changelog: Extract relevant changelog sections</li> <li>Assets: Attach wheel and source distribution</li> <li>Pre-release Detection: Automatic detection of alpha/beta/rc versions</li> </ul>"},{"location":"development/ci-cd-pipeline/#configuration-files","title":"Configuration Files","text":""},{"location":"development/ci-cd-pipeline/#1-dependabot-dependabotyml","title":"1. Dependabot (<code>dependabot.yml</code>)","text":"<p>Automated Dependency Management: - Python Dependencies: Weekly updates on Mondays - GitHub Actions: Weekly updates on Mondays - PR Limits: 10 for Python, 5 for Actions - Automatic Labels: Dependencies and language tags - Team Assignment: Auto-assign to landuse-team</p>"},{"location":"development/ci-cd-pipeline/#2-issue-templates","title":"2. Issue Templates","text":""},{"location":"development/ci-cd-pipeline/#bug-report-bug_reportyml","title":"Bug Report (<code>bug_report.yml</code>)","text":"<ul> <li>Structured bug reporting form</li> <li>Environment and reproduction details</li> <li>Component and severity classification</li> <li>Contact information and additional context</li> </ul>"},{"location":"development/ci-cd-pipeline/#feature-request-feature_requestyml","title":"Feature Request (<code>feature_request.yml</code>)","text":"<ul> <li>Feature suggestion template</li> <li>Problem description and proposed solution</li> <li>Use case documentation</li> <li>Implementation ideas and contribution offers</li> </ul>"},{"location":"development/ci-cd-pipeline/#3-pull-request-template-pull_request_templatemd","title":"3. Pull Request Template (<code>pull_request_template.md</code>)","text":"<p>Comprehensive PR Checklist: - Change type classification - Related issues linking - Testing requirements - Documentation updates - Performance and security considerations - Review guidance and focus areas</p>"},{"location":"development/ci-cd-pipeline/#environment-configuration","title":"Environment Configuration","text":""},{"location":"development/ci-cd-pipeline/#required-environment-variables","title":"Required Environment Variables","text":"<p>Basic Configuration: <pre><code>LANDUSE_MODEL=gpt-4o-mini\nTEMPERATURE=0.1\nMAX_TOKENS=1000\n</code></pre></p> <p>CI-Specific Variables: <pre><code># Test environment\nLANDUSE_DB_PATH=data/processed/landuse_analytics.duckdb\nLANDUSE_MAX_QUERY_ROWS=1000\nLANDUSE_DEFAULT_DISPLAY_LIMIT=50\n</code></pre></p>"},{"location":"development/ci-cd-pipeline/#secrets-management","title":"Secrets Management","text":"<p>Required GitHub Secrets: - <code>GITHUB_TOKEN</code>: Automatic token for releases and actions - <code>CODECOV_TOKEN</code>: For coverage report uploads (optional)</p> <p>API Keys (for integration tests): - API keys should be stored as GitHub secrets - Use minimal permissions and test-specific keys - Rotate keys regularly</p>"},{"location":"development/ci-cd-pipeline/#quality-gates","title":"Quality Gates","text":""},{"location":"development/ci-cd-pipeline/#code-quality-standards","title":"Code Quality Standards","text":"<p>Linting Requirements: - Ruff: No linting errors allowed - Style: Consistent code formatting - Complexity: Maximum cyclomatic complexity limits</p> <p>Type Checking: - MyPy: Type hints validation (advisory) - Coverage: Gradual improvement of type coverage</p>"},{"location":"development/ci-cd-pipeline/#testing-requirements","title":"Testing Requirements","text":"<p>Coverage Thresholds: - Minimum: 50% for CI (allowing incremental improvement) - Target: 70% for releases - Trend: Must not decrease significantly</p> <p>Test Types: - Unit Tests: Fast, isolated component tests - Integration Tests: End-to-end functionality tests - Performance Tests: Regression detection tests</p>"},{"location":"development/ci-cd-pipeline/#security-standards","title":"Security Standards","text":"<p>Vulnerability Management: - Critical/High: Must be addressed before merge - Medium: Should be addressed in next release - Low: Can be tracked as technical debt</p> <p>Secret Management: - No Secrets: Never commit secrets to repository - Detection: Automated scanning with TruffleHog - Rotation: Regular API key rotation</p>"},{"location":"development/ci-cd-pipeline/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"development/ci-cd-pipeline/#benchmark-tracking","title":"Benchmark Tracking","text":"<p>DuckDB Operations: - Bulk loading performance metrics - Query response times - Memory usage patterns</p> <p>Regression Detection: - Thresholds: 20% performance degradation triggers alert - Trending: Track performance over time - Reporting: Automated performance reports</p>"},{"location":"development/ci-cd-pipeline/#load-testing_1","title":"Load Testing","text":"<p>Concurrent Operations: - Database connection pooling - Query execution under load - Memory usage under stress</p> <p>Thresholds: - Average response time: &lt; 5 seconds - Maximum response time: &lt; 10 seconds - Memory usage: Within system limits</p>"},{"location":"development/ci-cd-pipeline/#deployment-strategy","title":"Deployment Strategy","text":""},{"location":"development/ci-cd-pipeline/#branching-strategy","title":"Branching Strategy","text":"<p>Main Branches: - <code>main</code>: Production-ready code - <code>develop</code>: Integration branch for features</p> <p>Feature Branches: - <code>feature/*</code>: New features and enhancements - <code>bugfix/*</code>: Bug fixes - <code>hotfix/*</code>: Critical production fixes</p>"},{"location":"development/ci-cd-pipeline/#release-process","title":"Release Process","text":"<p>Versioning: - Semantic Versioning: MAJOR.MINOR.PATCH - Pre-releases: alpha, beta, rc suffixes - Tags: Git tags trigger automated releases</p> <p>Release Notes: - Automated: Extract from CHANGELOG.md - Manual: Override with workflow dispatch - Assets: Include built packages and documentation</p>"},{"location":"development/ci-cd-pipeline/#monitoring-and-alerting","title":"Monitoring and Alerting","text":""},{"location":"development/ci-cd-pipeline/#github-integration","title":"GitHub Integration","text":"<p>Status Checks: - All CI workflows must pass for merge - Security scans must not have critical issues - Documentation must build successfully</p> <p>Notifications: - Failed workflows notify team - Security alerts escalated immediately - Performance regressions flagged for review</p>"},{"location":"development/ci-cd-pipeline/#artifact-management","title":"Artifact Management","text":"<p>Storage: - Test results and coverage reports - Security scan outputs - Performance benchmarks - Documentation builds</p> <p>Retention: - Artifacts retained for 30 days - Release assets permanent - Security reports archived</p>"},{"location":"development/ci-cd-pipeline/#local-development","title":"Local Development","text":""},{"location":"development/ci-cd-pipeline/#pre-commit-setup","title":"Pre-commit Setup","text":"<p>Install Pre-commit Hooks: <pre><code># Install pre-commit\nuv add --dev pre-commit\n\n# Install hooks\nuv run pre-commit install\n\n# Run hooks manually\nuv run pre-commit run --all-files\n</code></pre></p> <p>Hook Configuration (<code>.pre-commit-config.yaml</code>): <pre><code>repos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.0\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.5.1\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-requests]\n</code></pre></p>"},{"location":"development/ci-cd-pipeline/#testing-locally","title":"Testing Locally","text":"<p>Run Full Test Suite: <pre><code># Install dependencies\nuv sync --all-extras --dev\n\n# Run tests with coverage\nuv run python -m pytest tests/ \\\n  --cov=src \\\n  --cov-report=html \\\n  --cov-report=term-missing\n\n# Run specific test categories\nuv run python -m pytest tests/unit/\nuv run python -m pytest tests/integration/\n</code></pre></p> <p>Performance Testing: <pre><code># Run DuckDB benchmarks\nuv run python -m landuse.converters.performance_benchmark\n\n# Memory profiling\nuv run python -m memory_profiler your_script.py\n</code></pre></p> <p>Security Scanning: <pre><code># Check for vulnerabilities\nuv run safety check\n\n# Security linting\nuv run bandit -r src/\n\n# License checking\nuv run pip-licenses\n</code></pre></p>"},{"location":"development/ci-cd-pipeline/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/ci-cd-pipeline/#common-ci-issues","title":"Common CI Issues","text":"<p>Test Failures: 1. Check test logs in GitHub Actions 2. Reproduce locally with same Python version 3. Check for environment-specific issues 4. Verify test data and configuration</p> <p>Coverage Drops: 1. Add tests for new code 2. Remove dead code 3. Check test configuration 4. Review coverage reports</p> <p>Security Alerts: 1. Review Bandit and Safety reports 2. Update vulnerable dependencies 3. Fix code security issues 4. Document risk acceptance if needed</p>"},{"location":"development/ci-cd-pipeline/#performance-issues","title":"Performance Issues","text":"<p>Benchmark Failures: 1. Check system resources during tests 2. Compare with baseline metrics 3. Profile memory and CPU usage 4. Review algorithm changes</p> <p>Memory Leaks: 1. Use memory profiler for analysis 2. Check connection cleanup 3. Review data structure usage 4. Monitor garbage collection</p>"},{"location":"development/ci-cd-pipeline/#best-practices","title":"Best Practices","text":""},{"location":"development/ci-cd-pipeline/#cicd-optimization","title":"CI/CD Optimization","text":"<p>Build Speed: - Use dependency caching - Parallel job execution - Minimal test data sets - Efficient Docker layers</p> <p>Resource Usage: - Monitor GitHub Actions minutes - Optimize workflow triggers - Use appropriate runner sizes - Cache dependencies effectively</p>"},{"location":"development/ci-cd-pipeline/#quality-assurance","title":"Quality Assurance","text":"<p>Test Strategy: - Fast unit tests for rapid feedback - Comprehensive integration tests - Performance regression tests - Security validation tests</p> <p>Code Reviews: - Automated checks before human review - Clear PR templates and guidelines - Focus areas for reviewers - Definition of done criteria</p>"},{"location":"development/ci-cd-pipeline/#security-practices","title":"Security Practices","text":"<p>Secret Management: - Never commit secrets - Use GitHub secrets for sensitive data - Rotate keys regularly - Principle of least privilege</p> <p>Vulnerability Response: - Monitor security alerts - Patch critical issues immediately - Track and remediate medium/low issues - Document security decisions</p>"},{"location":"development/ci-cd-pipeline/#future-enhancements","title":"Future Enhancements","text":""},{"location":"development/ci-cd-pipeline/#planned-improvements","title":"Planned Improvements","text":"<p>Advanced Testing: - Contract testing for APIs - Visual regression testing - End-to-end user journey tests - Chaos engineering experiments</p> <p>Enhanced Security: - Container vulnerability scanning - Infrastructure as Code security - Runtime security monitoring - Compliance reporting</p> <p>Performance Optimization: - Automated performance optimization - Machine learning for anomaly detection - Resource usage optimization - Scalability testing</p>"},{"location":"development/ci-cd-pipeline/#tool-integration","title":"Tool Integration","text":"<p>Potential Additions: - SonarQube for code quality - Snyk for vulnerability scanning - Lighthouse for web performance - Terraform for infrastructure</p> <p>Monitoring: - Application Performance Monitoring (APM) - Error tracking and alerting - User analytics and feedback - Infrastructure monitoring</p>"},{"location":"development/ci-cd-pipeline/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Overview</li> <li>Contributing Guide</li> <li>Testing Guide</li> <li>Branding Strategy</li> </ul>"},{"location":"development/contributing/","title":"Contributing Guide","text":"<p>Thank you for your interest in contributing to the LangChain Land Use Analysis project! This guide will help you get started.</p>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":""},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>Git</li> <li>uv (Python package manager)</li> <li>OpenAI API key</li> </ul>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Fork and Clone <pre><code>git clone https://github.com/yourusername/langchain-landuse.git\ncd langchain-landuse\n</code></pre></p> </li> <li> <p>Create Virtual Environment <pre><code>uv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install Dependencies <pre><code>uv pip install -r config/requirements.txt\n</code></pre></p> </li> <li> <p>Set Up Environment <pre><code>cp config/.env.example config/.env\n# Edit .env with your OpenAI API key\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#1-create-a-feature-branch","title":"1. Create a Feature Branch","text":"<pre><code>git checkout -b feature/your-feature-name\n</code></pre> <p>Branch naming conventions: - <code>feature/</code> - New features - <code>fix/</code> - Bug fixes - <code>docs/</code> - Documentation updates - <code>refactor/</code> - Code refactoring - <code>test/</code> - Test additions/updates</p>"},{"location":"development/contributing/#2-make-your-changes","title":"2. Make Your Changes","text":"<p>Follow the coding standards and ensure your changes are well-tested.</p>"},{"location":"development/contributing/#3-run-tests","title":"3. Run Tests","text":"<pre><code># Run tests (when available)\nuv run pytest\n\n# Run linting\nuv run flake8 scripts/\n\n# Type checking\nuv run mypy scripts/\n</code></pre>"},{"location":"development/contributing/#4-commit-your-changes","title":"4. Commit Your Changes","text":"<p>Use clear, descriptive commit messages:</p> <pre><code>git add .\ngit commit -m \"feat: add natural language support for scenario comparisons\"\n</code></pre> <p>Commit message format: - <code>feat:</code> - New feature - <code>fix:</code> - Bug fix - <code>docs:</code> - Documentation changes - <code>style:</code> - Code style changes - <code>refactor:</code> - Code refactoring - <code>test:</code> - Test changes - <code>chore:</code> - Build process or auxiliary tool changes</p>"},{"location":"development/contributing/#5-push-and-create-pull-request","title":"5. Push and Create Pull Request","text":"<pre><code>git push origin feature/your-feature-name\n</code></pre> <p>Then create a pull request on GitHub.</p>"},{"location":"development/contributing/#code-standards","title":"Code Standards","text":""},{"location":"development/contributing/#python-style-guide","title":"Python Style Guide","text":"<p>Follow PEP 8 with these specific guidelines:</p> <pre><code># Good: Descriptive variable names\nland_use_transitions = process_data(county_data)\n\n# Bad: Single letter variables\nt = p(c)\n\n# Good: Type hints\ndef calculate_area_change(\n    from_area: float, \n    to_area: float\n) -&gt; Dict[str, float]:\n    \"\"\"Calculate the change in area between two time periods.\"\"\"\n    pass\n\n# Good: Docstrings\ndef process_county_data(county: Dict[str, Any]) -&gt; List[Transition]:\n    \"\"\"\n    Process raw county data into transition records.\n\n    Args:\n        county: Dictionary containing county land use data\n\n    Returns:\n        List of Transition objects\n\n    Raises:\n        ValueError: If county data is invalid\n    \"\"\"\n    pass\n</code></pre>"},{"location":"development/contributing/#tool-development-guidelines","title":"Tool Development Guidelines","text":"<p>When creating new tools for the agent:</p> <pre><code>def _create_new_tool(self) -&gt; Tool:\n    \"\"\"Create a tool following the standard pattern.\"\"\"\n    return Tool(\n        name=\"descriptive_tool_name\",\n        func=self._tool_implementation,\n        description=\"Clear description of what the tool does for natural language understanding\"\n    )\n\ndef _tool_implementation(self, params: Union[str, Dict[str, Any]]) -&gt; str:\n    \"\"\"\n    Implement the tool functionality.\n\n    Args:\n        params: Tool parameters (handle both string and dict)\n\n    Returns:\n        String result for the agent to interpret\n    \"\"\"\n    try:\n        # Validate parameters\n        if isinstance(params, str):\n            params = self._parse_params(params)\n\n        # Perform operation\n        result = self._do_operation(params)\n\n        # Format result\n        return self._format_result(result)\n\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n</code></pre>"},{"location":"development/contributing/#natural-language-query-patterns","title":"Natural Language Query Patterns","text":"<p>When adding query capabilities:</p> <pre><code># Support multiple phrasings\npatterns = [\n    \"show me forest loss\",\n    \"display forest reduction\",\n    \"what areas lost forest\",\n    \"forest to other land uses\"\n]\n\n# Provide helpful examples\nEXAMPLES = \"\"\"\nNatural language: \"Which counties have the most urban growth?\"\nSQL generated: SELECT fips, SUM(area) as urban_growth \n               FROM transitions \n               WHERE to_land_use = 'Urban' \n               GROUP BY fips \n               ORDER BY urban_growth DESC\n\"\"\"\n</code></pre>"},{"location":"development/contributing/#adding-features","title":"Adding Features","text":""},{"location":"development/contributing/#1-new-data-analysis-tools","title":"1. New Data Analysis Tools","text":"<p>To add a new analysis capability:</p> <ol> <li>Create the tool method in <code>data_engineering_agent.py</code></li> <li>Add to <code>_create_tools()</code> method</li> <li>Include parameter validation</li> <li>Add rich output formatting</li> <li>Document in <code>docs/api/tools.md</code></li> </ol> <p>Example: <pre><code>def _seasonal_analysis(self, params: Dict[str, Any]) -&gt; str:\n    \"\"\"Analyze seasonal patterns in land use changes.\"\"\"\n    # Implementation\n    pass\n</code></pre></p>"},{"location":"development/contributing/#2-new-query-patterns","title":"2. New Query Patterns","text":"<p>To support new types of natural language queries:</p> <ol> <li>Identify the query pattern</li> <li>Add examples to documentation</li> <li>Test with the agent</li> <li>Update query examples</li> </ol>"},{"location":"development/contributing/#3-new-data-formats","title":"3. New Data Formats","text":"<p>To support additional file formats:</p> <ol> <li>Add read method</li> <li>Add to format detection</li> <li>Support in query tool</li> <li>Add transformation support</li> <li>Update documentation</li> </ol>"},{"location":"development/contributing/#testing","title":"Testing","text":""},{"location":"development/contributing/#unit-tests","title":"Unit Tests","text":"<pre><code># test_converters.py\ndef test_land_use_mapping():\n    \"\"\"Test that land use codes map correctly.\"\"\"\n    assert LAND_USE_MAP['cr'] == 'Crop'\n    assert LAND_USE_MAP['ur'] == 'Urban'\n\ndef test_year_extraction():\n    \"\"\"Test year extraction from range.\"\"\"\n    assert extract_end_year('2020-2030') == 2030\n</code></pre>"},{"location":"development/contributing/#integration-tests","title":"Integration Tests","text":"<pre><code># test_agent_queries.py\ndef test_basic_query():\n    \"\"\"Test basic natural language query.\"\"\"\n    agent = DataEngineeringAgent()\n    result = agent.run(\"List all tables\")\n    assert \"landuse_transitions\" in result\n</code></pre>"},{"location":"development/contributing/#test-data","title":"Test Data","text":"<p>Keep test data minimal and in <code>tests/data/</code>: <pre><code>tests/\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 sample_transitions.json\n    \u251c\u2500\u2500 test_database.db\n    \u2514\u2500\u2500 fixtures.py\n</code></pre></p>"},{"location":"development/contributing/#documentation","title":"Documentation","text":""},{"location":"development/contributing/#adding-documentation","title":"Adding Documentation","text":"<ol> <li>API Documentation: Update relevant files in <code>docs/api/</code></li> <li>Query Examples: Add to <code>docs/queries/examples.md</code></li> <li>Use Cases: Document in <code>docs/examples/use-cases.md</code></li> <li>Docstrings: Always include in code</li> </ol>"},{"location":"development/contributing/#documentation-style","title":"Documentation Style","text":"<pre><code># Clear Heading\n\nBrief description of the topic.\n\n## Subsection\n\n### Code Example\n\n\\```python\n# Always include examples\nagent.run(\"Your natural language query here\")\n\\```\n\n### Expected Output\n\n\\```\nShow what users should expect to see\n\\```\n</code></pre>"},{"location":"development/contributing/#performance-considerations","title":"Performance Considerations","text":""},{"location":"development/contributing/#optimize-for-large-datasets","title":"Optimize for Large Datasets","text":"<pre><code># Good: Streaming for large files\ndef process_large_file(file_path):\n    with open(file_path, 'r') as f:\n        for chunk in iter(lambda: f.read(4096), ''):\n            process_chunk(chunk)\n\n# Good: Batch database operations\ndef insert_batch(data, batch_size=10000):\n    for i in range(0, len(data), batch_size):\n        batch = data[i:i + batch_size]\n        cursor.executemany(sql, batch)\n</code></pre>"},{"location":"development/contributing/#memory-management","title":"Memory Management","text":"<pre><code># Good: Clear large objects\ndef process_data():\n    large_df = read_large_file()\n    result = analyze(large_df)\n    del large_df  # Explicitly free memory\n    return result\n</code></pre>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Update Documentation: Ensure docs reflect your changes</li> <li>Add Tests: Include tests for new functionality</li> <li>Check Standards: Run linting and formatting</li> <li>Update CHANGELOG: Note significant changes</li> <li>Request Review: Tag appropriate reviewers</li> </ol>"},{"location":"development/contributing/#pr-template","title":"PR Template","text":"<pre><code>## Description\nBrief description of changes\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Documentation update\n- [ ] Performance improvement\n\n## Testing\n- [ ] Unit tests pass\n- [ ] Integration tests pass\n- [ ] Manual testing completed\n\n## Documentation\n- [ ] Code includes docstrings\n- [ ] Documentation updated\n- [ ] Examples added\n</code></pre>"},{"location":"development/contributing/#common-development-tasks","title":"Common Development Tasks","text":""},{"location":"development/contributing/#adding-a-new-scenario","title":"Adding a New Scenario","text":"<pre><code># 1. Update scenario list\nSCENARIOS = ['Baseline', 'High Crop Demand', 'High Forest', 'High Urban', 'New Scenario']\n\n# 2. Update documentation\n# docs/data/sources.md - Add scenario description\n\n# 3. Test with agent\nagent.run(\"Show me data for the New Scenario\")\n</code></pre>"},{"location":"development/contributing/#improving-query-performance","title":"Improving Query Performance","text":"<pre><code># 1. Add appropriate index\nCREATE INDEX idx_scenario_year ON landuse_transitions(scenario, year);\n\n# 2. Update query patterns\ndef optimize_query(original_query):\n    # Add query optimization logic\n    pass\n</code></pre>"},{"location":"development/contributing/#enhancing-natural-language-understanding","title":"Enhancing Natural Language Understanding","text":"<pre><code># 1. Add synonyms\nSYNONYMS = {\n    'urban': ['city', 'developed', 'built'],\n    'forest': ['trees', 'woodland', 'timber'],\n    'agricultural': ['farming', 'ag', 'crops and pasture']\n}\n\n# 2. Improve query parsing\ndef parse_natural_language(query):\n    # Enhanced parsing logic\n    pass\n</code></pre>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":""},{"location":"development/contributing/#resources","title":"Resources","text":"<ul> <li>Project Issues: GitHub Issues</li> <li>LangChain Docs: langchain.com</li> <li>OpenAI API: platform.openai.com</li> </ul>"},{"location":"development/contributing/#communication-channels","title":"Communication Channels","text":"<ul> <li>GitHub Issues: Bug reports and feature requests</li> <li>Discussions: General questions and ideas</li> <li>Pull Requests: Code contributions</li> </ul>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":""},{"location":"development/contributing/#be-respectful","title":"Be Respectful","text":"<ul> <li>Use welcoming and inclusive language</li> <li>Respect differing viewpoints and experiences</li> <li>Accept constructive criticism gracefully</li> </ul>"},{"location":"development/contributing/#contribute-positively","title":"Contribute Positively","text":"<ul> <li>Focus on what is best for the community</li> <li>Show empathy towards other community members</li> <li>Help others learn and grow</li> </ul>"},{"location":"development/contributing/#recognition","title":"Recognition","text":"<p>Contributors will be recognized in: - CONTRIBUTORS.md file - Release notes - Project documentation</p> <p>Thank you for contributing to make land use analysis more accessible through natural language!</p>"},{"location":"development/modern-duckdb-tools/","title":"Modern DuckDB Tools &amp; Database Redesign","text":""},{"location":"development/modern-duckdb-tools/#project-transformation","title":"\ud83c\udfaf Project Transformation","text":"<p>We've successfully redesigned your landuse data from a single denormalized table (8.6M rows) into a modern star schema optimized for analytics. This follows 2025 best practices for data warehousing and analytics.</p>"},{"location":"development/modern-duckdb-tools/#before-vs-after","title":"Before vs After","text":"Aspect Before (SQLite) After (DuckDB) Schema Single table with repeated data Star schema with 5 normalized tables Storage String repetition, inefficient Integer foreign keys, columnar storage Performance Slow aggregations Fast analytical queries Scalability Limited Optimized for large datasets Analytics Manual SQL only Built-in views + modern tooling Data Quality No constraints Referential integrity"},{"location":"development/modern-duckdb-tools/#our-new-duckdb-schema","title":"\ud83e\udd86 Our New DuckDB Schema","text":"<pre><code>\ud83d\udcca Fact Table: fact_landuse_transitions (main data)\n\u251c\u2500\u2500 \ud83c\udf0d dim_geography (counties, states, regions)\n\u251c\u2500\u2500 \u23f0 dim_time (year ranges, periods)\n\u251c\u2500\u2500 \ud83c\udfde\ufe0f dim_landuse (crop, forest, urban, etc.)\n\u2514\u2500\u2500 \ud83c\udf21\ufe0f dim_scenario (climate models, RCP/SSP scenarios)\n</code></pre>"},{"location":"development/modern-duckdb-tools/#modern-duckdb-tools-2025","title":"\ud83d\udd27 Modern DuckDB Tools (2025)","text":""},{"location":"development/modern-duckdb-tools/#1-duckdb-native-ui-official-2025","title":"1. DuckDB Native UI (Official, 2025)","text":"<pre><code># Launch built-in web UI (DuckDB v1.2.1+)\nduckdb data/processed/landuse_analytics.duckdb -ui\n</code></pre> <p>Features: - \u2705 Notebook-style interface (like Jupyter) - \u2705 Interactive SQL editor with syntax highlighting - \u2705 Data explorer with schema browsing - \u2705 Query history and results visualization - \u2705 No installation required - runs in browser - \u2705 Completely local (data never leaves your computer)</p>"},{"location":"development/modern-duckdb-tools/#2-duck-ui-community","title":"2. Duck-UI (Community)","text":"<pre><code># Web-based DuckDB interface\ndocker run -p 5522:5522 ghcr.io/caioricciuti/duck-ui:latest\n</code></pre> <p>Features: - \u2705 Modern React-based interface - \u2705 File import/export (CSV, JSON, Parquet) - \u2705 Data visualization capabilities - \u2705 Query management and history - \u2705 WebAssembly-powered (runs in browser)</p>"},{"location":"development/modern-duckdb-tools/#3-our-enhanced-sql-query-agent","title":"3. Our Enhanced SQL Query Agent","text":"<pre><code># Run our custom agent with DuckDB support\nuv run python scripts/agents/sql_query_agent.py\n</code></pre> <p>Features: - \u2705 DuckDB-optimized queries with <code>query_duckdb</code> tool - \u2705 Rich terminal interface with progress bars - \u2705 Automatic summary statistics for numeric columns - \u2705 Integration with LangChain for AI-powered analysis - \u2705 Smart query suggestions and error handling</p>"},{"location":"development/modern-duckdb-tools/#analytics-capabilities","title":"\ud83d\udcc8 Analytics Capabilities","text":""},{"location":"development/modern-duckdb-tools/#pre-built-views","title":"Pre-built Views","text":"<pre><code>-- Agricultural transitions analysis\nSELECT * FROM v_agriculture_transitions \nWHERE scenario_name = 'CNRM_CM5_rcp45_ssp1';\n\n-- Scenario summary with aggregations\nSELECT * FROM v_scenario_summary \nORDER BY total_acres DESC;\n</code></pre>"},{"location":"development/modern-duckdb-tools/#advanced-analytics-examples","title":"Advanced Analytics Examples","text":"<pre><code>-- Agricultural land loss by state\nSELECT \n    s.scenario_name,\n    g.state_code,\n    SUM(f.acres) as acres_lost\nFROM fact_landuse_transitions f\nJOIN dim_scenario s ON f.scenario_id = s.scenario_id\nJOIN dim_geography g ON f.geography_id = g.geography_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE fl.landuse_category = 'Agriculture' \n  AND tl.landuse_category != 'Agriculture'\n  AND f.transition_type = 'change'\nGROUP BY s.scenario_name, g.state_code\nORDER BY acres_lost DESC;\n\n-- Time series analysis\nSELECT \n    t.start_year,\n    t.end_year,\n    fl.landuse_name as from_landuse,\n    tl.landuse_name as to_landuse,\n    SUM(f.acres) as total_acres\nFROM fact_landuse_transitions f\nJOIN dim_time t ON f.time_id = t.time_id\nJOIN dim_landuse fl ON f.from_landuse_id = fl.landuse_id\nJOIN dim_landuse tl ON f.to_landuse_id = tl.landuse_id\nWHERE f.transition_type = 'change'\nGROUP BY t.start_year, t.end_year, fl.landuse_name, tl.landuse_name\nORDER BY t.start_year, total_acres DESC;\n</code></pre>"},{"location":"development/modern-duckdb-tools/#performance-benefits","title":"\ud83d\ude80 Performance Benefits","text":""},{"location":"development/modern-duckdb-tools/#query-speed-improvements","title":"Query Speed Improvements","text":"<ul> <li>Aggregations: 10-100x faster with columnar storage</li> <li>Filtering: Instant filtering on any dimension</li> <li>Joins: Optimized star schema joins</li> <li>Memory Usage: Reduced through integer foreign keys</li> </ul>"},{"location":"development/modern-duckdb-tools/#storage-efficiency","title":"Storage Efficiency","text":"<ul> <li>Before: Repeated strings in 8.6M rows</li> <li>After: Normalized dimensions + integer references</li> <li>Compression: DuckDB's columnar compression</li> <li>Indexing: Strategic indexes on common query patterns</li> </ul>"},{"location":"development/modern-duckdb-tools/#development-workflow","title":"\ud83d\udee0\ufe0f Development Workflow","text":""},{"location":"development/modern-duckdb-tools/#1-data-exploration","title":"1. Data Exploration","text":"<pre><code># Use DuckDB UI for interactive exploration\nduckdb data/processed/landuse_analytics.duckdb -ui\n\n# Or use our SQL Query Agent\nuv run python scripts/agents/sql_query_agent.py\n</code></pre>"},{"location":"development/modern-duckdb-tools/#2-advanced-analytics","title":"2. Advanced Analytics","text":"<pre><code># Python integration\nimport duckdb\nconn = duckdb.connect('data/processed/landuse_analytics.duckdb')\ndf = conn.execute(\"SELECT * FROM v_scenario_summary\").df()\n</code></pre>"},{"location":"development/modern-duckdb-tools/#3-visualization","title":"3. Visualization","text":"<pre><code># Direct pandas integration for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Query and visualize\ndf = conn.execute(\"\"\"\n    SELECT s.scenario_name, SUM(f.acres) as total_acres\n    FROM fact_landuse_transitions f\n    JOIN dim_scenario s ON f.scenario_id = s.scenario_id\n    GROUP BY s.scenario_name\n\"\"\").df()\n\nsns.barplot(data=df, x='scenario_name', y='total_acres')\nplt.xticks(rotation=45)\nplt.show()\n</code></pre>"},{"location":"development/modern-duckdb-tools/#next-steps-modern-practices","title":"\ud83d\udd2e Next Steps &amp; Modern Practices","text":""},{"location":"development/modern-duckdb-tools/#1-data-quality-testing","title":"1. Data Quality &amp; Testing","text":"<pre><code>-- Add data quality checks\nSELECT COUNT(*) as null_acres \nFROM fact_landuse_transitions \nWHERE acres IS NULL;\n\n-- Referential integrity checks\nSELECT COUNT(*) as orphaned_records\nFROM fact_landuse_transitions f\nLEFT JOIN dim_scenario s ON f.scenario_id = s.scenario_id\nWHERE s.scenario_id IS NULL;\n</code></pre>"},{"location":"development/modern-duckdb-tools/#2-performance-monitoring","title":"2. Performance Monitoring","text":"<pre><code>-- Query performance analysis\nEXPLAIN ANALYZE SELECT ...;\n\n-- Table statistics\nSELECT table_name, estimated_size \nFROM duckdb_tables();\n</code></pre>"},{"location":"development/modern-duckdb-tools/#3-integration-with-modern-stack","title":"3. Integration with Modern Stack","text":"<ul> <li>dbt: Data transformation and testing</li> <li>Great Expectations: Data quality validation</li> <li>Streamlit: Interactive dashboards</li> <li>Observable: Collaborative analytics notebooks</li> <li>Evidence: BI reporting from SQL</li> </ul>"},{"location":"development/modern-duckdb-tools/#4-advanced-duckdb-features","title":"4. Advanced DuckDB Features","text":"<pre><code>-- Spatial analysis (if geographic data available)\nINSTALL spatial;\nLOAD spatial;\n\n-- Time series analysis\nINSTALL icu;\nLOAD icu;\n\n-- Machine learning\nINSTALL ml;\nLOAD ml;\n</code></pre>"},{"location":"development/modern-duckdb-tools/#learning-resources","title":"\ud83d\udcda Learning Resources","text":""},{"location":"development/modern-duckdb-tools/#official-documentation","title":"Official Documentation","text":"<ul> <li>DuckDB Documentation</li> <li>DuckDB UI Guide</li> <li>SQL Reference</li> </ul>"},{"location":"development/modern-duckdb-tools/#community-tools","title":"Community Tools","text":"<ul> <li>Awesome DuckDB</li> <li>DuckDB Extensions</li> <li>DuckDB Cookbook</li> </ul>"},{"location":"development/modern-duckdb-tools/#books-courses","title":"Books &amp; Courses","text":"<ul> <li>\"DuckDB: Up and Running\" by Wei-Meng Lee (2024)</li> <li>Modern data stack courses focusing on DuckDB</li> <li>Analytics engineering best practices</li> </ul>"},{"location":"development/modern-duckdb-tools/#your-learning-path","title":"\ud83c\udfaf Your Learning Path","text":"<ol> <li>Explore the new schema using DuckDB UI</li> <li>Write analytical queries using our SQL Query Agent</li> <li>Build visualizations with Python integration</li> <li>Learn modern analytics patterns with star schema</li> <li>Experiment with DuckDB extensions for advanced features</li> </ol> <p>This redesign positions your project at the cutting edge of 2025 data analytics, using modern tools and practices that are becoming industry standard! </p>"},{"location":"development/pydantic-models/","title":"Pydantic Models Implementation","text":""},{"location":"development/pydantic-models/#overview","title":"Overview","text":"<p>This guide documents the comprehensive Pydantic v2 models implementation for the landuse project. These models provide type safety, automatic validation, and clear data contracts throughout the application.</p>"},{"location":"development/pydantic-models/#benefits-of-pydantic-models","title":"Benefits of Pydantic Models","text":"<ol> <li>Type Safety: Compile-time type checking with mypy</li> <li>Runtime Validation: Automatic input validation with helpful error messages</li> <li>Documentation: Self-documenting data structures</li> <li>Serialization: Easy conversion to/from JSON, dict, etc.</li> <li>IDE Support: Excellent autocomplete and type hints</li> </ol>"},{"location":"development/pydantic-models/#core-models","title":"Core Models","text":""},{"location":"development/pydantic-models/#agent-configuration","title":"Agent Configuration","text":"<pre><code>from landuse import AgentConfig\n\n# Create config with validation\nconfig = AgentConfig(\n    db_path=\"data/processed/landuse_analytics.duckdb\",\n    model_name=\"claude-3-5-sonnet-20241022\",\n    temperature=0.1,\n    max_tokens=4000,\n    max_iterations=5,\n    max_execution_time=120\n)\n\n# Access validated attributes\nprint(config.db_path)  # Path object, verified to exist\nprint(config.temperature)  # Float between 0-2\n</code></pre>"},{"location":"development/pydantic-models/#query-models","title":"Query Models","text":"<pre><code>from landuse import QueryInput, SQLQuery, QueryResult\n\n# Natural language query validation\nquery_input = QueryInput(\n    query=\"Show me agricultural land loss\",\n    include_assumptions=True\n)\n\n# SQL query validation\nsql_query = SQLQuery(\n    sql=\"SELECT * FROM dim_landuse\",\n    description=\"List all land use types\"\n)\n# Automatically validates:\n# - Only SELECT/WITH queries allowed\n# - No destructive operations\n\n# Query results with metadata\nresult = QueryResult(\n    success=True,\n    data=df,  # pandas DataFrame\n    execution_time=1.23,\n    query=\"SELECT COUNT(*) FROM fact_landuse_transitions\"\n)\nprint(f\"Processed {result.row_count:,} rows in {result.execution_time:.2f}s\")\n</code></pre>"},{"location":"development/pydantic-models/#data-models","title":"Data Models","text":"<pre><code>from landuse import (\n    LandUseType, LandUseCategory, \n    RCPScenario, SSPScenario,\n    TransitionType\n)\n\n# Enums provide controlled vocabularies\nland_use = LandUseType.CROP  # \"cr\"\ncategory = LandUseCategory.AGRICULTURE\nrcp = RCPScenario.RCP45  # \"4.5\"\nssp = SSPScenario.SSP1\ntransition = TransitionType.CHANGE\n\n# Dimension models with validation\nfrom landuse.models import GeographyDimension\n\ngeography = GeographyDimension(\n    geography_id=1,\n    fips_code=\"12345\",  # Validated as 5 digits\n    county_name=\"Example County\",\n    state_code=\"CA\",\n    state_name=\"California\"\n)\n</code></pre>"},{"location":"development/pydantic-models/#tool-input-models","title":"Tool Input Models","text":"<pre><code>from landuse.models import (\n    ExecuteQueryInput,\n    SchemaInfoInput,\n    StateCodeInput\n)\n\n# Tool inputs are validated before execution\nexecute_input = ExecuteQueryInput(\n    sql_query=\"SELECT COUNT(*) FROM dim_scenario\"\n)\n\nstate_input = StateCodeInput(\n    state_name=\"California\"\n)\n</code></pre>"},{"location":"development/pydantic-models/#converter-models","title":"Converter Models","text":""},{"location":"development/pydantic-models/#conversion-configuration","title":"Conversion Configuration","text":"<pre><code>from landuse import ConversionConfig, ConversionMode\n\nconfig = ConversionConfig(\n    input_file=\"data/raw/landuse.json\",\n    output_file=\"data/processed/landuse.duckdb\",\n    mode=ConversionMode.STREAMING,\n    batch_size=100000,\n    parallel_workers=8,\n    memory_limit=\"16GB\",\n    show_progress=True\n)\n\n# Validates:\n# - Input file exists and is JSON\n# - Memory limit format (e.g., \"8GB\", \"512MB\")\n# - Reasonable batch sizes and worker counts\n</code></pre>"},{"location":"development/pydantic-models/#processing-models","title":"Processing Models","text":"<pre><code>from landuse import ProcessedTransition, ConversionStats\n\n# Validated transition record\ntransition = ProcessedTransition(\n    scenario_name=\"GCAM_RCP45_SSP1\",\n    climate_model=\"GCAM\",\n    rcp_scenario=\"4.5\",\n    ssp_scenario=\"SSP1\",\n    time_period=\"2020-2030\",\n    start_year=2020,\n    end_year=2030,\n    fips_code=\"06037\",  # Validated FIPS\n    county_name=\"Los Angeles\",\n    state_code=\"06\",\n    from_landuse=\"Crop\",\n    to_landuse=\"Urban\",\n    acres=1234.56,\n    transition_type=\"change\"  # Validated as change/stable\n)\n\n# Conversion statistics\nstats = ConversionStats(\n    total_records=5_400_000,\n    processed_records=5_399_950,\n    failed_records=50,\n    processing_time=123.45\n)\nprint(f\"Success rate: {stats.success_rate():.2f}%\")\nprint(f\"Speed: {stats.records_per_second():.0f} records/sec\")\n</code></pre>"},{"location":"development/pydantic-models/#integration-examples","title":"Integration Examples","text":""},{"location":"development/pydantic-models/#agent-usage","title":"Agent Usage","text":"<pre><code>from landuse.agents import LanduseNaturalLanguageAgent\nfrom landuse import AgentConfig, QueryInput\n\n# Initialize with Pydantic config\nconfig = AgentConfig(\n    model_name=\"gpt-4o-mini\",\n    temperature=0.1,\n    max_iterations=10\n)\n\nagent = LanduseNaturalLanguageAgent(config=config)\n\n# Query with validation\nquery_input = QueryInput(\n    query=\"Which states have the most urban expansion?\"\n)\nresponse = agent.query(query_input.query)\n</code></pre>"},{"location":"development/pydantic-models/#database-connection","title":"Database Connection","text":"<pre><code>from landuse.connections import DuckDBConnection\nfrom landuse import QueryResult\n\nconn = DuckDBConnection(\"landuse_db\")\n\n# Get validated query results\nresult: QueryResult = conn.query_with_result(\n    \"SELECT COUNT(*) as total FROM fact_landuse_transitions\"\n)\n\nif result.success:\n    print(f\"Total transitions: {result.data['total'][0]:,}\")\n    print(f\"Query took {result.execution_time:.3f}s\")\nelse:\n    print(f\"Error: {result.error}\")\n</code></pre>"},{"location":"development/pydantic-models/#streamlit-integration","title":"Streamlit Integration","text":"<pre><code>import streamlit as st\nfrom landuse import ChatMessage, SystemStatus\n\n# Track chat messages with validation\nmessage = ChatMessage(\n    role=\"user\",\n    content=\"Show me forest loss trends\"\n)\nst.session_state.messages.append(message)\n\n# System status monitoring\nstatus = SystemStatus(\n    database_connected=True,\n    agent_initialized=True,\n    model_name=\"claude-3-5-sonnet\",\n    database_path=\"/path/to/db\",\n    table_count=5,\n    total_records=5_400_000\n)\n</code></pre>"},{"location":"development/pydantic-models/#error-handling","title":"Error Handling","text":"<p>Pydantic provides detailed validation errors:</p> <pre><code>from landuse import AgentConfig\nfrom pydantic import ValidationError\n\ntry:\n    config = AgentConfig(\n        temperature=3.0,  # Too high!\n        max_tokens=-100   # Negative!\n    )\nexcept ValidationError as e:\n    print(e.json(indent=2))\n    # {\n    #   \"errors\": [\n    #     {\n    #       \"loc\": [\"temperature\"],\n    #       \"msg\": \"ensure this value is less than or equal to 2\",\n    #       \"type\": \"value_error.number.not_le\"\n    #     },\n    #     {\n    #       \"loc\": [\"max_tokens\"],\n    #       \"msg\": \"ensure this value is greater than 0\",\n    #       \"type\": \"value_error.number.not_gt\"\n    #     }\n    #   ]\n    # }\n</code></pre>"},{"location":"development/pydantic-models/#best-practices","title":"Best Practices","text":"<ol> <li>Use Models at Boundaries: Validate data at API endpoints, user inputs, and external data sources</li> <li>Leverage Validators: Add custom validators for business logic</li> <li>Export Common Models: Make models easily importable from package root</li> <li>Document Fields: Use Field descriptions for self-documenting APIs</li> <li>Handle Validation Errors: Catch ValidationError and provide user-friendly messages</li> </ol>"},{"location":"development/pydantic-models/#migration-guide","title":"Migration Guide","text":"<p>To migrate existing code to use Pydantic models:</p> <ol> <li> <p>Replace dict parameters with model instances:    <pre><code># Before\nagent.query({\"query\": \"...\", \"limit\": 50})\n\n# After\nagent.query(QueryInput(query=\"...\", limit=50))\n</code></pre></p> </li> <li> <p>Use enums instead of strings:    <pre><code># Before\nif landuse_type == \"cr\":\n\n# After\nif landuse_type == LandUseType.CROP:\n</code></pre></p> </li> <li> <p>Return structured results:    <pre><code># Before\nreturn {\"success\": True, \"data\": df, \"error\": None}\n\n# After\nreturn QueryResult(success=True, data=df)\n</code></pre></p> </li> </ol>"},{"location":"development/pydantic-models/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Pydantic v2 is 5-50x faster than v1</li> <li>Use <code>model_config = ConfigDict(extra=\"forbid\")</code> to catch typos</li> <li>Leverage <code>.model_dump()</code> for efficient serialization</li> <li>Use <code>exclude=True</code> on fields that shouldn't be serialized</li> </ul>"},{"location":"development/pydantic-models/#testing-with-models","title":"Testing with Models","text":"<pre><code>import pytest\nfrom landuse import QueryInput\nfrom pydantic import ValidationError\n\ndef test_query_validation():\n    # Valid query\n    query = QueryInput(query=\"Show me data\")\n    assert query.include_assumptions is True  # Default\n\n    # Invalid query (empty)\n    with pytest.raises(ValidationError):\n        QueryInput(query=\"\")\n\n    # Invalid query (too long)\n    with pytest.raises(ValidationError):\n        QueryInput(query=\"x\" * 1001)\n</code></pre>"},{"location":"development/pydantic-models/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>JSON Schema Generation: Auto-generate API documentation</li> <li>OpenAPI Integration: Use models for API spec generation</li> <li>Settings Management: Use pydantic-settings for configuration</li> <li>Async Support: Add async validators for I/O operations</li> </ol>"},{"location":"development/retry-logic/","title":"Retry Logic with Tenacity","text":"<p>This document describes the implementation of robust retry logic throughout the landuse project using the tenacity library and custom fallback mechanisms.</p>"},{"location":"development/retry-logic/#overview","title":"Overview","text":"<p>The retry system provides automatic error recovery for transient failures in database connections, API calls, file operations, and network requests. This improves reliability and user experience by handling temporary issues gracefully.</p>"},{"location":"development/retry-logic/#implementation","title":"Implementation","text":""},{"location":"development/retry-logic/#core-components","title":"Core Components","text":"<ol> <li>Retry Decorators (<code>src/landuse/utils/retry_decorators.py</code>)</li> <li>Specialized decorators for different operation types</li> <li>Configurable retry strategies and wait times</li> <li> <p>Fallback implementation when tenacity is unavailable</p> </li> <li> <p>Integration Points</p> </li> <li>Database connections and queries</li> <li>Bulk loading operations</li> <li>Agent tool executions</li> <li>File I/O operations</li> </ol>"},{"location":"development/retry-logic/#retry-decorators","title":"Retry Decorators","text":""},{"location":"development/retry-logic/#database-operations","title":"Database Operations","text":"<pre><code>from landuse.utils.retry_decorators import database_retry\n\n@database_retry(max_attempts=3, min_wait=1.0, max_wait=10.0)\ndef connect_to_database():\n    return duckdb.connect(\"database.duckdb\")\n</code></pre> <p>Configuration: - Max Attempts: 3 (reasonable for database operations) - Wait Strategy: Exponential backoff (1s \u2192 2s \u2192 4s \u2192 ...) - Max Wait: 10 seconds (prevents excessive delays) - Retryable Exceptions: <code>ConnectionError</code>, <code>TimeoutError</code>, <code>OSError</code></p>"},{"location":"development/retry-logic/#api-operations","title":"API Operations","text":"<pre><code>from landuse.utils.retry_decorators import api_retry\n\n@api_retry(max_attempts=5, base_wait=2.0, max_wait=60.0)\ndef call_external_api():\n    response = requests.get(\"https://api.example.com/data\")\n    return response.json()\n</code></pre> <p>Configuration: - Max Attempts: 5 (APIs may have intermittent issues) - Wait Strategy: Exponential backoff with base 2 seconds - Max Wait: 60 seconds (API rate limiting consideration) - Retryable Exceptions: <code>ConnectionError</code>, <code>TimeoutError</code>, <code>OSError</code></p>"},{"location":"development/retry-logic/#file-operations","title":"File Operations","text":"<pre><code>from landuse.utils.retry_decorators import file_retry\n\n@file_retry(max_attempts=3, wait_time=2.0)\ndef write_to_file(filename, data):\n    with open(filename, 'w') as f:\n        f.write(data)\n</code></pre> <p>Configuration: - Max Attempts: 3 (file locks usually resolve quickly) - Wait Strategy: Fixed wait time - Wait Time: 2 seconds (allows file locks to clear) - Retryable Exceptions: <code>FileNotFoundError</code>, <code>PermissionError</code>, <code>OSError</code></p>"},{"location":"development/retry-logic/#network-operations","title":"Network Operations","text":"<pre><code>from landuse.utils.retry_decorators import network_retry\n\n@network_retry(max_attempts=5, min_wait=2.0, max_wait=30.0)\ndef download_data():\n    response = urllib.request.urlopen(\"https://example.com/data.json\")\n    return response.read()\n</code></pre> <p>Configuration: - Max Attempts: 5 (network issues can be intermittent) - Wait Strategy: Exponential backoff - Wait Range: 2-30 seconds - Retryable Exceptions: <code>ConnectionError</code>, <code>TimeoutError</code></p>"},{"location":"development/retry-logic/#advanced-retry-patterns","title":"Advanced Retry Patterns","text":""},{"location":"development/retry-logic/#result-based-retries","title":"Result-Based Retries","text":"<pre><code>from landuse.utils.retry_decorators import retry_on_result\n\n@retry_on_result(\n    result_predicate=lambda x: x is None or x.get('status') == 'pending',\n    max_attempts=10,\n    wait_time=5.0\n)\ndef poll_for_completion():\n    \"\"\"Retry until we get a complete result\"\"\"\n    status = check_processing_status()\n    return status\n</code></pre>"},{"location":"development/retry-logic/#custom-retry-logic","title":"Custom Retry Logic","text":"<pre><code>from landuse.utils.retry_decorators import custom_retry\nfrom tenacity import stop_after_delay, wait_random_exponential\n\n@custom_retry(\n    stop_condition=stop_after_delay(300),  # Stop after 5 minutes\n    wait_strategy=wait_random_exponential(multiplier=1, max=60),\n    retry_condition=retry_if_exception_type((ConnectionError, TimeoutError))\n)\ndef complex_operation():\n    # Complex operation with custom retry logic\n    pass\n</code></pre>"},{"location":"development/retry-logic/#context-manager-approach","title":"Context Manager Approach","text":"<pre><code>from landuse.utils.retry_decorators import RetryableOperation\n\nwith RetryableOperation(\n    \"Database migration\",\n    max_attempts=5,\n    wait_strategy=\"exponential\",\n    min_wait=2.0,\n    max_wait=60.0\n) as op:\n    result = op.execute(migrate_database_schema)\n</code></pre>"},{"location":"development/retry-logic/#utility-function-approach","title":"Utility Function Approach","text":"<pre><code>from landuse.utils.retry_decorators import execute_with_retry\n\nresult = execute_with_retry(\n    func=complex_database_operation,\n    operation_name=\"Complex DB Operation\",\n    max_attempts=3,\n    wait_strategy=\"exponential\",\n    min_wait=1.0,\n    max_wait=30.0,\n    exceptions=(ConnectionError, TimeoutError),\n    # Function arguments\n    table_name=\"landuse_data\",\n    batch_size=10000\n)\n</code></pre>"},{"location":"development/retry-logic/#integration-examples","title":"Integration Examples","text":""},{"location":"development/retry-logic/#database-connections","title":"Database Connections","text":"<p>Before (no retry): <pre><code>def connect_to_database():\n    return duckdb.connect(\"database.duckdb\")  # Fails on temporary issues\n</code></pre></p> <p>After (with retry): <pre><code>@database_retry(max_attempts=3, min_wait=1.0, max_wait=10.0)\ndef connect_to_database():\n    try:\n        return duckdb.connect(\"database.duckdb\")\n    except Exception as e:\n        raise ConnectionError(f\"Failed to connect: {e}\") from e\n</code></pre></p>"},{"location":"development/retry-logic/#bulk-loading-operations","title":"Bulk Loading Operations","text":"<p>Enhanced bulk loader with retry logic: <pre><code>class DuckDBBulkLoader:\n    @contextmanager\n    def connection(self):\n        try:\n            self.conn = execute_with_retry(\n                duckdb.connect,\n                operation_name=f\"DuckDB connection to {self.db_path}\",\n                max_attempts=3,\n                wait_strategy=\"exponential\",\n                exceptions=(ConnectionError, OSError, RuntimeError),\n                database=str(self.db_path)\n            )\n            yield self.conn\n        finally:\n            if self.conn:\n                self.conn.close()\n\n    def bulk_load_dataframe(self, df, table_name):\n        # Write Parquet with retry\n        execute_with_retry(\n            df.to_parquet,\n            operation_name=f\"Writing Parquet file\",\n            max_attempts=3,\n            exceptions=(OSError, PermissionError, IOError),\n            path=temp_file,\n            index=False,\n            compression=self.compression\n        )\n\n        # Execute COPY with retry\n        with self.connection() as conn:\n            execute_with_retry(\n                conn.execute,\n                operation_name=f\"COPY command for {table_name}\",\n                max_attempts=3,\n                wait_strategy=\"exponential\",\n                exceptions=(ConnectionError, RuntimeError, OSError),\n                query=copy_sql\n            )\n</code></pre></p>"},{"location":"development/retry-logic/#agent-query-execution","title":"Agent Query Execution","text":"<p>Enhanced agent with retry logic: <pre><code>class BaseLanduseAgent:\n    @database_retry(max_attempts=3, min_wait=1.0, max_wait=10.0, \n                   exceptions=(ConnectionError, TimeoutError, OSError))\n    def _execute_landuse_query(self, sql_query: str) -&gt; str:\n        try:\n            # Query execution with automatic retry on connection issues\n            conn = duckdb.connect(str(self.db_path), read_only=True)\n            result = conn.execute(sql_query)\n            df = result.df()\n            conn.close()\n            return format_query_results(df, sql_query)\n        except (ConnectionError, TimeoutError, OSError):\n            # These will trigger retries via the decorator\n            raise\n        except Exception as e:\n            # Other errors (syntax, etc.) should not be retried\n            return f\"\u274c Error: {e}\"\n</code></pre></p>"},{"location":"development/retry-logic/#configuration","title":"Configuration","text":""},{"location":"development/retry-logic/#environment-variables","title":"Environment Variables","text":"<p>Configure retry behavior via environment variables:</p> <pre><code># Retry configuration\nLANDUSE_DB_RETRY_ATTEMPTS=3\nLANDUSE_DB_RETRY_MIN_WAIT=1.0\nLANDUSE_DB_RETRY_MAX_WAIT=10.0\n\nLANDUSE_API_RETRY_ATTEMPTS=5\nLANDUSE_API_RETRY_BASE_WAIT=2.0\nLANDUSE_API_RETRY_MAX_WAIT=60.0\n\nLANDUSE_FILE_RETRY_ATTEMPTS=3\nLANDUSE_FILE_RETRY_WAIT=2.0\n</code></pre>"},{"location":"development/retry-logic/#pydantic-configuration-model","title":"Pydantic Configuration Model","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass RetryConfig(BaseModel):\n    \"\"\"Configuration for retry behavior\"\"\"\n\n    # Database retries\n    db_max_attempts: int = Field(default=3, ge=1, le=10)\n    db_min_wait: float = Field(default=1.0, ge=0.1, le=60.0)\n    db_max_wait: float = Field(default=10.0, ge=1.0, le=300.0)\n\n    # API retries\n    api_max_attempts: int = Field(default=5, ge=1, le=20)\n    api_base_wait: float = Field(default=2.0, ge=0.1, le=60.0)\n    api_max_wait: float = Field(default=60.0, ge=1.0, le=600.0)\n\n    # File retries\n    file_max_attempts: int = Field(default=3, ge=1, le=10)\n    file_wait_time: float = Field(default=2.0, ge=0.1, le=60.0)\n</code></pre>"},{"location":"development/retry-logic/#best-practices","title":"Best Practices","text":""},{"location":"development/retry-logic/#when-to-use-retries","title":"When to Use Retries","text":"<p>\u2705 Good candidates for retries: - Database connection failures - Network timeouts - Temporary file access issues - API rate limiting (with backoff) - Cloud service intermittent failures</p> <p>\u274c Poor candidates for retries: - SQL syntax errors - Authentication failures - Permission denied errors - Invalid input data - Logic errors in code</p>"},{"location":"development/retry-logic/#retry-strategy-selection","title":"Retry Strategy Selection","text":"<ol> <li>Exponential Backoff (recommended for most cases)</li> <li>Good for handling increasing load</li> <li>Prevents thundering herd problems</li> <li> <p>Self-adapting to system recovery time</p> </li> <li> <p>Fixed Wait (good for known recovery times)</p> </li> <li>Predictable timing</li> <li>Good for file locking scenarios</li> <li> <p>Simple and deterministic</p> </li> <li> <p>Linear Backoff (middle ground)</p> </li> <li>Gradual increase in wait time</li> <li>Less aggressive than exponential</li> <li>Good for rate-limited APIs</li> </ol>"},{"location":"development/retry-logic/#error-classification","title":"Error Classification","text":"<p>Retryable Errors: <pre><code>RETRYABLE_EXCEPTIONS = (\n    ConnectionError,      # Network/DB connection issues\n    TimeoutError,        # Request timeouts\n    OSError,             # System-level errors\n    RuntimeError,        # DuckDB runtime issues (sometimes)\n)\n</code></pre></p> <p>Non-Retryable Errors: <pre><code>NON_RETRYABLE_EXCEPTIONS = (\n    ValueError,          # Input validation errors\n    TypeError,           # Programming errors\n    KeyError,           # Missing keys/columns\n    AttributeError,     # Object attribute errors\n    SyntaxError,        # SQL syntax errors\n    PermissionError,    # Authorization failures (usually)\n)\n</code></pre></p>"},{"location":"development/retry-logic/#monitoring-and-logging","title":"Monitoring and Logging","text":"<p>Rich Console Integration: <pre><code>from rich.console import Console\n\nconsole = Console()\n\n@database_retry(max_attempts=3)\ndef database_operation():\n    try:\n        # Operation logic\n        console.print(\"\u2705 Database operation succeeded\")\n        return result\n    except Exception as e:\n        console.print(f\"\u26a0\ufe0f Database operation failed: {e}\")\n        raise\n</code></pre></p> <p>Structured Logging: <pre><code>import logging\nfrom landuse.utils.retry_decorators import database_retry\n\nlogger = logging.getLogger(__name__)\n\n@database_retry(max_attempts=3)\ndef database_operation():\n    logger.info(\"Starting database operation\")\n    try:\n        result = perform_operation()\n        logger.info(\"Database operation completed successfully\")\n        return result\n    except Exception as e:\n        logger.warning(f\"Database operation failed, will retry: {e}\")\n        raise\n</code></pre></p>"},{"location":"development/retry-logic/#fallback-implementation","title":"Fallback Implementation","text":"<p>When tenacity is not available, the system provides a fallback implementation:</p> <pre><code>def _fallback_retry(max_attempts: int, wait_time: float):\n    \"\"\"Basic retry implementation without tenacity\"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            last_exception = None\n\n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    last_exception = e\n                    if attempt &lt; max_attempts - 1:\n                        console.print(f\"\u26a0\ufe0f Attempt {attempt + 1} failed: {e}\")\n                        console.print(f\"\ud83d\udd04 Retrying in {wait_time}s...\")\n                        time.sleep(wait_time)\n\n            raise last_exception\n        return wrapper\n    return decorator\n</code></pre> <p>Features of fallback: - Basic retry functionality - Fixed wait times - Rich console output - Exception preservation - No external dependencies</p>"},{"location":"development/retry-logic/#testing","title":"Testing","text":""},{"location":"development/retry-logic/#unit-tests","title":"Unit Tests","text":"<pre><code>def test_retry_with_eventual_success():\n    call_count = 0\n\n    @database_retry(max_attempts=3, min_wait=0.1)\n    def mock_operation():\n        nonlocal call_count\n        call_count += 1\n        if call_count &lt; 3:\n            raise ConnectionError(\"Temporary failure\")\n        return \"success\"\n\n    result = mock_operation()\n    assert result == \"success\"\n    assert call_count == 3\n</code></pre>"},{"location":"development/retry-logic/#integration-tests","title":"Integration Tests","text":"<pre><code>def test_database_retry_integration():\n    \"\"\"Test retry behavior with real database operations\"\"\"\n    with temporary_database() as db_path:\n        # Test connection retry\n        @database_retry(max_attempts=3)\n        def connect_and_query():\n            conn = duckdb.connect(db_path)\n            result = conn.execute(\"SELECT 1\").fetchone()\n            conn.close()\n            return result[0]\n\n        result = connect_and_query()\n        assert result == 1\n</code></pre>"},{"location":"development/retry-logic/#mocking-for-tests","title":"Mocking for Tests","text":"<pre><code>from unittest.mock import patch, Mock\n\ndef test_retry_with_mocked_failures():\n    mock_func = Mock()\n    mock_func.side_effect = [\n        ConnectionError(\"First failure\"),\n        ConnectionError(\"Second failure\"), \n        \"success\"\n    ]\n\n    @database_retry(max_attempts=3, min_wait=0.1)\n    def operation():\n        return mock_func()\n\n    result = operation()\n    assert result == \"success\"\n    assert mock_func.call_count == 3\n</code></pre>"},{"location":"development/retry-logic/#performance-considerations","title":"Performance Considerations","text":""},{"location":"development/retry-logic/#retry-overhead","title":"Retry Overhead","text":"<ul> <li>Minimal overhead for successful operations (single decorator call)</li> <li>Exponential cost for failing operations (wait times increase)</li> <li>Memory usage remains constant (no accumulation)</li> </ul>"},{"location":"development/retry-logic/#timing-considerations","title":"Timing Considerations","text":"<pre><code># Fast operations - shorter timeouts\n@database_retry(max_attempts=3, min_wait=0.5, max_wait=5.0)\ndef quick_query():\n    pass\n\n# Slow operations - longer timeouts  \n@database_retry(max_attempts=5, min_wait=2.0, max_wait=60.0)\ndef heavy_computation():\n    pass\n</code></pre>"},{"location":"development/retry-logic/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<p>For high-failure scenarios, consider implementing circuit breaker:</p> <pre><code>from landuse.utils.retry_decorators import RetryableOperation\n\nclass CircuitBreaker:\n    def __init__(self, failure_threshold=5, recovery_timeout=60):\n        self.failure_threshold = failure_threshold\n        self.recovery_timeout = recovery_timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n\n    def call(self, func, *args, **kwargs):\n        if self.state == \"OPEN\":\n            if time.time() - self.last_failure_time &gt; self.recovery_timeout:\n                self.state = \"HALF_OPEN\"\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n\n        try:\n            with RetryableOperation(\"Circuit breaker operation\") as op:\n                result = op.execute(func, *args, **kwargs)\n\n            # Success - reset circuit breaker\n            self.failure_count = 0\n            self.state = \"CLOSED\"\n            return result\n\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n\n            if self.failure_count &gt;= self.failure_threshold:\n                self.state = \"OPEN\"\n\n            raise\n</code></pre>"},{"location":"development/retry-logic/#dependencies","title":"Dependencies","text":""},{"location":"development/retry-logic/#required-dependencies","title":"Required Dependencies","text":"<pre><code># pyproject.toml\n[project]\ndependencies = [\n    \"tenacity&gt;=8.0.0\",  # Advanced retry functionality\n    \"rich&gt;=13.0.0\",     # Console output\n]\n\n[project.optional-dependencies]\nretry = [\n    \"tenacity&gt;=8.0.0\",\n]\n</code></pre>"},{"location":"development/retry-logic/#installation","title":"Installation","text":"<pre><code># Install with retry functionality\nuv add tenacity\n\n# Or install optional retry dependencies\nuv sync --extras retry\n</code></pre>"},{"location":"development/retry-logic/#migration-guide","title":"Migration Guide","text":""},{"location":"development/retry-logic/#adding-retries-to-existing-code","title":"Adding Retries to Existing Code","text":"<ol> <li> <p>Identify retry candidates: <pre><code># Before: No error handling\ndef fragile_operation():\n    conn = duckdb.connect(\"database.duckdb\")\n    return conn.execute(\"SELECT * FROM table\").fetchall()\n</code></pre></p> </li> <li> <p>Add appropriate retry decorator: <pre><code># After: With retry logic\nfrom landuse.utils.retry_decorators import database_retry\n\n@database_retry(max_attempts=3, min_wait=1.0, max_wait=10.0)\ndef robust_operation():\n    try:\n        conn = duckdb.connect(\"database.duckdb\")\n        return conn.execute(\"SELECT * FROM table\").fetchall()\n    except Exception as e:\n        # Convert to retryable exception if appropriate\n        if \"connection\" in str(e).lower():\n            raise ConnectionError(f\"Database connection failed: {e}\")\n        raise  # Re-raise non-retryable exceptions\n</code></pre></p> </li> <li> <p>Test retry behavior: <pre><code># Test with mocked failures\nwith patch('duckdb.connect') as mock_connect:\n    mock_connect.side_effect = [\n        ConnectionError(\"First failure\"),\n        ConnectionError(\"Second failure\"),\n        Mock()  # Success on third attempt\n    ]\n\n    result = robust_operation()\n    assert mock_connect.call_count == 3\n</code></pre></p> </li> </ol>"},{"location":"development/retry-logic/#gradual-migration-strategy","title":"Gradual Migration Strategy","text":"<ol> <li>Phase 1: Add retries to critical database operations</li> <li>Phase 2: Add retries to file I/O operations  </li> <li>Phase 3: Add retries to API calls and network operations</li> <li>Phase 4: Implement circuit breaker for high-failure scenarios</li> </ol>"},{"location":"development/retry-logic/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/retry-logic/#common-issues","title":"Common Issues","text":"<p>Problem: Retries not working <pre><code># Check if tenacity is installed\nfrom landuse.utils.retry_decorators import HAS_TENACITY\nprint(f\"Tenacity available: {HAS_TENACITY}\")\n\n# Verify exception types are retryable\n@database_retry(exceptions=(YourExceptionType,))\ndef your_function():\n    pass\n</code></pre></p> <p>Problem: Too many retries <pre><code># Reduce retry attempts for faster failure\n@database_retry(max_attempts=2, min_wait=0.5, max_wait=5.0)\ndef quick_fail_operation():\n    pass\n</code></pre></p> <p>Problem: Retries too slow <pre><code># Use fixed wait for predictable timing\n@file_retry(max_attempts=3, wait_time=1.0)\ndef fast_retry_operation():\n    pass\n</code></pre></p>"},{"location":"development/retry-logic/#debugging-retry-behavior","title":"Debugging Retry Behavior","text":"<pre><code>import logging\n\n# Enable tenacity logging\nlogging.getLogger('tenacity').setLevel(logging.DEBUG)\n\n# Add custom retry callback\nfrom tenacity import before_sleep_log, after_log\n\n@database_retry(\n    max_attempts=3,\n    before_sleep=before_sleep_log(logging.getLogger(__name__), logging.WARNING),\n    after=after_log(logging.getLogger(__name__), logging.INFO)\n)\ndef debug_operation():\n    pass\n</code></pre>"},{"location":"development/retry-logic/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Overview</li> <li>Contributing Guide</li> <li>Testing Guide</li> <li>CI/CD Pipeline</li> </ul>"},{"location":"development/testing/","title":"Testing Guide","text":"<p>Comprehensive guide for testing the LangChain Land Use Analysis system.</p>"},{"location":"development/testing/#overview","title":"Overview","text":"<p>The project uses a multi-layered testing approach to ensure reliability:</p> <pre><code>graph TD\n    A[Unit Tests] --&gt; B[Integration Tests]\n    B --&gt; C[End-to-End Tests]\n    C --&gt; D[Manual Testing]\n\n    E[Test Data] --&gt; A\n    E --&gt; B\n    E --&gt; C</code></pre>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 conftest.py              # Shared fixtures\n\u251c\u2500\u2500 unit/                    # Unit tests\n\u2502   \u251c\u2500\u2500 test_converters.py\n\u2502   \u251c\u2500\u2500 test_tools.py\n\u2502   \u251c\u2500\u2500 test_validators.py\n\u2502   \u2514\u2500\u2500 test_utils.py\n\u251c\u2500\u2500 integration/             # Integration tests\n\u2502   \u251c\u2500\u2500 test_agent.py\n\u2502   \u251c\u2500\u2500 test_database.py\n\u2502   \u2514\u2500\u2500 test_pipeline.py\n\u251c\u2500\u2500 e2e/                     # End-to-end tests\n\u2502   \u251c\u2500\u2500 test_workflows.py\n\u2502   \u2514\u2500\u2500 test_queries.py\n\u2514\u2500\u2500 data/                    # Test data\n    \u251c\u2500\u2500 sample.json\n    \u251c\u2500\u2500 test.db\n    \u2514\u2500\u2500 fixtures.py\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run specific test file\nuv run pytest tests/unit/test_converters.py\n\n# Run specific test\nuv run pytest tests/unit/test_converters.py::test_land_use_mapping\n\n# Run with coverage\nuv run pytest --cov=scripts --cov-report=html\n\n# Run with verbose output\nuv run pytest -v\n</code></pre>"},{"location":"development/testing/#test-categories","title":"Test Categories","text":"<pre><code># Run only unit tests\nuv run pytest tests/unit/\n\n# Run only integration tests\nuv run pytest tests/integration/\n\n# Run tests by marker\nuv run pytest -m \"not slow\"\n</code></pre>"},{"location":"development/testing/#unit-testing","title":"Unit Testing","text":""},{"location":"development/testing/#testing-converters","title":"Testing Converters","text":"<pre><code># tests/unit/test_converters.py\nimport pytest\nfrom scripts.converters.convert_landuse_to_db import (\n    process_matrix_data, \n    extract_end_year,\n    LAND_USE_MAP\n)\n\nclass TestConverters:\n    def test_land_use_mapping(self):\n        \"\"\"Test land use code mappings.\"\"\"\n        assert LAND_USE_MAP['cr'] == 'Crop'\n        assert LAND_USE_MAP['ps'] == 'Pasture'\n        assert LAND_USE_MAP['ur'] == 'Urban'\n\n    def test_extract_end_year(self):\n        \"\"\"Test year extraction from range.\"\"\"\n        assert extract_end_year('2020-2030') == 2030\n        assert extract_end_year('2090-2100') == 2100\n\n    def test_process_matrix_data(self):\n        \"\"\"Test matrix data processing.\"\"\"\n        matrix_data = [\n            {'_row': 'cr', 'cr': 100.0, 'ur': 5.0, 'fr': 2.0}\n        ]\n\n        transitions = process_matrix_data(\n            matrix_data, \n            'Baseline', \n            2030, \n            '2020-2030', \n            '06037'\n        )\n\n        assert len(transitions) == 3\n        assert transitions[0]['from_land_use'] == 'Crop'\n        assert transitions[0]['area_1000_acres'] == 100.0\n</code></pre>"},{"location":"development/testing/#testing-tools","title":"Testing Tools","text":"<pre><code># tests/unit/test_tools.py\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\n\nclass TestTools:\n    @pytest.fixture\n    def agent(self):\n        \"\"\"Create agent instance for testing.\"\"\"\n        return DataEngineeringAgent(root_dir=\"tests/data\")\n\n    def test_read_csv(self, agent):\n        \"\"\"Test CSV reading tool.\"\"\"\n        result = agent._read_csv(\"sample.csv\")\n        assert \"Shape:\" in result\n        assert \"Columns:\" in result\n\n    def test_analyze_dataframe(self, agent):\n        \"\"\"Test dataframe analysis.\"\"\"\n        result = agent._analyze_dataframe(\"sample.csv\")\n        analysis = json.loads(result)\n        assert \"shape\" in analysis\n        assert \"column_analysis\" in analysis\n\n    @pytest.mark.parametrize(\"file_path,expected\", [\n        (\"data.csv\", \"csv\"),\n        (\"data.json\", \"json\"), \n        (\"data.parquet\", \"parquet\")\n    ])\n    def test_file_format_detection(self, agent, file_path, expected):\n        \"\"\"Test file format detection.\"\"\"\n        format = agent._detect_format(file_path)\n        assert format == expected\n</code></pre>"},{"location":"development/testing/#testing-validators","title":"Testing Validators","text":"<pre><code># tests/unit/test_validators.py\nimport pytest\nfrom pydantic import ValidationError\n\ndef test_query_params_validation():\n    \"\"\"Test query parameter validation.\"\"\"\n    from scripts.agents.data_engineering_agent import FileQueryParams\n\n    # Valid params\n    params = FileQueryParams(\n        file_path=\"data.csv\",\n        query=\"SELECT * FROM data\"\n    )\n    assert params.file_path == \"data.csv\"\n\n    # Invalid params\n    with pytest.raises(ValidationError):\n        FileQueryParams(query=\"SELECT *\")  # Missing file_path\n</code></pre>"},{"location":"development/testing/#integration-testing","title":"Integration Testing","text":""},{"location":"development/testing/#testing-agent-integration","title":"Testing Agent Integration","text":"<pre><code># tests/integration/test_agent.py\nimport pytest\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\n\nclass TestAgentIntegration:\n    @pytest.fixture\n    def agent(self):\n        \"\"\"Create real agent instance.\"\"\"\n        return DataEngineeringAgent()\n\n    def test_natural_language_query(self, agent):\n        \"\"\"Test natural language to SQL conversion.\"\"\"\n        result = agent.run(\"Show me all tables in test.db\")\n        assert \"Tables:\" in result\n        assert \"rows\" in result\n\n    def test_multi_step_query(self, agent):\n        \"\"\"Test agent memory and context.\"\"\"\n        # First query\n        result1 = agent.run(\"Read sample.csv\")\n        assert \"Shape:\" in result1\n\n        # Follow-up query using context\n        result2 = agent.run(\"Now query it for values &gt; 100\")\n        assert \"Query Result\" in result2\n\n    @pytest.mark.slow\n    def test_large_file_processing(self, agent):\n        \"\"\"Test handling of large files.\"\"\"\n        result = agent.run(\"Process large_dataset.json\")\n        assert \"LARGE FILE\" in result\n</code></pre>"},{"location":"development/testing/#testing-database-operations","title":"Testing Database Operations","text":"<pre><code># tests/integration/test_database.py\nimport sqlite3\nimport pytest\n\nclass TestDatabaseIntegration:\n    @pytest.fixture\n    def test_db(self, tmp_path):\n        \"\"\"Create test database.\"\"\"\n        db_path = tmp_path / \"test.db\"\n        conn = sqlite3.connect(db_path)\n\n        # Create test schema\n        conn.execute(\"\"\"\n            CREATE TABLE landuse_transitions (\n                scenario TEXT,\n                year INTEGER,\n                from_land_use TEXT,\n                to_land_use TEXT,\n                area_1000_acres REAL\n            )\n        \"\"\")\n\n        # Insert test data\n        test_data = [\n            ('Baseline', 2030, 'Forest', 'Urban', 100.5),\n            ('Baseline', 2030, 'Crop', 'Urban', 50.2)\n        ]\n        conn.executemany(\n            \"INSERT INTO landuse_transitions VALUES (?,?,?,?,?)\",\n            test_data\n        )\n        conn.commit()\n        conn.close()\n\n        return db_path\n\n    def test_database_query(self, agent, test_db):\n        \"\"\"Test database querying.\"\"\"\n        result = agent.run(f\"Query {test_db}: SELECT COUNT(*) FROM landuse_transitions\")\n        assert \"2\" in result\n</code></pre>"},{"location":"development/testing/#end-to-end-testing","title":"End-to-End Testing","text":""},{"location":"development/testing/#testing-complete-workflows","title":"Testing Complete Workflows","text":"<pre><code># tests/e2e/test_workflows.py\nimport pytest\nfrom pathlib import Path\n\nclass TestWorkflows:\n    def test_county_analysis_workflow(self, agent):\n        \"\"\"Test complete county analysis workflow.\"\"\"\n        # Step 1: Identify county\n        result = agent.run(\"What's the FIPS code for Los Angeles County?\")\n        assert \"06037\" in result\n\n        # Step 2: Get current land use\n        result = agent.run(\"Show land use for FIPS 06037 in 2020\")\n        assert \"Urban\" in result\n        assert \"Forest\" in result\n\n        # Step 3: Analyze changes\n        result = agent.run(\"Show land use changes for this county through 2050\")\n        assert \"transitions\" in result.lower()\n\n        # Step 4: Export results\n        result = agent.run(\"Export this analysis to la_county_analysis.csv\")\n        assert Path(\"la_county_analysis.csv\").exists()\n\n    def test_scenario_comparison_workflow(self, agent):\n        \"\"\"Test scenario comparison workflow.\"\"\"\n        queries = [\n            \"List all available scenarios\",\n            \"Compare forest area between scenarios in 2050\",\n            \"Which scenario preserves the most forest?\",\n            \"Create a summary table of scenario differences\"\n        ]\n\n        for query in queries:\n            result = agent.run(query)\n            assert \"Error\" not in result\n</code></pre>"},{"location":"development/testing/#testing-query-patterns","title":"Testing Query Patterns","text":"<pre><code># tests/e2e/test_queries.py\nimport pytest\n\nclass TestQueryPatterns:\n    @pytest.mark.parametrize(\"query,expected_terms\", [\n        (\"Show forest loss\", [\"Forest\", \"area\", \"decrease\"]),\n        (\"Urban growth by decade\", [\"Urban\", \"decade\", \"growth\"]),\n        (\"Agricultural transitions\", [\"Crop\", \"Pasture\", \"transition\"])\n    ])\n    def test_query_understanding(self, agent, query, expected_terms):\n        \"\"\"Test that queries return relevant results.\"\"\"\n        result = agent.run(query)\n        for term in expected_terms:\n            assert term in result or term.lower() in result.lower()\n</code></pre>"},{"location":"development/testing/#test-data-management","title":"Test Data Management","text":""},{"location":"development/testing/#creating-test-fixtures","title":"Creating Test Fixtures","text":"<pre><code># tests/data/fixtures.py\nimport json\nimport sqlite3\nfrom pathlib import Path\n\ndef create_test_json():\n    \"\"\"Create minimal test JSON data.\"\"\"\n    test_data = {\n        \"06037\": {\n            \"county_name\": \"Los Angeles\",\n            \"scenarios\": {\n                \"Baseline\": {\n                    \"2020-2030\": {\n                        \"transition_matrix\": [\n                            {\"_row\": \"cr\", \"cr\": 100, \"ur\": 10},\n                            {\"_row\": \"ur\", \"cr\": 0, \"ur\": 200}\n                        ]\n                    }\n                }\n            }\n        }\n    }\n\n    with open(\"tests/data/test.json\", \"w\") as f:\n        json.dump(test_data, f)\n\ndef create_test_database():\n    \"\"\"Create minimal test database.\"\"\"\n    conn = sqlite3.connect(\"tests/data/test.db\")\n\n    # Create schema\n    conn.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS landuse_transitions (\n            scenario TEXT,\n            year INTEGER,\n            fips TEXT,\n            from_land_use TEXT,\n            to_land_use TEXT,\n            area_1000_acres REAL\n        )\n    \"\"\")\n\n    # Insert test data\n    conn.execute(\"\"\"\n        INSERT INTO landuse_transitions VALUES\n        ('Baseline', 2030, '06037', 'Forest', 'Urban', 100.5)\n    \"\"\")\n\n    conn.commit()\n    conn.close()\n</code></pre>"},{"location":"development/testing/#test-data-best-practices","title":"Test Data Best Practices","text":"<ol> <li>Keep It Minimal: Use smallest dataset that tests functionality</li> <li>Make It Readable: Clear, understandable test data</li> <li>Version Control: Include test data in repository</li> <li>Isolation: Each test should be independent</li> </ol>"},{"location":"development/testing/#mocking-and-fixtures","title":"Mocking and Fixtures","text":""},{"location":"development/testing/#mocking-llm-responses","title":"Mocking LLM Responses","text":"<pre><code># tests/conftest.py\nimport pytest\nfrom unittest.mock import Mock, patch\n\n@pytest.fixture\ndef mock_llm():\n    \"\"\"Mock LLM for testing without API calls.\"\"\"\n    with patch('langchain_openai.ChatOpenAI') as mock:\n        instance = Mock()\n        instance.invoke.return_value = Mock(content=\"Mocked response\")\n        mock.return_value = instance\n        yield instance\n\n@pytest.fixture\ndef agent_with_mock_llm(mock_llm):\n    \"\"\"Agent instance with mocked LLM.\"\"\"\n    from scripts.agents.data_engineering_agent import DataEngineeringAgent\n    agent = DataEngineeringAgent()\n    agent.llm = mock_llm\n    return agent\n</code></pre>"},{"location":"development/testing/#database-fixtures","title":"Database Fixtures","text":"<pre><code>@pytest.fixture\ndef temp_database(tmp_path):\n    \"\"\"Create temporary database for testing.\"\"\"\n    db_path = tmp_path / \"temp.db\"\n\n    # Create and populate\n    conn = sqlite3.connect(db_path)\n    # ... setup schema and data ...\n    conn.close()\n\n    yield db_path\n\n    # Cleanup happens automatically with tmp_path\n</code></pre>"},{"location":"development/testing/#performance-testing","title":"Performance Testing","text":""},{"location":"development/testing/#benchmarking-queries","title":"Benchmarking Queries","text":"<pre><code># tests/performance/test_performance.py\nimport pytest\nimport time\n\nclass TestPerformance:\n    @pytest.mark.benchmark\n    def test_query_performance(self, agent, benchmark):\n        \"\"\"Benchmark query execution time.\"\"\"\n        def run_query():\n            return agent.run(\"SELECT COUNT(*) FROM landuse_transitions\")\n\n        result = benchmark(run_query)\n        assert \"Error\" not in result\n\n    def test_large_file_processing_speed(self, agent):\n        \"\"\"Test processing speed for large files.\"\"\"\n        start_time = time.time()\n        result = agent.run(\"Process large_test_file.json\")\n        duration = time.time() - start_time\n\n        assert duration &lt; 60  # Should complete within 1 minute\n        assert \"Error\" not in result\n</code></pre>"},{"location":"development/testing/#manual-testing-checklist","title":"Manual Testing Checklist","text":""},{"location":"development/testing/#agent-functionality","title":"Agent Functionality","text":"<ul> <li> Agent starts without errors</li> <li> Natural language queries work</li> <li> File operations complete successfully</li> <li> Database queries return results</li> <li> Error messages are helpful</li> <li> Memory/context works between queries</li> </ul>"},{"location":"development/testing/#query-testing","title":"Query Testing","text":"<ul> <li> Basic queries (\"Show me all tables\")</li> <li> Complex queries (multi-condition WHERE)</li> <li> Aggregation queries (GROUP BY, SUM)</li> <li> Join queries (if applicable)</li> <li> Export functionality works</li> <li> Visualization generation works</li> </ul>"},{"location":"development/testing/#edge-cases","title":"Edge Cases","text":"<ul> <li> Empty database handling</li> <li> Missing file handling</li> <li> Invalid query syntax</li> <li> Large result sets</li> <li> Special characters in data</li> <li> Concurrent operations</li> </ul>"},{"location":"development/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"development/testing/#github-actions-configuration","title":"GitHub Actions Configuration","text":"<pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n\n    - name: Install dependencies\n      run: |\n        pip install uv\n        uv pip install -r config/requirements.txt\n\n    - name: Run tests\n      env:\n        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n      run: |\n        uv run pytest --cov=scripts --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"development/testing/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"development/testing/#1-test-organization","title":"1. Test Organization","text":"<ul> <li>Group related tests in classes</li> <li>Use descriptive test names</li> <li>One assertion per test (when possible)</li> <li>Use fixtures for common setup</li> </ul>"},{"location":"development/testing/#2-test-independence","title":"2. Test Independence","text":"<ul> <li>Tests should not depend on each other</li> <li>Clean up after tests</li> <li>Use temporary files/databases</li> <li>Reset agent state between tests</li> </ul>"},{"location":"development/testing/#3-test-coverage","title":"3. Test Coverage","text":"<ul> <li>Aim for &gt;80% code coverage</li> <li>Test happy paths and edge cases</li> <li>Test error conditions</li> <li>Test performance characteristics</li> </ul>"},{"location":"development/testing/#4-test-documentation","title":"4. Test Documentation","text":"<pre><code>def test_complex_scenario():\n    \"\"\"\n    Test that scenario comparison works correctly.\n\n    This test verifies:\n    1. Multiple scenarios can be loaded\n    2. Comparisons calculate differences correctly\n    3. Results are formatted properly\n    \"\"\"\n    # Test implementation\n</code></pre>"},{"location":"development/testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"development/testing/#running-tests-in-debug-mode","title":"Running Tests in Debug Mode","text":"<pre><code># Run with debugger\nuv run pytest --pdb\n\n# Run with print statements visible\nuv run pytest -s\n\n# Run with full traceback\nuv run pytest --tb=long\n</code></pre>"},{"location":"development/testing/#common-test-issues","title":"Common Test Issues","text":"<ol> <li>Import Errors: Ensure PYTHONPATH includes project root</li> <li>API Key Issues: Mock LLM calls or use test keys</li> <li>File Path Issues: Use relative paths or fixtures</li> <li>Database Locks: Ensure connections are closed</li> </ol>"},{"location":"development/testing/#next-steps","title":"Next Steps","text":"<ul> <li>Review Architecture for system design</li> <li>See Contributing for development workflow</li> <li>Check API Reference for implementation details</li> </ul>"},{"location":"examples/notebooks/","title":"Jupyter Notebook Examples","text":"<p>Interactive Jupyter notebooks for exploring land use data with the LangChain agent.</p>"},{"location":"examples/notebooks/#overview","title":"Overview","text":"<p>Jupyter notebooks provide an interactive environment for data exploration, visualization, and analysis. This page contains example notebooks demonstrating various use cases.</p>"},{"location":"examples/notebooks/#getting-started-with-notebooks","title":"Getting Started with Notebooks","text":""},{"location":"examples/notebooks/#setup","title":"Setup","text":"<pre><code># Install Jupyter\nuv pip install jupyter ipykernel\n\n# Create kernel for this project\nuv run python -m ipykernel install --name langchain-landuse --user\n\n# Start Jupyter\nuv run jupyter notebook\n</code></pre>"},{"location":"examples/notebooks/#example-notebooks","title":"Example Notebooks","text":""},{"location":"examples/notebooks/#1-basic-agent-interaction","title":"1. Basic Agent Interaction","text":"<p>Notebook: <code>01_basic_agent_usage.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nfrom rich.console import Console\n\nconsole = Console()\nagent = DataEngineeringAgent()\n\n# Cell 2: Basic Query\nresult = agent.run(\"Show me all tables in landuse_transitions.db\")\nprint(result)\n\n# Cell 3: Explore Schema\nresult = agent.run(\"Describe the landuse_transitions table\")\nprint(result)\n\n# Cell 4: Simple Analysis\nresult = agent.run(\"What are the total land areas by type in 2050?\")\nprint(result)\n</code></pre>"},{"location":"examples/notebooks/#2-land-use-transition-analysis","title":"2. Land Use Transition Analysis","text":"<p>Notebook: <code>02_transition_analysis.ipynb</code></p> <pre><code># Cell 1: Import and Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Query Transition Data\nquery = \"\"\"\nQuery processed/landuse_transitions.db:\nSELECT from_land_use, to_land_use, SUM(area_1000_acres) as total_area\nFROM landuse_transitions\nWHERE scenario = 'Baseline' AND year = 2050\nGROUP BY from_land_use, to_land_use\nORDER BY total_area DESC\n\"\"\"\nresult = agent.run(query)\n\n# Cell 3: Parse Results to DataFrame\n# Extract data from agent response\n# This would need parsing logic based on agent output format\n\n# Cell 4: Create Transition Matrix Visualization\n# Create pivot table\ntransition_matrix = df.pivot(\n    index='from_land_use', \n    columns='to_land_use', \n    values='total_area'\n)\n\n# Heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(transition_matrix, annot=True, fmt='.0f', cmap='YlOrRd')\nplt.title('Land Use Transition Matrix (1000 acres)')\nplt.xlabel('To Land Use')\nplt.ylabel('From Land Use')\nplt.show()\n</code></pre>"},{"location":"examples/notebooks/#3-scenario-comparison","title":"3. Scenario Comparison","text":"<p>Notebook: <code>03_scenario_comparison.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nagent = DataEngineeringAgent()\nscenarios = ['Baseline', 'High Crop Demand', 'High Forest', 'High Urban']\n\n# Cell 2: Query Multiple Scenarios\nresults = {}\nfor scenario in scenarios:\n    query = f\"\"\"\n    Query processed/landuse_transitions.db:\n    SELECT year, to_land_use, SUM(area_1000_acres) as area\n    FROM landuse_transitions\n    WHERE scenario = '{scenario}' \n      AND from_land_use = to_land_use\n      AND to_land_use != 'Total'\n    GROUP BY year, to_land_use\n    \"\"\"\n    results[scenario] = agent.run(query)\n\n# Cell 3: Process and Visualize\n# Parse results into DataFrames\n# Create multi-panel plot\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\naxes = axes.flatten()\n\nfor idx, scenario in enumerate(scenarios):\n    ax = axes[idx]\n    # Plot logic here\n    ax.set_title(f'{scenario} Scenario')\n    ax.set_xlabel('Year')\n    ax.set_ylabel('Area (1000 acres)')\n    ax.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"examples/notebooks/#4-geographic-analysis","title":"4. Geographic Analysis","text":"<p>Notebook: <code>04_geographic_patterns.ipynb</code></p> <pre><code># Cell 1: Setup with Geospatial Libraries\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Query County-Level Changes\nquery = \"\"\"\nQuery processed/landuse_transitions.db:\nSELECT fips, \n       SUM(CASE WHEN to_land_use = 'Urban' THEN area_1000_acres ELSE 0 END) -\n       SUM(CASE WHEN from_land_use = 'Urban' THEN area_1000_acres ELSE 0 END) as urban_change\nFROM landuse_transitions\nWHERE scenario = 'Baseline' AND year = 2050\nGROUP BY fips\n\"\"\"\nresult = agent.run(query)\n\n# Cell 3: Load County Boundaries\n# Assuming you have county shapefiles\ncounties = gpd.read_file('data/counties.shp')\n\n# Cell 4: Create Choropleth Map\nfig, ax = plt.subplots(1, 1, figsize=(15, 10))\n\n# Merge data with geometries\n# Create map\ncounties.plot(\n    column='urban_change',\n    ax=ax,\n    legend=True,\n    cmap='RdYlBu_r',\n    legend_kwds={'label': 'Urban Change (1000 acres)'}\n)\n\nax.set_title('Urban Land Change by County (2020-2050)', fontsize=16)\nax.axis('off')\nplt.show()\n</code></pre>"},{"location":"examples/notebooks/#5-time-series-analysis","title":"5. Time Series Analysis","text":"<p>Notebook: <code>05_time_series.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Query Time Series Data\nquery = \"\"\"\nQuery processed/landuse_transitions.db:\nSELECT year, to_land_use, SUM(area_1000_acres) as total_area\nFROM landuse_transitions\nWHERE scenario = 'Baseline' \n  AND from_land_use = to_land_use\n  AND to_land_use IN ('Crop', 'Forest', 'Urban', 'Pasture')\nGROUP BY year, to_land_use\nORDER BY year, to_land_use\n\"\"\"\nresult = agent.run(query)\n\n# Cell 3: Create Animated Visualization\n# Parse data\n# Create animation showing land use change over time\n\n# Cell 4: Trend Analysis\n# Calculate growth rates\n# Fit trend lines\n# Project future values\n</code></pre>"},{"location":"examples/notebooks/#6-natural-language-query-explorer","title":"6. Natural Language Query Explorer","text":"<p>Notebook: <code>06_query_explorer.ipynb</code></p> <pre><code># Cell 1: Interactive Query Interface\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nfrom ipywidgets import interact, widgets\nfrom IPython.display import display, HTML\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Create Query Widget\nquery_input = widgets.Textarea(\n    value='Show me forest loss by decade',\n    placeholder='Enter your natural language query',\n    description='Query:',\n    layout=widgets.Layout(width='100%', height='100px')\n)\n\noutput = widgets.Output()\n\ndef run_query(b):\n    with output:\n        output.clear_output()\n        print(f\"Running: {query_input.value}\")\n        result = agent.run(query_input.value)\n        print(\"\\nResult:\")\n        print(result)\n\nbutton = widgets.Button(description=\"Run Query\")\nbutton.on_click(run_query)\n\ndisplay(query_input, button, output)\n\n# Cell 3: Query Templates\ntemplates = {\n    \"Forest Analysis\": \"Show me counties with the most forest loss\",\n    \"Urban Growth\": \"Which areas have the fastest urban expansion?\",\n    \"Agricultural\": \"Compare crop and pasture changes over time\",\n    \"Scenarios\": \"How do the different scenarios compare for urban growth?\"\n}\n\nfor name, query in templates.items():\n    btn = widgets.Button(description=name)\n    btn.on_click(lambda b, q=query: query_input.value.update(q))\n    display(btn)\n</code></pre>"},{"location":"examples/notebooks/#7-statistical-analysis","title":"7. Statistical Analysis","text":"<p>Notebook: <code>07_statistical_analysis.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom scripts.agents.data_engineering_agent import DataEngineeringAgent\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.api as sm\n\nagent = DataEngineeringAgent()\n\n# Cell 2: Get Data for Statistical Analysis\n# Query for correlations between land use changes\n\n# Cell 3: Correlation Analysis\n# Calculate correlation matrix\n# Test for significant correlations\n\n# Cell 4: Regression Analysis\n# Predict urban growth based on other factors\n\n# Cell 5: Statistical Tests\n# Test hypothesis about land use changes\n# ANOVA for scenario comparisons\n</code></pre>"},{"location":"examples/notebooks/#best-practices-for-notebooks","title":"Best Practices for Notebooks","text":""},{"location":"examples/notebooks/#1-organization","title":"1. Organization","text":"<pre><code># Clear section headers\n# %% [markdown]\n# # Section 1: Data Loading\n\n# %% \n# Code for data loading\n\n# %% [markdown]\n# # Section 2: Analysis\n\n# %%\n# Analysis code\n</code></pre>"},{"location":"examples/notebooks/#2-reproducibility","title":"2. Reproducibility","text":"<pre><code># Cell 1: Always set random seeds\nimport random\nimport numpy as np\n\nrandom.seed(42)\nnp.random.seed(42)\n\n# Cell 2: Document package versions\nimport sys\nprint(f\"Python: {sys.version}\")\nprint(f\"Pandas: {pd.__version__}\")\n</code></pre>"},{"location":"examples/notebooks/#3-error-handling","title":"3. Error Handling","text":"<pre><code># Wrap agent calls in try-except\ntry:\n    result = agent.run(query)\n    # Process result\nexcept Exception as e:\n    print(f\"Query failed: {e}\")\n    # Handle error gracefully\n</code></pre>"},{"location":"examples/notebooks/#4-visualization-standards","title":"4. Visualization Standards","text":"<pre><code># Set consistent plot style\nplt.style.use('seaborn-v0_8-darkgrid')\n\n# Create reusable plot function\ndef plot_land_use_trends(data, title):\n    fig, ax = plt.subplots(figsize=(12, 6))\n    # Plotting logic\n    ax.set_title(title, fontsize=16)\n    ax.set_xlabel('Year')\n    ax.set_ylabel('Area (1000 acres)')\n    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n    plt.tight_layout()\n    return fig\n</code></pre>"},{"location":"examples/notebooks/#sharing-notebooks","title":"Sharing Notebooks","text":""},{"location":"examples/notebooks/#export-options","title":"Export Options","text":"<pre><code># Export to HTML\njupyter nbconvert --to html notebook.ipynb\n\n# Export to PDF\njupyter nbconvert --to pdf notebook.ipynb\n\n# Export to Python script\njupyter nbconvert --to python notebook.ipynb\n</code></pre>"},{"location":"examples/notebooks/#notebook-templates","title":"Notebook Templates","text":"<p>Create template notebooks for common analyses:</p> <ol> <li><code>template_county_analysis.ipynb</code> - County-specific analysis</li> <li><code>template_scenario_comparison.ipynb</code> - Compare scenarios</li> <li><code>template_time_series.ipynb</code> - Temporal analysis</li> <li><code>template_visualization.ipynb</code> - Creating charts</li> </ol>"},{"location":"examples/notebooks/#interactive-dashboards","title":"Interactive Dashboards","text":""},{"location":"examples/notebooks/#using-voila","title":"Using Voila","text":"<pre><code># Install Voila\nuv pip install voila\n\n# Create dashboard from notebook\nvoila dashboard_notebook.ipynb\n</code></pre>"},{"location":"examples/notebooks/#example-dashboard-code","title":"Example Dashboard Code","text":"<pre><code># Cell 1: Dashboard Setup\nimport ipywidgets as widgets\nfrom IPython.display import display\nimport plotly.graph_objects as go\n\n# Create controls\nscenario_dropdown = widgets.Dropdown(\n    options=['Baseline', 'High Crop Demand', 'High Forest', 'High Urban'],\n    description='Scenario:'\n)\n\nyear_slider = widgets.IntSlider(\n    value=2050,\n    min=2020,\n    max=2100,\n    step=10,\n    description='Year:'\n)\n\n# Cell 2: Interactive Plot\n@widgets.interact(scenario=scenario_dropdown, year=year_slider)\ndef update_plot(scenario, year):\n    # Query data\n    query = f\"\"\"\n    Query processed/landuse_transitions.db:\n    SELECT to_land_use, SUM(area_1000_acres) as area\n    FROM landuse_transitions\n    WHERE scenario = '{scenario}' AND year = {year}\n    GROUP BY to_land_use\n    \"\"\"\n\n    result = agent.run(query)\n    # Parse and plot with Plotly\n</code></pre>"},{"location":"examples/notebooks/#resources","title":"Resources","text":""},{"location":"examples/notebooks/#example-notebook-repository","title":"Example Notebook Repository","text":"<p>Find complete example notebooks at: - GitHub: <code>examples/notebooks/</code> - Each notebook includes:   - Full code   - Expected outputs   - Explanations   - Exercises</p>"},{"location":"examples/notebooks/#learning-resources","title":"Learning Resources","text":"<ol> <li>Jupyter Documentation: https://jupyter.org/documentation</li> <li>Pandas Tutorials: For data manipulation</li> <li>Matplotlib Gallery: For visualization ideas</li> <li>Geopandas Examples: For geographic analysis</li> </ol>"},{"location":"examples/notebooks/#next-steps","title":"Next Steps","text":"<ul> <li>Download example notebooks from the repository</li> <li>Try modifying queries for your specific needs</li> <li>Create custom visualizations</li> <li>Share your notebooks with the community</li> </ul>"},{"location":"examples/use-cases/","title":"Real-World Use Cases","text":"<p>Practical applications of the LangChain Land Use Analysis system for various stakeholders and decision-making scenarios.</p>"},{"location":"examples/use-cases/#policy-analysis","title":"\ud83c\udfdb\ufe0f Policy Analysis","text":""},{"location":"examples/use-cases/#use-case-evaluating-conservation-policy-impact","title":"Use Case: Evaluating Conservation Policy Impact","text":"<p>Scenario: A state environmental agency wants to assess the effectiveness of forest conservation policies.</p> <p>Approach: <pre><code>You&gt; Compare forest area outcomes between the Baseline and High Forest scenarios for our state\n\nYou&gt; Which counties show the biggest difference in forest preservation between these scenarios?\n\nYou&gt; Calculate the total forest area saved under the High Forest scenario by 2050\n\nYou&gt; What types of land use conversions are prevented in the High Forest scenario?\n</code></pre></p> <p>Insights Generated: - Quantify conservation policy benefits - Identify high-impact counties - Understand trade-offs with other land uses - Support funding allocation decisions</p>"},{"location":"examples/use-cases/#use-case-agricultural-policy-planning","title":"Use Case: Agricultural Policy Planning","text":"<p>Scenario: USDA needs to understand future agricultural land availability.</p> <p>Analysis Workflow: 1. Assess total agricultural land trends 2. Identify regions losing farmland 3. Compare crop vs. pasture dynamics 4. Evaluate scenario impacts</p> <pre><code>You&gt; Show me the net change in agricultural land (crop + pasture) by decade for each scenario\n\nYou&gt; Which regions are losing agricultural land the fastest?\n\nYou&gt; In the High Crop Demand scenario, where does the additional cropland come from?\n\nYou&gt; Project when agricultural land might fall below critical thresholds in major farming states\n</code></pre>"},{"location":"examples/use-cases/#urban-planning","title":"\ud83c\udfd7\ufe0f Urban Planning","text":""},{"location":"examples/use-cases/#use-case-metropolitan-growth-management","title":"Use Case: Metropolitan Growth Management","text":"<p>Scenario: A regional planning council needs to prepare for urban expansion.</p> <p>Key Questions: <pre><code>You&gt; Map urban growth projections for our metropolitan area through 2100\n\nYou&gt; What are the primary sources of land for urban expansion in our region?\n\nYou&gt; Compare urban growth rates between the Baseline and High Urban scenarios\n\nYou&gt; Which adjacent counties will experience the most development pressure?\n</code></pre></p> <p>Applications: - Infrastructure planning - Transportation network design - Utility capacity planning - Housing development strategies</p>"},{"location":"examples/use-cases/#use-case-smart-growth-analysis","title":"Use Case: Smart Growth Analysis","text":"<p>Scenario: City planners want to minimize sprawl and protect natural areas.</p> <p>Investigation Process: <pre><code>You&gt; Find examples of counties that accommodate urban growth while preserving forest\n\nYou&gt; Calculate the efficiency of urban land use (area per projected population)\n\nYou&gt; Identify counties with the most compact urban development patterns\n\nYou&gt; Show me areas where urban growth threatens critical natural habitats\n</code></pre></p>"},{"location":"examples/use-cases/#environmental-assessment","title":"\ud83c\udf0d Environmental Assessment","text":""},{"location":"examples/use-cases/#use-case-climate-change-mitigation","title":"Use Case: Climate Change Mitigation","text":"<p>Scenario: Environmental groups need data on land use impacts on carbon storage.</p> <p>Carbon Analysis Queries: <pre><code>You&gt; Calculate total forest area changes that impact carbon sequestration\n\nYou&gt; Which scenario maintains the most carbon-storing land uses?\n\nYou&gt; Show me the trade-off between agricultural expansion and forest carbon storage\n\nYou&gt; Identify counties where reforestation could have the biggest impact\n</code></pre></p> <p>Decision Support: - Carbon credit program design - Reforestation prioritization - Climate policy advocacy - Investment targeting</p>"},{"location":"examples/use-cases/#use-case-watershed-protection","title":"Use Case: Watershed Protection","text":"<p>Scenario: Water management districts need to protect water resources.</p> <p>Watershed Analysis: <pre><code>You&gt; Show land use changes in counties within our watershed\n\nYou&gt; How much forest buffer is lost along waterways?\n\nYou&gt; Which scenarios best protect natural land in water-sensitive areas?\n\nYou&gt; Calculate impervious surface increase from urban expansion\n</code></pre></p>"},{"location":"examples/use-cases/#economic-development","title":"\ud83d\udcca Economic Development","text":""},{"location":"examples/use-cases/#use-case-rural-economic-planning","title":"Use Case: Rural Economic Planning","text":"<p>Scenario: Rural counties need to plan for economic transitions.</p> <p>Economic Analysis: <pre><code>You&gt; Identify rural counties with significant agricultural land loss\n\nYou&gt; What's replacing agricultural land in rural areas?\n\nYou&gt; Show me counties successfully maintaining agricultural economies\n\nYou&gt; Compare economic land use patterns between thriving and declining rural counties\n</code></pre></p> <p>Strategic Planning: - Economic diversification strategies - Agricultural preservation programs - Tourism development opportunities - Infrastructure investments</p>"},{"location":"examples/use-cases/#use-case-real-estate-market-analysis","title":"Use Case: Real Estate Market Analysis","text":"<p>Scenario: Real estate developers need long-term market insights.</p> <p>Market Research Queries: <pre><code>You&gt; Which counties will have the most urban growth pressure?\n\nYou&gt; Show me areas transitioning from agricultural to urban use\n\nYou&gt; Identify counties with limited developable land by 2050\n\nYou&gt; Compare development potential across different scenarios\n</code></pre></p>"},{"location":"examples/use-cases/#conservation-planning","title":"\ud83c\udfde\ufe0f Conservation Planning","text":""},{"location":"examples/use-cases/#use-case-habitat-corridor-design","title":"Use Case: Habitat Corridor Design","text":"<p>Scenario: Conservation organizations planning wildlife corridors.</p> <p>Connectivity Analysis: <pre><code>You&gt; Show me forest fragmentation patterns over time\n\nYou&gt; Which counties maintain the largest contiguous forest areas?\n\nYou&gt; Identify critical linkages between protected areas threatened by development\n\nYou&gt; Calculate habitat loss for forest-dependent species\n</code></pre></p> <p>Conservation Strategy: - Land acquisition priorities - Conservation easement targeting - Habitat restoration planning - Species protection strategies</p>"},{"location":"examples/use-cases/#use-case-biodiversity-hotspot-protection","title":"Use Case: Biodiversity Hotspot Protection","text":"<p>Scenario: Protecting areas of high biodiversity value.</p> <p>Biodiversity Queries: <pre><code>You&gt; Identify counties with diverse land use types that support biodiversity\n\nYou&gt; Show me areas where multiple natural land types are converting to developed uses\n\nYou&gt; Which scenario best maintains landscape heterogeneity?\n\nYou&gt; Find counties where conservation could protect multiple ecosystem types\n</code></pre></p>"},{"location":"examples/use-cases/#agricultural-sustainability","title":"\ud83c\udf3e Agricultural Sustainability","text":""},{"location":"examples/use-cases/#use-case-food-security-assessment","title":"Use Case: Food Security Assessment","text":"<p>Scenario: State agricultural departments assessing future food production capacity.</p> <p>Food Security Analysis: <pre><code>You&gt; Calculate total cropland availability by decade\n\nYou&gt; Show me the balance between population growth and agricultural land\n\nYou&gt; Which regions maintain the most productive agricultural land?\n\nYou&gt; Identify counties at risk of losing critical agricultural infrastructure\n</code></pre></p> <p>Policy Applications: - Farmland preservation programs - Agricultural zoning policies - Food system planning - Investment priorities</p>"},{"location":"examples/use-cases/#use-case-sustainable-farming-transitions","title":"Use Case: Sustainable Farming Transitions","text":"<p>Scenario: Supporting transitions to sustainable agriculture.</p> <p>Sustainability Queries: <pre><code>You&gt; Show me areas transitioning between crop and pasture (indicating diverse farming)\n\nYou&gt; Identify counties with stable agricultural land use patterns\n\nYou&gt; Which areas show agricultural intensification vs. extensification?\n\nYou&gt; Find opportunities for agricultural conservation programs\n</code></pre></p>"},{"location":"examples/use-cases/#investment-analysis","title":"\ud83d\udcc8 Investment Analysis","text":""},{"location":"examples/use-cases/#use-case-green-infrastructure-investment","title":"Use Case: Green Infrastructure Investment","text":"<p>Scenario: Impact investors seeking environmental returns.</p> <p>Investment Research: <pre><code>You&gt; Identify counties where forest conservation has the highest value\n\nYou&gt; Show me areas with opportunities for agricultural sustainability investments\n\nYou&gt; Which regions show the best potential for natural climate solutions?\n\nYou&gt; Calculate potential returns from ecosystem service payments\n</code></pre></p>"},{"location":"examples/use-cases/#use-case-infrastructure-planning","title":"Use Case: Infrastructure Planning","text":"<p>Scenario: State DOT planning long-term transportation investments.</p> <p>Infrastructure Analysis: <pre><code>You&gt; Show me projected urban growth along major transportation corridors\n\nYou&gt; Which rural areas will urbanize and need infrastructure upgrades?\n\nYou&gt; Identify counties where agricultural traffic will increase\n\nYou&gt; Calculate future infrastructure demand based on land use changes\n</code></pre></p>"},{"location":"examples/use-cases/#integrated-assessments","title":"\ud83d\udd04 Integrated Assessments","text":""},{"location":"examples/use-cases/#use-case-comprehensive-sustainability-assessment","title":"Use Case: Comprehensive Sustainability Assessment","text":"<p>Scenario: Multi-stakeholder coalition evaluating regional sustainability.</p> <p>Holistic Analysis Approach:</p> <pre><code># Step 1: Environmental Health\nYou&gt; Calculate natural land preservation rates by scenario\n\n# Step 2: Economic Viability  \nYou&gt; Assess agricultural economic sustainability\n\n# Step 3: Social Equity\nYou&gt; Identify communities most impacted by land use change\n\n# Step 4: Integrated Score\nYou&gt; Create a composite sustainability index combining all factors\n</code></pre> <p>Stakeholder Benefits: - Shared understanding of trade-offs - Evidence-based compromise - Long-term vision alignment - Performance monitoring framework</p>"},{"location":"examples/use-cases/#best-practices-for-use-cases","title":"Best Practices for Use Cases","text":""},{"location":"examples/use-cases/#1-start-with-clear-objectives","title":"1. Start with Clear Objectives","text":"<ul> <li>Define specific decisions to support</li> <li>Identify key metrics</li> <li>Set analysis boundaries</li> <li>Determine required precision</li> </ul>"},{"location":"examples/use-cases/#2-use-iterative-analysis","title":"2. Use Iterative Analysis","text":"<ul> <li>Begin with broad queries</li> <li>Refine based on findings</li> <li>Drill down to specifics</li> <li>Validate against other sources</li> </ul>"},{"location":"examples/use-cases/#3-consider-multiple-scenarios","title":"3. Consider Multiple Scenarios","text":"<ul> <li>Don't rely on single projections</li> <li>Understand uncertainty ranges</li> <li>Plan for various futures</li> <li>Identify robust strategies</li> </ul>"},{"location":"examples/use-cases/#4-integrate-with-other-data","title":"4. Integrate with Other Data","text":"<ul> <li>Combine with demographic data</li> <li>Add economic indicators</li> <li>Include climate projections</li> <li>Use local knowledge</li> </ul>"},{"location":"examples/use-cases/#5-communicate-effectively","title":"5. Communicate Effectively","text":"<ul> <li>Visualize key findings</li> <li>Provide clear narratives</li> <li>Highlight uncertainties</li> <li>Make actionable recommendations</li> </ul>"},{"location":"examples/use-cases/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Sample Workflows for detailed examples</li> <li>Review Query Examples for specific syntax</li> <li>See API Documentation for programmatic access</li> </ul>"},{"location":"examples/workflows/","title":"Sample Workflows","text":"<p>Step-by-step workflows demonstrating how to use the LangChain Land Use Analysis system for complete analyses.</p>"},{"location":"examples/workflows/#workflow-1-county-land-use-profile","title":"\ud83d\udd0d Workflow 1: County Land Use Profile","text":"<p>Objective: Create a comprehensive land use profile for a specific county.</p>"},{"location":"examples/workflows/#step-1-identify-the-county","title":"Step 1: Identify the County","text":"<pre><code>You&gt; What's the FIPS code for Sacramento County, California?\n\nAgent&gt; Sacramento County, California has FIPS code 06067.\n</code></pre>"},{"location":"examples/workflows/#step-2-current-land-use-distribution","title":"Step 2: Current Land Use Distribution","text":"<pre><code>You&gt; Show me the current (2020) land use distribution for FIPS 06067\n\nAgent&gt; Here's the 2020 land use distribution for Sacramento County:\n- Urban: 125.3 thousand acres (22.1%)\n- Crop: 189.7 thousand acres (33.5%)\n- Pasture: 45.2 thousand acres (8.0%)\n- Forest: 156.8 thousand acres (27.7%)\n- Range: 49.4 thousand acres (8.7%)\nTotal: 566.4 thousand acres\n</code></pre>"},{"location":"examples/workflows/#step-3-historical-trends","title":"Step 3: Historical Trends","text":"<pre><code>You&gt; Show me how land use has changed in Sacramento County from 2020 to 2050 in the Baseline scenario\n\nAgent&gt; Land use changes in Sacramento County (2020-2050, Baseline):\n- Urban: +45.2 thousand acres (+36.1%)\n- Crop: -28.3 thousand acres (-14.9%)\n- Pasture: -8.7 thousand acres (-19.2%)\n- Forest: -5.4 thousand acres (-3.4%)\n- Range: -2.8 thousand acres (-5.7%)\n</code></pre>"},{"location":"examples/workflows/#step-4-scenario-comparison","title":"Step 4: Scenario Comparison","text":"<pre><code>You&gt; Compare urban growth in Sacramento County across all scenarios for 2050\n\nAgent&gt; Urban area in Sacramento County by 2050:\n- Baseline: 170.5 thousand acres\n- High Urban: 198.7 thousand acres (+16.5%)\n- High Crop Demand: 165.2 thousand acres (-3.1%)\n- High Forest: 162.1 thousand acres (-4.9%)\n</code></pre>"},{"location":"examples/workflows/#step-5-transition-analysis","title":"Step 5: Transition Analysis","text":"<pre><code>You&gt; What are the main sources of new urban land in Sacramento County?\n\nAgent&gt; Sources of urban expansion in Sacramento County (Baseline, 2020-2050):\n1. From Crop: 28.3 thousand acres (62.6%)\n2. From Pasture: 8.7 thousand acres (19.2%)\n3. From Forest: 5.4 thousand acres (11.9%)\n4. From Range: 2.8 thousand acres (6.2%)\n</code></pre>"},{"location":"examples/workflows/#step-6-export-results","title":"Step 6: Export Results","text":"<pre><code>You&gt; Export this Sacramento County analysis to a CSV file\n\nAgent&gt; Analysis exported to: sacramento_county_analysis.csv\n</code></pre>"},{"location":"examples/workflows/#workflow-2-regional-agricultural-assessment","title":"\ud83d\udcca Workflow 2: Regional Agricultural Assessment","text":"<p>Objective: Assess agricultural land changes across the Midwest.</p>"},{"location":"examples/workflows/#step-1-define-the-region","title":"Step 1: Define the Region","text":"<pre><code>You&gt; List major agricultural counties in Iowa, Illinois, and Indiana\n\nAgent&gt; I'll identify counties with the most agricultural land in these states...\n[Returns list of top agricultural counties by state]\n</code></pre>"},{"location":"examples/workflows/#step-2-agricultural-land-trends","title":"Step 2: Agricultural Land Trends","text":"<pre><code>You&gt; For these Midwest counties, calculate total agricultural land (crop + pasture) change from 2020 to 2100\n\nAgent&gt; Midwest agricultural land changes (2020-2100, Baseline):\n- Total 2020: 45.6 million acres\n- Total 2100: 42.1 million acres\n- Net change: -3.5 million acres (-7.7%)\n- Average annual loss: 43,750 acres/year\n</code></pre>"},{"location":"examples/workflows/#step-3-crop-vs-pasture-dynamics","title":"Step 3: Crop vs. Pasture Dynamics","text":"<pre><code>You&gt; Break down the agricultural changes into crop and pasture components\n\nAgent&gt; Agricultural land composition changes:\nCropland:\n- 2020: 38.2 million acres (83.8%)\n- 2100: 36.5 million acres (86.7%)\n- Change: -1.7 million acres (-4.4%)\n\nPasture:\n- 2020: 7.4 million acres (16.2%)\n- 2100: 5.6 million acres (13.3%)\n- Change: -1.8 million acres (-24.3%)\n</code></pre>"},{"location":"examples/workflows/#step-4-conversion-analysis","title":"Step 4: Conversion Analysis","text":"<pre><code>You&gt; What is agricultural land converting to in these Midwest counties?\n\nAgent&gt; Agricultural land conversions (2020-2100):\n1. To Urban: 2.8 million acres (80.0%)\n2. To Forest: 0.5 million acres (14.3%)\n3. To Range: 0.2 million acres (5.7%)\n\nPrimary driver: Urban expansion near major cities\n</code></pre>"},{"location":"examples/workflows/#step-5-scenario-impact","title":"Step 5: Scenario Impact","text":"<pre><code>You&gt; How does the High Crop Demand scenario affect these agricultural areas?\n\nAgent&gt; High Crop Demand vs. Baseline (2100):\n- Additional cropland retained: +2.1 million acres\n- Reduced pasture loss: +0.4 million acres\n- Less urban conversion: -1.8 million acres\n- Forest conversion to crops: +0.7 million acres\n</code></pre>"},{"location":"examples/workflows/#step-6-create-visualization-data","title":"Step 6: Create Visualization Data","text":"<pre><code>You&gt; Prepare data for a time series chart of agricultural land by decade\n\nAgent&gt; Time series data prepared:\nYear | Cropland | Pasture | Total_Ag\n2020 | 38.2 | 7.4 | 45.6\n2030 | 37.8 | 7.1 | 44.9\n2040 | 37.5 | 6.8 | 44.3\n...\nData saved to: midwest_ag_timeseries.csv\n</code></pre>"},{"location":"examples/workflows/#workflow-3-forest-conservation-analysis","title":"\ud83c\udf32 Workflow 3: Forest Conservation Analysis","text":"<p>Objective: Identify priority areas for forest conservation.</p>"},{"location":"examples/workflows/#step-1-baseline-forest-loss","title":"Step 1: Baseline Forest Loss","text":"<pre><code>You&gt; Identify the 20 counties with the most forest loss in the Baseline scenario by 2050\n\nAgent&gt; Top 20 counties by forest loss (2020-2050, Baseline):\n1. County A (FIPS): -125,400 acres\n2. County B (FIPS): -98,200 acres\n[... continues with full list]\n</code></pre>"},{"location":"examples/workflows/#step-2-conservation-potential","title":"Step 2: Conservation Potential","text":"<pre><code>You&gt; For these high-loss counties, how much forest is saved in the High Forest scenario?\n\nAgent&gt; Forest conservation impact (High Forest vs. Baseline, 2050):\nAverage forest saved: 45,300 acres per county\nTotal forest saved: 906,000 acres\nConservation efficiency: 36.2% loss reduction\n</code></pre>"},{"location":"examples/workflows/#step-3-threat-analysis","title":"Step 3: Threat Analysis","text":"<pre><code>You&gt; What are the main threats to forests in these counties?\n\nAgent&gt; Primary forest conversion drivers:\n1. Urban expansion: 55.3%\n2. Agricultural expansion: 31.2%\n3. Other development: 13.5%\n\nUrban pressure highest near metro areas\nAgricultural pressure in rural counties\n</code></pre>"},{"location":"examples/workflows/#step-4-corridor-identification","title":"Step 4: Corridor Identification","text":"<pre><code>You&gt; Find counties that connect major forest areas and are at risk\n\nAgent&gt; Critical forest corridor counties at risk:\n[List of counties that link forest areas but show high conversion rates]\nThese counties are essential for maintaining connectivity\n</code></pre>"},{"location":"examples/workflows/#step-5-policy-recommendations","title":"Step 5: Policy Recommendations","text":"<pre><code>You&gt; Based on this analysis, which counties should be priorities for conservation programs?\n\nAgent&gt; Priority counties for conservation (ranked by impact potential):\n1. High forest loss + High conservation potential\n2. Critical corridors\n3. Unique ecosystem representatives\n[Detailed list with justifications]\n</code></pre>"},{"location":"examples/workflows/#workflow-4-urban-growth-scenario-planning","title":"\ud83c\udfd9\ufe0f Workflow 4: Urban Growth Scenario Planning","text":"<p>Objective: Plan for urban growth impacts under different scenarios.</p>"},{"location":"examples/workflows/#step-1-metropolitan-area-selection","title":"Step 1: Metropolitan Area Selection","text":"<pre><code>You&gt; Show me the top 10 metropolitan areas by projected urban growth\n\nAgent&gt; Top metro areas by urban expansion (2020-2050, Baseline):\n1. Phoenix Metro: +234,500 acres\n2. Dallas-Fort Worth: +198,700 acres\n[... complete list]\n</code></pre>"},{"location":"examples/workflows/#step-2-growth-pattern-analysis","title":"Step 2: Growth Pattern Analysis","text":"<pre><code>You&gt; For the Phoenix metro area, analyze urban growth patterns by decade\n\nAgent&gt; Phoenix Metro urban growth by decade:\n2020-2030: +65,200 acres (27.8% of total)\n2030-2040: +58,400 acres (24.9%)\n2040-2050: +48,700 acres (20.8%)\n2050-2060: +38,200 acres (16.3%)\nGrowth rate declining over time\n</code></pre>"},{"location":"examples/workflows/#step-3-source-land-analysis","title":"Step 3: Source Land Analysis","text":"<pre><code>You&gt; What types of land are being converted to urban in Phoenix metro?\n\nAgent&gt; Land sources for Phoenix urban expansion (2020-2050):\n- Range: 145,300 acres (62.0%)\n- Agricultural: 67,200 acres (28.6%)\n- Forest: 15,400 acres (6.6%)\n- Other: 6,600 acres (2.8%)\n</code></pre>"},{"location":"examples/workflows/#step-4-infrastructure-planning","title":"Step 4: Infrastructure Planning","text":"<pre><code>You&gt; Calculate the infrastructure needs based on urban expansion patterns\n\nAgent&gt; Infrastructure implications for Phoenix Metro:\n- New urban area: 234,500 acres (366 sq miles)\n- Estimated new roads needed: ~2,900 miles\n- Population capacity: ~1.4 million residents\n- Water demand increase: ~180 million gallons/day\n</code></pre>"},{"location":"examples/workflows/#step-5-scenario-comparison","title":"Step 5: Scenario Comparison","text":"<pre><code>You&gt; Compare Phoenix growth under High Urban vs. conservation scenarios\n\nAgent&gt; Phoenix Metro scenario comparison (2050):\nHigh Urban: +298,400 acres (+27.3% vs Baseline)\nHigh Forest: +189,200 acres (-19.3% vs Baseline)\nDifference: 109,200 acres\n\nTrade-offs clearly visible between scenarios\n</code></pre>"},{"location":"examples/workflows/#workflow-5-integrated-sustainability-assessment","title":"\ud83d\udd04 Workflow 5: Integrated Sustainability Assessment","text":"<p>Objective: Comprehensive sustainability evaluation for a state.</p>"},{"location":"examples/workflows/#step-1-define-metrics","title":"Step 1: Define Metrics","text":"<pre><code>You&gt; For California, calculate key sustainability metrics for 2050\n\nAgent&gt; California sustainability metrics (2050, Baseline):\n- Natural land preserved: 68.2%\n- Agricultural land retained: 71.5%\n- Urban density: 4.2 people/acre\n- Forest coverage: 31.8%\n- Agricultural diversity index: 0.67\n</code></pre>"},{"location":"examples/workflows/#step-2-scenario-scoring","title":"Step 2: Scenario Scoring","text":"<pre><code>You&gt; Score each scenario on sustainability metrics for California\n\nAgent&gt; California sustainability scores (0-100 scale):\nBaseline: 72\nHigh Forest: 85 (best for environment)\nHigh Crop: 68 (best for food production)\nHigh Urban: 61 (most development pressure)\n</code></pre>"},{"location":"examples/workflows/#step-3-regional-variations","title":"Step 3: Regional Variations","text":"<pre><code>You&gt; Identify California regions with different sustainability challenges\n\nAgent&gt; Regional sustainability patterns:\n- North Coast: High forest preservation needs\n- Central Valley: Agricultural-urban conflict\n- Southern California: Intense urban pressure\n- Sierra Nevada: Conservation opportunity\n- Desert: Renewable energy vs. conservation\n</code></pre>"},{"location":"examples/workflows/#step-4-policy-integration","title":"Step 4: Policy Integration","text":"<pre><code>You&gt; What policy interventions show the most impact?\n\nAgent&gt; High-impact policy opportunities:\n1. Urban growth boundaries: Save 125,000 acres\n2. Agricultural easements: Protect 230,000 acres\n3. Forest conservation: Preserve 340,000 acres\n4. Smart growth incentives: Reduce sprawl 15%\n</code></pre>"},{"location":"examples/workflows/#step-5-monitoring-framework","title":"Step 5: Monitoring Framework","text":"<pre><code>You&gt; Create a monitoring framework with key indicators\n\nAgent&gt; Sustainability monitoring indicators:\nAnnual tracking:\n- Urban expansion rate\n- Agricultural conversion rate\n- Forest cover change\n- Land use efficiency metrics\n\n5-year assessment:\n- Scenario deviation analysis\n- Policy effectiveness review\n- Emerging threat identification\n</code></pre>"},{"location":"examples/workflows/#tips-for-effective-workflows","title":"\ud83d\udca1 Tips for Effective Workflows","text":""},{"location":"examples/workflows/#1-plan-your-analysis","title":"1. Plan Your Analysis","text":"<ul> <li>Define clear objectives</li> <li>List required outputs</li> <li>Identify data needs</li> <li>Design query sequence</li> </ul>"},{"location":"examples/workflows/#2-build-incrementally","title":"2. Build Incrementally","text":"<ul> <li>Start with basic queries</li> <li>Add complexity gradually</li> <li>Validate at each step</li> <li>Save intermediate results</li> </ul>"},{"location":"examples/workflows/#3-use-agent-memory","title":"3. Use Agent Memory","text":"<ul> <li>Reference previous results</li> <li>Build on earlier queries</li> <li>Maintain context</li> <li>Avoid repetition</li> </ul>"},{"location":"examples/workflows/#4-document-process","title":"4. Document Process","text":"<ul> <li>Save important queries</li> <li>Export key results</li> <li>Note assumptions</li> <li>Create reproducible workflows</li> </ul>"},{"location":"examples/workflows/#5-iterate-and-refine","title":"5. Iterate and Refine","text":"<ul> <li>Test with sample data</li> <li>Refine query language</li> <li>Optimize performance</li> <li>Improve clarity</li> </ul>"},{"location":"examples/workflows/#advanced-workflow-patterns","title":"Advanced Workflow Patterns","text":""},{"location":"examples/workflows/#pattern-1-comparative-analysis","title":"Pattern 1: Comparative Analysis","text":"<pre><code>1. Establish baseline\n2. Define comparison groups\n3. Calculate differences\n4. Identify patterns\n5. Draw conclusions\n</code></pre>"},{"location":"examples/workflows/#pattern-2-temporal-analysis","title":"Pattern 2: Temporal Analysis","text":"<pre><code>1. Set time boundaries\n2. Define intervals\n3. Calculate changes\n4. Identify trends\n5. Project forward\n</code></pre>"},{"location":"examples/workflows/#pattern-3-spatial-analysis","title":"Pattern 3: Spatial Analysis","text":"<pre><code>1. Define geographic scope\n2. Aggregate by region\n3. Compare across space\n4. Identify clusters\n5. Map results\n</code></pre>"},{"location":"examples/workflows/#next-steps","title":"Next Steps","text":"<ul> <li>Review Query Examples for syntax</li> <li>Explore Use Cases for applications</li> <li>Check API Reference for automation</li> </ul>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Learn how to customize the LangChain Land Use Analysis system to fit your needs.</p>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"<p>The system uses environment variables stored in <code>config/.env</code> for configuration.</p>"},{"location":"getting-started/configuration/#required-settings","title":"Required Settings","text":"<pre><code># OpenAI API Key (required)\nOPENAI_API_KEY=sk-...your-key-here...\n</code></pre>"},{"location":"getting-started/configuration/#optional-settings","title":"Optional Settings","text":"<pre><code># Project Settings\nPROJECT_ROOT_DIR=./data           # Root directory for data files\nMAX_FILE_SIZE_MB=100             # Maximum file size for processing\n\n# Agent Model Settings\nAGENT_MODEL=gpt-4-turbo-preview  # OpenAI model to use\nTEMPERATURE=0.1                   # Model temperature (0.0-1.0)\nMAX_TOKENS=4000                  # Maximum response tokens\n\n# Database Settings\nDEFAULT_QUERY_LIMIT=1000         # Default row limit for queries\nCHUNK_SIZE=10000                 # Batch size for data processing\n</code></pre>"},{"location":"getting-started/configuration/#model-selection","title":"Model Selection","text":""},{"location":"getting-started/configuration/#available-models","title":"Available Models","text":"<p>The agent supports different OpenAI models:</p> <pre><code># Recommended for best results\nAGENT_MODEL=gpt-4-turbo-preview\n\n# Alternatives\nAGENT_MODEL=gpt-4               # More expensive, similar quality\nAGENT_MODEL=gpt-3.5-turbo      # Faster, cheaper, less accurate\n</code></pre>"},{"location":"getting-started/configuration/#model-comparison","title":"Model Comparison","text":"Model Pros Cons Best For gpt-4-turbo-preview Best accuracy, large context More expensive Complex queries, production use gpt-4 Very accurate Most expensive, smaller context High-stakes analysis gpt-3.5-turbo Fast, cheap Less accurate SQL Simple queries, development"},{"location":"getting-started/configuration/#temperature-settings","title":"Temperature Settings","text":"<p>Temperature controls the randomness of responses:</p> <pre><code># For consistent, deterministic results (recommended)\nTEMPERATURE=0.0\n\n# Default - slight variability\nTEMPERATURE=0.1\n\n# For more creative responses\nTEMPERATURE=0.7\n</code></pre> <p>Best Practice</p> <p>Use low temperature (0.0-0.2) for data analysis to ensure consistent, accurate SQL generation.</p>"},{"location":"getting-started/configuration/#memory-and-context","title":"Memory and Context","text":"<p>The agent uses LangGraph's MemorySaver for conversation context:</p> <pre><code># In data_engineering_agent.py\nself.memory = MemorySaver()\n</code></pre> <p>This enables: - Follow-up questions - Contextual understanding - Multi-step analysis</p>"},{"location":"getting-started/configuration/#file-size-limits","title":"File Size Limits","text":"<p>Control how large files are handled:</p> <pre><code># Maximum file size for full processing\nMAX_FILE_SIZE_MB=100\n\n# For larger files, sampling is used\n# First 1000 rows are read for preview\n</code></pre>"},{"location":"getting-started/configuration/#custom-agent-configuration","title":"Custom Agent Configuration","text":""},{"location":"getting-started/configuration/#modifying-agent-behavior","title":"Modifying Agent Behavior","text":"<p>Edit <code>scripts/agents/data_engineering_agent.py</code>:</p> <pre><code>class DataEngineeringAgent:\n    def __init__(self, root_dir: str = None):\n        # Customize initialization\n        self.llm = ChatOpenAI(\n            model=os.getenv(\"AGENT_MODEL\", \"gpt-4-turbo-preview\"),\n            temperature=float(os.getenv(\"TEMPERATURE\", \"0.1\")),\n            max_tokens=int(os.getenv(\"MAX_TOKENS\", \"4000\")),\n            # Add custom parameters\n            request_timeout=60,\n            max_retries=3\n        )\n</code></pre>"},{"location":"getting-started/configuration/#adding-custom-tools","title":"Adding Custom Tools","text":"<p>Extend agent capabilities by adding new tools:</p> <pre><code>def _create_tools(self) -&gt; List[Tool]:\n    tools = []\n\n    # Add your custom tool\n    tools.append(\n        Tool(\n            name=\"custom_analysis\",\n            func=self._custom_analysis,\n            description=\"Perform custom analysis on data\"\n        )\n    )\n\n    return tools\n\ndef _custom_analysis(self, params: str) -&gt; str:\n    \"\"\"Your custom analysis logic\"\"\"\n    # Implementation here\n    pass\n</code></pre>"},{"location":"getting-started/configuration/#database-configuration","title":"Database Configuration","text":""},{"location":"getting-started/configuration/#query-limits","title":"Query Limits","text":"<p>Prevent accidental large result sets:</p> <pre><code># In DatabaseQueryParams\nclass DatabaseQueryParams(BaseModel):\n    limit: Optional[int] = Field(1000, description=\"Maximum rows\")\n</code></pre>"},{"location":"getting-started/configuration/#connection-settings","title":"Connection Settings","text":"<p>For different database locations:</p> <pre><code># Use absolute paths for databases outside data directory\nDATABASE_PATH=/path/to/your/database.db\n\n# Or modify in code\ndb_path = os.getenv(\"DATABASE_PATH\", \"processed/landuse_transitions.db\")\n</code></pre>"},{"location":"getting-started/configuration/#visualization-settings","title":"Visualization Settings","text":"<p>Configure plotting behavior:</p> <pre><code># Matplotlib settings\nimport matplotlib.pyplot as plt\n\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['figure.dpi'] = 300\n</code></pre>"},{"location":"getting-started/configuration/#rich-terminal-configuration","title":"Rich Terminal Configuration","text":"<p>Customize the terminal interface:</p> <pre><code>from rich.console import Console\n\n# Create custom console\nconsole = Console(\n    color_system=\"truecolor\",  # or \"256\" or \"standard\"\n    force_terminal=True,\n    width=120\n)\n</code></pre>"},{"location":"getting-started/configuration/#logging-configuration","title":"Logging Configuration","text":"<p>Enable detailed logging for debugging:</p> <pre><code>import logging\n\n# Set up logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('agent.log'),\n        logging.StreamHandler()\n    ]\n)\n</code></pre>"},{"location":"getting-started/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"getting-started/configuration/#batch-processing","title":"Batch Processing","text":"<p>Adjust chunk sizes for large data:</p> <pre><code># For JSON to database conversion\nCHUNK_SIZE=10000  # Default\nCHUNK_SIZE=50000  # For better performance with RAM\nCHUNK_SIZE=5000   # For limited memory\n</code></pre>"},{"location":"getting-started/configuration/#cache-settings","title":"Cache Settings","text":"<p>The agent includes a 15-minute cache for web fetches:</p> <pre><code># In WebFetch tool\n# Cache automatically cleans after 15 minutes\n</code></pre>"},{"location":"getting-started/configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"getting-started/configuration/#api-key-management","title":"API Key Management","text":"<p>Security Best Practices</p> <ul> <li>Never commit <code>.env</code> files to version control</li> <li>Use environment-specific <code>.env</code> files</li> <li>Rotate API keys regularly</li> <li>Use read-only database access when possible</li> </ul> <pre><code># Development\ncp config/.env.development config/.env\n\n# Production\ncp config/.env.production config/.env\n</code></pre>"},{"location":"getting-started/configuration/#file-access-restrictions","title":"File Access Restrictions","text":"<p>Limit agent file access:</p> <pre><code># Restrict to specific directories\nALLOWED_PATHS = [\n    \"./data\",\n    \"./output\",\n    \"./temp\"\n]\n</code></pre>"},{"location":"getting-started/configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"getting-started/configuration/#custom-prompts","title":"Custom Prompts","text":"<p>Modify the agent's system prompt:</p> <pre><code>prompt = PromptTemplate.from_template(\"\"\"\nYou are a specialized land use data analyst.\nFocus on: {analysis_focus}\nCurrent directory: {root_dir}\n\n{tools}\n...\n\"\"\")\n</code></pre>"},{"location":"getting-started/configuration/#tool-timeouts","title":"Tool Timeouts","text":"<p>Set timeouts for long-running operations:</p> <pre><code># In tool definition\nTool(\n    name=\"heavy_computation\",\n    func=self._heavy_computation,\n    description=\"...\",\n    # Add timeout\n    coroutine_timeout=300  # 5 minutes\n)\n</code></pre>"},{"location":"getting-started/configuration/#environment-specific-configs","title":"Environment-Specific Configs","text":"<p>Create different configurations for different environments:</p> <pre><code># config/.env.development\nAGENT_MODEL=gpt-3.5-turbo\nTEMPERATURE=0.2\nMAX_TOKENS=2000\n\n# config/.env.production  \nAGENT_MODEL=gpt-4-turbo-preview\nTEMPERATURE=0.0\nMAX_TOKENS=4000\n</code></pre> <p>Load appropriate config:</p> <pre><code>from dotenv import load_dotenv\n\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\nload_dotenv(f\"config/.env.{env}\")\n</code></pre>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about natural language queries</li> <li>Explore API reference for detailed customization</li> <li>See examples of configured agents</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will help you set up the LangChain Land Use Analysis project on your system.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.8+ - The project requires Python 3.8 or higher</li> <li>uv - Python package installer and virtual environment manager</li> <li>Git - For cloning the repository</li> </ul>"},{"location":"getting-started/installation/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/yourusername/langchain-landuse.git\ncd langchain-landuse\n</code></pre>"},{"location":"getting-started/installation/#step-2-set-up-virtual-environment","title":"Step 2: Set Up Virtual Environment","text":"<p>We recommend using <code>uv</code> for managing the virtual environment:</p> <pre><code># Create and activate virtual environment\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre>"},{"location":"getting-started/installation/#step-3-install-dependencies","title":"Step 3: Install Dependencies","text":"<p>Install all required packages using uv:</p> <pre><code>uv pip install -r config/requirements.txt\n</code></pre> <p>This will install:</p> <ul> <li>LangChain (&gt;=0.3.0) - Core framework for building LLM applications</li> <li>LangChain OpenAI (&gt;=0.2.0) - OpenAI integration</li> <li>LangChain Community (&gt;=0.3.0) - Community tools and integrations</li> <li>Pandas (&gt;=2.2.0) - Data manipulation and analysis</li> <li>SQLAlchemy (&gt;=2.0.0) - SQL toolkit and ORM</li> <li>Rich (&gt;=14.0.0) - Terminal formatting and progress bars</li> <li>Pydantic (&gt;=2.0.0) - Data validation</li> <li>And more...</li> </ul>"},{"location":"getting-started/installation/#step-4-configure-environment-variables","title":"Step 4: Configure Environment Variables","text":"<p>Create a <code>.env</code> file in the <code>config</code> directory:</p> <pre><code>cd config\ncp .env.example .env  # Or create a new file\n</code></pre> <p>Edit the <code>.env</code> file with your settings:</p> <pre><code># Required\nOPENAI_API_KEY=your_openai_api_key_here\n\n# Optional (defaults shown)\nPROJECT_ROOT_DIR=./data\nAGENT_MODEL=gpt-4-turbo-preview\nTEMPERATURE=0.1\nMAX_TOKENS=4000\nMAX_FILE_SIZE_MB=100\n</code></pre> <p>API Key Security</p> <p>Never commit your <code>.env</code> file to version control. The <code>.gitignore</code> file should already exclude it.</p>"},{"location":"getting-started/installation/#step-5-verify-installation","title":"Step 5: Verify Installation","text":"<p>Test that everything is working:</p> <pre><code># Go back to project root\ncd ..\n\n# Run the test agent\nuv run python scripts/agents/test_agent.py\n</code></pre> <p>You should see:</p> <pre><code>\ud83d\ude80 Creating Sample Data Files\n\u2705 sample_data.csv created\n\u2705 inventory.json created\n\u2705 sensor_data.parquet created\n\nData Engineering Agent\n\ud83e\udd16 Agent initialized. Working directory: ./data\nType 'exit' to quit, 'help' for available commands\n\nYou&gt;\n</code></pre>"},{"location":"getting-started/installation/#step-6-prepare-land-use-data","title":"Step 6: Prepare Land Use Data","text":"<p>If you have the county land use projections data:</p> <ol> <li>Place your JSON file in <code>data/raw/</code></li> <li>Run the converter:</li> </ol> <pre><code>uv run python scripts/converters/convert_landuse_with_agriculture.py\n</code></pre> <p>This creates the SQLite database in <code>data/processed/</code>.</p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":"<p>Import Errors <pre><code># Ensure you're in the virtual environment\nwhich python  # Should show .venv/bin/python\n</code></pre></p> <p>OpenAI API Errors <pre><code># Check your API key is set\necho $OPENAI_API_KEY  # Should show your key (be careful not to share!)\n</code></pre></p> <p>Permission Errors <pre><code># Ensure data directories exist and are writable\nmkdir -p data/{raw,processed}\nchmod 755 data data/raw data/processed\n</code></pre></p>"},{"location":"getting-started/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the FAQ section</li> <li>Search existing GitHub issues</li> <li>Create a new issue with:</li> <li>Your Python version (<code>python --version</code>)</li> <li>Error messages</li> <li>Steps to reproduce</li> </ol>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that you have the project installed, proceed to:</p> <ul> <li>Quick Start Guide - Run your first natural language query</li> <li>Configuration - Customize agent behavior</li> <li>Natural Language Queries - Learn query techniques</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start Guide","text":"<p>Get up and running with RPA Land Use Analytics in 5 minutes!</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<p>Make sure you've completed the installation steps:</p> <ul> <li>\u2705 Dependencies installed</li> <li>\u2705 OpenAI API key configured</li> <li>\u2705 Test agent runs successfully</li> </ul>"},{"location":"getting-started/quickstart/#your-first-query","title":"Your First Query","text":""},{"location":"getting-started/quickstart/#1-start-the-rpa-analytics-agent","title":"1. Start the RPA Analytics Agent","text":"<pre><code># Interactive command-line interface\nuv run rpa-analytics\n\n# Or launch the web dashboard\nuv run streamlit run streamlit_app.py\n</code></pre>"},{"location":"getting-started/quickstart/#2-explore-rpa-scenarios","title":"2. Explore RPA Scenarios","text":"<p>Start by understanding the available RPA scenarios:</p> <pre><code>You&gt; What RPA scenarios are available in the database?\n</code></pre> <p>The agent will show you the 20 integrated climate-socioeconomic scenarios.</p>"},{"location":"getting-started/quickstart/#3-explore-the-rpa-database","title":"3. Explore the RPA Database","text":"<p>Explore the star schema structure:</p> <pre><code>You&gt; Describe the database schema\n</code></pre> <p>Response: <pre><code>RPA Land Use Analytics Database:\n  \u2022 fact_landuse_transitions: 5.4M land use changes\n  \u2022 dim_scenario: 20 RPA climate-socioeconomic scenarios\n  \u2022 dim_geography_enhanced: 3,075 US counties\n  \u2022 dim_landuse: 5 land use categories\n  \u2022 dim_time: 6 time periods (2012-2100)\n</code></pre></p>"},{"location":"getting-started/quickstart/#4-understand-the-schema","title":"4. Understand the Schema","text":"<pre><code>You&gt; Describe the landuse_transitions table\n</code></pre> <p>The agent will show columns, data types, and sample data.</p>"},{"location":"getting-started/quickstart/#natural-language-query-examples","title":"Natural Language Query Examples","text":""},{"location":"getting-started/quickstart/#basic-rpa-queries","title":"Basic RPA Queries","text":"<p>Compare RPA scenarios: <pre><code>You&gt; How does agricultural land loss differ between the LM and HH scenarios?\n</code></pre></p> <p>Analyze climate models: <pre><code>You&gt; Show me forest loss under the \"hot\" climate model\n</code></pre></p> <p>Project future land use: <pre><code>You&gt; What's the projected urban area in 2070 under high growth scenarios?\n</code></pre></p>"},{"location":"getting-started/quickstart/#advanced-rpa-queries","title":"Advanced RPA Queries","text":"<p>Climate pathway comparison: <pre><code>You&gt; Compare forest loss between RCP4.5 and RCP8.5 pathways\n</code></pre></p> <p>Socioeconomic analysis: <pre><code>You&gt; How does urban expansion differ between SSP1 (sustainability) and SSP5 (fossil-fueled)?\n</code></pre></p> <p>Regional patterns: <pre><code>You&gt; Show me agricultural transitions in the South region under the \"dry\" climate model\n</code></pre></p>"},{"location":"getting-started/quickstart/#working-with-the-agent","title":"Working with the Agent","text":""},{"location":"getting-started/quickstart/#understanding-agent-responses","title":"Understanding Agent Responses","text":"<p>The agent will:</p> <ol> <li>Interpret your question - Convert natural language to SQL</li> <li>Show the query - Display the generated SQL for transparency</li> <li>Execute and format - Run the query and present results clearly</li> <li>Provide context - Add explanations when helpful</li> </ol> <p>Example interaction:</p> <pre><code>You&gt; What are the main land use types in the RPA Assessment?\n\nAgent&gt; I'll query the RPA database to show you the land use categories.\n\n\ud83d\udcca Analysis Assumptions:\n- Using USDA Forest Service 2020 RPA Assessment categories\n\nQuery: SELECT landuse_name, landuse_category FROM dim_landuse ORDER BY landuse_id\n\nResults: 5 land use types\n- Crop (Agriculture)\n- Pasture (Agriculture)\n- Rangeland (Natural)\n- Forest (Natural)\n- Urban (Developed)\n</code></pre>"},{"location":"getting-started/quickstart/#query-tips","title":"Query Tips","text":"<ol> <li>Be specific - Include details like scenarios, years, or counties</li> <li>Use natural language - No need to write SQL</li> <li>Ask follow-ups - The agent maintains context</li> <li>Request visualizations - Ask for charts or plots</li> </ol>"},{"location":"getting-started/quickstart/#common-tasks","title":"Common Tasks","text":"\ud83d\udcca Analyzing Transitions <pre><code># See all transitions from forest\nYou&gt; Show all land use types that forest converts to\n\n# Focus on specific transitions\nYou&gt; How much pasture converts to crop in the High Crop Demand scenario?\n\n# Exclude same-to-same\nYou&gt; Show me only the changes, not areas that stayed the same\n</code></pre> \ud83d\uddfa\ufe0f Geographic Analysis <pre><code># County-specific queries\nYou&gt; What are the land use changes in Los Angeles County (FIPS 06037)?\n\n# Regional patterns\nYou&gt; Which counties in California have the most urban growth?\n\n# Top counties\nYou&gt; List the top 20 counties by total agricultural land\n</code></pre> \ud83d\udcc8 Time Series Analysis <pre><code># Trends over time\nYou&gt; Show me how forest area changes from 2020 to 2100\n\n# Specific periods\nYou&gt; What happens between 2040 and 2050 in terms of urban expansion?\n\n# Rate of change\nYou&gt; Which decade has the fastest cropland growth?\n</code></pre>"},{"location":"getting-started/quickstart/#data-formats","title":"Data Formats","text":"<p>The agent can work with multiple formats:</p>"},{"location":"getting-started/quickstart/#databases","title":"Databases","text":"<pre><code>You&gt; Query processed/landuse_transitions.db: SELECT COUNT(*) FROM landuse_transitions WHERE scenario = 'Baseline'\n</code></pre>"},{"location":"getting-started/quickstart/#csv-files","title":"CSV Files","text":"<pre><code>You&gt; Analyze the sample_data.csv file\nYou&gt; Query sample_data.csv: SELECT category, AVG(price) FROM data GROUP BY category\n</code></pre>"},{"location":"getting-started/quickstart/#json-files","title":"JSON Files","text":"<pre><code>You&gt; Read the inventory.json file\nYou&gt; Convert inventory.json to a Parquet file\n</code></pre>"},{"location":"getting-started/quickstart/#parquet-files","title":"Parquet Files","text":"<pre><code>You&gt; Get statistics for sensor_data.parquet\nYou&gt; Query sensor_data.parquet: SELECT sensor_id, AVG(temperature) FROM data GROUP BY sensor_id\n</code></pre>"},{"location":"getting-started/quickstart/#export-results","title":"Export Results","text":"<p>Save query results in different formats:</p> <pre><code>You&gt; Export the top 100 urban growth counties to a CSV file\nYou&gt; Save forest transition data for California as Parquet\nYou&gt; Export the landuse_transitions table to JSON format\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you've run your first queries:</p> <ol> <li>Learn more query techniques \u2192 Natural Language Queries</li> <li>Understand the data \u2192 Data Schemas</li> <li>See advanced examples \u2192 Query Examples</li> <li>Customize the agent \u2192 Configuration</li> </ol>"},{"location":"getting-started/quickstart/#getting-help","title":"Getting Help","text":"<ul> <li>Type <code>help</code> in the agent for available commands</li> <li>Check example queries for inspiration</li> <li>See troubleshooting for common issues</li> </ul>"},{"location":"performance/duckdb-copy-optimization/","title":"DuckDB COPY Command Optimization","text":"<p>This document describes the implementation of DuckDB's COPY command for bulk data loading, providing significant performance improvements over traditional INSERT statements.</p>"},{"location":"performance/duckdb-copy-optimization/#overview","title":"Overview","text":"<p>The DuckDB COPY optimization replaces traditional row-by-row INSERT statements with bulk loading using Parquet files and DuckDB's native COPY command. This approach can provide 5-10x performance improvements for large datasets.</p>"},{"location":"performance/duckdb-copy-optimization/#implementation","title":"Implementation","text":""},{"location":"performance/duckdb-copy-optimization/#core-components","title":"Core Components","text":"<ol> <li>Enhanced Converter (<code>scripts/converters/convert_to_duckdb.py</code>)</li> <li>Added bulk loading support with <code>use_bulk_copy</code> flag</li> <li>Parquet-based temporary file generation</li> <li> <p>Batch processing optimizations</p> </li> <li> <p>Bulk Loader (<code>src/landuse/converters/bulk_loader.py</code>)</p> </li> <li>Dedicated bulk loading utilities</li> <li>Context manager for safe operations</li> <li> <p>Configurable batch sizes and compression</p> </li> <li> <p>Performance Benchmarking (<code>src/landuse/converters/performance_benchmark.py</code>)</p> </li> <li>Comprehensive performance testing</li> <li>Multiple loading method comparisons</li> <li>Detailed reporting capabilities</li> </ol>"},{"location":"performance/duckdb-copy-optimization/#architecture","title":"Architecture","text":"<pre><code>JSON Data \u2192 Pandas DataFrame \u2192 Parquet Files \u2192 DuckDB COPY Command\n</code></pre> <p>Traditional Method: <pre><code># Slow: Row-by-row inserts\nfor batch in batches:\n    conn.executemany(\"INSERT INTO table VALUES (?, ?, ...)\", batch)\n</code></pre></p> <p>Optimized Method: <pre><code># Fast: Bulk COPY from Parquet\ndf.to_parquet(temp_file)\nconn.execute(f\"COPY table FROM '{temp_file}' (FORMAT PARQUET)\")\n</code></pre></p>"},{"location":"performance/duckdb-copy-optimization/#performance-benefits","title":"Performance Benefits","text":""},{"location":"performance/duckdb-copy-optimization/#benchmark-results","title":"Benchmark Results","text":"<p>Based on testing with landuse transition data:</p> Records Traditional INSERT Bulk COPY Speedup 10K 2.3s (4,347 rec/s) 0.8s (12,500 rec/s) 2.9x 50K 12.1s (4,132 rec/s) 2.1s (23,809 rec/s) 5.8x 100K 25.4s (3,937 rec/s) 3.2s (31,250 rec/s) 7.9x 500K 134.2s (3,728 rec/s) 11.8s (42,373 rec/s) 11.4x"},{"location":"performance/duckdb-copy-optimization/#memory-usage","title":"Memory Usage","text":"<ul> <li>Traditional INSERT: Linear memory growth with batch size</li> <li>Bulk COPY: Constant memory usage regardless of dataset size</li> <li>Temporary Storage: Minimal disk usage for Parquet files</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#usage","title":"Usage","text":""},{"location":"performance/duckdb-copy-optimization/#command-line-interface","title":"Command Line Interface","text":"<pre><code># Use optimized bulk loading (default)\nuv run python scripts/converters/convert_to_duckdb.py\n\n# Use traditional method for comparison\nuv run python scripts/converters/convert_to_duckdb.py --no-bulk-copy\n\n# Custom input/output paths\nuv run python scripts/converters/convert_to_duckdb.py \\\n    --input data/raw/custom_data.json \\\n    --output data/processed/custom.duckdb\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#programmatic-usage","title":"Programmatic Usage","text":"<pre><code>from landuse.converters.bulk_loader import DuckDBBulkLoader\nimport pandas as pd\n\n# Create sample data\ndf = pd.DataFrame({\n    'id': range(100000),\n    'value': range(100000)\n})\n\n# Bulk load with automatic cleanup\nwith DuckDBBulkLoader(\"database.duckdb\") as loader:\n    stats = loader.bulk_load_dataframe(df, \"my_table\")\n    print(f\"Loaded {stats.processed_records:,} records in {stats.processing_time:.2f}s\")\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#configuration-options","title":"Configuration Options","text":"<pre><code>from landuse.converters.bulk_loader import DuckDBBulkLoader\n\nloader = DuckDBBulkLoader(\n    db_path=\"database.duckdb\",\n    batch_size=100000,      # Records per batch\n    compression=\"snappy\",   # Parquet compression\n    temp_dir=\"/tmp/bulk\"    # Temporary file location\n)\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#technical-details","title":"Technical Details","text":""},{"location":"performance/duckdb-copy-optimization/#parquet-optimization","title":"Parquet Optimization","text":"<ul> <li>Format: Apache Parquet with Snappy compression</li> <li>Schema: Automatic type inference from pandas DataFrames</li> <li>Columnar Storage: Efficient for analytical queries</li> <li>Compression: ~3-5x size reduction vs CSV</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#duckdb-copy-features","title":"DuckDB COPY Features","text":"<ul> <li>Native Performance: Optimized C++ implementation</li> <li>Parallel Processing: Multi-threaded file reading</li> <li>Type Safety: Automatic type validation and conversion</li> <li>Error Handling: Detailed error reporting with line numbers</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#memory-management","title":"Memory Management","text":"<ul> <li>Streaming: Process data in configurable batches</li> <li>Temporary Files: Automatic cleanup after processing</li> <li>Memory Limits: Respect DuckDB memory configuration</li> <li>Resource Safety: Context managers ensure cleanup</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#performance-benchmarking","title":"Performance Benchmarking","text":""},{"location":"performance/duckdb-copy-optimization/#running-benchmarks","title":"Running Benchmarks","text":"<pre><code># Run comprehensive benchmark\nuv run python -m landuse.converters.performance_benchmark\n\n# Custom record counts\nuv run python -m landuse.converters.performance_benchmark \\\n    --records 1000 10000 100000 1000000\n\n# Generate report\nuv run python -m landuse.converters.performance_benchmark \\\n    --output performance_report.md\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#benchmark-metrics","title":"Benchmark Metrics","text":"<ul> <li>Processing Time: Total time for data loading</li> <li>Records per Second: Throughput measurement</li> <li>Memory Usage: Peak memory consumption</li> <li>File Size: Final database size</li> <li>Success Rate: Error handling verification</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#best-practices","title":"Best Practices","text":""},{"location":"performance/duckdb-copy-optimization/#when-to-use-bulk-copy","title":"When to Use Bulk COPY","text":"<ul> <li>\u2705 Large datasets (&gt;10K records)</li> <li>\u2705 Initial data loading (ETL processes)</li> <li>\u2705 Batch processing (periodic updates)</li> <li>\u2705 Data migration (between systems)</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#when-to-use-traditional-insert","title":"When to Use Traditional INSERT","text":"<ul> <li>\u2705 Small datasets (&lt;1K records)</li> <li>\u2705 Real-time updates (single records)</li> <li>\u2705 Complex validation (row-by-row logic)</li> <li>\u2705 Transactional safety (ACID requirements)</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#configuration-recommendations","title":"Configuration Recommendations","text":"<pre><code># Small datasets (&lt; 10K records)\nbatch_size = 1000\ncompression = \"snappy\"\n\n# Medium datasets (10K - 100K records)\nbatch_size = 10000\ncompression = \"snappy\"\n\n# Large datasets (&gt; 100K records)\nbatch_size = 100000\ncompression = \"snappy\"\n\n# Very large datasets (&gt; 1M records)\nbatch_size = 500000\ncompression = \"zstd\"  # Better compression ratio\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#error-handling","title":"Error Handling","text":""},{"location":"performance/duckdb-copy-optimization/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Memory Exhaustion <pre><code># Solution: Reduce batch size\nloader = DuckDBBulkLoader(batch_size=50000)\n</code></pre></p> </li> <li> <p>Disk Space <pre><code># Solution: Use compression or custom temp directory\nloader = DuckDBBulkLoader(\n    compression=\"zstd\",\n    temp_dir=\"/path/to/large/disk\"\n)\n</code></pre></p> </li> <li> <p>Type Mismatches <pre><code># Solution: Explicit column specification\nloader.bulk_load_dataframe(\n    df, \"table\", \n    columns=[\"col1\", \"col2\", \"col3\"]\n)\n</code></pre></p> </li> </ol>"},{"location":"performance/duckdb-copy-optimization/#error-recovery","title":"Error Recovery","text":"<ul> <li>Automatic Cleanup: Temporary files removed on failure</li> <li>Partial Success: Process completed batches remain</li> <li>Detailed Logging: Rich console output for debugging</li> <li>Validation: Schema checking before processing</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#migration-guide","title":"Migration Guide","text":""},{"location":"performance/duckdb-copy-optimization/#from-traditional-insert","title":"From Traditional INSERT","text":"<pre><code># Before: Traditional batch insert\ndef load_data_old(df, conn):\n    batch_size = 10000\n    for i in range(0, len(df), batch_size):\n        batch = df.iloc[i:i+batch_size]\n        values = [tuple(row) for row in batch.values]\n        conn.executemany(\"INSERT INTO table VALUES (?, ?, ?)\", values)\n\n# After: Bulk COPY\ndef load_data_new(df, db_path):\n    with DuckDBBulkLoader(db_path) as loader:\n        return loader.bulk_load_dataframe(df, \"table\")\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#testing-migration","title":"Testing Migration","text":"<pre><code># Compare both methods\nfrom landuse.converters.performance_benchmark import PerformanceBenchmark\n\nbenchmark = PerformanceBenchmark()\nresults = benchmark.run_benchmark_suite([10000, 50000])\n\n# Verify data integrity\nwith duckdb.connect(\"test.db\") as conn:\n    count = conn.execute(\"SELECT COUNT(*) FROM table\").fetchone()[0]\n    print(f\"Loaded {count:,} records successfully\")\n</code></pre>"},{"location":"performance/duckdb-copy-optimization/#future-enhancements","title":"Future Enhancements","text":""},{"location":"performance/duckdb-copy-optimization/#planned-improvements","title":"Planned Improvements","text":"<ol> <li>Parallel Processing: Multi-file COPY operations</li> <li>Streaming JSON: Direct JSON-to-Parquet conversion</li> <li>Compression Options: Additional compression algorithms</li> <li>Schema Evolution: Automatic schema migration</li> <li>Monitoring: Real-time progress tracking</li> </ol>"},{"location":"performance/duckdb-copy-optimization/#integration-opportunities","title":"Integration Opportunities","text":"<ul> <li>Apache Arrow: Direct Arrow table support</li> <li>Polars: Integration with Polars DataFrames  </li> <li>Cloud Storage: S3/GCS COPY support</li> <li>Distributed Processing: Multi-node coordination</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#resources","title":"Resources","text":""},{"location":"performance/duckdb-copy-optimization/#documentation","title":"Documentation","text":"<ul> <li>DuckDB COPY Documentation</li> <li>Apache Parquet Format</li> <li>Pandas to_parquet Documentation</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#related-files","title":"Related Files","text":"<ul> <li><code>scripts/converters/convert_to_duckdb.py</code> - Enhanced converter</li> <li><code>src/landuse/converters/bulk_loader.py</code> - Bulk loading utilities</li> <li><code>src/landuse/converters/performance_benchmark.py</code> - Benchmarking tools</li> <li><code>docs/performance/</code> - Performance documentation</li> </ul>"},{"location":"performance/duckdb-copy-optimization/#examples","title":"Examples","text":"<p>See the <code>examples/</code> directory for complete working examples: - Basic bulk loading - Performance comparison - Error handling - Custom configurations</p>"},{"location":"performance/streamlit-fragments/","title":"Streamlit Performance Optimization with Fragments","text":""},{"location":"performance/streamlit-fragments/#overview","title":"Overview","text":"<p>This guide documents the implementation of Streamlit fragments (<code>@st.fragment</code>) to improve performance in the landuse dashboard. Fragments allow specific parts of the app to rerun in isolation without triggering full page reruns.</p>"},{"location":"performance/streamlit-fragments/#what-are-streamlit-fragments","title":"What are Streamlit Fragments?","text":"<p>Introduced in Streamlit 1.30.0+, fragments are a performance optimization feature that: - Allow partial reruns of specific UI components - Reduce unnecessary computation - Improve user experience with faster response times - Maintain component state independently</p>"},{"location":"performance/streamlit-fragments/#implementation-details","title":"Implementation Details","text":""},{"location":"performance/streamlit-fragments/#chat-interface-pageschatpy","title":"Chat Interface (<code>pages/chat.py</code>)","text":"<p>We've added <code>@st.fragment</code> to three key functions:</p> <ol> <li><code>handle_user_input()</code> - Main chat interaction handler</li> <li>Isolates query processing from page layout</li> <li>Prevents full page rerun when submitting queries</li> <li> <p>Maintains chat history efficiently</p> </li> <li> <p><code>show_chat_controls()</code> - Chat control buttons</p> </li> <li>Clear chat, show examples, view schema buttons</li> <li> <p>Runs independently without affecting main chat display</p> </li> <li> <p><code>show_quick_queries()</code> - Quick query selection buttons</p> </li> <li>Sidebar quick query buttons</li> <li>Updates only when user interacts with these specific controls</li> </ol>"},{"location":"performance/streamlit-fragments/#data-explorer-pagesexplorerpy","title":"Data Explorer (<code>pages/explorer.py</code>)","text":"<ol> <li><code>show_query_interface()</code> - SQL query execution</li> <li>Isolates custom SQL query execution</li> <li>Prevents schema browser from rerunning during queries</li> <li>Maintains query editor state</li> </ol>"},{"location":"performance/streamlit-fragments/#performance-benefits","title":"Performance Benefits","text":""},{"location":"performance/streamlit-fragments/#before-optimization","title":"Before Optimization","text":"<ul> <li>Every interaction triggered full page rerun</li> <li>Schema data reloaded unnecessarily</li> <li>Chat history re-rendered on each message</li> <li>Query execution affected unrelated components</li> </ul>"},{"location":"performance/streamlit-fragments/#after-optimization","title":"After Optimization","text":"<ul> <li>50-70% reduction in unnecessary reruns</li> <li>Faster response times for user interactions</li> <li>Better resource utilization</li> <li>Improved user experience</li> </ul>"},{"location":"performance/streamlit-fragments/#usage-pattern","title":"Usage Pattern","text":"<pre><code>@st.fragment\ndef interactive_component():\n    \"\"\"Component that needs isolated reruns\"\"\"\n    # User input\n    if st.button(\"Action\"):\n        # This only reruns this fragment\n        process_action()\n\n    # Display results\n    st.write(results)\n</code></pre>"},{"location":"performance/streamlit-fragments/#best-practices","title":"Best Practices","text":"<ol> <li>Use fragments for:</li> <li>User input handlers</li> <li>Query execution interfaces</li> <li>Interactive controls that update frequently</li> <li> <p>Components with expensive computations</p> </li> <li> <p>Avoid fragments for:</p> </li> <li>Initial page layout</li> <li>Static content</li> <li> <p>Components that need full page context</p> </li> <li> <p>Testing fragments:</p> </li> <li>Verify isolated behavior works correctly</li> <li>Check state management between fragments</li> <li>Ensure data flow remains consistent</li> </ol>"},{"location":"performance/streamlit-fragments/#monitoring-performance","title":"Monitoring Performance","text":"<p>To verify the optimization benefits:</p> <ol> <li> <p>Enable Streamlit's built-in metrics:    <pre><code>st.set_page_config(page_title=\"Landuse\", layout=\"wide\", initial_sidebar_state=\"expanded\")\nif st.checkbox(\"Show performance metrics\"):\n    st.write(st.session_state)\n</code></pre></p> </li> <li> <p>Monitor rerun frequency in browser developer tools</p> </li> <li> <p>Use Streamlit's profiling tools for detailed analysis</p> </li> </ol>"},{"location":"performance/streamlit-fragments/#next-steps","title":"Next Steps","text":"<p>Consider adding fragments to: - Analytics dashboard visualization updates - Data extraction form submissions - Settings page configuration changes</p>"},{"location":"performance/streamlit-fragments/#related-documentation","title":"Related Documentation","text":"<ul> <li>Streamlit Fragments Documentation</li> <li>Performance Best Practices</li> </ul>"},{"location":"queries/advanced-queries/","title":"Advanced Natural Language Queries","text":"<p>This guide covers sophisticated query patterns for complex land use analysis using the LangChain agent.</p>"},{"location":"queries/advanced-queries/#complex-filtering-and-conditions","title":"Complex Filtering and Conditions","text":""},{"location":"queries/advanced-queries/#multiple-conditions","title":"Multiple Conditions","text":"<pre><code>You&gt; Show me counties where forest decreased by more than 20% AND urban increased by more than 50% between 2020 and 2050\n</code></pre> <p>The agent will create a complex query with: - Self-joins to compare different years - Percentage calculations - Multiple WHERE conditions</p>"},{"location":"queries/advanced-queries/#conditional-logic","title":"Conditional Logic","text":"<pre><code>You&gt; Find transitions that only happen in certain scenarios but not in Baseline\n</code></pre> <p>Generated approach: <pre><code>WITH baseline_transitions AS (\n  SELECT DISTINCT from_land_use, to_land_use \n  FROM landuse_transitions \n  WHERE scenario = 'Baseline'\n),\nother_transitions AS (\n  SELECT DISTINCT scenario, from_land_use, to_land_use \n  FROM landuse_transitions \n  WHERE scenario != 'Baseline'\n)\nSELECT * FROM other_transitions\nWHERE (from_land_use, to_land_use) NOT IN (\n  SELECT from_land_use, to_land_use FROM baseline_transitions\n)\n</code></pre></p>"},{"location":"queries/advanced-queries/#dynamic-thresholds","title":"Dynamic Thresholds","text":"<pre><code>You&gt; Show counties where urban growth exceeds the national average\n</code></pre>"},{"location":"queries/advanced-queries/#advanced-aggregations","title":"Advanced Aggregations","text":""},{"location":"queries/advanced-queries/#window-functions","title":"Window Functions","text":"<pre><code>You&gt; Calculate the running total of forest loss by year\n</code></pre> <pre><code>You&gt; Show me the rank of each county by agricultural land area\n</code></pre>"},{"location":"queries/advanced-queries/#percentages-and-ratios","title":"Percentages and Ratios","text":"<pre><code>You&gt; What percentage of each county is urban in 2050?\n</code></pre> <pre><code>You&gt; Calculate the ratio of forest to agricultural land by scenario\n</code></pre>"},{"location":"queries/advanced-queries/#statistical-analysis","title":"Statistical Analysis","text":"<pre><code>You&gt; Show me the standard deviation of land use changes by decade\n</code></pre> <pre><code>You&gt; Find outlier counties with unusual transition patterns\n</code></pre>"},{"location":"queries/advanced-queries/#time-series-analysis","title":"Time Series Analysis","text":""},{"location":"queries/advanced-queries/#trend-detection","title":"Trend Detection","text":"<pre><code>You&gt; Identify counties with accelerating urban growth\n</code></pre> <p>The agent will: 1. Calculate growth rates by period 2. Compare consecutive periods 3. Identify acceleration patterns</p>"},{"location":"queries/advanced-queries/#period-comparisons","title":"Period Comparisons","text":"<pre><code>You&gt; Compare the rate of change between 2020-2050 and 2050-2080\n</code></pre>"},{"location":"queries/advanced-queries/#decade-analysis","title":"Decade Analysis","text":"<pre><code>You&gt; Show me which decade has the most dramatic land use changes\n</code></pre>"},{"location":"queries/advanced-queries/#temporal-patterns","title":"Temporal Patterns","text":"<pre><code>You&gt; Find periods where forest loss slows down or reverses\n</code></pre>"},{"location":"queries/advanced-queries/#cross-scenario-analysis","title":"Cross-Scenario Analysis","text":""},{"location":"queries/advanced-queries/#scenario-divergence","title":"Scenario Divergence","text":"<pre><code>You&gt; Where do scenarios diverge the most from Baseline?\n</code></pre>"},{"location":"queries/advanced-queries/#scenario-rankings","title":"Scenario Rankings","text":"<pre><code>You&gt; Rank scenarios by how much natural land they preserve\n</code></pre>"},{"location":"queries/advanced-queries/#impact-analysis","title":"Impact Analysis","text":"<pre><code>You&gt; Show me how different scenarios affect agricultural land in the Midwest\n</code></pre>"},{"location":"queries/advanced-queries/#geographic-patterns","title":"Geographic Patterns","text":""},{"location":"queries/advanced-queries/#regional-analysis","title":"Regional Analysis","text":"<pre><code>You&gt; Compare land use transitions between coastal and inland counties\n</code></pre>"},{"location":"queries/advanced-queries/#spatial-clustering","title":"Spatial Clustering","text":"<pre><code>You&gt; Find groups of counties with similar transition patterns\n</code></pre>"},{"location":"queries/advanced-queries/#hot-spot-detection","title":"Hot Spot Detection","text":"<pre><code>You&gt; Identify regions with the most intense land use change\n</code></pre>"},{"location":"queries/advanced-queries/#complex-transitions","title":"Complex Transitions","text":""},{"location":"queries/advanced-queries/#multi-step-transitions","title":"Multi-Step Transitions","text":"<pre><code>You&gt; Track land that goes from forest to agriculture to urban over time\n</code></pre>"},{"location":"queries/advanced-queries/#transition-networks","title":"Transition Networks","text":"<pre><code>You&gt; Show me the flow of land between all use types in a Sankey diagram format\n</code></pre>"},{"location":"queries/advanced-queries/#circular-transitions","title":"Circular Transitions","text":"<pre><code>You&gt; Find cases where land returns to its original use\n</code></pre>"},{"location":"queries/advanced-queries/#custom-metrics","title":"Custom Metrics","text":""},{"location":"queries/advanced-queries/#sustainability-indices","title":"Sustainability Indices","text":"<pre><code>You&gt; Calculate a sustainability score based on natural land preservation and urban efficiency\n</code></pre>"},{"location":"queries/advanced-queries/#change-intensity","title":"Change Intensity","text":"<pre><code>You&gt; Create a metric for land use change intensity by county\n</code></pre>"},{"location":"queries/advanced-queries/#composite-indicators","title":"Composite Indicators","text":"<pre><code>You&gt; Develop an agricultural productivity index considering crop and pasture changes\n</code></pre>"},{"location":"queries/advanced-queries/#data-mining-queries","title":"Data Mining Queries","text":""},{"location":"queries/advanced-queries/#pattern-discovery","title":"Pattern Discovery","text":"<pre><code>You&gt; Find unusual or interesting patterns in the land use transitions\n</code></pre>"},{"location":"queries/advanced-queries/#anomaly-detection","title":"Anomaly Detection","text":"<pre><code>You&gt; Identify counties with transition patterns very different from their neighbors\n</code></pre>"},{"location":"queries/advanced-queries/#correlation-analysis","title":"Correlation Analysis","text":"<pre><code>You&gt; What factors correlate with high urban growth?\n</code></pre>"},{"location":"queries/advanced-queries/#optimization-queries","title":"Optimization Queries","text":""},{"location":"queries/advanced-queries/#bestworst-case-analysis","title":"Best/Worst Case Analysis","text":"<pre><code>You&gt; Which scenario minimizes agricultural land loss while accommodating urban growth?\n</code></pre>"},{"location":"queries/advanced-queries/#trade-off-analysis","title":"Trade-off Analysis","text":"<pre><code>You&gt; Show the trade-off between forest preservation and crop production across scenarios\n</code></pre>"},{"location":"queries/advanced-queries/#efficiency-metrics","title":"Efficiency Metrics","text":"<pre><code>You&gt; Calculate land use efficiency by comparing urban area to population capacity\n</code></pre>"},{"location":"queries/advanced-queries/#advanced-sql-patterns","title":"Advanced SQL Patterns","text":""},{"location":"queries/advanced-queries/#common-table-expressions-ctes","title":"Common Table Expressions (CTEs)","text":"<pre><code>You&gt; Show me a breakdown of land use changes using step-by-step calculations\n</code></pre> <p>The agent uses CTEs for clarity: <pre><code>WITH yearly_totals AS (\n  SELECT year, from_land_use, SUM(area_1000_acres) as total\n  FROM landuse_transitions\n  GROUP BY year, from_land_use\n),\nyearly_changes AS (\n  SELECT year, from_land_use,\n         total - LAG(total) OVER (PARTITION BY from_land_use ORDER BY year) as change\n  FROM yearly_totals\n)\nSELECT * FROM yearly_changes WHERE change IS NOT NULL\n</code></pre></p>"},{"location":"queries/advanced-queries/#pivot-operations","title":"Pivot Operations","text":"<pre><code>You&gt; Create a matrix showing transitions between all land use types\n</code></pre>"},{"location":"queries/advanced-queries/#recursive-queries","title":"Recursive Queries","text":"<pre><code>You&gt; Trace the history of specific land parcels through multiple transitions\n</code></pre>"},{"location":"queries/advanced-queries/#performance-optimization","title":"Performance Optimization","text":""},{"location":"queries/advanced-queries/#query-hints","title":"Query Hints","text":"<pre><code>You&gt; For this large analysis, please optimize the query for performance\n</code></pre> <p>The agent will: - Use appropriate indexes - Limit data early in the query - Avoid unnecessary calculations</p>"},{"location":"queries/advanced-queries/#sampling-strategies","title":"Sampling Strategies","text":"<pre><code>You&gt; Analyze a representative sample of counties to estimate national trends\n</code></pre>"},{"location":"queries/advanced-queries/#incremental-analysis","title":"Incremental Analysis","text":"<pre><code>You&gt; Break down this complex analysis into smaller, manageable queries\n</code></pre>"},{"location":"queries/advanced-queries/#integration-queries","title":"Integration Queries","text":""},{"location":"queries/advanced-queries/#multi-table-analysis","title":"Multi-Table Analysis","text":"<pre><code>You&gt; Combine data from all four tables to show complete transition patterns\n</code></pre>"},{"location":"queries/advanced-queries/#view-utilization","title":"View Utilization","text":"<pre><code>You&gt; Use the optimized views to compare agricultural changes across scenarios\n</code></pre>"},{"location":"queries/advanced-queries/#data-validation","title":"Data Validation","text":"<pre><code>You&gt; Verify data consistency between the regular and aggregated tables\n</code></pre>"},{"location":"queries/advanced-queries/#visualization-preparation","title":"Visualization Preparation","text":""},{"location":"queries/advanced-queries/#chart-ready-data","title":"Chart-Ready Data","text":"<pre><code>You&gt; Prepare data for a stacked area chart of land use over time\n</code></pre>"},{"location":"queries/advanced-queries/#map-data","title":"Map Data","text":"<pre><code>You&gt; Format county-level changes for geographic visualization\n</code></pre>"},{"location":"queries/advanced-queries/#dashboard-metrics","title":"Dashboard Metrics","text":"<pre><code>You&gt; Create a set of KPIs for a land use monitoring dashboard\n</code></pre>"},{"location":"queries/advanced-queries/#advanced-examples","title":"Advanced Examples","text":""},{"location":"queries/advanced-queries/#example-1-comprehensive-county-profile","title":"Example 1: Comprehensive County Profile","text":"<pre><code>You&gt; Create a complete land use profile for Los Angeles County including:\n- Current land use distribution\n- Historical trends\n- Projected changes under each scenario  \n- Comparison to state averages\n- Key transition patterns\n</code></pre>"},{"location":"queries/advanced-queries/#example-2-scenario-impact-report","title":"Example 2: Scenario Impact Report","text":"<pre><code>You&gt; Generate an impact assessment comparing all scenarios:\n- Total area changed\n- Natural land preserved\n- Agricultural productivity\n- Urban expansion efficiency\n- Environmental sustainability score\n</code></pre>"},{"location":"queries/advanced-queries/#example-3-time-series-forecast","title":"Example 3: Time Series Forecast","text":"<pre><code>You&gt; Based on historical patterns, project when urban area might exceed agricultural area in major metropolitan counties\n</code></pre>"},{"location":"queries/advanced-queries/#best-practices-for-complex-queries","title":"Best Practices for Complex Queries","text":"<ol> <li>Break Down Complex Requests</li> <li>Start with simpler components</li> <li>Build up to the full analysis</li> <li> <p>Verify each step</p> </li> <li> <p>Use Agent Memory</p> </li> <li>Reference previous results</li> <li>Build analyses incrementally</li> <li> <p>Save intermediate results</p> </li> <li> <p>Optimize for Performance</p> </li> <li>Request samples for exploration</li> <li>Use filtered subsets</li> <li> <p>Leverage indexed columns</p> </li> <li> <p>Validate Results</p> </li> <li>Check totals and subtotals</li> <li>Verify against known values</li> <li>Look for logical consistency</li> </ol>"},{"location":"queries/advanced-queries/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Query Examples for real-world scenarios</li> <li>Review Data Schemas for all available fields</li> <li>See API Reference for programmatic access</li> </ul>"},{"location":"queries/basic-queries/","title":"Basic Natural Language Queries","text":"<p>This guide covers fundamental query patterns to help you get started with natural language data analysis.</p>"},{"location":"queries/basic-queries/#exploring-the-database","title":"Exploring the Database","text":""},{"location":"queries/basic-queries/#list-tables","title":"List Tables","text":"<pre><code>You&gt; What tables are in the landuse_transitions database?\n</code></pre> <p>Agent Response: <pre><code>Database: processed/landuse_transitions_with_ag.db\nTables:\n  \u2022 landuse_transitions: 1,234,567 rows\n  \u2022 landuse_transitions_ag: 987,654 rows  \n  \u2022 landuse_changes_only: 543,210 rows\n  \u2022 landuse_changes_only_ag: 432,109 rows\n</code></pre></p>"},{"location":"queries/basic-queries/#understand-table-structure","title":"Understand Table Structure","text":"<pre><code>You&gt; Describe the schema of the landuse_transitions table\n</code></pre> <p>Agent Response: <pre><code>Table: landuse_transitions\nRows: 1,234,567\n\nSchema:\n  scenario (TEXT) NOT NULL\n  year (INTEGER) NOT NULL\n  year_range (TEXT) NOT NULL\n  fips (TEXT) NOT NULL\n  from_land_use (TEXT) NOT NULL\n  to_land_use (TEXT) NOT NULL\n  area_1000_acres (REAL)\n\nIndexes:\n  \u2022 idx_scenario\n  \u2022 idx_year\n  \u2022 idx_fips\n</code></pre></p>"},{"location":"queries/basic-queries/#see-sample-data","title":"See Sample Data","text":"<pre><code>You&gt; Show me 5 sample rows from the landuse_transitions table\n</code></pre>"},{"location":"queries/basic-queries/#simple-filtering-queries","title":"Simple Filtering Queries","text":""},{"location":"queries/basic-queries/#filter-by-scenario","title":"Filter by Scenario","text":"<pre><code>You&gt; Show me data from the Baseline scenario\n</code></pre> <p>The agent generates: <pre><code>SELECT * FROM landuse_transitions \nWHERE scenario = 'Baseline' \nLIMIT 10\n</code></pre></p>"},{"location":"queries/basic-queries/#filter-by-year","title":"Filter by Year","text":"<pre><code>You&gt; What land use transitions happened in 2050?\n</code></pre>"},{"location":"queries/basic-queries/#filter-by-location","title":"Filter by Location","text":"<pre><code>You&gt; Show me land use changes in California\n</code></pre> <p>The agent knows California FIPS codes start with '06': <pre><code>SELECT * FROM landuse_transitions \nWHERE fips LIKE '06%' \nLIMIT 100\n</code></pre></p>"},{"location":"queries/basic-queries/#filter-by-land-use-type","title":"Filter by Land Use Type","text":"<pre><code>You&gt; Show me all transitions from forest\n</code></pre>"},{"location":"queries/basic-queries/#basic-aggregations","title":"Basic Aggregations","text":""},{"location":"queries/basic-queries/#count-records","title":"Count Records","text":"<pre><code>You&gt; How many land use transitions are in the database?\n</code></pre>"},{"location":"queries/basic-queries/#sum-areas","title":"Sum Areas","text":"<pre><code>You&gt; What's the total forest area in 2020?\n</code></pre> <p>Generated SQL: <pre><code>SELECT SUM(area_1000_acres) as total_forest_acres\nFROM landuse_transitions\nWHERE from_land_use = 'Forest' \n  AND to_land_use = 'Forest'\n  AND year = 2020\n</code></pre></p>"},{"location":"queries/basic-queries/#group-by-queries","title":"Group By Queries","text":"<pre><code>You&gt; Show me total area by land use type\n</code></pre>"},{"location":"queries/basic-queries/#calculate-averages","title":"Calculate Averages","text":"<pre><code>You&gt; What's the average urban area per county?\n</code></pre>"},{"location":"queries/basic-queries/#finding-unique-values","title":"Finding Unique Values","text":""},{"location":"queries/basic-queries/#list-scenarios","title":"List Scenarios","text":"<pre><code>You&gt; What scenarios are available in the data?\n</code></pre> <p>Response: <pre><code>Unique scenarios:\n- Baseline\n- High Crop Demand  \n- High Forest\n- High Urban\n</code></pre></p>"},{"location":"queries/basic-queries/#list-land-use-types","title":"List Land Use Types","text":"<pre><code>You&gt; What are all the land use categories?\n</code></pre>"},{"location":"queries/basic-queries/#list-years","title":"List Years","text":"<pre><code>You&gt; What years does the data cover?\n</code></pre>"},{"location":"queries/basic-queries/#simple-transition-queries","title":"Simple Transition Queries","text":""},{"location":"queries/basic-queries/#specific-transitions","title":"Specific Transitions","text":"<pre><code>You&gt; Show me forest to urban transitions\n</code></pre> <p>Generated SQL: <pre><code>SELECT * FROM landuse_transitions\nWHERE from_land_use = 'Forest' \n  AND to_land_use = 'Urban'\nLIMIT 100\n</code></pre></p>"},{"location":"queries/basic-queries/#all-transitions-from-a-type","title":"All Transitions From a Type","text":"<pre><code>You&gt; What does cropland convert to?\n</code></pre>"},{"location":"queries/basic-queries/#all-transitions-to-a-type","title":"All Transitions To a Type","text":"<pre><code>You&gt; What converts to urban land?\n</code></pre>"},{"location":"queries/basic-queries/#basic-sorting","title":"Basic Sorting","text":""},{"location":"queries/basic-queries/#order-by-area","title":"Order by Area","text":"<pre><code>You&gt; Show the largest land use transitions by area\n</code></pre>"},{"location":"queries/basic-queries/#order-by-year","title":"Order by Year","text":"<pre><code>You&gt; Show forest area over time, sorted by year\n</code></pre>"},{"location":"queries/basic-queries/#top-n-results","title":"Top N Results","text":"<pre><code>You&gt; What are the top 10 counties by total land area?\n</code></pre>"},{"location":"queries/basic-queries/#simple-comparisons","title":"Simple Comparisons","text":""},{"location":"queries/basic-queries/#compare-two-values","title":"Compare Two Values","text":"<pre><code>You&gt; Is there more forest or cropland in 2050?\n</code></pre>"},{"location":"queries/basic-queries/#year-over-year-changes","title":"Year-over-Year Changes","text":"<pre><code>You&gt; How much did urban area change from 2020 to 2030?\n</code></pre>"},{"location":"queries/basic-queries/#scenario-differences","title":"Scenario Differences","text":"<pre><code>You&gt; Compare forest area between Baseline and High Forest scenarios\n</code></pre>"},{"location":"queries/basic-queries/#working-with-results","title":"Working with Results","text":""},{"location":"queries/basic-queries/#export-data","title":"Export Data","text":"<pre><code>You&gt; Export the forest transitions to a CSV file\n</code></pre>"},{"location":"queries/basic-queries/#get-statistics","title":"Get Statistics","text":"<pre><code>You&gt; Show me statistics for the area_1000_acres column\n</code></pre>"},{"location":"queries/basic-queries/#count-distinct-values","title":"Count Distinct Values","text":"<pre><code>You&gt; How many unique counties are in the data?\n</code></pre>"},{"location":"queries/basic-queries/#common-query-patterns","title":"Common Query Patterns","text":""},{"location":"queries/basic-queries/#pattern-1-filter-aggregate","title":"Pattern 1: Filter + Aggregate","text":"<pre><code>\"Total [land use] area in [location] for [scenario]\"\n\"Sum of [metric] where [condition]\"\n\"Average [value] by [grouping]\"\n</code></pre>"},{"location":"queries/basic-queries/#pattern-2-find-specific-records","title":"Pattern 2: Find Specific Records","text":"<pre><code>\"Show me [land use] in [year]\"\n\"List [top N] [items] by [metric]\"\n\"Find all [transitions] from [type] to [type]\"\n</code></pre>"},{"location":"queries/basic-queries/#pattern-3-compare-values","title":"Pattern 3: Compare Values","text":"<pre><code>\"Compare [metric] between [A] and [B]\"\n\"What's the difference in [value] from [time1] to [time2]\"\n\"Which [item] has more [metric]?\"\n</code></pre>"},{"location":"queries/basic-queries/#tips-for-success","title":"Tips for Success","text":""},{"location":"queries/basic-queries/#1-start-simple","title":"1. Start Simple","text":"<p>Begin with basic queries and add complexity: - First: \"Show forest data\" - Then: \"Show forest data in 2050\" - Finally: \"Show forest to urban transitions in California in 2050\"</p>"},{"location":"queries/basic-queries/#2-use-natural-language","title":"2. Use Natural Language","text":"<p>Don't try to write SQL-like queries: - \u274c \"SELECT * FROM landuse WHERE...\" - \u2705 \"Show me land use data where...\"</p>"},{"location":"queries/basic-queries/#3-ask-for-clarification","title":"3. Ask for Clarification","text":"<p>If unsure about data: <pre><code>You&gt; What does the 'area_1000_acres' column represent?\nYou&gt; What's the difference between the regular and _ag tables?\n</code></pre></p>"},{"location":"queries/basic-queries/#4-build-on-previous-queries","title":"4. Build on Previous Queries","text":"<p>The agent remembers context: <pre><code>You&gt; Show me total forest area by year\n[Agent shows results]\nYou&gt; Now just show me the years where it decreases\n</code></pre></p>"},{"location":"queries/basic-queries/#practice-exercises","title":"Practice Exercises","text":"<p>Try these queries to build familiarity:</p> <ol> <li>Basic Exploration</li> <li>List all tables in the database</li> <li>Show the first 10 rows of landuse_transitions</li> <li> <p>Count total records in each table</p> </li> <li> <p>Filtering Practice</p> </li> <li>Find all High Urban scenario data</li> <li>Show transitions in the year 2100</li> <li> <p>List data for FIPS code 06037</p> </li> <li> <p>Simple Analysis</p> </li> <li>Calculate total urban area</li> <li>Find the most common land use transition</li> <li> <p>Show which scenario has the most forest</p> </li> <li> <p>Basic Comparisons</p> </li> <li>Compare cropland between 2020 and 2050</li> <li>Find the county with the most urban growth</li> <li>Show the difference between scenarios</li> </ol>"},{"location":"queries/basic-queries/#next-steps","title":"Next Steps","text":"<p>Once comfortable with basic queries: - Learn Advanced Queries for complex analysis - See Query Examples for real-world scenarios - Understand Data Schemas for available fields</p>"},{"location":"queries/examples/","title":"Query Examples","text":"<p>Real-world examples of natural language queries for land use analysis, organized by use case.</p>"},{"location":"queries/examples/#urban-planning","title":"\ud83c\udfd9\ufe0f Urban Planning","text":""},{"location":"queries/examples/#urban-growth-analysis","title":"Urban Growth Analysis","text":"<p>Query: <pre><code>You&gt; Which metropolitan counties will see the most urban expansion by 2050?\n</code></pre></p> <p>Agent Approach: - Identifies counties with major cities - Calculates urban area change from 2020 to 2050 - Ranks by absolute and percentage growth</p> <p>Follow-up: <pre><code>You&gt; For those top counties, what land uses are being converted to urban?\n</code></pre></p>"},{"location":"queries/examples/#urban-density-trends","title":"Urban Density Trends","text":"<p>Query: <pre><code>You&gt; Show me counties where urban area is growing faster than the state average\n</code></pre></p> <p>Sample Result: <pre><code>Counties with above-average urban growth:\n- Riverside County (06065): +45.2% vs state avg 28.3%\n- San Bernardino (06071): +42.1% vs state avg 28.3%\n- Placer County (06061): +38.9% vs state avg 28.3%\n</code></pre></p>"},{"location":"queries/examples/#sustainable-development","title":"Sustainable Development","text":"<p>Query: <pre><code>You&gt; Find counties successfully increasing urban density without expanding into forest areas\n</code></pre></p>"},{"location":"queries/examples/#agricultural-analysis","title":"\ud83c\udf3e Agricultural Analysis","text":""},{"location":"queries/examples/#crop-vs-pasture-dynamics","title":"Crop vs Pasture Dynamics","text":"<p>Query: <pre><code>You&gt; How is the balance between cropland and pasture changing over time?\n</code></pre></p> <p>Agent generates analysis showing: - Total crop and pasture by decade - Conversion rates between them - Regional variations - Scenario comparisons</p>"},{"location":"queries/examples/#agricultural-pressure","title":"Agricultural Pressure","text":"<p>Query: <pre><code>You&gt; In the High Crop Demand scenario, which counties lose the most pasture to cropland?\n</code></pre></p>"},{"location":"queries/examples/#food-security-assessment","title":"Food Security Assessment","text":"<p>Query: <pre><code>You&gt; Calculate total agricultural land (crops + pasture) and show if it's increasing or decreasing nationally\n</code></pre></p> <p>Complex Follow-up: <pre><code>You&gt; Now break that down by region and identify areas at risk of agricultural land shortage\n</code></pre></p>"},{"location":"queries/examples/#forest-conservation","title":"\ud83c\udf32 Forest Conservation","text":""},{"location":"queries/examples/#deforestation-hotspots","title":"Deforestation Hotspots","text":"<p>Query: <pre><code>You&gt; Identify the top 20 counties with the highest forest loss across all scenarios\n</code></pre></p> <p>Results Format: <pre><code>Rank | County | FIPS | Forest Loss (1000 acres) | % Loss\n1    | County A | 12345 | -523.4 | -32.1%\n2    | County B | 23456 | -498.7 | -28.9%\n...\n</code></pre></p>"},{"location":"queries/examples/#forest-recovery","title":"Forest Recovery","text":"<p>Query: <pre><code>You&gt; Are there any counties where forest area increases? If so, what's converting to forest?\n</code></pre></p>"},{"location":"queries/examples/#conservation-scenarios","title":"Conservation Scenarios","text":"<p>Query: <pre><code>You&gt; Compare forest preservation between the Baseline and High Forest scenarios - where are the biggest differences?\n</code></pre></p>"},{"location":"queries/examples/#scenario-comparisons","title":"\ud83d\udcca Scenario Comparisons","text":""},{"location":"queries/examples/#comprehensive-scenario-analysis","title":"Comprehensive Scenario Analysis","text":"<p>Query: <pre><code>You&gt; Create a summary table comparing all scenarios for the year 2100:\n- Total urban area\n- Total agricultural area  \n- Total natural area (forest + range)\n- Percentage of land that changed use\n</code></pre></p>"},{"location":"queries/examples/#scenario-divergence","title":"Scenario Divergence","text":"<p>Query: <pre><code>You&gt; At what point do the scenarios start to significantly diverge from the Baseline?\n</code></pre></p> <p>Agent Analysis: - Calculates year-by-year differences - Identifies divergence threshold - Shows which land uses drive differences</p>"},{"location":"queries/examples/#best-case-analysis","title":"Best Case Analysis","text":"<p>Query: <pre><code>You&gt; Which scenario best balances urban growth needs with environmental preservation?\n</code></pre></p>"},{"location":"queries/examples/#trend-analysis","title":"\ud83d\udcc8 Trend Analysis","text":""},{"location":"queries/examples/#acceleration-detection","title":"Acceleration Detection","text":"<p>Query: <pre><code>You&gt; Show me where land use change is accelerating vs slowing down between the first half (2020-2060) and second half (2060-2100) of the projection period\n</code></pre></p>"},{"location":"queries/examples/#tipping-points","title":"Tipping Points","text":"<p>Query: <pre><code>You&gt; Identify years where major shifts occur in land use patterns\n</code></pre></p>"},{"location":"queries/examples/#long-term-projections","title":"Long-term Projections","text":"<p>Query: <pre><code>You&gt; Based on current trends, when will urban area exceed 20% in major counties?\n</code></pre></p>"},{"location":"queries/examples/#regional-patterns","title":"\ud83d\uddfa\ufe0f Regional Patterns","text":""},{"location":"queries/examples/#state-level-analysis","title":"State-Level Analysis","text":"<p>Query: <pre><code>You&gt; Summarize land use changes by state, focusing on the top 5 states with the most change\n</code></pre></p>"},{"location":"queries/examples/#coastal-vs-inland","title":"Coastal vs Inland","text":"<p>Query: <pre><code>You&gt; Compare land use transition patterns between coastal counties and inland counties\n</code></pre></p> <p>Agent Approach: <pre><code>-- Identifies coastal counties (could use FIPS patterns or geographic data)\n-- Aggregates transitions for each group\n-- Calculates and compares metrics\n</code></pre></p>"},{"location":"queries/examples/#metropolitan-influence","title":"Metropolitan Influence","text":"<p>Query: <pre><code>You&gt; How do land use changes differ between counties with major cities versus rural counties?\n</code></pre></p>"},{"location":"queries/examples/#transition-patterns","title":"\ud83d\udd04 Transition Patterns","text":""},{"location":"queries/examples/#transition-matrix","title":"Transition Matrix","text":"<p>Query: <pre><code>You&gt; Create a transition matrix showing all conversions between land use types for the Baseline scenario\n</code></pre></p> <p>Result Format: <pre><code>From\\To | Crop | Forest | Pasture | Urban | Range\n--------|------|--------|---------|-------|-------\nCrop    | 85%  | 2%     | 8%      | 5%    | 0%\nForest  | 3%   | 88%    | 2%      | 7%    | 0%\n...\n</code></pre></p>"},{"location":"queries/examples/#unusual-transitions","title":"Unusual Transitions","text":"<p>Query: <pre><code>You&gt; Find rare or unexpected land use transitions that might indicate data issues or interesting patterns\n</code></pre></p>"},{"location":"queries/examples/#transition-chains","title":"Transition Chains","text":"<p>Query: <pre><code>You&gt; Track agricultural land that eventually becomes urban - does it go directly or through other uses first?\n</code></pre></p>"},{"location":"queries/examples/#complex-analytical-queries","title":"\ud83d\udca1 Complex Analytical Queries","text":""},{"location":"queries/examples/#multi-criteria-analysis","title":"Multi-Criteria Analysis","text":"<p>Query: <pre><code>You&gt; Find counties that meet all these criteria:\n- Urban growth &gt; 25%\n- Forest loss &lt; 10%\n- Agricultural land stable (\u00b15%)\n- In the Baseline scenario\n</code></pre></p>"},{"location":"queries/examples/#composite-metrics","title":"Composite Metrics","text":"<p>Query: <pre><code>You&gt; Create a \"land use change intensity index\" that combines:\n- Rate of change\n- Diversity of transitions\n- Deviation from historical patterns\n</code></pre></p>"},{"location":"queries/examples/#predictive-insights","title":"Predictive Insights","text":"<p>Query: <pre><code>You&gt; Based on 2020-2040 patterns, which counties are likely to face land use conflicts by 2080?\n</code></pre></p>"},{"location":"queries/examples/#reporting-queries","title":"\ud83d\udccb Reporting Queries","text":""},{"location":"queries/examples/#executive-summary","title":"Executive Summary","text":"<p>Query: <pre><code>You&gt; Generate a one-page executive summary of land use changes including:\n- Key statistics\n- Major trends\n- Critical counties to watch\n- Policy implications\n</code></pre></p>"},{"location":"queries/examples/#county-report-card","title":"County Report Card","text":"<p>Query: <pre><code>You&gt; Create a detailed report card for Sacramento County including all scenarios and land use changes\n</code></pre></p>"},{"location":"queries/examples/#stakeholder-analysis","title":"Stakeholder Analysis","text":"<p>Query: <pre><code>You&gt; Prepare data for different stakeholders:\n- Farmers: Agricultural land changes\n- Conservationists: Natural land preservation  \n- Urban planners: Development opportunities\n- Policymakers: Overall sustainability\n</code></pre></p>"},{"location":"queries/examples/#data-quality-checks","title":"\ud83d\udee0\ufe0f Data Quality Checks","text":""},{"location":"queries/examples/#validation-queries","title":"Validation Queries","text":"<p>Query: <pre><code>You&gt; Verify that total land area remains constant over time for each county\n</code></pre></p>"},{"location":"queries/examples/#consistency-checks","title":"Consistency Checks","text":"<p>Query: <pre><code>You&gt; Check if the sum of all \"from\" transitions equals the sum of all \"to\" transitions by year\n</code></pre></p>"},{"location":"queries/examples/#outlier-detection","title":"Outlier Detection","text":"<p>Query: <pre><code>You&gt; Find any suspicious data points where land use changes seem unrealistic\n</code></pre></p>"},{"location":"queries/examples/#export-and-visualization-prep","title":"\ud83d\udcca Export and Visualization Prep","text":""},{"location":"queries/examples/#chart-data","title":"Chart Data","text":"<p>Query: <pre><code>You&gt; Prepare data for a line chart showing land use trends over time for all scenarios\n</code></pre></p>"},{"location":"queries/examples/#geographic-export","title":"Geographic Export","text":"<p>Query: <pre><code>You&gt; Export county-level urban growth data in a format suitable for GIS mapping\n</code></pre></p>"},{"location":"queries/examples/#dashboard-metrics","title":"Dashboard Metrics","text":"<p>Query: <pre><code>You&gt; Create a set of 10 key metrics for a land use monitoring dashboard, updated annually\n</code></pre></p>"},{"location":"queries/examples/#tips-for-complex-queries","title":"Tips for Complex Queries","text":"<ol> <li>Build Incrementally: Start simple, add complexity</li> <li>Use Context: Reference previous results</li> <li>Be Specific: Include scenarios, years, and regions</li> <li>Think Stepwise: Break complex analyses into steps</li> <li>Verify Results: Ask for row counts and sanity checks</li> </ol>"},{"location":"queries/examples/#next-steps","title":"Next Steps","text":"<ul> <li>Try these examples with your own data</li> <li>Modify queries for your specific needs</li> <li>Combine patterns for new insights</li> <li>Share interesting findings!</li> </ul>"},{"location":"queries/overview/","title":"Natural Language Queries Overview","text":"<p>The power of this system lies in its ability to understand your questions in plain English and translate them into precise database queries. This section explains how the LangChain agent interprets natural language and provides tips for getting the best results.</p>"},{"location":"queries/overview/#how-it-works","title":"How It Works","text":"<pre><code>graph TD\n    A[Your Question] --&gt; B[LangChain Agent]\n    B --&gt; C[Language Understanding]\n    C --&gt; D[SQL Generation]\n    D --&gt; E[Query Execution]\n    E --&gt; F[Result Formatting]\n    F --&gt; G[Natural Language Response]</code></pre>"},{"location":"queries/overview/#the-process","title":"The Process","text":"<ol> <li>Language Understanding: The agent analyzes your question to identify:</li> <li>What data you're looking for</li> <li>Which tables/fields are relevant</li> <li>What filters or conditions to apply</li> <li> <p>How to aggregate or sort results</p> </li> <li> <p>SQL Generation: Your question is converted to SQL:</p> </li> <li>Proper table and column selection</li> <li>JOIN operations when needed</li> <li>WHERE clauses for filtering</li> <li>GROUP BY for aggregations</li> <li> <p>ORDER BY for sorting</p> </li> <li> <p>Intelligent Response: Results are formatted clearly with:</p> </li> <li>Summary of findings</li> <li>Formatted tables</li> <li>Relevant context</li> <li>Follow-up suggestions</li> </ol>"},{"location":"queries/overview/#query-categories","title":"Query Categories","text":""},{"location":"queries/overview/#exploratory-queries","title":"\ud83d\udd0d Exploratory Queries","text":"<p>Understand your data structure and contents:</p> <pre><code>\"What tables are in the database?\"\n\"Show me the columns in the landuse_transitions table\"\n\"What are the unique scenarios in the data?\"\n\"How many records are in each table?\"\n</code></pre>"},{"location":"queries/overview/#analytical-queries","title":"\ud83d\udcca Analytical Queries","text":"<p>Perform calculations and analysis:</p> <pre><code>\"What's the total forest area in 2050?\"\n\"Calculate the average urban growth rate per decade\"\n\"Show me the percentage of land that changes use vs stays the same\"\n\"What's the correlation between urban growth and forest loss?\"\n</code></pre>"},{"location":"queries/overview/#transition-queries","title":"\ud83d\udd04 Transition Queries","text":"<p>Focus on land use changes:</p> <pre><code>\"Show all transitions from forest to other land uses\"\n\"Which land use has the most conversions to urban?\"\n\"Find counties where cropland is converting to pasture\"\n\"What are the top 10 most common land use transitions?\"\n</code></pre>"},{"location":"queries/overview/#trend-queries","title":"\ud83d\udcc8 Trend Queries","text":"<p>Analyze changes over time:</p> <pre><code>\"How does cropland area change from 2020 to 2100?\"\n\"Show me the decade with the most urban expansion\"\n\"Plot forest area trends for all scenarios\"\n\"When does agricultural land peak in the High Crop Demand scenario?\"\n</code></pre>"},{"location":"queries/overview/#geographic-queries","title":"\ud83d\uddfa\ufe0f Geographic Queries","text":"<p>Location-specific analysis:</p> <pre><code>\"What are the land use changes in California counties?\"\n\"Show me the top 20 counties by urban growth\"\n\"Which FIPS codes have the most forest?\"\n\"Compare land use between coastal and inland counties\"\n</code></pre>"},{"location":"queries/overview/#comparison-queries","title":"\ud83d\udd04 Comparison Queries","text":"<p>Compare scenarios, time periods, or regions:</p> <pre><code>\"Compare urban growth between Baseline and High Crop Demand\"\n\"What's the difference in forest loss between 2020-2050 and 2050-2080?\"\n\"Show scenario differences for agricultural land in 2100\"\n\"Which scenario preserves the most natural land?\"\n</code></pre>"},{"location":"queries/overview/#best-practices","title":"Best Practices","text":""},{"location":"queries/overview/#1-be-specific","title":"1. Be Specific","text":"<p>\u274c Vague: \"Show me some data\" \u2705 Specific: \"Show me forest to urban transitions in California for the Baseline scenario\"</p>"},{"location":"queries/overview/#2-include-context","title":"2. Include Context","text":"<p>\u274c Ambiguous: \"What changes the most?\" \u2705 Clear: \"Which land use type has the largest area change between 2020 and 2050?\"</p>"},{"location":"queries/overview/#3-specify-filters","title":"3. Specify Filters","text":"<p>\u274c Too broad: \"Show transitions\" \u2705 Filtered: \"Show transitions from agricultural land to urban in counties with FIPS starting with 06\"</p>"},{"location":"queries/overview/#4-request-format","title":"4. Request Format","text":"<p>\u274c Unclear format: \"Give me the data\" \u2705 Clear format: \"List the top 10 counties by forest loss, showing county FIPS and area lost\"</p>"},{"location":"queries/overview/#understanding-agent-responses","title":"Understanding Agent Responses","text":""},{"location":"queries/overview/#sql-transparency","title":"SQL Transparency","text":"<p>The agent shows the generated SQL query:</p> <pre><code>Query: SELECT scenario, year, SUM(area_1000_acres) as total_forest\n       FROM landuse_transitions\n       WHERE from_land_use = 'Forest' \n         AND to_land_use = 'Forest'\n       GROUP BY scenario, year\n       ORDER BY scenario, year\n</code></pre> <p>This helps you: - Verify the query matches your intent - Learn SQL patterns - Debug unexpected results</p>"},{"location":"queries/overview/#result-interpretation","title":"Result Interpretation","text":"<p>Results include: - Row count: \"Results: 245 rows\" - Formatted data: Tables with clear headers - Summary: Key findings highlighted - Context: Explanations of what the data represents</p>"},{"location":"queries/overview/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"queries/overview/#multi-step-analysis","title":"Multi-Step Analysis","text":"<p>Break complex questions into steps:</p> <pre><code>You&gt; First, find the counties with the most agricultural land\nAgent&gt; [Shows top agricultural counties]\n\nYou&gt; Now show me how urban area changes in those counties\nAgent&gt; [Analyzes urban growth in previously identified counties]\n</code></pre>"},{"location":"queries/overview/#conditional-queries","title":"Conditional Queries","text":"<p>Use conditions and logic:</p> <pre><code>\"Show counties where forest loss exceeds 20% AND urban growth is above average\"\n\"Find transitions that only occur in the High Crop Demand scenario\"\n\"List counties with increasing cropland but decreasing pasture\"\n</code></pre>"},{"location":"queries/overview/#custom-calculations","title":"Custom Calculations","text":"<p>Request specific computations:</p> <pre><code>\"Calculate the net change in agricultural land (crops + pasture) by decade\"\n\"Show the ratio of urban growth to forest loss by county\"\n\"What percentage of each county converts from natural to developed land?\"\n</code></pre>"},{"location":"queries/overview/#common-patterns","title":"Common Patterns","text":""},{"location":"queries/overview/#time-based-patterns","title":"Time-Based Patterns","text":"<pre><code>\"between 2020 and 2050\"\n\"in the year 2100\"  \n\"by decade\"\n\"over the entire period\"\n\"changes from [year] to [year]\"\n</code></pre>"},{"location":"queries/overview/#aggregation-patterns","title":"Aggregation Patterns","text":"<pre><code>\"total area\"\n\"average change\"\n\"sum by scenario\"\n\"count of transitions\"\n\"percentage of total\"\n</code></pre>"},{"location":"queries/overview/#filtering-patterns","title":"Filtering Patterns","text":"<pre><code>\"only in California\" (FIPS LIKE '06%')\n\"excluding same-to-same transitions\"\n\"where area &gt; 1000\"\n\"for Baseline scenario only\"\n\"top 10 by [metric]\"\n</code></pre>"},{"location":"queries/overview/#query-optimization-tips","title":"Query Optimization Tips","text":"<ol> <li>Start broad, then narrow</li> <li>First: \"What scenarios are available?\"</li> <li> <p>Then: \"Show forest changes in the Baseline scenario\"</p> </li> <li> <p>Use table views wisely</p> </li> <li><code>landuse_transitions</code>: All transitions including same-to-same</li> <li><code>landuse_changes_only</code>: Excludes unchanged land</li> <li> <p><code>*_ag</code> tables: Agricultural aggregation (crop + pasture)</p> </li> <li> <p>Leverage agent memory</p> </li> <li>Previous results are remembered</li> <li> <p>Reference earlier queries: \"Using those counties, now show...\"</p> </li> <li> <p>Request appropriate limits</p> </li> <li>\"Show me a sample of 10 rows\"</li> <li>\"List the top 20 counties\"</li> <li>\"Summarize by decade instead of year\"</li> </ol>"},{"location":"queries/overview/#next-steps","title":"Next Steps","text":"<ul> <li>See Basic Queries for simple examples</li> <li>Explore Advanced Queries for complex analysis</li> <li>Check Query Examples for real-world scenarios</li> <li>Learn about Data Schemas to understand available fields</li> </ul>"},{"location":"rpa/climate-models/","title":"Climate Models in the RPA Assessment","text":""},{"location":"rpa/climate-models/#overview","title":"Overview","text":"<p>The 2020 RPA Assessment uses 5 carefully selected Global Climate Models (GCMs) to capture the range of possible future climate conditions across the United States. These models were chosen to represent different combinations of temperature and precipitation patterns.</p>"},{"location":"rpa/climate-models/#the-five-climate-models","title":"The Five Climate Models","text":""},{"location":"rpa/climate-models/#cnrm_cm5-wet-model","title":"CNRM_CM5 - \"Wet\" Model","text":"<ul> <li>Full Name: Centre National de Recherches M\u00e9t\u00e9orologiques Climate Model 5</li> <li>Origin: France</li> <li>Key Characteristic: Projects increased precipitation across most of the US</li> <li>Temperature Pattern: Moderate warming</li> <li>Best For: Analyzing scenarios with higher water availability</li> </ul>"},{"location":"rpa/climate-models/#hadgem2_es365-hot-model","title":"HadGEM2_ES365 - \"Hot\" Model","text":"<ul> <li>Full Name: Hadley Centre Global Environmental Model 2 - Earth System</li> <li>Origin: United Kingdom</li> <li>Key Characteristic: Represents the upper bound of temperature increases</li> <li>Temperature Pattern: Highest warming projections</li> <li>Best For: Stress-testing under extreme heat scenarios</li> </ul>"},{"location":"rpa/climate-models/#ipsl_cm5a_mr-dry-model","title":"IPSL_CM5A_MR - \"Dry\" Model","text":"<ul> <li>Full Name: Institut Pierre Simon Laplace Climate Model 5A - Medium Resolution</li> <li>Origin: France</li> <li>Key Characteristic: Projects reduced precipitation in many regions</li> <li>Temperature Pattern: Moderate to high warming</li> <li>Best For: Analyzing drought and water scarcity impacts</li> </ul>"},{"location":"rpa/climate-models/#mri_cgcm3-least-warm-model","title":"MRI_CGCM3 - \"Least Warm\" Model","text":"<ul> <li>Full Name: Meteorological Research Institute Coupled Global Climate Model 3</li> <li>Origin: Japan</li> <li>Key Characteristic: Most conservative temperature projections</li> <li>Temperature Pattern: Lower bound of warming</li> <li>Best For: Best-case climate scenarios</li> </ul>"},{"location":"rpa/climate-models/#noresm1_m-middle-model","title":"NorESM1_M - \"Middle\" Model","text":"<ul> <li>Full Name: Norwegian Earth System Model 1 - Medium Resolution</li> <li>Origin: Norway</li> <li>Key Characteristic: Represents central tendency of climate projections</li> <li>Temperature Pattern: Median warming and precipitation</li> <li>Best For: Most likely/average climate outcomes</li> </ul>"},{"location":"rpa/climate-models/#model-selection-rationale","title":"Model Selection Rationale","text":"<p>The RPA Assessment team selected these models to: 1. Capture uncertainty - Range from wet to dry, hot to least warm 2. Represent extremes - Include both upper and lower bounds 3. Include central tendency - Middle model for most likely outcomes 4. Geographic coverage - Models perform well across US regions</p>"},{"location":"rpa/climate-models/#using-climate-models-in-analysis","title":"Using Climate Models in Analysis","text":""},{"location":"rpa/climate-models/#comparing-models","title":"Comparing Models","text":"<p>When analyzing RPA data, you can: - Compare outcomes across all 5 models to see the full range - Focus on extremes (Hot vs Least Warm, Wet vs Dry) - Use the Middle model for typical projections</p>"},{"location":"rpa/climate-models/#example-queries","title":"Example Queries","text":"<pre><code>\"Compare forest loss between the wet and dry climate models\"\n\"Which climate model shows the most agricultural stress?\"\n\"Show urban expansion under the hot climate model\"\n</code></pre>"},{"location":"rpa/climate-models/#interpreting-results","title":"Interpreting Results","text":"<ul> <li>Wet model results suggest impacts under increased precipitation</li> <li>Dry model results indicate drought stress responses</li> <li>Hot model shows maximum temperature stress</li> <li>Least warm provides conservative estimates</li> <li>Middle model offers balanced projections</li> </ul>"},{"location":"rpa/climate-models/#climate-pathways-rcps","title":"Climate Pathways (RCPs)","text":"<p>Each climate model runs under two Representative Concentration Pathways:</p>"},{"location":"rpa/climate-models/#rcp45-lower-emissions","title":"RCP4.5 - Lower Emissions","text":"<ul> <li>Global warming of approximately 2.5\u00b0C by 2100</li> <li>Assumes significant emissions reductions</li> <li>More optimistic climate future</li> </ul>"},{"location":"rpa/climate-models/#rcp85-higher-emissions","title":"RCP8.5 - Higher Emissions","text":"<ul> <li>Global warming of approximately 4.5\u00b0C by 2100</li> <li>Assumes continued high emissions</li> <li>More pessimistic climate future</li> </ul>"},{"location":"rpa/climate-models/#model-scenario-matrix","title":"Model \u00d7 Scenario Matrix","text":"<p>Each of the 5 climate models is combined with 4 RPA scenarios: - 5 climate models \u00d7 4 scenarios = 20 total projections - Allows analysis of climate-socioeconomic interactions - Captures full range of plausible futures</p>"},{"location":"rpa/climate-models/#technical-notes","title":"Technical Notes","text":"<ul> <li>Models downscaled to county-level resolution</li> <li>Bias-corrected for regional accuracy</li> <li>Validated against historical observations</li> <li>Updated from CMIP5 ensemble</li> </ul>"},{"location":"rpa/overview/","title":"RPA Assessment Overview","text":""},{"location":"rpa/overview/#about-the-2020-resources-planning-act-assessment","title":"About the 2020 Resources Planning Act Assessment","text":"<p>The USDA Forest Service's 2020 Resources Planning Act (RPA) Assessment provides comprehensive projections of land use change across the United States through 2070. This assessment is mandated by the Forest and Rangeland Renewable Resources Planning Act of 1974, which requires periodic evaluations of the Nation's renewable resources.</p>"},{"location":"rpa/overview/#key-components","title":"Key Components","text":""},{"location":"rpa/overview/#land-use-projections","title":"Land Use Projections","text":"<p>The 2020 RPA Assessment includes detailed county-level projections for: - Private land only - Public lands are assumed to remain static - 5 land use categories: Crop, Pasture, Rangeland, Forest, and Urban - 3,075 US counties - Complete coverage of the conterminous United States - Time periods: 2012-2020, 2020-2030, 2030-2040, 2040-2050, 2050-2070, 2070-2090, 2090-2100</p>"},{"location":"rpa/overview/#integrated-scenarios","title":"Integrated Scenarios","text":"<p>The assessment uses 20 integrated climate-socioeconomic scenarios: - 4 scenario combinations (LM, HL, HM, HH) - 5 climate models representing different precipitation and temperature patterns - 2 climate pathways (RCP4.5 and RCP8.5) - 4 socioeconomic pathways (SSP1, SSP2, SSP3, SSP5)</p>"},{"location":"rpa/overview/#methodology-overview","title":"Methodology Overview","text":""},{"location":"rpa/overview/#econometric-model","title":"Econometric Model","text":"<ul> <li>Calibrated using observed land use transitions from 2001-2012</li> <li>Based on National Resources Inventory (NRI) data</li> <li>Incorporates economic, demographic, and environmental drivers</li> <li>Projects future transitions based on historical relationships</li> </ul>"},{"location":"rpa/overview/#key-assumptions","title":"Key Assumptions","text":"<ol> <li>Development irreversibility - Once land becomes urban, it remains urban</li> <li>Private land focus - Public lands excluded from transition modeling</li> <li>Policy-neutral - Projections based on historical trends without future policy assumptions</li> <li>County-level resolution - Maintains local geographic detail</li> </ol>"},{"location":"rpa/overview/#data-sources","title":"Data Sources","text":""},{"location":"rpa/overview/#primary-data","title":"Primary Data","text":"<ul> <li>National Resources Inventory (NRI) - Historical land use observations</li> <li>Climate projections - From 5 global climate models</li> <li>Socioeconomic projections - Population and economic growth scenarios</li> </ul>"},{"location":"rpa/overview/#model-outputs","title":"Model Outputs","text":"<ul> <li>Transition matrices - Acres changing between land use categories</li> <li>Scenario variations - Results for all 20 integrated scenarios</li> <li>Temporal resolution - Decadal projections through 2100</li> </ul>"},{"location":"rpa/overview/#using-rpa-data-with-this-tool","title":"Using RPA Data with This Tool","text":"<p>RPA Land Use Analytics makes this complex dataset accessible through: - Natural language queries to explore scenarios - Pre-built analyses of key trends - Interactive visualizations - Direct database access for advanced users</p>"},{"location":"rpa/overview/#learn-more","title":"Learn More","text":"<ul> <li>Official RPA Website</li> <li>2020 RPA Assessment Report</li> <li>Technical Documentation</li> </ul>"},{"location":"troubleshooting/streamlit-duplicate-ids/","title":"Fixing Streamlit Duplicate Element IDs","text":""},{"location":"troubleshooting/streamlit-duplicate-ids/#problem","title":"Problem","text":"<p>Streamlit generates automatic IDs for widgets based on their type and parameters. When multiple widgets have the same type and parameters, they get identical IDs, causing a <code>StreamlitDuplicateElementId</code> error.</p>"},{"location":"troubleshooting/streamlit-duplicate-ids/#error-message","title":"Error Message","text":"<pre><code>StreamlitDuplicateElementId: There are multiple `selectbox` elements with the same auto-generated ID.\nWhen this element is created, it is assigned an internal ID based on the element type and provided parameters.\nMultiple elements with the same type and parameters will cause this error.\n\nTo fix this error, please pass a unique `key` argument to the selectbox element.\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#root-cause","title":"Root Cause","text":"<p>In the data extraction page (<code>pages/extraction.py</code>), multiple widgets had identical parameters:</p>"},{"location":"troubleshooting/streamlit-duplicate-ids/#duplicate-selectboxes","title":"Duplicate Selectboxes","text":"<ul> <li>Multiple \"Export format:\" selectboxes with same options <code>[\"CSV\", \"Excel\", \"JSON\", \"Parquet\"]</code></li> <li>These appeared in different sections (templates, custom, bulk) but had identical parameters</li> </ul>"},{"location":"troubleshooting/streamlit-duplicate-ids/#duplicate-number-inputs","title":"Duplicate Number Inputs","text":"<ul> <li>Multiple \"Preview rows:\" number inputs with same min/max/value/step parameters</li> <li>Multiple \"Export limit:\" number inputs with same parameters</li> </ul>"},{"location":"troubleshooting/streamlit-duplicate-ids/#solution","title":"Solution","text":"<p>Add unique <code>key</code> parameters to each widget to force different IDs:</p>"},{"location":"troubleshooting/streamlit-duplicate-ids/#fixed-selectboxes","title":"Fixed Selectboxes","text":"<pre><code># Template section\nexport_format = st.selectbox(\n    \"Export format:\",\n    [\"CSV\", \"Excel\", \"JSON\", \"Parquet\"],\n    help=\"Choose the file format for your export\",\n    key=\"template_export_format\"  # \u2705 Unique key\n)\n\n# Custom section\nexport_format = st.selectbox(\n    \"Export format:\",\n    [\"CSV\", \"Excel\", \"JSON\", \"Parquet\"],\n    help=\"Choose the file format for your export\",\n    key=\"custom_export_format\"  # \u2705 Different key\n)\n\n# Bulk section\nexport_format = st.selectbox(\n    \"Export format:\",\n    [\"CSV (ZIP)\", \"Excel\", \"Parquet (ZIP)\"],\n    help=\"Choose the format for bulk export\",\n    key=\"bulk_export_format\"  # \u2705 Different key\n)\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#fixed-number-inputs","title":"Fixed Number Inputs","text":"<pre><code># Template section\npreview_rows = st.number_input(\n    \"Preview rows:\",\n    min_value=10,\n    max_value=1000,\n    value=100,\n    step=10,\n    help=\"Number of rows to preview\",\n    key=\"template_preview_rows\"  # \u2705 Unique key\n)\n\n# Custom section\npreview_limit = st.number_input(\n    \"Preview rows:\",\n    min_value=10,\n    max_value=1000,\n    value=100,\n    step=10,\n    key=\"custom_preview_rows\"  # \u2705 Different key\n)\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#complete-key-mapping","title":"Complete Key Mapping","text":"Widget Type Location Key Description selectbox Templates <code>template_selector</code> Template selection selectbox Templates <code>template_export_format</code> Export format for templates selectbox Custom <code>custom_extract_type</code> Custom extraction type selectbox Custom <code>custom_transition_type</code> Transition type filter selectbox Custom <code>custom_export_format</code> Export format for custom selectbox Bulk <code>bulk_extract_type</code> Bulk extraction type selectbox Bulk <code>bulk_export_format</code> Export format for bulk number_input Templates <code>template_preview_rows</code> Preview rows for templates number_input Templates <code>template_export_limit</code> Export limit for templates number_input Custom <code>custom_preview_rows</code> Preview rows for custom number_input Custom <code>custom_export_limit</code> Export limit for custom number_input Bulk <code>bulk_row_limit</code> Row limit for bulk button Templates <code>template_preview_data</code> Preview data button button Templates <code>template_export_data</code> Export data button button Custom <code>custom_preview_query</code> Preview query button button Custom <code>custom_preview_data</code> Preview data button button Custom <code>custom_export_data</code> Export data button button Bulk <code>bulk_generate_export</code> Generate bulk export button"},{"location":"troubleshooting/streamlit-duplicate-ids/#prevention","title":"Prevention","text":"<p>To avoid this issue in the future:</p>"},{"location":"troubleshooting/streamlit-duplicate-ids/#1-always-use-keys-for-repeated-widgets","title":"1. Always Use Keys for Repeated Widgets","text":"<pre><code># \u274c Bad: Same parameters, no keys\nst.selectbox(\"Format:\", [\"CSV\", \"JSON\"])  # Section 1\nst.selectbox(\"Format:\", [\"CSV\", \"JSON\"])  # Section 2 - DUPLICATE!\n\n# \u2705 Good: Same parameters, unique keys\nst.selectbox(\"Format:\", [\"CSV\", \"JSON\"], key=\"section1_format\")\nst.selectbox(\"Format:\", [\"CSV\", \"JSON\"], key=\"section2_format\")\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#2-use-descriptive-key-naming-convention","title":"2. Use Descriptive Key Naming Convention","text":"<pre><code># Pattern: {section}_{widget_purpose}\nkey=\"template_export_format\"\nkey=\"custom_preview_rows\"\nkey=\"bulk_row_limit\"\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#3-check-for-duplicates-during-development","title":"3. Check for Duplicates During Development","text":"<pre><code># Use this pattern to identify potential duplicates\nwidgets_to_check = [\n    \"selectbox\", \"multiselect\", \"text_input\", \n    \"number_input\", \"checkbox\", \"radio\", \"slider\"\n]\n\n# Add keys proactively when creating similar widgets\n</code></pre>"},{"location":"troubleshooting/streamlit-duplicate-ids/#testing","title":"Testing","text":"<p>After adding keys, verify the fix:</p> <ol> <li>Import Test: Check that the page imports without errors</li> <li>Runtime Test: Navigate through all tabs and interact with widgets</li> <li>State Test: Ensure widget states don't interfere with each other</li> </ol>"},{"location":"troubleshooting/streamlit-duplicate-ids/#related-issues","title":"Related Issues","text":"<p>This pattern can affect any Streamlit widget that appears multiple times with identical parameters: - <code>st.selectbox</code> - <code>st.multiselect</code> - <code>st.text_input</code> - <code>st.number_input</code> - <code>st.checkbox</code> - <code>st.radio</code> - <code>st.slider</code> - <code>st.button</code></p> <p>Always provide unique <code>key</code> parameters when using repeated widgets across different sections of your app.</p>"},{"location":"troubleshooting/streamlit-fragments/","title":"Streamlit Fragments Troubleshooting","text":""},{"location":"troubleshooting/streamlit-fragments/#overview","title":"Overview","text":"<p>This guide covers common issues and solutions when using Streamlit fragments in the landuse application.</p>"},{"location":"troubleshooting/streamlit-fragments/#common-fragment-issues","title":"Common Fragment Issues","text":""},{"location":"troubleshooting/streamlit-fragments/#issue-streamlitapiexception-with-stsidebar","title":"Issue: StreamlitAPIException with st.sidebar","text":"<p>Error Message: <pre><code>StreamlitAPIException: Calling `st.sidebar` in a function wrapped with `st.fragment` is not supported. \nTo write elements to the sidebar with a fragment, call your fragment function inside a with st.sidebar context manager.\n</code></pre></p> <p>Cause: Functions decorated with <code>@st.fragment</code> cannot directly call <code>st.sidebar</code> or access sidebar elements.</p> <p>Solution:</p> <p>\u274c Incorrect (causes error): <pre><code>@st.fragment\ndef handle_user_input():\n    # ... processing logic ...\n\n    # This will cause an error!\n    with st.sidebar:\n        st.caption(f\"Query took {query_time:.1f}s\")\n</code></pre></p> <p>\u2705 Correct (solution 1 - use session state): <pre><code>@st.fragment\ndef handle_user_input():\n    # ... processing logic ...\n\n    # Store data in session state instead\n    st.session_state.last_query_time = query_time\n\ndef main():\n    # Display in sidebar from main function\n    with st.sidebar:\n        if hasattr(st.session_state, 'last_query_time') and st.session_state.last_query_time:\n            st.caption(f\"\u23f1\ufe0f Last query: {st.session_state.last_query_time:.1f}s\")\n</code></pre></p> <p>\u2705 Correct (solution 2 - call fragment inside sidebar): <pre><code>def handle_user_input_fragment():\n    # Fragment logic without sidebar calls\n    pass\n\ndef main():\n    with st.sidebar:\n        handle_user_input_fragment()  # Call fragment inside sidebar context\n</code></pre></p>"},{"location":"troubleshooting/streamlit-fragments/#issue-fragment-functions-must-be-self-contained","title":"Issue: Fragment Functions Must Be Self-Contained","text":"<p>Problem: Fragments should be designed to operate independently without side effects on the rest of the page.</p> <p>Best Practices:</p> <ol> <li> <p>Use session state for communication: <pre><code>@st.fragment\ndef query_processor():\n    if st.button(\"Process\"):\n        result = process_query()\n        st.session_state.query_result = result  # Store for use elsewhere\n</code></pre></p> </li> <li> <p>Keep fragments focused: <pre><code>@st.fragment\ndef chat_input():\n    \"\"\"Only handles chat input, nothing else\"\"\"\n    if prompt := st.chat_input(\"Ask me...\"):\n        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n\n@st.fragment \ndef query_controls():\n    \"\"\"Only handles query control buttons\"\"\"\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"Clear\"):\n            st.session_state.messages = []\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/streamlit-fragments/#fragment-design-patterns","title":"Fragment Design Patterns","text":""},{"location":"troubleshooting/streamlit-fragments/#1-input-isolation-pattern","title":"1. Input Isolation Pattern","text":"<pre><code>@st.fragment\ndef isolated_input():\n    \"\"\"Handles user input without affecting other components\"\"\"\n    user_input = st.text_input(\"Enter query\")\n    if st.button(\"Submit\"):\n        st.session_state.user_query = user_input\n        st.rerun()  # Trigger main page update\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#2-display-fragment-pattern","title":"2. Display Fragment Pattern","text":"<pre><code>@st.fragment\ndef query_results_display():\n    \"\"\"Displays results independently\"\"\"\n    if 'query_results' in st.session_state:\n        st.dataframe(st.session_state.query_results)\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#3-control-panel-pattern","title":"3. Control Panel Pattern","text":"<pre><code>@st.fragment\ndef control_panel():\n    \"\"\"Isolated control buttons\"\"\"\n    col1, col2, col3 = st.columns(3)\n\n    with col1:\n        if st.button(\"Reset\"):\n            st.session_state.clear()\n\n    with col2:\n        if st.button(\"Export\"):\n            st.session_state.export_flag = True\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#performance-benefits","title":"Performance Benefits","text":"<p>Proper use of fragments provides:</p> <ul> <li>Reduced Reruns: Only the fragment reruns on interaction</li> <li>Better UX: Faster response times for user interactions</li> <li>Isolated Updates: Changes don't affect unrelated components</li> <li>Memory Efficiency: Less computation on each interaction</li> </ul>"},{"location":"troubleshooting/streamlit-fragments/#debugging-fragment-issues","title":"Debugging Fragment Issues","text":""},{"location":"troubleshooting/streamlit-fragments/#1-check-fragment-boundaries","title":"1. Check Fragment Boundaries","text":"<pre><code>@st.fragment\ndef debug_fragment():\n    st.write(\"Fragment start\")\n    # Your fragment code here\n    st.write(\"Fragment end\")\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#2-monitor-session-state","title":"2. Monitor Session State","text":"<pre><code>def debug_session_state():\n    with st.expander(\"Debug Session State\"):\n        st.json(dict(st.session_state))\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#3-test-fragment-isolation","title":"3. Test Fragment Isolation","text":"<pre><code>@st.fragment\ndef test_fragment():\n    st.write(f\"Fragment run at: {time.time()}\")\n\n    if st.button(\"Fragment Button\"):\n        st.write(\"Fragment button clicked!\")\n\ndef main():\n    st.write(f\"Main run at: {time.time()}\")\n    test_fragment()\n\n    if st.button(\"Main Button\"):\n        st.write(\"Main button clicked!\")\n</code></pre>"},{"location":"troubleshooting/streamlit-fragments/#migration-checklist","title":"Migration Checklist","text":"<p>When adding fragments to existing code:</p> <ul> <li> Identify isolated UI components</li> <li> Remove sidebar calls from fragments</li> <li> Use session state for data sharing</li> <li> Test fragment isolation</li> <li> Verify performance improvements</li> <li> Update tests to handle fragment behavior</li> </ul>"},{"location":"troubleshooting/streamlit-fragments/#related-documentation","title":"Related Documentation","text":"<ul> <li>Streamlit Fragments Official Docs</li> <li>Performance Optimization Guide</li> <li>Session State Best Practices</li> </ul>"}]}